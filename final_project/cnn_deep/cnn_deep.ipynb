{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import ast\n",
    "sys.path.append(os.path.join(os.getcwd(), '..','..'))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from final_project.cnn.preprocess import generate_cnn_data, split_preprocess_cnn_data, preprocess_cnn_data\n",
    "from final_project.cnn_deep.model import build_train_cnn, full_cnn_pipeline\n",
    "from final_project.cnn.evaluate import gridsearch_analysis\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "\n",
    "\n",
    "from final_project.cnn_deep.config import STANDARD_CAT_FEATURES, STANDARD_NUM_FEATURES, NUM_FEATURES_DICT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Full Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Generating CNN Data for Season: ['2020-21', '2021-22'], Position: GK =======\n",
      "Dropping Players with Avg. Playtime < 1e-06...\n",
      "\n",
      "Total players of type GK = 163.\n",
      "82 players dropped due to low average playtime.\n",
      "Generated windowed dataframe for CNN of shape: (2502, 7).\n",
      "Generated combined features dataframe for preprocessing of shape: (2988, 9).\n",
      "\n",
      "========== EDA ==========\n",
      "========== Done Generating CNN Data ==========\n",
      "\n",
      "========== Splitting CNN Data ==========\n",
      "\n",
      "=== Stratifying Split by : Stdev ===\n",
      "Shape of windowed_df: (2502, 7)\n",
      "Shape of a given window (prior to preprocessing): (6, 9)\n",
      "stdev Distribution of Players:\n",
      "\n",
      "========== Preprocessing CNN Data ==========\n",
      "\n",
      "Mean of Standard Scaler:\n",
      "[1.89197166e+00 4.73813459e+01 0.00000000e+00 1.18063754e-03\n",
      " 1.49940968e-01 9.55312869e+00 2.59740260e-02 1.18063754e-03]\n",
      "\n",
      "Standard Deviation of Standard Scaler:\n",
      "[2.67958644e+00 4.48476343e+01 1.00000000e+00 3.43401171e-02\n",
      " 3.57013549e-01 1.04005585e+01 1.59057776e-01 3.43401171e-02]\n",
      "Transforming features using StandardScaler + OHE Pipeline.\n",
      "========== Done Preprocessing CNN Data ==========\n",
      "\n",
      "========== Done Splitting CNN Data ==========\n",
      "\n",
      "====== Building CNN Architecture ======\n",
      "====== Done Building CNN Architecture ======\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (64x1x1). Calculated output size: (64x1x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(SEED)\n\u001b[0;32m      7\u001b[0m DATA_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mfull_cnn_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                \u001b[49m\u001b[43mseason\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2020-21\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2021-22\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                \u001b[49m\u001b[43mposition\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGK\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnum_filters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnum_dense\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdrop_low_playtime\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlow_playtime_cutoff\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mNUM_FEATURES_DICT\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGK\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlarge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSTANDARD_CAT_FEATURES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstratify_by\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstdev\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconv_activation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdense_activation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.000001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmae\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                \u001b[49m\u001b[43mregularization\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m                \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# only used if early stopping is turned on, threshold to define low val loss decrease\u001b[39;49;00m\n\u001b[0;32m     33\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# num of iterations before early stopping bc of low val loss decrease\u001b[39;49;00m\n\u001b[0;32m     34\u001b[0m \u001b[43m                \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdraw_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstandardize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dean\\Code\\csci-567\\ml-premier-predictor\\final_project\\cnn_deep\\..\\..\\final_project\\cnn_deep\\model.py:399\u001b[0m, in \u001b[0;36mfull_cnn_pipeline\u001b[1;34m(data_dir, season, position, window_size, kernel_size, num_filters, num_dense, batch_size, epochs, drop_low_playtime, low_playtime_cutoff, num_features, cat_features, conv_activation, dense_activation, optimizer, learning_rate, loss, metrics, verbose, regularization, early_stopping, tolerance, patience, plot, draw_model, standardize, test_size, val_size, stratify_by)\u001b[0m\n\u001b[0;32m    383\u001b[0m (X_train, d_train, y_train, \n\u001b[0;32m    384\u001b[0m  X_val, d_val, y_val, \n\u001b[0;32m    385\u001b[0m  X_test, d_test, y_test, pipeline) \u001b[38;5;241m=\u001b[39m generate_datasets(data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    395\u001b[0m                             low_playtime_cutoff\u001b[38;5;241m=\u001b[39mlow_playtime_cutoff,\n\u001b[0;32m    396\u001b[0m                             verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    398\u001b[0m \u001b[38;5;66;03m#call build_train_cnn passing on all params \u001b[39;00m\n\u001b[1;32m--> 399\u001b[0m model, expt_res \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_train_cnn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseason\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseason\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_filters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_filters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_dense\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_dense\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_low_playtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_low_playtime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlow_playtime_cutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_playtime_cutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconv_activation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdense_activation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdense_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregularization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregularization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdraw_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdraw_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstandardize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstandardize\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, expt_res\n",
      "File \u001b[1;32mc:\\Users\\Dean\\Code\\csci-567\\ml-premier-predictor\\final_project\\cnn_deep\\..\\..\\final_project\\cnn_deep\\model.py:286\u001b[0m, in \u001b[0;36mbuild_train_cnn\u001b[1;34m(X_train, d_train, y_train, X_val, d_val, y_val, X_test, d_test, y_test, season, position, window_size, kernel_size, num_filters, num_dense, batch_size, epochs, drop_low_playtime, low_playtime_cutoff, num_features, cat_features, conv_activation, dense_activation, optimizer, learning_rate, loss, metrics, verbose, regularization, early_stopping, tolerance, patience, plot, draw_model, standardize)\u001b[0m\n\u001b[0;32m    284\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    285\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 286\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output, y_batch)\n\u001b[0;32m    288\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Dean\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dean\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dean\\Code\\csci-567\\ml-premier-predictor\\final_project\\cnn_deep\\..\\..\\final_project\\cnn_deep\\model.py:67\u001b[0m, in \u001b[0;36mCNNModel.forward\u001b[1;34m(self, x_input, d_input)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_input, d_input):\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Pass through Conv1D layer\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m#print(f\"x_input size before conv: {x_input.size()}\")\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m#x = self.flatten(x, dim=1)\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvolutional_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_input\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Shape: (batch_size, num_filters, new_length)\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m#print(f\"x size after conv: {x.size()}\")\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# Flatten only the non-batch dimensions\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Shape: (batch_size, flattened_features)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dean\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dean\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dean\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Dean\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dean\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dean\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py:555\u001b[0m, in \u001b[0;36mAvgPool1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mavg_pool1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount_include_pad\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given input size: (64x1x1). Calculated output size: (64x1x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "SEED = 266\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "DATA_DIR = os.path.join(os.getcwd(), '..', 'data', 'clean_data')\n",
    "\n",
    "full_cnn_pipeline(DATA_DIR,\n",
    "                season = ['2020-21', '2021-22'], \n",
    "                position = 'GK', \n",
    "                window_size=10,\n",
    "                kernel_size=3,\n",
    "                num_filters=64,\n",
    "                num_dense=64,\n",
    "                batch_size = 32,\n",
    "                epochs = 2000,  \n",
    "                drop_low_playtime = True,\n",
    "                low_playtime_cutoff = 1e-6,\n",
    "                num_features = NUM_FEATURES_DICT['GK']['large'],\n",
    "                cat_features = STANDARD_CAT_FEATURES, \n",
    "                stratify_by = 'stdev', \n",
    "                conv_activation = 'relu',\n",
    "                dense_activation = 'relu',\n",
    "                optimizer='adam',\n",
    "                learning_rate= 0.000001,  \n",
    "                loss = 'mse',\n",
    "                metrics = ['mae'],\n",
    "                verbose = True,\n",
    "                regularization = 0.01, \n",
    "                early_stopping = True, \n",
    "                tolerance = 1e-5, # only used if early stopping is turned on, threshold to define low val loss decrease\n",
    "                patience = 20,   # num of iterations before early stopping bc of low val loss decrease\n",
    "                plot = True, \n",
    "                draw_model = False,\n",
    "                standardize= True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlpremier.cnn.experiment import gridsearch_cnn\n",
    "\n",
    "#gridsearch_cnn(epochs=100, verbose=False)\n",
    "\n",
    "#PERFORMING VIA COMMAND LINE SCRIPT NOW FOR EFFICIENCY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate GridSearch Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curve, Filter Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def investigate_model(expt_name: str = 'gridsearch', \n",
    "                      drop_low_playtime: bool = True,\n",
    "                      **kwargs):\n",
    "    \"\"\"\n",
    "    Investigate the best model for the given experiment and drop status.\n",
    "\n",
    "    Retrains the model on the same exact data split (to avoid data leakage), and\n",
    "    generates learning curves.\n",
    "    \"\"\"\n",
    "    season =  \"['2020-21', '2021-22']\"\n",
    "    best_params = gridsearch_analysis(expt_name, \n",
    "                        season=season, \n",
    "                        eval_top=1,\n",
    "                        drop_low_playtime=drop_low_playtime,\n",
    "                        **kwargs)\n",
    "    \n",
    "    POSITIONS = ['GK', 'DEF', 'MID', 'FWD']\n",
    "    best_models = {}\n",
    "    for position in POSITIONS: \n",
    "\n",
    "        print(f\"\\n======= Retraining and Filter Analysis for {position} model: =======\\n\")\n",
    "        # Clean up and consolidate parameters in the 'params' dictionary\n",
    "        params = best_params.loc[position, :].to_dict()\n",
    "\n",
    "        serialized_dataset = params.pop('dataset')\n",
    "        dataset = pickle.loads(ast.literal_eval(serialized_dataset))\n",
    "\n",
    "        # Retrieve individual datasets\n",
    "        X_train = dataset['X_train']\n",
    "        d_train = dataset['d_train']\n",
    "        y_train = dataset['y_train']\n",
    "        X_val = dataset['X_val']\n",
    "        d_val = dataset['d_val']\n",
    "        y_val = dataset['y_val']\n",
    "        X_test = dataset['X_test']\n",
    "        d_test = dataset['d_test']\n",
    "        y_test = dataset['y_test']\n",
    "\n",
    "        serialized_pipeline = params.pop('pipeline')\n",
    "        pipeline = pickle.loads(ast.literal_eval(serialized_pipeline))\n",
    "\n",
    "        params['season'] = ['2020-21', '2021-22']\n",
    "        params['metrics'] = ['mae']\n",
    "        params['num_features'] = NUM_FEATURES_DICT[params['position']][params.pop('amt_num_features')]\n",
    "        params.pop('stratify_by')  #don't need this, we have the pickled split data \n",
    "\n",
    "        # Add the datasets to params\n",
    "        params.update({\n",
    "            'X_train': X_train,\n",
    "            'd_train': d_train,\n",
    "            'y_train': y_train,\n",
    "            'X_val': X_val,\n",
    "            'd_val': d_val,\n",
    "            'y_val': y_val,\n",
    "            'X_test': X_test,\n",
    "            'd_test': d_test,\n",
    "            'y_test': y_test,\n",
    "            'plot': True,\n",
    "        })\n",
    "\n",
    "        # =========== Qualitative Analysis of Best & Worst Ex =============\n",
    "\n",
    "        print(f\"X_train shape: {X_train.shape}\")\n",
    "        print(f\"X_val shape: {X_val.shape}\")\n",
    "        print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "        model, expt_res = build_train_cnn(**params)\n",
    "        best_models[position] = model\n",
    "\n",
    "        y_pred = model.predict([X_test, d_test])\n",
    "        y_test_flattened = y_test.flatten()\n",
    "        y_pred_flattened = y_pred.flatten()\n",
    "        mse_per_example = np.square(y_test_flattened - y_pred_flattened)\n",
    "\n",
    "        results_df = pd.DataFrame({'Actual Score': y_test_flattened, 'Predicted Score': y_pred_flattened, 'MSE': mse_per_example})\n",
    "        results_df['d_test'] = d_test\n",
    "\n",
    "        # Add X_test features to the DataFrame\n",
    "        # unstandardize the features\n",
    "        X_test_original = X_test.copy()\n",
    "\n",
    "        # Calculate unstandardized pts\n",
    "        numerical_transformer = pipeline.named_steps['preprocessor'].named_transformers_['num']\n",
    "        X_test_reshaped = X_test_original.reshape(-1, X_test_original.shape[-1])\n",
    "        X_test_unstandardized = numerical_transformer.inverse_transform(X_test_reshaped).astype(int)\n",
    "        X_test_unstandardized = X_test_unstandardized.reshape(X_test_original.shape)\n",
    "        X_test_unstandardized_2d = X_test_unstandardized.reshape(X_test_unstandardized.shape[0], -1)\n",
    "        column_names = [f'pts_week{i}' for i in range(X_test_unstandardized_2d.shape[1])]\n",
    "        unstandardized_df = pd.DataFrame(X_test_unstandardized_2d, columns=column_names)\n",
    "\n",
    "        results_df = pd.concat([results_df, unstandardized_df], axis=1)\n",
    "\n",
    "        results_df.sort_values(by='MSE', ascending=False, inplace=True)\n",
    "\n",
    "        print(f\"\\nWorst two examples for {position}:\\n\")\n",
    "        display(results_df.head(2))\n",
    "\n",
    "        print(f\"\\nBest two examples for {position}:\\n\")\n",
    "        display(results_df.tail(2))\n",
    "\n",
    "\n",
    "        for layer in model.layers:\n",
    "            if 'conv' not in layer.name:\n",
    "                continue\n",
    "            filters, biases = layer.get_weights()\n",
    "\n",
    "        # retrieve filter weights from the second hidden layer\n",
    "        filters, biases = model.layers[1].get_weights()\n",
    "\n",
    "        # normalize filter values by z-score normalization\n",
    "        mean_value, std_dev = filters.mean(), filters.std()\n",
    "        normalized_filters = (filters - mean_value) / std_dev\n",
    "        mean_filter = normalized_filters.mean(axis=-1)\n",
    "\n",
    "        # set greyscale color map\n",
    "        cmap = plt.cm.Greys_r\n",
    "        cmap.set_bad('0.5')  # Set the color for NaN values (if any) to medium-grey\n",
    "\n",
    "        # plot the normalized average filter with numeric values inside pixels\n",
    "        fig, ax = plt.subplots()\n",
    "        img = ax.imshow(mean_filter, cmap=cmap, vmin=-1, vmax=1)\n",
    "\n",
    "        # add text annotations with normalized values inside each pixel\n",
    "        for i, value in enumerate(mean_filter):\n",
    "            value = value[0]\n",
    "            # set text color based on brightness\n",
    "            text_color = 'white' if value < 0 else 'black'\n",
    "            ax.text(0, i, f\"{value:.4f}\", ha='center', va='center', fontsize=8, color=text_color)\n",
    "        ax.set_title(f\"Averaged 1D Convolution Filter (Normalized) â€” {position}\")\n",
    "        ax.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return best_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V12 (overfits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_models = investigate_model('gridsearch_v12', drop_low_playtime=True, stratify_by='stdev')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V11 (stratified by stdev score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with drop benched players\n",
    "#best_models = investigate_model('gridsearch_v11', drop_low_playtime=True, stratify_by='stdev')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy Model (Full Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easier model\n",
    "#best_models = investigate_model('gridsearch_v11', drop_low_playtime=False, stratify_by='stdev')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worse Stability with 'Skill' instead of 'stdev'? \n",
    "### Ans: No Significant Diff. -> Skill the better stratification for performance based on top 1 and top 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_analysis('gridsearch_v11', drop_low_playtime=True, stratify_by='skill', eval_top=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n ========= Interesting Model (DROP BENCHWARMERS) ==========\")\n",
    "best_models = investigate_model('gridsearch_v11', drop_low_playtime=True, stratify_by='skill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"\\n ========= Easier Model (FULL DATA) ==========\")\n",
    "#best_models = investigate_model('gridsearch_v11', drop_low_playtime=False, stratify_by='skill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 1 and Top 5 Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_analysis('gridsearch_v11', \n",
    "                    stratify_by='skill', \n",
    "                    eval_top=2, \n",
    "                    drop_low_playtime = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def investigate_model_v0(expt_name: str = 'gridsearch', \n",
    "                      drop_low_playtime: bool = True,\n",
    "                      **kwargs):\n",
    "    \"\"\"\n",
    "    Investigate the best model for the given experiment and drop status.\n",
    "\n",
    "    Retrains the model on the same exact data split (to avoid data leakage), and\n",
    "    generates learning curves.\n",
    "    \"\"\"\n",
    "    season =  \"['2020-21', '2021-22']\"\n",
    "    best_params = gridsearch_analysis(expt_name, \n",
    "                        season=season, \n",
    "                        eval_top=1,\n",
    "                        drop_low_playtime=drop_low_playtime,\n",
    "                        **kwargs)\n",
    "    \n",
    "    POSITIONS = ['GK', 'DEF', 'MID', 'FWD']\n",
    "    best_models = {}\n",
    "    for position in POSITIONS: \n",
    "\n",
    "        print(f\"\\n======= Retraining and Filter Analysis for {position} model: =======\\n\")\n",
    "        # Clean up and consolidate parameters in the 'params' dictionary\n",
    "        params = best_params.loc[position, :].to_dict()\n",
    "\n",
    "        serialized_dataset = params.pop('dataset')\n",
    "        dataset = pickle.loads(ast.literal_eval(serialized_dataset))\n",
    "\n",
    "        # Retrieve individual datasets\n",
    "        X_train = dataset['X_train']\n",
    "        d_train = dataset['d_train']\n",
    "        y_train = dataset['y_train']\n",
    "        X_val = dataset['X_val']\n",
    "        d_val = dataset['d_val']\n",
    "        y_val = dataset['y_val']\n",
    "        X_test = dataset['X_test']\n",
    "        d_test = dataset['d_test']\n",
    "        y_test = dataset['y_test']\n",
    "\n",
    "        serialized_pipeline = params.pop('pipeline')\n",
    "        pipeline = pickle.loads(ast.literal_eval(serialized_pipeline))\n",
    "\n",
    "        params['season'] = ['2020-21', '2021-22']\n",
    "        params['metrics'] = ['mae']\n",
    "        params['num_features'] = NUM_FEATURES_DICT[params['position']][params.pop('amt_num_features')]\n",
    "\n",
    "        # Add the datasets to params\n",
    "        params.update({\n",
    "            'X_train': X_train,\n",
    "            'd_train': d_train,\n",
    "            'y_train': y_train,\n",
    "            'X_val': X_val,\n",
    "            'd_val': d_val,\n",
    "            'y_val': y_val,\n",
    "            'X_test': X_test,\n",
    "            'd_test': d_test,\n",
    "            'y_test': y_test,\n",
    "            'plot': True,\n",
    "        })\n",
    "\n",
    "        # =========== Qualitative Analysis of Best & Worst Ex =============\n",
    "\n",
    "        print(f\"X_train shape: {X_train.shape}\")\n",
    "        print(f\"X_val shape: {X_val.shape}\")\n",
    "        print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "        model, expt_res = build_train_cnn(**params)\n",
    "        best_models[position] = model\n",
    "\n",
    "        y_pred = model.predict([X_test, d_test])\n",
    "        y_test_flattened = y_test.flatten()\n",
    "        y_pred_flattened = y_pred.flatten()\n",
    "        mse_per_example = np.square(y_test_flattened - y_pred_flattened)\n",
    "\n",
    "        results_df = pd.DataFrame({'Actual Score': y_test_flattened, 'Predicted Score': y_pred_flattened, 'MSE': mse_per_example})\n",
    "        results_df['d_test'] = d_test\n",
    "\n",
    "        # Add X_test features to the DataFrame\n",
    "        # unstandardize the features\n",
    "        X_test_original = X_test.copy()\n",
    "\n",
    "        # Calculate unstandardized pts\n",
    "        numerical_transformer = pipeline.named_steps['preprocessor'].named_transformers_['num']\n",
    "        X_test_reshaped = X_test_original.reshape(-1, X_test_original.shape[-1])\n",
    "        X_test_unstandardized = numerical_transformer.inverse_transform(X_test_reshaped).astype(int)\n",
    "        X_test_unstandardized = X_test_unstandardized.reshape(X_test_original.shape)\n",
    "        X_test_unstandardized_2d = X_test_unstandardized.reshape(X_test_unstandardized.shape[0], -1)\n",
    "        column_names = [f'pts_week{i}' for i in range(X_test_unstandardized.shape[1])]\n",
    "        unstandardized_df = pd.DataFrame(X_test_unstandardized_2d, columns=column_names)\n",
    "\n",
    "        results_df = pd.concat([results_df, unstandardized_df], axis=1)\n",
    "\n",
    "        results_df.sort_values(by='MSE', ascending=False, inplace=True)\n",
    "\n",
    "        print(f\"\\nWorst two examples for {position}:\\n\")\n",
    "        display(results_df.head(2))\n",
    "\n",
    "        print(f\"\\nBest two examples for {position}:\\n\")\n",
    "        display(results_df.tail(2))\n",
    "\n",
    "\n",
    "        for layer in model.layers:\n",
    "            if 'conv' not in layer.name:\n",
    "                continue\n",
    "            filters, biases = layer.get_weights()\n",
    "\n",
    "        # retrieve filter weights from the second hidden layer\n",
    "        filters, biases = model.layers[1].get_weights()\n",
    "\n",
    "        # normalize filter values by z-score normalization\n",
    "        mean_value, std_dev = filters.mean(), filters.std()\n",
    "        normalized_filters = (filters - mean_value) / std_dev\n",
    "        mean_filter = normalized_filters.mean(axis=-1)\n",
    "\n",
    "        # set greyscale color map\n",
    "        cmap = plt.cm.Greys_r\n",
    "        cmap.set_bad('0.5')  # Set the color for NaN values (if any) to medium-grey\n",
    "\n",
    "        # plot the normalized average filter with numeric values inside pixels\n",
    "        fig, ax = plt.subplots()\n",
    "        img = ax.imshow(mean_filter, cmap=cmap, vmin=-1, vmax=1)\n",
    "\n",
    "        # add text annotations with normalized values inside each pixel\n",
    "        for i, value in enumerate(mean_filter):\n",
    "            value = value[0]\n",
    "            # set text color based on brightness\n",
    "            text_color = 'white' if value < 0 else 'black'\n",
    "            ax.text(0, i, f\"{value:.4f}\", ha='center', va='center', fontsize=8, color=text_color)\n",
    "        ax.set_title(\"Averaged 1D Convolution Filter (Normalized)\")\n",
    "        ax.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easier model\n",
    "#best_models = investigate_model_v0('gridsearch_v10', drop_low_playtime=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DROP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with drop benched players\n",
    "#best_models = investigate_model_v0('gridsearch_v10', drop_low_playtime=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_models = investigate_model_v0('gridsearch_v9', drop_low_playtime=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with player dropping\n",
    "\"\"\"\n",
    "best_params = gridsearch_analysis('gridsearch_v8', \n",
    "                    season=\"['2020-21', '2021-22']\", \n",
    "                    eval_top=1,\n",
    "                    drop_low_playtime = True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with player dropping\n",
    "\"\"\"\n",
    "best_hyperparams = gridsearch_analysis('gridsearch_v8', \n",
    "                    season=\"['2020-21', '2021-22']\", \n",
    "                    eval_top=1,\n",
    "                    drop_low_playtime = False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with player dropping\n",
    "\"\"\"\n",
    "gridsearch_analysis('gridsearch_v7', \n",
    "                    season=\"['2020-21', '2021-22']\", \n",
    "                    eval_top=1,\n",
    "                    drop_low_playtime = True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without player dropping\n",
    "\"\"\"\n",
    "gridsearch_analysis('gridsearch_v7', \n",
    "                    season=\"['2020-21', '2021-22']\", \n",
    "                    eval_top=1,\n",
    "                    drop_low_playtime = False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V6  With Player Dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "gridsearch_analysis('gridsearch_v6', \n",
    "                    season=\"['2020-21', '2021-22']\", \n",
    "                    eval_top=5,\n",
    "                    drop_low_playtime = True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V6 Best Models Without Player Dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"gridsearch_analysis('gridsearch_v6', \n",
    "                    season=\"['2020-21', '2021-22']\", \n",
    "                    eval_top=1,\n",
    "                    num_dense=64,\n",
    "                    num_filters=64,\n",
    "                    amt_num_features = 'ptsonly',\n",
    "                    drop_low_playtime = True)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"gridsearch_analysis('_gridsearch_v4', \n",
    "                    season=\"['2020-21', '2021-22']\", \n",
    "                    eval_top=1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"gridsearch_analysis('gridsearch_v4_singleyear_drop', \n",
    "                    season='2020-21',\n",
    "                    eval_top=1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"gridsearch_analysis('gridsearch_v4_singleyear_drop', \n",
    "                    season='2021-22',\n",
    "                    eval_top=1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"gridsearch_analysis('gridsearch_v5', eval_top=3)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"best_hyperparams = gridsearch_analysis('gridsearch_v4_optimal_drop', \n",
    "                    eval_top=1)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
