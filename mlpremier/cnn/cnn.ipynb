{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path_to_data_folder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/danielfrees/Desktop/mlpremier/mlpremier/cnn/cnn.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielfrees/Desktop/mlpremier/mlpremier/cnn/cnn.ipynb#W0sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m window_size \u001b[39m=\u001b[39m \u001b[39m6\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielfrees/Desktop/mlpremier/mlpremier/cnn/cnn.ipynb#W0sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m# Load and preprocess the data\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danielfrees/Desktop/mlpremier/mlpremier/cnn/cnn.ipynb#W0sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m df \u001b[39m=\u001b[39m load_and_preprocess_data(data_folder, window_size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielfrees/Desktop/mlpremier/mlpremier/cnn/cnn.ipynb#W0sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39m# Define numerical and categorical features\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielfrees/Desktop/mlpremier/mlpremier/cnn/cnn.ipynb#W0sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m numerical_features \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mgoals\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39massists\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mother_numerical_features\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;32m/Users/danielfrees/Desktop/mlpremier/mlpremier/cnn/cnn.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielfrees/Desktop/mlpremier/mlpremier/cnn/cnn.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m all_data \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielfrees/Desktop/mlpremier/mlpremier/cnn/cnn.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Iterate through files in the data folder\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danielfrees/Desktop/mlpremier/mlpremier/cnn/cnn.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(data_folder):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielfrees/Desktop/mlpremier/mlpremier/cnn/cnn.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mif\u001b[39;00m filename\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danielfrees/Desktop/mlpremier/mlpremier/cnn/cnn.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         player_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_folder, filename))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_data_folder'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def load_and_preprocess_data(data_folder, window_size):\n",
    "    all_data = []\n",
    "\n",
    "    # Iterate through files in the data folder\n",
    "    for filename in os.listdir(data_folder):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            player_data = pd.read_csv(os.path.join(data_folder, filename))\n",
    "\n",
    "            # Check if the player has a valid position (GKP, DEF, MID, FWD)\n",
    "            if player_data['position'].iloc[0] in ['GKP', 'DEF', 'MID', 'FWD']:\n",
    "                features = player_data.iloc[:, 1:-1]\n",
    "                targets = player_data.iloc[:, -1].values\n",
    "\n",
    "                # Create training samples using the specified window size\n",
    "                X, y, player_names = [], [], []\n",
    "                for i in range(len(player_data) - window_size):\n",
    "                    X.append(features.iloc[i:i + window_size])\n",
    "                    y.append(targets[i + window_size])\n",
    "                    player_names.append(player_data['player_name'].iloc[i + window_size])\n",
    "\n",
    "                all_data.extend(list(zip(player_names, X, y)))\n",
    "\n",
    "    # Convert the list of tuples to a DataFrame\n",
    "    df = pd.DataFrame(all_data, columns=['player_name', 'features', 'target'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def split_data(df):\n",
    "    # Split data into 70% train and 30% test (by player)\n",
    "    players = df['player_name'].unique()\n",
    "    players_train, players_test = train_test_split(players, test_size=0.3, shuffle=False)\n",
    "\n",
    "    # Further split 10% of training data for validation\n",
    "    players_train, players_val = train_test_split(players_train, test_size=0.1, shuffle=False)\n",
    "\n",
    "    # Filter data for train, validation, and test sets\n",
    "    train_data = df[df['player_name'].isin(players_train)]\n",
    "    val_data = df[df['player_name'].isin(players_val)]\n",
    "    test_data = df[df['player_name'].isin(players_test)]\n",
    "\n",
    "    # Drop player name from features\n",
    "    X_train = np.array(train_data['features'].tolist())\n",
    "    X_val = np.array(val_data['features'].tolist())\n",
    "    X_test = np.array(test_data['features'].tolist())\n",
    "\n",
    "    y_train = np.array(train_data['target'])\n",
    "    y_val = np.array(val_data['target'])\n",
    "    y_test = np.array(test_data['target'])\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# Assume 'path_to_data_folder' is the path to the folder containing all player CSV files\n",
    "data_folder = 'path_to_data_folder'  # Change this to the actual path\n",
    "window_size = 6\n",
    "\n",
    "# Load and preprocess the data\n",
    "df = load_and_preprocess_data(data_folder, window_size)\n",
    "\n",
    "# Define numerical and categorical features\n",
    "numerical_features = ['goals', 'assists', 'other_numerical_features']\n",
    "categorical_features = ['position']  # Assuming 'position' is the categorical feature\n",
    "\n",
    "# Create transformers for numerical and categorical features\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder()\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline to apply the transformations\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# Apply the transformations to the features\n",
    "df['features'] = pipeline.fit_transform(df['features'])\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(df)\n",
    "\n",
    "# Print the shapes of the resulting arrays\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tflow3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
