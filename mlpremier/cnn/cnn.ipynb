{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '..','..'))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlpremier.cnn.preprocess import generate_cnn_data, split_preprocess_cnn_data\n",
    "from mlpremier.cnn.model import build_train_cnn\n",
    "from mlpremier.cnn.evaluate import gridsearch_analysis\n",
    "import tensorflow as tf\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Full Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Generating CNN Data for Season: ['2020-21', '2021-22'], Position: DEF =======\n",
      "Dropping Players with Avg. Playtime < 15...\n",
      "\n",
      "Total players of type DEF = 490.\n",
      "202 players dropped due to low average playtime.\n",
      "Generated windowed dataframe for CNN of shape: (9878, 5).\n",
      "Generated combined features dataframe for preprocessing of shape: (10742, 5).\n",
      "\n",
      "========== EDA ==========\n",
      "Selected Statistics:\n",
      "      total_points  clean_sheets  saves        bps\n",
      "mean      1.899088      0.165425    0.0   9.867529\n",
      "min      -7.000000      0.000000    0.0 -11.000000\n",
      "max      21.000000      1.000000    0.0  63.000000\n",
      "std       2.891525      0.371581    0.0  10.450109\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Done Generating CNN Data ==========\n",
      "\n",
      "========== Splitting CNN Data ==========\n",
      "\n",
      "Shape of windowed_df: (9878, 5)\n",
      "Shape of a given window (prior to preprocessing): (3, 5)\n",
      "Skill Distribution of Players:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS8AAAERCAYAAAAqriEFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABSPElEQVR4nO3dd3gUVdvA4d9sTdtN75BGCIQSegcDiFRRsSEWiiLiK0pRBLFR1Bc/USm2V1SwIBYUREQRBVSQEkBAKSGUJEBCEtI3bbO78/0RCQQSSNlks9lzX1cu2NmZM88kmydnzpwiybIsIwiCYGcUtg5AEAShNkTyEgTBLonkJQiCXRLJSxAEuySSlyAIdkkkL0EQ7JJIXoIg2CWRvARBsEsieQmCYJdE8qqDuXPnIklSg5yrf//+9O/fv/z1tm3bkCSJNWvWNMj5x48fT1hYWIOcq7YMBgMTJ04kICAASZKYNm1ancu8+DO+cOHCNfer7PsjSRJz584tf71y5UokSSIxMbHOcQkieZW7+MG6+OXk5ERQUBBDhgxh6dKl5OfnW+U8KSkpzJ07lwMHDlilPGtqzLFVxyuvvMLKlSt59NFH+fTTT3nggQeq3NdoNLJkyRI6deqEXq/Hw8ODtm3bMmnSJI4dO9aAUQu1pbJ1AI3N/PnzCQ8Pp7S0lPPnz7Nt2zamTZvGG2+8wfr164mJiSnf97nnnmP27Nk1Kj8lJYV58+YRFhZGx44dq33czz//XKPz1Ma1Ylu+fDkWi6XeY6iLLVu20LNnT1588cXr7nvHHXfw448/MmbMGB5++GFKS0s5duwYGzZsoHfv3rRu3bpG57aH709TI5LXFYYNG0bXrl3LXz/zzDNs2bKFm2++mVtuuYWjR4/i7OwMgEqlQqWq329hYWEhLi4uaDSaej3P9ajVapuevzrS09Np06bNdfeLi4tjw4YNvPzyy8yZM6fCe2+99RY5OTk1Prc9fH+aGnHbWA0DBw7k+eefJykpic8++6x8e2VtXps3b6Zv3754eHjg5uZGq1atyn9Btm3bRrdu3QCYMGFC+S3qypUrgbJ2rXbt2rFv3z5uuOEGXFxcyo+9ss3rIrPZzJw5cwgICMDV1ZVbbrmFM2fOVNgnLCyM8ePHX3Xs5WVeL7bK2nQKCgp48sknad68OVqtllatWrFo0SKunKhEkiSmTJnCunXraNeuHVqtlrZt2/LTTz9V/g2/Qnp6Og899BD+/v44OTnRoUMHPv744/L3L7b/nT59mh9++KE89qralk6ePAlAnz59rnpPqVTi7e19zXiSkpKIjIykXbt2pKWlAbVvE9y7dy9DhgzBx8cHZ2dnwsPDefDBB2tcjiMSNa9qeuCBB5gzZw4///wzDz/8cKX7HD58mJtvvpmYmBjmz5+PVqvlxIkT7NixA4Do6Gjmz5/PCy+8wKRJk+jXrx8AvXv3Li8jMzOTYcOGcc8993D//ffj7+9/zbhefvllJEli1qxZpKens3jxYgYNGsSBAwfKa4jVUZ3YLifLMrfccgtbt27loYceomPHjmzatImZM2dy7tw53nzzzQr7b9++nW+//Zb//Oc/6HQ6li5dyh133EFycvI1k0VRURH9+/fnxIkTTJkyhfDwcL7++mvGjx9PTk4OU6dOJTo6mk8//ZTp06fTrFkznnzySQB8fX0rLTM0NBSAVatW0adPnxrVnk+ePMnAgQPx8vJi8+bN+Pj4VPvYK6WnpzN48GB8fX2ZPXs2Hh4eJCYm8u2339a6TIciC7Isy/KKFStkQI6Li6tyH3d3d7lTp07lr1988UX58m/hm2++KQNyRkZGlWXExcXJgLxixYqr3ouNjZUB+b333qv0vdjY2PLXW7dulQE5ODhYzsvLK9/+1VdfyYC8ZMmS8m2hoaHyuHHjrlvmtWIbN26cHBoaWv563bp1MiC/9NJLFfa78847ZUmS5BMnTpRvA2SNRlNh28GDB2VAXrZs2VXnutzixYtlQP7ss8/KtxmNRrlXr16ym5tbhWsPDQ2VR4wYcc3yZFmWLRZL+ffa399fHjNmjPz222/LSUlJV+178WeckZEhHz16VA4KCpK7desmZ2VlVdjvyu/Pxet+8cUXy19f/IydPn1almVZXrt27XU/c0LVxG1jDbi5uV3zqaOHhwcA3333Xa0bb7VaLRMmTKj2/mPHjkWn05W/vvPOOwkMDGTjxo21On91bdy4EaVSyRNPPFFh+5NPPoksy/z4448Vtg8aNIgWLVqUv46JiUGv13Pq1KnrnicgIIAxY8aUb1Or1TzxxBMYDAZ+++23GscuSRKbNm3ipZdewtPTk9WrV/PYY48RGhrK6NGjK23z+ueff4iNjSUsLIxffvkFT0/PGp/3Shc/Lxs2bKC0tLTO5TkakbxqwGAwVEgUVxo9ejR9+vRh4sSJ+Pv7c8899/DVV1/VKJEFBwfXqHG+ZcuWFV5LkkRkZGS99yVKSkoiKCjoqu9HdHR0+fuXCwkJuaoMT09PsrOzr3ueli1bolBU/KhWdZ7q0mq1PPvssxw9epSUlBRWr15Nz549+eqrr5gyZcpV+48cORKdTsemTZvQ6/W1OueVYmNjueOOO5g3bx4+Pj7ceuutrFixgpKSEquU39SJ5FVNZ8+eJTc3l8jIyCr3cXZ25vfff+eXX37hgQce4NChQ4wePZqbbroJs9lcrfPUpJ2quqrqSFvdmKxBqVRWul1uBLOQBwYGcs899/D777/TsmVLvvrqK0wmU4V97rjjDk6ePMmqVausdt6LnYx37tzJlClTOHfuHA8++CBdunTBYDBY7TxNlUhe1fTpp58CMGTIkGvup1AouPHGG3njjTc4cuQIL7/8Mlu2bGHr1q1A1YmkthISEiq8lmWZEydOVHjy5enpWemt0JW1lprEFhoaSkpKylW30Rc7eF5sFK+r0NBQEhISrqq9Wvs8UHY7GhMTQ2lp6VU96l977TUeeugh/vOf//D5559b7ZwAPXv25OWXX2bv3r2sWrWKw4cP88UXX1j1HE2RSF7VsGXLFhYsWEB4eDj33XdflftlZWVdte1iZ8+LtwKurq4AtepLVJlPPvmkQgJZs2YNqampDBs2rHxbixYt2LVrF0ajsXzbhg0brupSUZPYhg8fjtls5q233qqw/c0330SSpArnr4vhw4dz/vx5vvzyy/JtJpOJZcuW4ebmRmxsbI3LTEhIIDk5+artOTk57Ny5E09Pz6ueVEqSxPvvv8+dd97JuHHjWL9+fc0v5grZ2dlX1Tyv/LwIVRNdJa7w448/cuzYMUwmE2lpaWzZsoXNmzcTGhrK+vXrcXJyqvLY+fPn8/vvvzNixAhCQ0NJT0/nnXfeoVmzZvTt2xcoSyQeHh6899576HQ6XF1d6dGjB+Hh4bWK18vLi759+zJhwgTS0tJYvHgxkZGRFbpzTJw4kTVr1jB06FDuvvtuTp48yWeffVahAb2msY0cOZIBAwbw7LPPkpiYSIcOHfj555/57rvvmDZt2lVl19akSZP43//+x/jx49m3bx9hYWGsWbOGHTt2sHjx4mu2QVbl4MGD3HvvvQwbNox+/frh5eXFuXPn+Pjjj0lJSWHx4sWV3uYqFAo+++wzbrvtNu6++242btzIwIEDa31tH3/8Me+88w6jRo2iRYsW5Ofns3z5cvR6PcOHD691uQ7Dtg87G4+Lj7Evfmk0GjkgIEC+6aab5CVLllR4JH/RlV0lfv31V/nWW2+Vg4KCZI1GIwcFBcljxoyRjx8/XuG47777Tm7Tpo2sUqkqdE2IjY2V27ZtW2l8VXWVWL16tfzMM8/Ifn5+srOzszxixIhKH/m//vrrcnBwsKzVauU+ffrIe/fuvarMa8VWWVeA/Px8efr06XJQUJCsVqvlli1byq+99ppssVgq7AfIjz322FUxVdWF40ppaWnyhAkTZB8fH1mj0cjt27evtDtHdbtKpKWlyQsXLpRjY2PlwMBAWaVSyZ6envLAgQPlNWvWVNj38q4SFxUWFsqxsbGym5ubvGvXLlmWa9dVYv/+/fKYMWPkkJAQWavVyn5+fvLNN98s792797rXIMiyJMuNoMVUEAShhkSblyAIdkkkL0EQ7JJIXoIg2CWRvARBsEsieQmCYJdE8hIEwS6J5CUIgl0SyUsQBLskkpcgCHZJJC9BEOySSF6CINglkbwEQbBLInkJgmCXRPISBMEuieQlCIJdEslLEAS7JJKXIAh2SSQvQRDskkhegiDYJZG8BEGwSyJ5CYJgl0TyamS2bduGJEnXXPh15cqVeHh4NFhMgtAYieTVyPTu3ZvU1FTc3d1tHYogNGpixexGRqPREBAQYOswBKHREzWveta/f38ef/xxpk2bhqenJ/7+/ixfvpyCggImTJiATqcjMjKSH3/8Eaj8tnHlypWEhITg4uLCqFGjyMzMtNHVCELjIZJXA/j444/x8fFhz549PP744zz66KPcdddd9O7dm/379zN48GAeeOABCgsLrzp29+7dPPTQQ0yZMoUDBw4wYMAAXnrpJRtchSA0LpIsy7Ktg2jK+vfvj9ls5o8//gDAbDbj7u7O7bffzieffALA+fPnCQwMZOfOnRQXFzNgwACys7Px8PDg3nvvJTc3lx9++KG8zHvuuYeffvrpmo36gtDUiZpXA4iJiSn/v1KpxNvbm/bt25dv8/f3ByA9Pf2qY48ePUqPHj0qbOvVq1c9RSoI9kMkrwagVqsrvJYkqcI2SZIAsFgsDRqXINgzkbwauejoaHbv3l1h265du2wUjSA0HqKrRCP3xBNP0KdPHxYtWsStt97Kpk2b+Omnnxrs/HnGPM7lnyPFkMI5wzlSC1LJN+ZTaCqksLSwwr9FpiIkJDRKDVqlFo1SU/alKHvtrnXH39Uff5dLX34ufvi6+KKQxN9RoWZE8mrkevbsyfLly3nxxRd54YUXGDRoEM899xwLFiyw6nlyS3I5fOEw/2T+w9HMo5zJP0OKIYX80nyrnqcySklJc11zojyjaOXVitZerWnl2Qp/V/96P7dgv8TTRgdkspj4+8LfHMo4xD8X/uFw5mHO5J+xdVhX8XLyIsozivY+7eke2J1Ofp3QKrW2DktoJETychAZhRlsP7edP879wa6UXQ1So7I2jULDsOCJBCluIjbKl7ZBYgiVIxPJqwk7mHGQ3878xh/n/iA+Kx4Z+/9RR1qm8ld8IAB+Oi03RvtzW8cguod7lT+1FRyDSF5NTFJeEt+f/J4fTv3AWcNZW4djVWqFmuITcyksUV71XrCHM7d2DOL2zsFE+ulsEJ3Q0ETyagIKSwvZlLiJbxO+5UDGAVuHU2+i3Duwb9eY6+7XNkjPqE7B3NoxGF+daCNrqkTysmPnDOf4+PDHfH/yewylBluHU+86uY3h97gO1d5fo1RwS8cgJt0QQZS/qI01NSJ52aHj2cf58O8P+TnxZ0yyydbhNJigwlnEJ3nW+DhJgtgoXybdEEHvFj71EJlgCyJ52ZG95/fy4T8fsv3cdluH0uB0aj3n/56NRa5bZ9b2we48fEMEI9oHolSIBn57JpKXHdiftp/F+xfzV/pftg7FZtp79OXPnTdbrbwIH1dmD2vN4LZi4kd7JZJXI3Y2/yxv7HuDzUmbbR2KzbV3eog//2pp9XJ7Rnjx7PA2tG8m+ozZG5G8GiGD0cD7f7/PqiOrMFqMtg6nUdBfeIFzGS71UrYkwaiOwcwc2opAd+d6OYdgfSJ5NSIW2cKa42t4+8DbZBVn2TqcRiPAJZiEfY/X+3mc1Aom9o1gysBInNRX9yUTGheRvBqJxNxEntvxHAczDto6lEano8dQ/tjZv8HOF+Hjymt3xdAl1KvBzinUnJiHxMYssoVPDn/CXd/fJRJXFYrzWjTo+U5dKOCu93by8g9HKC41N+i5heoTNS8bOpN3hud2PMf+9P22DqXRUkgK5KR55BWor79zPYjwdWXRXR3oHFLz/mVC/RLJy0ZWH1vNm/vepMhUZOtQGrUIXTQH94yzaQxKhcTEvuHMGByFViXawhoLMRlhAysoLeC57c/xS/Ivtg7FLrhLbWwdAmaLzP9+P8Wu01m8d39n8USykRBtXg3odO5p7v3hXpG4aiD7QpitQyh38EwOI5dtZ9cpsehvYyCSVwPZkryFe3+4l1O5p2wdit1wVjkTn+ht6zAquGAwcv8Hu/lw+2lbh+LwRPKqZxbZwtL9S5m2dZpDzPxgTeFu7TGaG99H1GSRWbDhCNO++Es8jbQh0eZVj4pNxcz8bSbbzm6zdSh2SW1sbesQrmndgRSOpxn4aHw3AtydbB2Ow2l8f9aaiHxjPo9sfkQkrjpISW1u6xCu60hqHne+9ydJmQW2DsXhiORVDy4UXWDCTxNE/6068Hby4VSKfUwgeDa7iDvf20n8eesuatK/f3+mTZtm1TK3bduGJEnk5ORYtVxbEMnLys4ZzjHux3HEZ8fbOhS71syp+jOmNgYZ+SWMfn8nfyVn2zoUhyGSlxWdyD7B2I1jSc5PtnUods9UEGnrEGosp7CU+z/YzY4TF2wdikMQyctKTmSfYMKmCaQXpds6lCbhZFKgrUOolQKjmQkr4/jlSJpVyjOZTEyZMgV3d3d8fHx4/vnnuTgo5tNPP6Vr167odDoCAgK49957SU+v+PnbuHEjUVFRODs7M2DAABITE60SV2MgkpcVnDOc45HNj5BTkmPrUJqEELcIMnLt9+md0WThP5/vt0pn1o8//hiVSsWePXtYsmQJb7zxBh988AEApaWlLFiwgIMHD7Ju3ToSExMZP358+bFnzpzh9ttvZ+TIkRw4cICJEycye/bsOsfUWIixjXWUWZTJuJ/GkZSXZOtQmoxO7rfw+67etg6jznROKr56pBfRgfpaHd+/f3/S09M5fPhw+YK6s2fPZv369Rw5cuSq/ffu3Uu3bt3Iz8/Hzc2NOXPm8N1333H48OHyfWbPns2rr75KdnY2Hh4etYqrsRA1rzrIN+Yz+ZfJInFZWX52hK1DsIr8YhPjPtrDmazCWpfRs2fPCiuB9+rVi4SEBMxmM/v27WPkyJGEhISg0+mIjY0FIDm5rM316NGj9OjRo0J5vXr1qnUsjY1IXrVUbCpmyq9TOJZ1zNahNClqhZpjp31tHYbVpOeXMO6jPWQVWHc67+LiYoYMGYJer2fVqlXExcWxdu1aAIxGx5g6XCSvWpBlmad/f1r046oH4bq2FBmb1rQzpy4UMGHFHgqNNV9jc/fu3RVe79q1i5YtW3Ls2DEyMzNZuHAh/fr1o3Xr1lc11kdHR7Nnz56rjm8qRPKqhXcPvsvWM1ttHUaT5GqOtnUI9eLg2VymfP4XFkvNmpiTk5OZMWMG8fHxrF69mmXLljF16lRCQkLQaDQsW7aMU6dOsX79ehYsWFDh2MmTJ5OQkMDMmTOJj4/n888/Z+XKlVa8KtsSyauGfj/7O+8dfM/WYTRZaWkhtg6h3mw5ls7iX47X6JixY8dSVFRE9+7deeyxx5g6dSqTJk3C19eXlStX8vXXX9OmTRsWLlzIokWLKhwbEhLCN998w7p16+jQoQPvvfcer7zyijUvyabE08YaSM5L5p4f7iHfaN1hIDVVEF/AhY0XKEoqwpRjIuTxEPRdLj3RMuWaOP/VeQyHDZgLzbhGuRJ4fyDaAO01y72w6QJZW7MozSxFqVPi3tUd/zv9UWjK/sbl/JnD+TXnsRRb8OznSeCYS32xjBlGEhcl0mJuC5TOtbvt02vcST00q86rYjdmkgTLH+jKoDb+tg7F7jXdT4mVFZYWMm3bNJsnLgBLiQWnECeCHgi66j1ZlklamoQxw0jIEyFEzotE7aMm8bVELCWWKsvM2ZlD2tdp+N3qR8tXWhL8YDC5e3JJ+6ass6Up38S5FecIHB1I2FNh5PyZQ96BvPLjUz5Nwf8u/1onLoBQl5gmnbgAZBmmf3WA5MzaP4EUyjTtT4oVzf1zLgnZCbYOAwBdjA7/O/wr1LYuMqYZKTpZRNC4IFwiXNAGagkaG4TFaCFnV06VZRaeKMSlpQsevTzQ+GrQtdPh3sOdolNlc+wbM4wonZW493DHJcIF12hXSlJKAMjZlYOklHDvWsdVp4ui6na8ncgvNvHY5/sxmqr+YyJcn0he1fBV/Ff8mPijrcOoFrm0rBVAUl/qGyQpJCS1ROHxqv/au0S6UJRYROGpsn2M6UYMhwy4xbgBoPXXYjFaym5VDSaKThfh1NwJc4GZ9G/TCby/7sN5Es9dXZNsqv4+l8srG4/aOgy7JiYjvI7kvGQW7V10/R0bCW2gFrW3mrSv0wgeH4yklcjclIkpy4Qpt+pH9R69PDAbzJx++TQyMpjBa4AXfiP9AFC6Kmn2cDPOLj+LbJTx6O2Brr2Osx+exetGL0ovlJK8JBnZLON3mx/u3WpWCwtwCSYhw7VO125vVv6ZyA1RPgxsLdq/akMkr2swW8w8u/1Zu1qeTFJJhDwewrkPz3H0saOgALc2bmU1qGs8mjEcNZDxfQaBYwNxiXDBmG4kdVUq6d+l43drWQLTd9FXuFUtOFZAydkSgu4P4vis4zSf3ByVu4qT80/i2soVlb76H68ATXsax015w3pu7T/8PMMbN634Vawpcdt4DYe2nqHz+UEosK9Ok85hzkQuiCT6nWhaL25N2FNhmA1mNL6aKo9JX5uOR28PvGK9cGruhL6LHv87/cn4IQO5kr5JllILKZ+kEDQuCGO6Edks49raFW2gFm2AlsKTNWuQbuhVsRuLlNxiXv1RjNKoDZG8qpCTVsiedYlo9jTnyXNLiFba1+R4AEoXJSq9ipLzJRSdLkLXueqZSS0llqs/Ddf4dGSsz8CtvRvOYc5lye2ytmfZVPH19SgkBfGJAdU/oIn5bHcSexOzbB2G3RHJqxKyLLP1s2OYSst+A/OTzQzcPZEJ5icbRS3MXGymKKmIoqR/nwReMFKUVIQxs2xMW+6eXAxHDRjTjeTtzyPxtUT0nfXo2l1KXmffP8v5r8+Xv9Z11JG1JYucXTkYM4wY/jGQ/m06uo46JIVU4fzF54rJ3ZOL/+1lbTXaQC1IkPVbFvkH8ilJLcE5ovoLs4bpWpFXoK7198PeyTLM+uYQJSaxElFNiBvtSsTvOk9KQk6FbeZSC9o9ITwZsoTvQ97nmPmQbYIDik4XkfhqYvnr86vLkpBHHw+aPdwMU66J1C9SMeeaUXmo8Ojtge+tFQc7GzONcFlO8rvFD0mSSP82ndLsUlQ6FbqOZV0yLifLMikrUwgYE4BCW/a3T6FREDwxmNRPU5FLZQIfCETtWf1k5E7bGn4Hmp6TGQW8teUETw5uZetQ7IboYX+FUqOZVc/vpCC36pH5Ko0CQ6fTfCy9iSyJb19dhZY8yT+nms5MErWlVkpseLwfrQLsY+ERWxO3jVf4a1PSNRMXgMlowWl3KE+lLqOVsl0DRdY0OaucOZ7UuFbFtpVSs8x/fxR9v6pLJK/LFOSU8Nfm6i+ekZ9k5qY9jzDOMg1Jlq5/gHCVcLeYRrkqtq1si8+wyvTRjkB8ai6z67uTmIw1G7JhMlpw3h3OU+eXEalsU0+RNV1qo2jjudKrP4muE9Uhkte/MpLzid91/vo7ViE/0czQPY8yVp4qamE1cM4OVsVuaH8l57DpcO0/i45CJK9/7Vx7gro+ujAZLbjsiuCptKW0ULS2TmBNmLeTL6ftZFXshrZoUzzmGk5c6GhE8gLSk/I4c9R6Kx3nn7YwbO9jPCA/IWph19DMKcbWITRaCekGvtl/1tZhNGoieQH7N1l/hWtTiQXXXS14Km0pEUrRrlMZU0FLW4fQqC35JQGTWUybUxWH76Sam1HIqQMZ9VZ+/mkLI1KnkNXxGKukt+vtPPboRC1Wxc7d+RWFx3dSmnUWSaVBGxyNZ+x41N7NyveRTUaytnxI4dHfkc2lOId3xmvwoyhdPass12IsIue3lRQe34WlOB+Vuz+6LiPRdRpevk/Wr8sp+OdXJLUTHrHjcGs7oPy9gmPbKfjnV/zufLHG11SVczlFbDqcxogY+1w9vL45fM3rr81nKh14bE2lxRZ0u6KYmbaMcKWobQCEuLXgQu61p6WuTPGZf9B1HkHA/YvwH70AzCbSvnoei7G4fJ+sX5dTdGIPPrfNxv/ehZgMmWSsvfbc7dlbPqDo1H58Rj5J0MR30XW9lazN71GYULZ6T+GJ3RQc/Q2/uxfg2X8CWT8tw1yYC4ClpICc3z/Ba/CjNb6e61mx47TVy2wqHDp5FeYZObYztcHOl3/Kws17p3Iv/2mwczZW3rXs3Ot/93zc2g9C4xuKxi8C7xHTMedlYEw7AZQlEsOhzXgOfAjn0A5oAyLxGT6NknNHKTlXdReEknNHcW03EKeQmLJaV8ehaPzCKUktWzCjNPMMTs3bow1siWubWCSNC6bcsimys7euQNdpOCq9X62u6Vr2JmXz99lcq5fbFDh08jq09Qzm0oZtUygtNqPf2YqZ6UsJUTjmNDAAeVnhVinHUlIAgMKpbMbXkvMnwGLCOaxj+T5q7+Yo9b6UpFSdvLTB0RSd2IMp/wKyLFOcdIjS7BScwzsBoPENx3j+BOZiAyXnTyCbSlB5BlF89jDGtJPouoy0yvVURtS+KuewbV4Ws4Uj21Nsdv78kzK3pkznQsd/WI1jLaWmUWiIP1n3sYyybCH71+Vog9ug8Q0DwFKQDUpVeTK7SOnqgbmg6ifKXoMmk7lpGefeGQ8KJUgS3kMfx6l5WQ3ROaILrm37c/7j6UgqDT4jpqNQa8na9A7eI6aT/9dG8vdvQOmsx2vIFDS+oXW+vos2HErlmeHR+OpqfpvdlDlszSvpcBZF+aU2jaG0yIz7zmhmZiwlRBFh01gakrVWxc76+V2MGUn43PJ0ncvK2/c9JSnx+N7xPIHjFuM54CGyNr9HUeKB8n08+t5H8CPLCXrobVyiepO782ucwjoiKZTk7vySgPv+D7eYwWT+8Ead47mc0Wxh1e4kq5bZFDhs8opvwLau68k/IXPb/hmMZpKtQ2kQzua6d+DN2vwuRSfj8B/zCiq9T/l2hasnmE1Yig0V9jcX5FT5tNFSWkLO75/gOXAiLpE90PiFo+8yEtfW/cjb822lx5RmnqHgyFY8+t1PcfLfODVrh9LFHZfW/TCmncRSYt2lzT7fnVzj1babOodMXsUFpZz++4Ktw6jAWGTGc2dbZmYsobnCOu1BjVV6HVbFlmWZrM3vUnh8J/73vIzao+IMrNqASFCoKEo6WL6tNPMs5rwMtEFVJE2LGSwmJK7oUCwpqGzYhSzLZG56G8+BE1FonEG2IFv+Xdzk4r+yddtS0/NL2H1azLZ6OYdMXglxaVhMjfOvWP4JGPXXk9zNw7YOpV7oNe4knKn9+o5Zm9/FcHgbPiNnotC4YDZkYzZkYyktW0NSoXXFLeYmsrd8QHHSIUrOnyBz42K0Qa3RBl9KXueWT6bw+J//HuOCtnk7srd9RHHyIUpzzmP4+xcKDm/BJarXVTEYDm5C6azHJbIHUNbYX5x0iJJzx8iL+w61d8hVbW7W8MPftmujbYwccjLCr/8bR3qS7Ve+vh63lrDa7w3OWZpOe0d7j378uXNErY9PevXmSrd7D5+GW/tBwOWdVH9DNpfiFN4Z75v+g9LNs0I5lx9jNmST/dvHFCfux1JsQKn3Q9dhCLputyFJl2pk5oJsUj95koD7X0OluzQPWc6O1eTvXY/CxR2fEdPRBll/VIWPm4bdcwahVIghZ+CAySv7fAGfz91t6zCqTeOiJKXjX6yRP7R1KFbRXvsQfx4QHXVr67OHetC3pc/1d3QADnfbePpg42rruh5joRmfP2N4KnMxQYratxU1Folng20dgl3bcEjcOl7kcMkr+bB9zlJpOC5x14GnuUOaYOtQai3QpRkpF1xsHYZd23T4vBis/S+HSl7GYhOpJ+13qEVJgRnfPzvyVNZiAhXNrn9AI+Ovbm/rEOxedmEpu06Jp47gYMnr7NFsLGb7b+IzxEvcfeAZRknjbB1KjTjqqtjWtuOkfTV91BeHSl5J/zSdH3pJgQn/PzvzVPab+EuNvx1JKSk5luh//R2F6xILdJRxrOR1uOlVtw3HFNxzaA63KR6wdSjXFKZrRX6h466KbU1/n82l0GiydRg25zDJKyulgIKcEluHUS9KDCYCdnTlqew38FM0zonr9LJYWclaTBaZuETrTVturxwmeZ0/bb8N9dVlOKbk3kPPcYviPluHcpWsC2G2DqFJEbeODpS8MuygR701FOebCNrRnSdzXsdXEXD9AxqAi8qF+CQvW4fRpIjk5UDJKz0pz9YhNKiCoyruO/Q8IxVjbB0KYW7tKRWrYluVaPdykORlNlm4cM5w/R2bmOJ8E8E7ejIj53W8JetPUVxdYlVs6zNZZI6nOd5n+nIOkbwyzxka7SwSDaHwqIoH/nmRmxX32OT851LEqtj1ISHNMZpCquIQycseZpCob8V5Jprt6MWMvEV4Keo+BXN1+Tj5cTpVrIpdHxLSRc2rycs4I5LXRYWH1Yz9ey7DlXc3yPmCxarY9UbUvBxAbnqRrUNoVIrzTIRs78OMvNfwkup3ehWTIbJey3dkoublAPIzRfKqTOFhDeMOz2OI8o56KV9CIiEpqF7KFspW1HbkJ45NPnnJFhlDdtPsWW8NRbkmwrffwIz81/CUvK9/QA2EuLUgM09j1TKFS2QZTjhw7avJJ6+C3JImMZNEfSv8R8P4I/MZrBxltTK9FG2tVpZQuaRM665SZE+afPLKyyy2dQh2oyjHRMT2/kw3vIq7VPkyYTWRl920V0FqDLIKjLYOwWaafPLKF8mrxor+duLBIy8xSHlrrcvQKDTEJzZclwxHlSmSV9OVnyWSV20U5ZiI3D6QaYaF6CWPGh9vrVWxhWvLKnDc9twmn7xKCh33aYw1FP/tzMSjr3Cj8pYaHedsjq6niITLidvGJsxUYrZ1CHavMLuUljtuZFpB9WthdVkVW6i+CwaRvJqsUpG8rEOG4kPOTDz2CgOUlS/8elHZqtj6BgrMsYmaVxMmkpd1FWaV0mrHTUwteAWdVHmCCnXpgEVu8h+tRiHbgZOXytYB1LfSkrq3eZ1IOcQvB78k+UICeYWZPDx4Hh3C+5a/n1eYxXe7l3P07D6KjAYiA2K4q+8U/NyvvTzZ1kPf8MeR9WQb0nF1cqdTxA3c0n0ialVZx864hF/4bvcHlJQW0bPVEO7o/Z/yYzPzz/PWD0/z9O3v4qxxrfM11ogMJYdcedhrIfvafM9v5h8rvl8kVsRuKCUmx13D0W7+PG7btg1JksjJyanRcdaoeZWYigj2bsHovk9c9Z4sy7y/6QUu5KXyyJD5zL7jf3jp/Fi2YSYlpVUPS4pL+JXv9ixnWJexPDd6BffFPsW+k9tYv+cDAAxFuXz+2+uM6vkIU0a8SlzCr/ydtLP8+C//WMKt3R9u+MR1mcKsUqJ3DOWJwldwu6wWJlbFbjhmi+N2wK735GU02rZaW1pS979MbUN6MLL7gxVqWxel554lMf0o9/SbRqhfa/w9mjO63zRKTUb2ndhSZZmn0w4T4d+Obi1vxFsXQHTzrnSNHEBSRjwAF/JTcdK40iVyAKF+rYkK6khadjIAe09sQalQ0TGiX52vrc5kMB505ZH4hdygHCpWxW5gjpy8anzbmJ+fz+TJk1m3bh16vZ6nn36a7777jo4dO7J48WLCwsJ46KGHSEhIYN26ddx+++2sXLmS7du388wzz7B37158fHwYNWoU//3vf3F1Las5fPrppyxZsoT4+HhcXV0ZOHAgixcvxs/Pj8TERAYMGACAp2dZz+9x48axcuXKakRcvz9ck7kUAJXy0hg+haRApVRz8vw/9I4eUelx4f5tiUv4hcT0Y4T5teZCXgqHk/fQveUgAPzcgyk1lXDmQgJebv4kZcTTs/VQCkvy2RC3gqkjX6/X66qpgsxS2u4YxsDBsXw1qDkmyW4q9XZNgWTrEGymxslrxowZ7Nixg/Xr1+Pv788LL7zA/v376dixY/k+ixYt4oUXXuDFF18E4OTJkwwdOpSXXnqJjz76iIyMDKZMmcKUKVNYsWIFAKWlpSxYsIBWrVqRnp7OjBkzGD9+PBs3bqR58+Z888033HHHHcTHx6PX63F2dq5WvApl/f4SBXiE4Onmx/o9HzDmhuloVE5s/XsNOQUZ5BZWvU5kt5Y3UlCcy5vfTUVGxmIx07fNSIZ0Llv5x0Wr44EBs/hk66uUmkroHnUTbZp3Y9W214htexuZeef530/PY7aYGN51LJ0iYuv1Oq/HyUnJoEh3pFPFlPR5lyWWR0myQq1XuDaNJJJXteTn5/Pxxx/z+eefc+ONNwKwYsUKgoIqTnsycOBAnnzyyfLXEydO5L777mPatGkAtGzZkqVLlxIbG8u7776Lk5MTDz74YPn+ERERLF26lG7dumEwGHBzc8PLq2z1GT8/Pzw8PKods6So3x+uUqni4cHzWPXbIp5eeRsKSUGr4C60ad6da9X6jqccYNNfnzO67xOE+kVzIS+FNX++zY/7PmVYl7IFZDuE961wq5qQcpBzWae5q8/jzP1iLBNufBa9ixevrX2MyMAYdM51H49YG80CnOnqrEQ+mw/oiDAn82Lpw3ypf5NNeeIWsj4pRfKqnlOnTlFaWkr37t3Lt7m7u9OqVcUFFrp27Vrh9cGDBzl06BCrVq0q3ybLMhaLhdOnTxMdHc2+ffuYO3cuBw8eJDs7G4ul7K92cnIybdrUfsFSpar+f7ghvlE8c+f7FJUYMFlM6Jw9eG3tY4T4RFV5zA9xK+je8qby28pg7whKSotY/cebDOl8H4orbrtKzUa+3L6EcQNmk5F3DovFTMugDgD4uTcjMe0o7cN6199FVqFbtCdBFwqRsy891dUXdadA8Qljcx+grcczvJPfjWIHbpupT0rHzV3102B/sR3rIoPBwCOPPMKBAwfKvw4ePEhCQgItWrSgoKCAIUOGoNfrWbVqFXFxcaxduxaoe4O/WtNw4+uctW7onD1Izz1LcsZxYsL6VLmv0VSCdMVfTYXi31jlq3/RN+1fRZvm3WjuG4VFtmCRLz1FNVtMWOSGvUVTqxQMa+9FUKoBSiue2+XUpalwuuT8l1c1bxLp5MC/ZfXISeG4bYs1qnlFRESgVquJi4sjJKRs+Edubi7Hjx/nhhtuqPK4zp07c+TIESIjK58S+O+//yYzM5OFCxfSvHnZSjN79+6tsI9GU9YgbjbXrOuDWlv35FVSWkRG7rny15n55zl74QQuWh1eOn/2n/wNN2d3vNz8SMk6zZodbxMT1ofo5pdqoJ9sWYi7qw+39pgIQLvQXmw9tIZmPpGE+UWTkXeODXEraB/S61IS+1dqdiL7Tm5l9h3/A8DfIwRJkvjz2Eb0zl6k5SQT6tdwy4v5eWvp7aVFrmJtANUpf7TRAZSUngfAp+gPnpMO8Y1+Md/niZ731uSlbvJdNatUoyvX6XSMGzeOmTNn4uXlhZ+fHy+++CIKheKqWsTlZs2aRc+ePZkyZQoTJ07E1dWVI0eOsHnzZt566y1CQkLQaDQsW7aMyZMn888//7BgwYIKZYSGhiJJEhs2bGD48OE4Ozvj5uZ2/Qu0QvJKyohn6feX2vC+3fkuAD2iBvPAgFnkFWby7c53yS/KRu/iRY+owQztfH+FMrIM6RW+R0M734+ExIa4FeQWXMDN2YN2IT0Z2f2hCsfJsszq39/k9l6PolWXPaTQqLTc3/9pvtq+FJO5lLv7PI6Ha8NMPxMT6U6EoQQ549pTa7vLPUjnu/LXajmXe3In0NZ9OssK+lEgJoi0Cu8GvLNobCRZruQe5Roq6yrxxRdfMHDgQP773/8SFhbGtGnTyhvnL4qLi+PZZ59l586dyLJMixYtGD16NHPmzAFg9erVzJkzh9TUVDp37swzzzzDLbfcwl9//VX+JHPBggW88847pKWlMXbs2Gp1ldi+JoGDv5ypySUKlZAUEje29cT1bH61ep+UdDhFov/8St/LdurBW4pZHCsSCayuRvi682E7x5z0scbJ60oFBQUEBwfz+uuv89BDD13/gAZ24Jdkdqw5Yesw7JqHXk1skAucr/6Uwxa1iVM3TsVsKaj0fZPkxvfub7Am17rz5juasUHe/F8rx1zUt8atfX/99RerV6/m5MmT7N+/n/vuK+uXdOuttZ91sz65emhtHYJdax2mo79OXaPEBaAoVeGu7lbl+yrZwKicSTyv+wV9PffFa8q8HbjNq1afmkWLFtGhQwcGDRpEQUEBf/zxBz4+9bv+X23pvJxsHYJ9kiC2nRet8oqRC0prVYTbhU7X3ad13rssVM6lvegOViveGsdNXjW+8k6dOrFv3776iKVeiJpXzbm6qBgYpkNxtm4rMmuPREEPBXDtbhzuJQeZabyPn9xfZ3VuQD0P6GpafETNq+lyddfUey/7piQs2JWbfLQoUuq+HqAi1xm9NqZa+yrlYkbkPMZctw14qur2sTQe3Ef2nKlk3HUTaQM7Ubx9a4X3ZVnGsOIdMu68ibShPcl+6hFMZ5OuWWbB5x+S+eh9pI/oQ/rtA8l5fjqm5MQK++S/s4j0W2PJGD2Uol82VniveNtmsudMrdN1VaaFi+P+cW7yyUuhVOCiU9s6DLvQq60nHUpKkfOsNxOIzlB1u1dlIvNXsFB6hi6ute90KxcXoW4Rhe6JZyp9v/CLlRR+uxrd9Dl4vf0JkpMzObMeQzZWvZiF8eB+XG4djddbn+D52rvIJhPZTz+KXFTWZaTkz98o/vUnPP/vHdwmTSVv0XwsudkAWAz5GD56C/3U2bW+pspIQAsXx20WafLJC8DdTzSoXItWq2REey/8zhnAZN2bNueEmi/E4WY8xvSCMYx3T67VB1Tboy9uDz2GU7+BV70nyzKF33yO6/0P49RnAOoWUehnL8B8IYOSK2pol/N89W2ch96CKrwF6hatcJ81D0v6eUqPHwHAlHwadccuqFu1xfnGYShcXTGnpgBgeH8JziPvQukfWIurqVozJw0uDvywwyGu3LvZ9TuzOqogP2eGBbugqqK3fF0pz3rhrAmt8XGSbOKmnOm85LoGX7X1Pqbm1HNYsi6g6dKjfJvCTYc6uh3GI4eqXY6loOy2WqF3B0DVIgpT/FEs+XmUHj+CXFKCMrg5xr//ojThKC63j7HaNVzU0oFvGcFBkpdvc5G8KtO5lQfdsSDX89qW7qU9rr9TFUINq3lFnkEvN+usRWDJugCAwtOrwnaFpzeWrMxqlSFbLOS/vQh1u46owsuGvGm79cZp0HCyHr2fvFdfRD9rPpKTM/mLX0E//VmK1n/NhbG3kfX4eEynT1rlWlq6Ou4tIzhI8vJpprN1CI2KUiUxpL0XzdMKkI31P6Db+Uz7Oh3vUnqa/+SPYZL7CRrDYJj8Jf/FdPoE7s8vrLDdbfxkfD5bj/eHX+PUbyAFn3+EpnMPUKoo+OwDvJZ+hPPwUeQufN4qcbRy4PYucJDk5RXkisKR5w65jLenhpsj9DjV021iZdTHglGp3OtUhgIzsTmzeMXlMwI1tf/YKrzK+iNasitOFGnJzkThdf3e/nlLFlKy6w+83liO0te/yv1Myacp/uUHXB/8D6UH96KO6YzCwwun/oMxJRzFUlj5yIOaEDUvB6BUKfAKst1CFY1F2xZ6+jkpIb1mveXrSrIo8FD0skpZzQrW8pL5cWJ1tXsiqgwMRuHlg3H/7vJtlgIDpUf/QdOm6m4dsiyXJa7tW/B8/X8oA6teZESWZfLeeAndo0+icHZBNlvAVDbfmWz+d94zS91qvBpJop1b9WYTbqocInkB+Dhwo70kwcD2XkRmFSEX1X0puNpwTetgtbKcTGd5OO9eHnM/irqS2UwsRYWUnoin9ETZYibm1HOUnojHnJaKJEm43HEvBZ99QPGObZSeSiBv4fMofXzR9h1QXkb2k49QuPaL8tf5S/5L8S8/4P7cK0gurpizLmDOuoBccnV7YdEPa1F4eKLtXTY1t6ZdR4wH4jAeOUThms9QhkagcKtbU0ZHvQvODvykERxg3caL/MPdObbzvK3DaHB6nZr+zVyRGvA2sTKawy2Q+qmR5doNNbqShEzvnOeIcB3GYvMkzlw2X74p/gjZMx4uf214t2yxEqchI3GfNR+Xe8YjFxeR/8ZLWAz5aNp3xGPh20iaS0/vTClnUOfmlL8uWv81ANnTL5ULoH96Hs5Dbyl/bc7KpGDVB3gtW1m+TR3dDpe77idnzhMoPLxwn1X5bBs10cvDcf8YX1TnWSXsRU56Iate2GXrMBpUyxA32losyAbrJIy6Shv5Ljklu6+/Yw0ZlX587vYGm/Mc5zZqdUwEA7wde2JHh6l3evi5oPdxnAbOfu28aGMwNprEBeCW26VeytWY0xmfez/T3f/CyQGGgqkk6O4u2nAdJnkBNI/2uv5Ods7FScnN7TzxOpsPjWzRC+djNe9tXxNdc15ioWYZEU5N+2Pdzs0FV1Vj6DRiW037p3yFpp68QgJdGBzgjPJs3QdV1wdFug5XbdUrKlmDb9FWXih5iBH6xvk9sIaeHqLWBQ6WvJq19myyM0x0b+NJJ5MZOafqwcWNgb649r3tq0ttyeLe3HE8rd+JSxP8ed/oVfe2rsTERCRJ4sCBAwBs27YNSZLIycmpc9kNxaGSl9ZFjV9o0+ptr1GXLUEWmHL1EmSNkfPpttffyUo65C5ioXoRrZybTgLzVCkb5ZPGlStX1mgxaGtwqOQFEBbTOGd8rY0AHyeGh7qisXE3iJpQnfRHo26YlY4AvIv/ZE7ROEa5ZzfYOevTjd56VE2wNnmRLMuYTNXri+hwySuqm3/ZREh2rmNLd3oqQb5Qv4OqrU2SJdzlng16TpWcz505E3lWtxWdnXfsHOFb/WFWP/30E3379sXDwwNvb29uvvlmTp6s/aDwgwcPMmDAAHQ6HXq9ni5durB37162bdvGhAkTyM3NRZIkJEli7ty5AHz66ad07doVnU5HQEAA9957L+np6eVlXrxd/fHHH+nSpQtarZbt27dXKx77/knWgt7HmcCIuo2zsyWlQuKmGC9CMwqRS6wz00JDc0vpaJPztsl7i1eV82lnp9O76ZQKBtagb1dBQQEzZsxg7969/PrrrygUCkaNGoWllkOT7rvvPpo1a0ZcXBz79u1j9uzZqNVqevfuzeLFi9Hr9aSmppKamspTTz0FQGlpKQsWLODgwYOsW7eOxMRExo8ff1XZs2fPZuHChRw9epSYmOrNvuswPewvF9Xdn9STubYOo8Y83dXcEOACyfZzm1gZ1ZFQFAHOWCzXXri2PriX/MXTxvv5wf0Nvsz1a/Dz18UwX3e0iurXN+64444Krz/66CN8fX05cuRItRZsvlJycjIzZ86kdevWALRs2bL8PXd3dyRJIiAgoMIxDz74YPn/IyIiWLp0Kd26dcNgMFSIYf78+dx00001isfhal4AkV387W6WiehwHbGuKkhr2EHV9UFhVOFxjWXR6ptSLuKWnEd5Ufcj7nWcL78h3ebnWaP9ExISGDNmDBEREej1esLCwoCyJHQ9bm5u5V+TJ08GYMaMGUycOJFBgwaxcOHCat2C7tu3j5EjRxISEoJOpyM2NrbSGLp27VqjawMHTV5ObmpC2trJYqcSDGjvRVROMXKhbQZV1we3zM62DoGovA94VXqOTq6NqzNvZYK1amK9avakfOTIkWRlZbF8+XJ2797N7t1lQ7OMxuvPyHHgwIHyr/nzy8Zizp07l8OHDzNixAi2bNlCmzZtWLt2bZVlFBQUMGTIEPR6PatWrSIuLq58/ytjcHWted81h7xthLJbx8RDF2wdxjW5uaoYGKqz+aDq+qA9GgXdrr8sWn3TGQ8zo/RefnZfxGe5wY122bVxwT4oK5lBoyqZmZnEx8ezfPly+vXrB1DthnCAyMjISrdHRUURFRXF9OnTGTNmDCtWrGDUqFFoNBrM5optsMeOHSMzM5OFCxfSvHnZqt579+6tdgzX45A1L4CIjr646DW2DqNKEc3cGOStRbLCEmSNkSLbBZ224fp8XYtCNjI05wkWuK3Fx4rz5VuLViFxb2DN7hQ8PT3x9vbm/fff58SJE2zZsoUZM2bUOoaioiKmTJnCtm3bSEpKYseOHcTFxREdXTbkKywsDIPBwK+//sqFCxcoLCwkJCQEjUbDsmXLOHXqFOvXr2fBggW1juFKje8n1UCUKgXt+zezdRiV6tPWk/ZFRqsuQdYY6Qts1+5VmfD8z3hFnkkPK82Xby0jfT3wqeHK2AqFgi+++IJ9+/bRrl07pk+fzmuvvVbrGJRKJZmZmYwdO5aoqCjuvvtuhg0bxrx58wDo3bs3kydPZvTo0fj6+vJ///d/+Pr6snLlSr7++mvatGnDwoULWbRoUa1juJLDTIlTmWJDKR/P2YGpAeZxrw4nrZIbo/SozjTN2taVTCGZnGz9pK3DuIoFJb95vMqK3HAaQxrb2KUlnfViPOOVHLbmBWUN9617WnctvdoK9ndhaLCLwyQuAFWyN06axlf7VWBmQM5TvOy6Gv86zJdvDR11LiJxVcGhkxdAhxub27zHfZdWHnSTzfW+BFlj5G5q2N72NdHcsIaXzVPpp7PdnGgPNWs6w9mszWGfNl7k4e9CWHsfmzx5VKsU3BjtgfZMfqN9ylXfDm9Ws3jLeRISSsjMNDNvnj99+l6qaciyzMcrs9m4MR+DwULbdk5MnepDs2bqKsv8/PNstm8v5EyyEa1Wok0bJx6e5EXz5pce0Lz7TiY//5yPk5PExIle3DjoUjeE334zsPlnAy+9HICzKZlH8sbQ1uNlPshrZe0Fxa8p3FnDqBr27XIkDl/zAug8OKTBz+nrpWVEuBvaJtgNoiZKTuqJjNTx+BOV1zC+/CKXtWvzmDrNh7feCsLJSWL27FSM12inPHSomFtv0bPsrWBe/b9ATGaZWU+fp6io7JidfxawZYuBha8G8vAkb15//QK5uWWtWwaDhY8+zK4Qj4RMv5w5/Nd5BcENeBs5MzywSQ/CriuRvIDASI8GnW2ifaSePhoJOaPhh8c0NgPDevHkI7fRt+/V7TqyLPPtt7ncd78Hffq4EtFCy6xZfmReMLNje9UjDRYuDGTIUB1hYRpatNDy9NN+pKebSEgom+ssObmUDh2caNVKy8CBbri4KEhNLbs1XP5+JiNv0eHvf/VNSVDBBuab/sON+vq/vW/t6sRtfh71fh57JpLXv3rd1qLeJyqUFBKDYryIyCxCLm4Mz7EaB7f0TpVuT001kZVlpnPnSwtruLkpiI7WcuRI9RNIQUFZjUunK5s6OaKFhuPHS8jPN3P8eAlGo4XgYDV//11Mwgkjo0ZVPXDfyZzKg7n38YT7IbQ16DRaU0+HB6Cox/KbAodv87rIK8iV1r0COLojtV7Kd9er6R/kaveDquuD5nALpL5Xt2FlZ5cleE/PivO1e3gqycquXvK3WGTeeTuTtu20hIeXtXl16+bCjYPceOw/59BoJZ6e5YeTk4IlSzJ4+mk/vv8+j3Vr83B3VzB9hi9hYVd3Zu6RM49wl0EstjxGUol1u9p00Dkz3NfDqmU2RaLmdZnuN0egqoce1i1D3RigV8P5ui/x3hQpCrToNR3rpeylSy+QmGjkuef8K2wfN86LTz4N4YMPmtO3ryurV+fQubMzKiWs+iyHxUuCGDZcz6sL06soGfwKf2Gu8WGG6q37c50d3ji67zR2Inldxs1TS8yNza1a5g3tvGiT37iWIGuMdHlXzypwscaVfUUtKyfbjJfn9VfPWbb0Art3FbLo9UB8fau+yUhONvLrL/lMmODFwYPFtI9xwsNDSWysKwkJRgoLq65ZaSwXeCB3LE/p46yy7NoNnm4Ovx5jdYnkdYUuQ0Jxcqv6MXx1uTirGNnWE89GuARZY+QUf/WyaIGBKry8lPy1/9KDjYICC0ePltCmTdVrcMqyzLKlF9i+vYDXFgURGFj1z1OWZRa/eYHJk71xdlZgtsiY/+0PYTaX/Wupxs+vU+5C/k/zOpF1mC/fSSGxMMq6fzybMpG8rqBxVtH3rpbX3/EaQoNcGOznhOJc/faW33XmABPWzKbL26No/uoN/HT8jwrvZxRkMf2HV+jy9ihavn4T93/1FKezzlyzzB/jf2P4xw/TdvFwot4YzJAVD/LNP5sq7PPe7tV0XHYLHZfdwv/2fFHhvb9SjjB85URMlupN31NgLORwWgLHDqYBkHq+lBMnSkhLMyFJErff7s6qVTn8+WcBp04ZeXVhOt4+Svr0vTQd6synUli37tLkkkuXZvLLLwbmPOuHi4tEVpaJrCwTJZW0TW3cmI+7u5JevcuedrZr58RfB4o4cqSYb9bkEhqqxs2temskehft4LmiCdzqXruJLp8I9SfCRVurYx2RaLCvRKseASTEpZH0T2aNj+0Z7Yl/RiFyYf3fJhYZi4n2a8HdMcOZtPa5Cu/JsszEb59FpVDy4e2voNO4sjzuS8Z8OYMtD32Ci8a50jI9nPU83usBIr1CUCvV/HryT57cuBBvF0/6R3TnaPpJXt/+ESvvXIgsw/hvZnFDeDeifVtgsph4ZtPrLBz6FCpF9T5ah87Hc/fqqeWv33s3C4DBg914epYfo+9xp7jYwptvXMBgsNCuvRML/xuA5rL+VikppvJ+WgDfr88D4MkZFR++zJzpy5ChlzqjZmeZ+HxVDkuWBpVva93aibvu9ODZOefx9FTy9KyaLRailnO5O+dB2rhPY2nBDRSYq1frbumiZUqIfc3samsOPTD7WvKzilk9fzel1ezSoFErGNTaA7WNOp02f/UGlo96maFRZXM3nco6Q+zy+/jlwY9p5RsOgEW20Pmt25h1wyTGdLi52mUPW/kQAyN6MfOGiXx/dAvL475i/dj3ABj5ySM80v0ebm49gLd2fkZGQSbzBk29TomVM7VM5WT4M7U6tjHK1nblbeUcjhZd+1dMAr7tFNkolzRrzMRtYxV0Xk70uq1FtfYN9HVmeIirzRJXZUrMZdPpaFWXHvMrJAUapZo9Zw9VqwxZltmeuI+TWWfo0bwDAK19IziVfYZzeWmczT3P6awztPIJJzH7HF/9vZGZ/R6udczKEwGoVU1nLJ9nyV6eKbqfu9yvXYMfHeAlElctiNvGa2gXG0zC3jRST1TdhtEpyoPQnGLkzMY1qDrSK5RgvT+v/vY+/x36FC5qJz6I+4rU/AzSDdf+ZcorMdDt7Tswmo0oJSUvDZ7ODeFlc2+19Alj1g2TuPfLsontZsU+QkufMMZ8MZ05/R/lt9N7eGPHCtQKFXMHPU7P5h2rHbMkS3hIPclgQ62vu7FRyoXcljOJaP0jLCkcSq65Yrubr0bFC5FBVRwtXItIXtcgSRIDH4jmy5f2YLpiNWqlUuLGtp44JzfOQdVqpYr3R73EzB9fpf2SESglJX3DujAgogfXayhw07jw04QPKTQWsT1pHwu2vE2oRxC9Qsp6wj/Q6VYe6HRr+f5f//0jrhoXugS3pf/y+9kw9n+k5mfw2Pp5/PnIlxVqf9fjmhJDhm/TSV4Xtcr7Hwu1O3lP+yIH/x3ZJAFLW4fgpRa/hrUhvmvX4eHvQt+7W7JtVXz5Nm8PDX39nRt9b/mYgFZsmvAReSUGSs0mvF08GPnJI8QEtLrmcQpJQbhn2Txbbf1bciIzibd2flaevC6XVZjD4h0rWXPvMv5KOUK4VzPCvZoT7tUck9nEqewzRPtW7/YbQHMkHMUAJyyWxlWTtQZ9ySGeNN7HJvdFfJ4byKRmvqJPVx2INq9qaNsvmJbdynpot4nQ089FaVdLkOm1bni7eHA66wyHzsczuGXfGh1vkWWM5sqfns7b8hYTu91NoN4Ps2zBdNkiDGaLucYLnEolatzVNV8Gy14o5WKG50xhsc8unm0hetLXhah5VVP/+1oRogS3+Kzr3nY1lAJjIYnZ58pfn8lN5XBaAh7OeoL1/mw4thVvFw+C9P4cyzjJ3F+WMaRlX2LDu5cfM23DywTofJgd+wgAb+38jJiAVoR6BmM0GdlyahffHt7EK4Ovnq7599NxnMo6w5sj5gDQMaA1J7KS2HpyFyn56SgUSiK8aj7dkC6rC9mu1V/pxt6oVHpuiRyOpgYLyApXE8mrmjROKloMCyP9VA5yI5nz/so+UvO3vAXAne2G8uaIOaQbMpm/5S0uFGTj5+bNHW2HMLXPuAplnMtLQ7ps9oLC0iKe3fwGqfkZOKm0RHqFsOTm57gl+sYKxxWVlvD8L4t555a5KKSyX8JAvR8LBk3jyR8XolGqeXPEHJzVNe90qT0aBV0laJStiXXXJvpVnJ0bfg65pkb086qhwoMZZK0+ZuswmrxzI1/DUHLY1mFYXWjII0RGPm3rMJoEUW+tIZcOvrjd0PgWjWhq9IXdr7+TnfHzG06LFjNtHUaTIZJXLbgPC8O5Q82GjQg143Kyja1DsCp39660bbOowi26UDciedWCJEl43RWFtkXVM24KdaNM9MVJE2zrMKzCxSWcDjH/Q6EQg66tSSSvWpJUCrwfaIM6UKypV1/czY13WbTqUqu96NjhI9RqD1uH0uSI5FUHCicVPhPaofQUf1Hrg8vZ9rYOoU4UCic6xCwXTxbriUhedaTUa/B5sB0K17pPYChUpD7aHKXSPgcsKxROxMT8D3f3jrYOpckSycsK1L4u+E5qj0JX/TF8wvVJJiUeyh62DqPGlEoXOnb4EG+vmo1kEGpGJC8rUfu74vdIDEoPcQtpTW4ZlS+L1lgplW507LACT0/7b69r7ETysiKVjzO+k2NQelc9v7pQM5ojLZEk+xgIolLp6NRxJR4eTXdsZmMikpeVqTyc8HskBpVf5dMsCzWjyNei03SwdRjXpVK506njJ7i721dN0Z6J5FUPlHotvpNiUDezz8bmxkaf37hrMk5OzejSeTV6fYytQ3EoInnVE6WbBr9HYkRPfCtwOn71smiNhbt7V7p1/RY3t2vPkSZYn0he9UhSK/Ee0xr94NCyaTOFWlGmeOCijbB1GFcJDLyTzp0+RaPxtnUoDkkkrwagHxiC9/3RSJrqrf8nXE1f0pi6TCiIjHyGNtGvolCI7jG2IpJXA3Fu64PffzqI3vi15JLcztYhAGVdITrEvE9oyERbh+LwRPJqQOoAV/wf74RzTNNZ3quhqOIDUau8bBqDXt+RHt2/x8dngE3jEMqI5NXAFC5qvO+NxvOuKCStuI2sLklW4CHZquOngtDQyXTp/KUYp9iIiJlUbciUVUzWV/EYE/NsHYpdKOlynETvVxr0nE5OzWgT/X94ejamNjcBRM3LplReTvhOiil7GqkUjyOvR3M4HIXUcA3kQYF306P7D7VOXOPHj+e222675j5hYWEsXry4VuU7OvsYd9GESQoJ/cAQnNt4k/3dSYynq16d29FJxWr0mq7klPxZr+dxcWlBVNQLDTKwOi4uDlfXS3PCSZLE2rVrr5v0BJG8Gg11QNnA7sID6eRsPI0lz2jrkBolXU4XcpzrJ3kplW6Eh0+hebPxKBQNM8WRr6/oxFxb4raxkXHp6EfAk11wuyFY3EpWwulIffRklwgIuI1ePTcTGvJwjRPXmjVraN++Pc7Oznh7ezNo0CAKCgrK31+0aBGBgYF4e3vz2GOPUVp6aQHfy28bw8LCABg1ahSSJJW/Bvjuu+/o3LkzTk5OREREMG/ePEwmU62vuCkQNa9GSKFV4TE8AteuAeT+cIri+Gxbh9RoKDLdcNNGYyg5apXydG5tiYp6odYzQaSmpjJmzBj+7//+j1GjRpGfn88ff/zBxedgW7duJTAwkK1bt3LixAlGjx5Nx44defjhh68qKy4uDj8/P1asWMHQoUNRKsueRv/xxx+MHTuWpUuX0q9fP06ePMmkSZMAePHFF2t55fZPJK9GTO3ngs+EdhjP5JP3S5JIYv/SF3XHoKhb8tLp2hIeNgUfn5vqtKJPamoqJpOJ22+/ndDQUADat780fbWnpydvvfUWSqWS1q1bM2LECH799ddKk9fFW0gPDw8CAgLKt8+bN4/Zs2czblzZgsEREREsWLCAp59+WiQvoXHTNNeJJHYZ55NtoWXtjtXrOxEe9pjVOpp26NCBG2+8kfbt2zNkyBAGDx7MnXfeiaenJwBt27Ytr0EBBAYG8vfff9foHAcPHmTHjh28/PLL5dvMZjPFxcUUFhbi4uJilWuxNyJ52ZEKSWxLMsXHssABe+mpTvuhbRNASen5ah/j4dGd8LApeHn1sWosSqWSzZs38+eff/Lzzz+zbNkynn32WXbv3g2AWl2x/UySJCwWS43OYTAYmDdvHrfffvtV7zk5Oe7ElyJ52SFNcx0+49piyiqmYM95Cvaex2Iovf6BTYi7pRfprL3mPkqlK/5+IwgKGl2vC2FIkkSfPn3o06cPL7zwAqGhoaxde+3YqqJWqzGbzRW2de7cmfj4eCIjI60RbpMhkpcdU3k54T40DP1NIRQdzqRgVyolpxyjn5hrSgz4V54g9LoYgoJG4+9/MypV/U4IuXv3bn799VcGDx6Mn58fu3fvJiMjg+joaA4dOlTj8sLCwvj111/p06cPWq0WT09PXnjhBW6++WZCQkK48847USgUHDx4kH/++YeXXnqpHq7KPoiuEk2ApFTgEuOL76QY/Gd0Qde/OaomPo+++nAISuWlzp1qtSfNgh+ge7cNdOu2luDge+o9cQHo9Xp+//13hg8fTlRUFM899xyvv/46w4YNq1V5r7/+Ops3b6Z58+Z06lQ2pfSQIUPYsGEDP//8M926daNnz568+eab5Q8IHJUY29iEGc8ZKPrnAkVHMjGlFdo6HKvLvXUjKm8nfH0H4+nRHUkSA90diUheDsKUWUTRkSxKTuVQkpiHXGSHHRyVEprmOpxaeeHU2gtNoOv1jxGaLJG8HJAsy5jSCik5nUtJYh7G07mYG+FwJIVOjSZEjzZEjyZUhybYDUktaldCGZG8rKB///507NjRqrMDbNu2jQEDBpCdnY2Hh4fVyq2KKauY0vRCTOmFl/1bhFxc/zU0SatE5eOMytsJlbczan8XNCF6VF5Nu91OqBvxtFEAyp5cqrycoHXF2UrN+UZMGUWYDUYsBaVYCkoxGy79KxeZkC0yyHJZnzNZRv73XxQSCicVCud/v1wu+7+rBpVPWbJS6sQ88ELNieRlp1auXMnKlSvZtm1bvZ5HqdOI5CI0SqKrhJWYTCamTJmCu7s7Pj4+PP/88+WDcz/99FO6du2KTqcjICCAe++9l/T09ArHb9y4kaioKJydnRkwYACJiYk2uApBsB8ieVnJxx9/jEqlYs+ePSxZsoQ33niDDz74AIDS0lIWLFjAwYMHWbduHYmJiYwfP7782DNnznD77bczcuRIDhw4wMSJE5k9e7aNrkQQ7IQs1FlsbKwcHR0tWyyW8m2zZs2So6OjK90/Li5OBuT8/HxZlmX5mWeekdu0aVNhn1mzZsmAnJ2dXWkZK1askGNjY60SvyDYI1HzspKePXtWmFqlV69eJCQkYDab2bdvHyNHjiQkJASdTkdsbCwAycnJABw9epQePSrOk96rV68Kr5OTk3Fzcyv/mjx5Mn/88UeFba+80rCLUwiCLYkG+3pWXFzMkCFDGDJkCKtWrcLX15fk5GSGDBmC0Vj9vlVBQUEcOHCg/PW3337LN998w6pVq8q3eXnZdl1DQWhIInlZycUpUC7atWsXLVu25NixY2RmZrJw4UKaN28OwN69eyvsGx0dzfr16686/nIqlarCrAJ+fn44OzuLmQYEhyVuG60kOTmZGTNmEB8fz+rVq1m2bBlTp04lJCQEjUbDsmXLOHXqFOvXr2fBggUVjp08eTIJCQnMnDmT+Ph4Pv/8c1auXGmbCxEEOyGSl5WMHTuWoqIiunfvzmOPPcbUqVOZNGkSvr6+rFy5kq+//po2bdqwcOFCFi1aVOHYkJAQvvnmG9atW0eHDh147733RPuVIFyHGB4kCIJdEjUvQRDskkhegiDYJZG8BEGwSyJ5CYJgl0TyEgTBLonkJQiCXRLJSxAEuySSlyAIdkkkL0EQ7JJIXoIg2CWRvARBsEsieQmCYJdE8hIEwS6J5CUIgl0SyUsQBLskkpcgCHZJJC9BEOySSF6CINglkbwEQbBLInkJgmCXRPISBMEuieQlCIJdEslLEAS79P+smg/cGR6dcgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Preprocessing CNN Data ==========\n",
      "\n",
      "Mean of Standard Scaler:\n",
      "[1.8809562  0.16220119 0.         9.96550618]\n",
      "\n",
      "Standard Deviation of Standard Scaler:\n",
      "[ 2.84211157  0.36863527  1.         10.31315839]\n",
      "Transforming features using StandardScaler + OHE Pipeline.\n",
      "========== Done Preprocessing CNN Data ==========\n",
      "\n",
      "========== Done Splitting CNN Data ==========\n",
      "\n",
      "====== Building CNN Architecture ======\n",
      "====== Done Building CNN Architecture ======\n",
      "Epoch 1/1000\n",
      "180/180 [==============================] - 0s 1ms/step - loss: 8.1908 - mae: 1.9190 - val_loss: 8.0852 - val_mae: 1.9843\n",
      "Epoch 2/1000\n",
      "180/180 [==============================] - 0s 732us/step - loss: 7.6854 - mae: 1.9332 - val_loss: 7.9602 - val_mae: 1.9044\n",
      "Epoch 3/1000\n",
      "180/180 [==============================] - 0s 780us/step - loss: 7.5834 - mae: 1.9192 - val_loss: 7.9310 - val_mae: 1.9242\n",
      "Epoch 4/1000\n",
      "180/180 [==============================] - 0s 749us/step - loss: 7.5373 - mae: 1.9237 - val_loss: 7.8522 - val_mae: 1.9737\n",
      "Epoch 5/1000\n",
      "180/180 [==============================] - 0s 806us/step - loss: 7.4870 - mae: 1.9202 - val_loss: 7.8543 - val_mae: 1.9478\n",
      "Epoch 6/1000\n",
      "180/180 [==============================] - 0s 800us/step - loss: 7.4297 - mae: 1.9167 - val_loss: 7.8782 - val_mae: 2.0758\n",
      "Epoch 7/1000\n",
      "180/180 [==============================] - 0s 751us/step - loss: 7.4257 - mae: 1.9133 - val_loss: 7.8168 - val_mae: 2.0306\n",
      "Epoch 8/1000\n",
      "180/180 [==============================] - 0s 712us/step - loss: 7.4150 - mae: 1.9154 - val_loss: 7.7850 - val_mae: 1.9271\n",
      "Epoch 9/1000\n",
      "180/180 [==============================] - 0s 734us/step - loss: 7.3616 - mae: 1.9120 - val_loss: 7.7649 - val_mae: 1.9585\n",
      "Epoch 10/1000\n",
      "180/180 [==============================] - 0s 738us/step - loss: 7.3622 - mae: 1.9148 - val_loss: 7.7583 - val_mae: 1.9537\n",
      "Epoch 11/1000\n",
      "180/180 [==============================] - 0s 741us/step - loss: 7.3396 - mae: 1.9135 - val_loss: 7.7731 - val_mae: 1.9877\n",
      "Epoch 12/1000\n",
      "180/180 [==============================] - 0s 742us/step - loss: 7.3311 - mae: 1.9162 - val_loss: 7.7554 - val_mae: 1.9144\n",
      "Epoch 13/1000\n",
      "180/180 [==============================] - 0s 705us/step - loss: 7.3254 - mae: 1.9130 - val_loss: 7.7520 - val_mae: 1.9241\n",
      "Epoch 14/1000\n",
      "180/180 [==============================] - 0s 714us/step - loss: 7.3224 - mae: 1.9097 - val_loss: 7.7932 - val_mae: 2.0731\n",
      "Epoch 15/1000\n",
      "180/180 [==============================] - 0s 722us/step - loss: 7.2928 - mae: 1.9073 - val_loss: 7.7167 - val_mae: 1.9557\n",
      "Epoch 16/1000\n",
      "180/180 [==============================] - 0s 733us/step - loss: 7.3152 - mae: 1.9218 - val_loss: 7.7243 - val_mae: 1.9388\n",
      "Epoch 17/1000\n",
      "180/180 [==============================] - 0s 723us/step - loss: 7.2936 - mae: 1.9078 - val_loss: 7.7792 - val_mae: 1.9085\n",
      "Epoch 18/1000\n",
      "180/180 [==============================] - 0s 747us/step - loss: 7.2909 - mae: 1.9126 - val_loss: 7.7816 - val_mae: 1.9074\n",
      "Epoch 19/1000\n",
      "180/180 [==============================] - 0s 716us/step - loss: 7.2779 - mae: 1.9051 - val_loss: 7.7056 - val_mae: 1.9699\n",
      "Epoch 20/1000\n",
      "180/180 [==============================] - 0s 737us/step - loss: 7.2382 - mae: 1.9059 - val_loss: 7.7250 - val_mae: 1.9736\n",
      "Epoch 21/1000\n",
      "180/180 [==============================] - 0s 713us/step - loss: 7.2510 - mae: 1.8965 - val_loss: 7.7353 - val_mae: 2.0604\n",
      "Epoch 22/1000\n",
      "180/180 [==============================] - 0s 724us/step - loss: 7.2634 - mae: 1.9148 - val_loss: 7.7038 - val_mae: 1.9555\n",
      "Epoch 23/1000\n",
      "180/180 [==============================] - 0s 695us/step - loss: 7.2432 - mae: 1.9162 - val_loss: 7.7074 - val_mae: 1.9439\n",
      "Epoch 24/1000\n",
      "180/180 [==============================] - 0s 745us/step - loss: 7.2491 - mae: 1.9111 - val_loss: 7.7296 - val_mae: 1.8943\n",
      "Epoch 25/1000\n",
      "180/180 [==============================] - 0s 704us/step - loss: 7.2385 - mae: 1.9014 - val_loss: 7.7373 - val_mae: 1.9183\n",
      "Epoch 26/1000\n",
      "180/180 [==============================] - 0s 753us/step - loss: 7.2279 - mae: 1.9025 - val_loss: 7.7159 - val_mae: 2.0246\n",
      "Epoch 27/1000\n",
      "180/180 [==============================] - 0s 724us/step - loss: 7.2404 - mae: 1.9134 - val_loss: 7.7359 - val_mae: 1.8757\n",
      "Epoch 28/1000\n",
      "180/180 [==============================] - 0s 804us/step - loss: 7.2352 - mae: 1.9044 - val_loss: 7.6927 - val_mae: 1.9815\n",
      "Epoch 29/1000\n",
      "180/180 [==============================] - 0s 741us/step - loss: 7.2243 - mae: 1.9016 - val_loss: 7.6979 - val_mae: 1.9636\n",
      "Epoch 30/1000\n",
      "180/180 [==============================] - 0s 770us/step - loss: 7.2187 - mae: 1.9128 - val_loss: 7.6800 - val_mae: 1.9577\n",
      "Epoch 31/1000\n",
      "180/180 [==============================] - 0s 753us/step - loss: 7.2150 - mae: 1.9047 - val_loss: 7.7377 - val_mae: 1.9013\n",
      "Epoch 32/1000\n",
      "180/180 [==============================] - 0s 716us/step - loss: 7.2215 - mae: 1.9060 - val_loss: 7.6890 - val_mae: 1.9501\n",
      "Epoch 33/1000\n",
      "180/180 [==============================] - 0s 726us/step - loss: 7.1975 - mae: 1.8975 - val_loss: 7.7549 - val_mae: 2.0772\n",
      "Epoch 34/1000\n",
      "180/180 [==============================] - 0s 728us/step - loss: 7.2151 - mae: 1.9067 - val_loss: 7.6809 - val_mae: 1.9682\n",
      "Epoch 35/1000\n",
      "180/180 [==============================] - 0s 743us/step - loss: 7.1888 - mae: 1.8981 - val_loss: 7.8164 - val_mae: 1.8863\n",
      "Epoch 36/1000\n",
      "180/180 [==============================] - 0s 727us/step - loss: 7.1887 - mae: 1.9037 - val_loss: 7.7598 - val_mae: 1.9398\n",
      "Epoch 37/1000\n",
      "180/180 [==============================] - 0s 707us/step - loss: 7.1964 - mae: 1.9045 - val_loss: 7.7209 - val_mae: 1.9838\n",
      "Epoch 38/1000\n",
      "180/180 [==============================] - 0s 752us/step - loss: 7.1786 - mae: 1.8959 - val_loss: 7.7109 - val_mae: 1.9591\n",
      "Epoch 39/1000\n",
      "180/180 [==============================] - 0s 719us/step - loss: 7.1884 - mae: 1.9071 - val_loss: 7.7647 - val_mae: 1.8737\n",
      "Epoch 40/1000\n",
      "180/180 [==============================] - 0s 694us/step - loss: 7.1791 - mae: 1.8971 - val_loss: 7.8070 - val_mae: 1.8614\n",
      "Epoch 41/1000\n",
      "180/180 [==============================] - 0s 726us/step - loss: 7.1656 - mae: 1.8976 - val_loss: 7.6939 - val_mae: 1.9790\n",
      "Epoch 42/1000\n",
      "180/180 [==============================] - 0s 708us/step - loss: 7.1714 - mae: 1.8914 - val_loss: 7.7076 - val_mae: 1.9973\n",
      "Epoch 43/1000\n",
      "180/180 [==============================] - 0s 714us/step - loss: 7.1577 - mae: 1.9035 - val_loss: 7.7005 - val_mae: 1.9639\n",
      "Epoch 44/1000\n",
      "180/180 [==============================] - 0s 706us/step - loss: 7.1620 - mae: 1.9008 - val_loss: 7.7139 - val_mae: 1.9431\n",
      "Epoch 45/1000\n",
      "180/180 [==============================] - 0s 680us/step - loss: 7.1458 - mae: 1.8869 - val_loss: 7.6955 - val_mae: 1.9688\n",
      "Epoch 46/1000\n",
      "180/180 [==============================] - 0s 710us/step - loss: 7.1593 - mae: 1.8955 - val_loss: 7.7048 - val_mae: 1.9987\n",
      "Epoch 47/1000\n",
      "180/180 [==============================] - 0s 747us/step - loss: 7.1633 - mae: 1.8962 - val_loss: 7.7222 - val_mae: 1.9832\n",
      "Epoch 48/1000\n",
      "180/180 [==============================] - 0s 750us/step - loss: 7.1453 - mae: 1.8968 - val_loss: 7.7537 - val_mae: 1.9238\n",
      "Epoch 49/1000\n",
      "180/180 [==============================] - 0s 737us/step - loss: 7.1367 - mae: 1.8974 - val_loss: 7.7996 - val_mae: 1.8639\n",
      "Epoch 50/1000\n",
      "180/180 [==============================] - 0s 727us/step - loss: 7.1381 - mae: 1.8881 - val_loss: 7.7402 - val_mae: 2.0136\n",
      "Epoch 50: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss (MSE): 7.5541605949401855, Test Mean Absolute Error (MAE): 1.9395393133163452\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<keras.src.engine.sequential.Sequential at 0x2c6cb8070>,\n",
       " {'season': ['2020-21', '2021-22'],\n",
       "  'position': 'DEF',\n",
       "  'train_mse': 7.122589588165283,\n",
       "  'train_mae': 1.949203372001648,\n",
       "  'val_mse': 7.740184307098389,\n",
       "  'val_mae': 2.0135815143585205,\n",
       "  'test_mse': 7.5541605949401855,\n",
       "  'test_mae': 1.9395393133163452,\n",
       "  'verbose': True,\n",
       "  'window_size': 3,\n",
       "  'kernel_size': 2,\n",
       "  'num_filters': 64,\n",
       "  'num_dense': 64,\n",
       "  'conv_activation': 'relu',\n",
       "  'dense_activation': 'relu',\n",
       "  'drop_low_playtime': True,\n",
       "  'low_playtime_cutoff': 15,\n",
       "  'optimizer': 'adam',\n",
       "  'learning_rate': 0.001,\n",
       "  'loss': 'mse',\n",
       "  'metrics': ['mae'],\n",
       "  'regularization': 0.0005,\n",
       "  'early_stopping': True,\n",
       "  'tolerance': 1e-05,\n",
       "  'patience': 20,\n",
       "  'standardize': True})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STANDARD_NUM_FEATURES = ['minutes', 'goals_scored', 'assists', 'goals_conceded',\n",
    "                          'clean_sheets', 'bps', 'yellow_cards', 'red_cards', \n",
    "                          'own_goals', 'saves', 'penalties_missed', 'penalties_saved',\n",
    "                          'ict_index', 'total_points']\n",
    "STANDARD_CAT_FEATURES = []\n",
    "SEED = 229\n",
    "\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "DATA_DIR = os.path.join(os.getcwd(), '..', 'data', 'clean_data')\n",
    "\n",
    "build_train_cnn(DATA_DIR,\n",
    "                season = ['2020-21', '2021-22'], \n",
    "                position = 'DEF', \n",
    "                window_size=3,\n",
    "                kernel_size=2,\n",
    "                num_filters=64,\n",
    "                num_dense=64,\n",
    "                batch_size = 32,\n",
    "                epochs = 1000,  \n",
    "                drop_low_playtime = True,\n",
    "                low_playtime_cutoff = 15,\n",
    "                num_features = ['total_points', 'clean_sheets', 'saves', 'bps'],\n",
    "                cat_features = STANDARD_CAT_FEATURES, \n",
    "                conv_activation = 'relu',\n",
    "                dense_activation = 'relu',\n",
    "                optimizer='adam',\n",
    "                learning_rate= 0.001,  \n",
    "                loss = 'mse',\n",
    "                metrics = ['mae'],\n",
    "                verbose = True,\n",
    "                regularization = 0.0005, \n",
    "                early_stopping = True, \n",
    "                tolerance = 1e-5, # only used if early stopping is turned on, threshold to define low val loss decrease\n",
    "                patience = 20,   # num of iterations before early stopping bc of low val loss decrease\n",
    "                plot = True, \n",
    "                standardize= True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.4491 - mae: 0.9632 - val_loss: 3.4063 - val_mae: 0.8426\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 924us/step - loss: 3.6519 - mae: 0.9348 - val_loss: 3.3650 - val_mae: 1.1013\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 878us/step - loss: 3.5257 - mae: 0.9329 - val_loss: 3.2219 - val_mae: 0.7165\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 867us/step - loss: 3.5422 - mae: 0.9134 - val_loss: 3.1024 - val_mae: 0.8221\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 893us/step - loss: 3.3814 - mae: 0.9086 - val_loss: 3.5800 - val_mae: 1.0960\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 835us/step - loss: 3.3686 - mae: 0.9070 - val_loss: 3.3085 - val_mae: 0.8281\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 834us/step - loss: 3.4349 - mae: 0.9239 - val_loss: 3.0727 - val_mae: 0.7983\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 830us/step - loss: 3.3810 - mae: 0.8979 - val_loss: 3.1049 - val_mae: 0.8831\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 840us/step - loss: 3.3025 - mae: 0.9419 - val_loss: 3.1094 - val_mae: 0.7210\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 3.3496 - mae: 0.9171 - val_loss: 2.9149 - val_mae: 0.8435\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 854us/step - loss: 3.2976 - mae: 0.9373 - val_loss: 2.9381 - val_mae: 0.9610\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 847us/step - loss: 3.3225 - mae: 0.9236 - val_loss: 2.9471 - val_mae: 0.7566\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 833us/step - loss: 3.2710 - mae: 0.8951 - val_loss: 2.9415 - val_mae: 0.7587\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 828us/step - loss: 3.2686 - mae: 0.8911 - val_loss: 2.9004 - val_mae: 0.8188\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 833us/step - loss: 3.2435 - mae: 0.9114 - val_loss: 2.9976 - val_mae: 0.7568\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 800us/step - loss: 3.3253 - mae: 0.9161 - val_loss: 2.8883 - val_mae: 0.7734\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 827us/step - loss: 3.2386 - mae: 0.8805 - val_loss: 3.0441 - val_mae: 0.7618\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 872us/step - loss: 3.2237 - mae: 0.8885 - val_loss: 2.9180 - val_mae: 0.7697\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 851us/step - loss: 3.2422 - mae: 0.8852 - val_loss: 2.9079 - val_mae: 0.9085\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 981us/step - loss: 3.2392 - mae: 0.8972 - val_loss: 2.8722 - val_mae: 0.7815\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 806us/step - loss: 3.2254 - mae: 0.8931 - val_loss: 2.9053 - val_mae: 0.8098\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 871us/step - loss: 3.2245 - mae: 0.8832 - val_loss: 2.8852 - val_mae: 0.8556\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 803us/step - loss: 3.2088 - mae: 0.9155 - val_loss: 2.8557 - val_mae: 0.8163\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 797us/step - loss: 3.2292 - mae: 0.8784 - val_loss: 2.9164 - val_mae: 0.9171\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 821us/step - loss: 3.2318 - mae: 0.9008 - val_loss: 2.9974 - val_mae: 0.7666\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 835us/step - loss: 3.2373 - mae: 0.9206 - val_loss: 2.8782 - val_mae: 0.7500\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 837us/step - loss: 3.2282 - mae: 0.8886 - val_loss: 2.8944 - val_mae: 0.8151\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 830us/step - loss: 3.2158 - mae: 0.8910 - val_loss: 2.8705 - val_mae: 0.7197\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 780us/step - loss: 3.2051 - mae: 0.8774 - val_loss: 2.8427 - val_mae: 0.8184\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 827us/step - loss: 3.2198 - mae: 0.9111 - val_loss: 2.8602 - val_mae: 0.7867\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 913us/step - loss: 3.2040 - mae: 0.9000 - val_loss: 2.8721 - val_mae: 0.7744\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 881us/step - loss: 3.1963 - mae: 0.8840 - val_loss: 2.8596 - val_mae: 0.7510\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 879us/step - loss: 3.1748 - mae: 0.8720 - val_loss: 2.8868 - val_mae: 0.8816\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 860us/step - loss: 3.1986 - mae: 0.8802 - val_loss: 2.8450 - val_mae: 0.8359\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 851us/step - loss: 3.1799 - mae: 0.8780 - val_loss: 2.8475 - val_mae: 0.8155\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 832us/step - loss: 3.1948 - mae: 0.8861 - val_loss: 2.8504 - val_mae: 0.8631\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 832us/step - loss: 3.2200 - mae: 0.8686 - val_loss: 3.0073 - val_mae: 0.9953\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 834us/step - loss: 3.1890 - mae: 0.8921 - val_loss: 2.8481 - val_mae: 0.7751\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 835us/step - loss: 3.1663 - mae: 0.8815 - val_loss: 2.8861 - val_mae: 0.9500\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 867us/step - loss: 3.1843 - mae: 0.8845 - val_loss: 2.8658 - val_mae: 0.8166\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 853us/step - loss: 3.1671 - mae: 0.8762 - val_loss: 2.8607 - val_mae: 0.8790\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 865us/step - loss: 3.1889 - mae: 0.9066 - val_loss: 2.8289 - val_mae: 0.7594\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 879us/step - loss: 3.2064 - mae: 0.8676 - val_loss: 2.8575 - val_mae: 0.8391\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 827us/step - loss: 3.2034 - mae: 0.9069 - val_loss: 2.8444 - val_mae: 0.8100\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 825us/step - loss: 3.1582 - mae: 0.8769 - val_loss: 2.8387 - val_mae: 0.7709\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 839us/step - loss: 3.1732 - mae: 0.8890 - val_loss: 2.8374 - val_mae: 0.7863\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 845us/step - loss: 3.1785 - mae: 0.8607 - val_loss: 2.8400 - val_mae: 0.8185\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 853us/step - loss: 3.1770 - mae: 0.8897 - val_loss: 2.8600 - val_mae: 0.8532\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 834us/step - loss: 3.1900 - mae: 0.8933 - val_loss: 2.8429 - val_mae: 0.7739\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 815us/step - loss: 3.1845 - mae: 0.9060 - val_loss: 2.8264 - val_mae: 0.7536\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 829us/step - loss: 3.1782 - mae: 0.8694 - val_loss: 2.8595 - val_mae: 0.7900\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 784us/step - loss: 3.1684 - mae: 0.8752 - val_loss: 2.8259 - val_mae: 0.7559\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 817us/step - loss: 3.1788 - mae: 0.8781 - val_loss: 2.8351 - val_mae: 0.8680\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 804us/step - loss: 3.1761 - mae: 0.8852 - val_loss: 2.8253 - val_mae: 0.8106\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 842us/step - loss: 3.1770 - mae: 0.9009 - val_loss: 2.8421 - val_mae: 0.8298\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 813us/step - loss: 3.1701 - mae: 0.8981 - val_loss: 2.8416 - val_mae: 0.7524\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 811us/step - loss: 3.1734 - mae: 0.8872 - val_loss: 2.8520 - val_mae: 0.7670\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 860us/step - loss: 3.1568 - mae: 0.8602 - val_loss: 2.8411 - val_mae: 0.8103\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 826us/step - loss: 3.1491 - mae: 0.9012 - val_loss: 2.8212 - val_mae: 0.7967\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 844us/step - loss: 3.1467 - mae: 0.8588 - val_loss: 2.8546 - val_mae: 0.7450\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 823us/step - loss: 3.1702 - mae: 0.8610 - val_loss: 2.8283 - val_mae: 0.8366\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 832us/step - loss: 3.1563 - mae: 0.9002 - val_loss: 2.8344 - val_mae: 0.9035\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 862us/step - loss: 3.1780 - mae: 0.9049 - val_loss: 2.8443 - val_mae: 0.8459\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 841us/step - loss: 3.1529 - mae: 0.8529 - val_loss: 2.8409 - val_mae: 0.8808\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 823us/step - loss: 3.1623 - mae: 0.9078 - val_loss: 2.8309 - val_mae: 0.8237\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 881us/step - loss: 3.1618 - mae: 0.8743 - val_loss: 2.8688 - val_mae: 0.8169\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 893us/step - loss: 3.1736 - mae: 0.8862 - val_loss: 2.8834 - val_mae: 0.8486\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 916us/step - loss: 3.1519 - mae: 0.8741 - val_loss: 2.8914 - val_mae: 0.7451\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 797us/step - loss: 3.1451 - mae: 0.8668 - val_loss: 2.8448 - val_mae: 0.8019\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 855us/step - loss: 3.1468 - mae: 0.8922 - val_loss: 2.8390 - val_mae: 0.7304\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 910us/step - loss: 3.1520 - mae: 0.8605 - val_loss: 2.8270 - val_mae: 0.8052\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 881us/step - loss: 3.1582 - mae: 0.8968 - val_loss: 2.8240 - val_mae: 0.7915\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 861us/step - loss: 3.1611 - mae: 0.8767 - val_loss: 2.8412 - val_mae: 0.8380\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 865us/step - loss: 3.1457 - mae: 0.8896 - val_loss: 2.8318 - val_mae: 0.7627\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 814us/step - loss: 3.1426 - mae: 0.8770 - val_loss: 2.8425 - val_mae: 0.8471\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 818us/step - loss: 3.1339 - mae: 0.8879 - val_loss: 2.8229 - val_mae: 0.7389\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 824us/step - loss: 3.1439 - mae: 0.8708 - val_loss: 2.8628 - val_mae: 0.7871\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 841us/step - loss: 3.1841 - mae: 0.8590 - val_loss: 2.8158 - val_mae: 0.7785\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 840us/step - loss: 3.1678 - mae: 0.9266 - val_loss: 2.8212 - val_mae: 0.8013\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 839us/step - loss: 3.1468 - mae: 0.8933 - val_loss: 2.9090 - val_mae: 0.7262\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 838us/step - loss: 3.1975 - mae: 0.8965 - val_loss: 2.8660 - val_mae: 0.8192\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 881us/step - loss: 3.1426 - mae: 0.8934 - val_loss: 2.8441 - val_mae: 0.8417\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 843us/step - loss: 3.1342 - mae: 0.8717 - val_loss: 2.8700 - val_mae: 0.8343\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 844us/step - loss: 3.1637 - mae: 0.8931 - val_loss: 2.8195 - val_mae: 0.8355\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 910us/step - loss: 3.1372 - mae: 0.8720 - val_loss: 2.8339 - val_mae: 0.8022\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 952us/step - loss: 3.1486 - mae: 0.9060 - val_loss: 2.8326 - val_mae: 0.7711\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 913us/step - loss: 3.1471 - mae: 0.8664 - val_loss: 2.8743 - val_mae: 0.9226\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 913us/step - loss: 3.1307 - mae: 0.8924 - val_loss: 2.8484 - val_mae: 0.7493\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 883us/step - loss: 3.1214 - mae: 0.8661 - val_loss: 2.8971 - val_mae: 0.8167\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 924us/step - loss: 3.1691 - mae: 0.8892 - val_loss: 2.8355 - val_mae: 0.8884\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 3.1409 - mae: 0.9022 - val_loss: 2.8299 - val_mae: 0.7758\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 952us/step - loss: 3.1422 - mae: 0.8825 - val_loss: 2.8457 - val_mae: 0.7517\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 926us/step - loss: 3.1528 - mae: 0.8549 - val_loss: 2.8397 - val_mae: 0.8253\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 966us/step - loss: 3.1295 - mae: 0.8833 - val_loss: 2.8342 - val_mae: 0.8261\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 916us/step - loss: 3.1367 - mae: 0.8801 - val_loss: 2.8566 - val_mae: 0.8463\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 919us/step - loss: 3.1252 - mae: 0.8825 - val_loss: 2.8476 - val_mae: 0.8095\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 903us/step - loss: 3.1575 - mae: 0.8817 - val_loss: 2.8628 - val_mae: 0.9279\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 957us/step - loss: 3.1401 - mae: 0.8849 - val_loss: 2.8479 - val_mae: 0.7642\n",
      "Epoch 98: early stopping\n",
      "Test Loss (MSE): 2.858470916748047, Test Mean Absolute Error (MAE): 0.8099737763404846\n",
      "Epoch 1/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 4.2448 - mae: 0.9520 - val_loss: 3.3139 - val_mae: 0.7324\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 919us/step - loss: 3.6103 - mae: 0.9285 - val_loss: 2.8916 - val_mae: 0.7375\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 860us/step - loss: 3.5194 - mae: 0.9135 - val_loss: 2.8170 - val_mae: 0.8080\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 832us/step - loss: 3.4630 - mae: 0.9246 - val_loss: 2.7997 - val_mae: 0.7442\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 843us/step - loss: 3.3792 - mae: 0.9194 - val_loss: 2.7455 - val_mae: 0.8190\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 859us/step - loss: 3.3545 - mae: 0.9301 - val_loss: 2.7532 - val_mae: 0.7927\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 847us/step - loss: 3.2840 - mae: 0.9100 - val_loss: 2.9611 - val_mae: 0.7309\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 854us/step - loss: 3.2877 - mae: 0.9217 - val_loss: 2.6829 - val_mae: 0.7922\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 847us/step - loss: 3.3005 - mae: 0.9245 - val_loss: 2.6912 - val_mae: 0.8176\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 843us/step - loss: 3.2897 - mae: 0.9288 - val_loss: 2.7598 - val_mae: 0.7326\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 862us/step - loss: 3.3337 - mae: 0.9295 - val_loss: 3.2795 - val_mae: 0.7420\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 834us/step - loss: 3.4419 - mae: 0.9245 - val_loss: 2.6739 - val_mae: 0.7623\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 870us/step - loss: 3.2268 - mae: 0.9225 - val_loss: 2.8412 - val_mae: 0.6460\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 859us/step - loss: 3.2870 - mae: 0.9194 - val_loss: 2.6344 - val_mae: 0.7781\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 825us/step - loss: 3.2171 - mae: 0.9157 - val_loss: 2.7168 - val_mae: 0.7277\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 856us/step - loss: 3.2375 - mae: 0.8897 - val_loss: 2.7137 - val_mae: 0.8139\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 839us/step - loss: 3.2026 - mae: 0.9285 - val_loss: 2.9685 - val_mae: 0.7361\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 809us/step - loss: 3.2103 - mae: 0.9106 - val_loss: 2.6717 - val_mae: 0.8126\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 830us/step - loss: 3.1674 - mae: 0.9012 - val_loss: 2.6608 - val_mae: 0.8230\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 837us/step - loss: 3.2323 - mae: 0.9282 - val_loss: 2.6680 - val_mae: 0.7912\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 842us/step - loss: 3.1920 - mae: 0.9155 - val_loss: 2.7201 - val_mae: 0.7804\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 790us/step - loss: 3.1983 - mae: 0.9276 - val_loss: 2.6681 - val_mae: 0.7681\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 825us/step - loss: 3.1913 - mae: 0.8902 - val_loss: 2.6606 - val_mae: 0.8036\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 829us/step - loss: 3.1913 - mae: 0.9017 - val_loss: 2.6857 - val_mae: 0.7307\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 844us/step - loss: 3.1666 - mae: 0.9110 - val_loss: 2.7722 - val_mae: 0.7286\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 812us/step - loss: 3.1894 - mae: 0.9096 - val_loss: 2.6685 - val_mae: 0.7765\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 817us/step - loss: 3.1763 - mae: 0.8860 - val_loss: 2.8529 - val_mae: 0.7666\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 827us/step - loss: 3.1845 - mae: 0.9047 - val_loss: 2.6880 - val_mae: 0.8443\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 819us/step - loss: 3.1696 - mae: 0.9017 - val_loss: 2.7518 - val_mae: 0.7237\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 822us/step - loss: 3.1576 - mae: 0.9271 - val_loss: 2.6752 - val_mae: 0.7524\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 858us/step - loss: 3.1992 - mae: 0.9089 - val_loss: 2.6876 - val_mae: 0.7254\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 851us/step - loss: 3.1424 - mae: 0.9081 - val_loss: 2.6729 - val_mae: 0.7705\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 874us/step - loss: 3.1801 - mae: 0.8914 - val_loss: 2.6988 - val_mae: 0.8180\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 815us/step - loss: 3.1464 - mae: 0.9170 - val_loss: 2.6689 - val_mae: 0.7160\n",
      "Epoch 34: early stopping\n",
      "Test Loss (MSE): 3.0955681800842285, Test Mean Absolute Error (MAE): 0.703886866569519\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 5.3219 - mae: 1.1844 - val_loss: 2.1320 - val_mae: 0.5320\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 863us/step - loss: 4.5534 - mae: 1.0864 - val_loss: 1.8389 - val_mae: 0.4938\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 912us/step - loss: 4.4820 - mae: 1.1213 - val_loss: 1.7606 - val_mae: 0.4642\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 880us/step - loss: 4.2359 - mae: 1.0671 - val_loss: 1.7021 - val_mae: 0.4781\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 882us/step - loss: 4.1611 - mae: 1.1233 - val_loss: 1.8339 - val_mae: 0.4263\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 876us/step - loss: 4.0985 - mae: 1.0812 - val_loss: 1.5652 - val_mae: 0.5062\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 873us/step - loss: 4.0510 - mae: 1.0935 - val_loss: 1.5630 - val_mae: 0.5051\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 880us/step - loss: 4.0395 - mae: 1.0709 - val_loss: 1.6198 - val_mae: 0.4284\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 855us/step - loss: 4.1295 - mae: 1.1020 - val_loss: 1.5911 - val_mae: 0.4819\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 870us/step - loss: 4.1523 - mae: 1.1180 - val_loss: 1.5385 - val_mae: 0.4639\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 867us/step - loss: 4.0464 - mae: 1.0849 - val_loss: 1.5776 - val_mae: 0.5340\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 881us/step - loss: 3.9815 - mae: 1.0927 - val_loss: 1.5310 - val_mae: 0.4660\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 855us/step - loss: 4.0354 - mae: 1.0801 - val_loss: 1.5427 - val_mae: 0.4534\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 853us/step - loss: 4.0174 - mae: 1.0844 - val_loss: 1.5221 - val_mae: 0.3988\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 857us/step - loss: 4.0848 - mae: 1.1046 - val_loss: 1.5254 - val_mae: 0.4567\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 874us/step - loss: 3.9412 - mae: 1.0893 - val_loss: 1.5824 - val_mae: 0.3927\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 874us/step - loss: 4.0563 - mae: 1.0658 - val_loss: 1.6075 - val_mae: 0.6316\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 861us/step - loss: 3.9476 - mae: 1.0881 - val_loss: 1.5075 - val_mae: 0.4856\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 843us/step - loss: 3.9873 - mae: 1.0885 - val_loss: 1.6549 - val_mae: 0.4911\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 3.9843 - mae: 1.0817 - val_loss: 1.5348 - val_mae: 0.4523\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 947us/step - loss: 3.9464 - mae: 1.0685 - val_loss: 1.5475 - val_mae: 0.4626\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 876us/step - loss: 4.0176 - mae: 1.0726 - val_loss: 1.6667 - val_mae: 0.6501\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 843us/step - loss: 3.9151 - mae: 1.0739 - val_loss: 1.6003 - val_mae: 0.5096\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 824us/step - loss: 4.1078 - mae: 1.1109 - val_loss: 1.5278 - val_mae: 0.4146\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 904us/step - loss: 3.9570 - mae: 1.0878 - val_loss: 1.5787 - val_mae: 0.4638\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 867us/step - loss: 3.9119 - mae: 1.0654 - val_loss: 1.5623 - val_mae: 0.5662\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 878us/step - loss: 3.9209 - mae: 1.0671 - val_loss: 1.5916 - val_mae: 0.5128\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 800us/step - loss: 3.9161 - mae: 1.0727 - val_loss: 1.5495 - val_mae: 0.4450\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 844us/step - loss: 3.8893 - mae: 1.0753 - val_loss: 1.5758 - val_mae: 0.3980\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 846us/step - loss: 3.8887 - mae: 1.0572 - val_loss: 1.5538 - val_mae: 0.4591\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 858us/step - loss: 3.9883 - mae: 1.0715 - val_loss: 1.7242 - val_mae: 0.4428\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 816us/step - loss: 4.0326 - mae: 1.1262 - val_loss: 1.5630 - val_mae: 0.5484\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 864us/step - loss: 3.8818 - mae: 1.0440 - val_loss: 1.5202 - val_mae: 0.3887\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 837us/step - loss: 3.8690 - mae: 1.0471 - val_loss: 1.5684 - val_mae: 0.5208\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 870us/step - loss: 3.8472 - mae: 1.0648 - val_loss: 1.5909 - val_mae: 0.4273\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 867us/step - loss: 3.8815 - mae: 1.0603 - val_loss: 1.5770 - val_mae: 0.5178\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 858us/step - loss: 3.8712 - mae: 1.0775 - val_loss: 1.6084 - val_mae: 0.3936\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 898us/step - loss: 3.9311 - mae: 1.0668 - val_loss: 1.5574 - val_mae: 0.4949\n",
      "Epoch 38: early stopping\n",
      "Test Loss (MSE): 2.3173272609710693, Test Mean Absolute Error (MAE): 0.7147079110145569\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 3.8812 - mae: 0.8293 - val_loss: 4.0157 - val_mae: 0.8547\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 921us/step - loss: 3.3143 - mae: 0.8243 - val_loss: 3.7537 - val_mae: 0.9074\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 890us/step - loss: 3.2555 - mae: 0.7906 - val_loss: 3.6973 - val_mae: 0.8856\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 913us/step - loss: 3.1127 - mae: 0.7999 - val_loss: 3.9063 - val_mae: 0.7885\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 849us/step - loss: 3.0621 - mae: 0.8285 - val_loss: 3.6489 - val_mae: 0.7848\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 898us/step - loss: 2.9455 - mae: 0.7927 - val_loss: 3.5576 - val_mae: 0.8681\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 863us/step - loss: 2.8848 - mae: 0.7964 - val_loss: 3.7017 - val_mae: 0.8227\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 865us/step - loss: 2.9005 - mae: 0.7914 - val_loss: 3.6012 - val_mae: 0.8064\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 891us/step - loss: 2.8203 - mae: 0.7902 - val_loss: 3.5597 - val_mae: 0.8371\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 864us/step - loss: 2.8979 - mae: 0.7862 - val_loss: 3.5093 - val_mae: 0.8399\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 902us/step - loss: 2.7886 - mae: 0.7893 - val_loss: 3.4032 - val_mae: 0.8823\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 881us/step - loss: 2.8631 - mae: 0.8119 - val_loss: 3.7740 - val_mae: 0.9523\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 862us/step - loss: 2.8522 - mae: 0.7906 - val_loss: 3.5173 - val_mae: 1.0061\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 860us/step - loss: 2.8180 - mae: 0.8380 - val_loss: 3.5427 - val_mae: 0.9351\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 866us/step - loss: 2.7810 - mae: 0.7813 - val_loss: 3.4772 - val_mae: 0.8936\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 881us/step - loss: 2.7496 - mae: 0.7743 - val_loss: 3.4030 - val_mae: 0.8807\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 859us/step - loss: 2.7817 - mae: 0.7876 - val_loss: 3.6282 - val_mae: 0.8502\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 921us/step - loss: 2.7756 - mae: 0.7758 - val_loss: 3.5926 - val_mae: 0.8645\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 861us/step - loss: 2.7545 - mae: 0.7758 - val_loss: 3.5666 - val_mae: 0.8850\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 897us/step - loss: 2.7793 - mae: 0.7924 - val_loss: 3.4969 - val_mae: 0.8080\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 868us/step - loss: 2.8485 - mae: 0.7844 - val_loss: 3.5120 - val_mae: 0.8515\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 858us/step - loss: 2.8020 - mae: 0.7877 - val_loss: 3.5548 - val_mae: 0.8331\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 860us/step - loss: 2.7576 - mae: 0.7648 - val_loss: 3.6656 - val_mae: 0.7933\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 887us/step - loss: 2.7004 - mae: 0.7809 - val_loss: 3.4854 - val_mae: 0.8373\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 912us/step - loss: 2.7322 - mae: 0.7890 - val_loss: 3.5076 - val_mae: 0.8254\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 886us/step - loss: 2.7422 - mae: 0.7748 - val_loss: 3.4637 - val_mae: 0.9395\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 870us/step - loss: 2.7109 - mae: 0.7770 - val_loss: 3.5015 - val_mae: 0.8381\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 881us/step - loss: 2.7260 - mae: 0.7682 - val_loss: 3.5169 - val_mae: 0.8707\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 897us/step - loss: 2.7350 - mae: 0.7927 - val_loss: 3.5387 - val_mae: 0.8273\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 932us/step - loss: 2.7102 - mae: 0.7868 - val_loss: 3.5707 - val_mae: 0.9425\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 882us/step - loss: 2.7056 - mae: 0.7826 - val_loss: 3.4978 - val_mae: 0.8298\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 865us/step - loss: 2.7127 - mae: 0.7646 - val_loss: 3.5027 - val_mae: 0.8464\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 857us/step - loss: 2.6913 - mae: 0.7659 - val_loss: 3.4703 - val_mae: 0.8447\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 866us/step - loss: 2.6635 - mae: 0.7643 - val_loss: 3.5074 - val_mae: 0.9006\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 883us/step - loss: 2.6570 - mae: 0.7811 - val_loss: 3.5232 - val_mae: 0.9177\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 884us/step - loss: 2.6895 - mae: 0.7763 - val_loss: 3.5382 - val_mae: 0.8456\n",
      "Epoch 36: early stopping\n",
      "Test Loss (MSE): 3.5925183296203613, Test Mean Absolute Error (MAE): 0.9161204099655151\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.4392 - mae: 2.7938 - val_loss: 10.4255 - val_mae: 2.1727\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 11.6283 - mae: 2.4240 - val_loss: 11.8391 - val_mae: 2.9835\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 10.2074 - mae: 2.4917 - val_loss: 8.4398 - val_mae: 2.1240\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.5178 - mae: 2.4361 - val_loss: 8.2895 - val_mae: 2.3167\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.1794 - mae: 2.3214 - val_loss: 8.0733 - val_mae: 2.2841\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.2405 - mae: 2.4216 - val_loss: 7.7897 - val_mae: 2.1559\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.8489 - mae: 2.3895 - val_loss: 7.9066 - val_mae: 2.3306\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.8139 - mae: 2.3972 - val_loss: 7.5740 - val_mae: 2.1419\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.8799 - mae: 2.3638 - val_loss: 7.6238 - val_mae: 1.9921\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.0508 - mae: 2.4101 - val_loss: 7.6773 - val_mae: 1.9956\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.7703 - mae: 2.4068 - val_loss: 7.4630 - val_mae: 2.0462\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.7325 - mae: 2.2932 - val_loss: 7.7907 - val_mae: 2.3721\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.6376 - mae: 2.3305 - val_loss: 7.3736 - val_mae: 2.1635\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.6253 - mae: 2.4149 - val_loss: 7.6647 - val_mae: 2.3088\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.6175 - mae: 2.2987 - val_loss: 8.0634 - val_mae: 2.4430\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.9730 - mae: 2.4179 - val_loss: 8.5217 - val_mae: 2.5946\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.0101 - mae: 2.3728 - val_loss: 7.7106 - val_mae: 2.3490\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.7532 - mae: 2.4294 - val_loss: 7.3585 - val_mae: 2.1246\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.5741 - mae: 2.3719 - val_loss: 7.3115 - val_mae: 2.0545\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.4844 - mae: 2.3199 - val_loss: 7.6568 - val_mae: 2.3356\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.4587 - mae: 2.3393 - val_loss: 7.7120 - val_mae: 2.3665\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.4196 - mae: 2.3688 - val_loss: 7.3275 - val_mae: 2.0158\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.3711 - mae: 2.3024 - val_loss: 8.1004 - val_mae: 2.4781\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.7008 - mae: 2.3649 - val_loss: 7.7576 - val_mae: 2.3502\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.4431 - mae: 2.3275 - val_loss: 7.3578 - val_mae: 2.0122\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.3881 - mae: 2.3391 - val_loss: 7.4570 - val_mae: 2.2354\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.4048 - mae: 2.3341 - val_loss: 7.3463 - val_mae: 2.1879\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.3965 - mae: 2.3341 - val_loss: 7.3462 - val_mae: 2.1806\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.3671 - mae: 2.3366 - val_loss: 7.4348 - val_mae: 2.2465\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.3599 - mae: 2.3174 - val_loss: 7.2791 - val_mae: 2.1747\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.2958 - mae: 2.3159 - val_loss: 7.4272 - val_mae: 2.2508\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.3839 - mae: 2.3429 - val_loss: 7.2471 - val_mae: 2.0299\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.3670 - mae: 2.3632 - val_loss: 7.2833 - val_mae: 2.1873\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.3219 - mae: 2.3373 - val_loss: 7.2708 - val_mae: 1.9970\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.6102 - mae: 2.3783 - val_loss: 7.7810 - val_mae: 2.3701\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.4851 - mae: 2.2772 - val_loss: 7.6492 - val_mae: 2.3325\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.3186 - mae: 2.3396 - val_loss: 7.2455 - val_mae: 2.1221\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.3399 - mae: 2.3205 - val_loss: 7.2445 - val_mae: 2.1020\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.2679 - mae: 2.3193 - val_loss: 7.2576 - val_mae: 2.1274\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.2652 - mae: 2.3590 - val_loss: 7.3156 - val_mae: 1.9791\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.6502 - mae: 2.2800 - val_loss: 8.2524 - val_mae: 2.5111\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.2918 - mae: 2.3168 - val_loss: 7.2152 - val_mae: 2.0943\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.2270 - mae: 2.3128 - val_loss: 7.5640 - val_mae: 2.2971\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.3210 - mae: 2.2792 - val_loss: 7.4335 - val_mae: 2.2520\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.2213 - mae: 2.3504 - val_loss: 7.3541 - val_mae: 1.9251\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.4590 - mae: 2.2654 - val_loss: 8.0023 - val_mae: 2.4456\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.3894 - mae: 2.2904 - val_loss: 7.7226 - val_mae: 2.3543\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.4737 - mae: 2.3637 - val_loss: 7.3339 - val_mae: 1.9222\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.2728 - mae: 2.3226 - val_loss: 7.3464 - val_mae: 2.1532\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.2511 - mae: 2.3107 - val_loss: 7.3817 - val_mae: 2.1944\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.1978 - mae: 2.2697 - val_loss: 7.6257 - val_mae: 2.3054\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.2570 - mae: 2.3140 - val_loss: 7.4455 - val_mae: 2.2380\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.2014 - mae: 2.2999 - val_loss: 7.4258 - val_mae: 2.2035\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.1966 - mae: 2.3047 - val_loss: 7.4357 - val_mae: 2.2194\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.1345 - mae: 2.2650 - val_loss: 7.5439 - val_mae: 2.2730\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.1554 - mae: 2.3017 - val_loss: 7.3729 - val_mae: 2.1381\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.0927 - mae: 2.2837 - val_loss: 7.4087 - val_mae: 2.1438\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.1417 - mae: 2.3000 - val_loss: 7.3014 - val_mae: 2.1057\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.2130 - mae: 2.2893 - val_loss: 7.3339 - val_mae: 2.1283\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.1436 - mae: 2.2971 - val_loss: 7.3366 - val_mae: 2.0604\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.4289 - mae: 2.3037 - val_loss: 8.0973 - val_mae: 2.4463\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.0248 - mae: 2.2724 - val_loss: 7.3601 - val_mae: 1.9542\n",
      "Epoch 62: early stopping\n",
      "Test Loss (MSE): 10.392147064208984, Test Mean Absolute Error (MAE): 2.314913272857666\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 11.6673 - mae: 2.4229 - val_loss: 9.1191 - val_mae: 2.2813\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 9.3493 - mae: 2.2474 - val_loss: 9.0834 - val_mae: 2.1596\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 9.2080 - mae: 2.1898 - val_loss: 9.6748 - val_mae: 2.1471\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 9.2306 - mae: 2.2263 - val_loss: 8.6439 - val_mae: 2.3169\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.7368 - mae: 2.1761 - val_loss: 8.6424 - val_mae: 2.3643\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.6537 - mae: 2.2153 - val_loss: 8.9841 - val_mae: 2.2202\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.4663 - mae: 2.2085 - val_loss: 9.0416 - val_mae: 2.1743\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.6364 - mae: 2.1585 - val_loss: 8.7555 - val_mae: 2.2234\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.8667 - mae: 2.2125 - val_loss: 8.7452 - val_mae: 2.2758\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.2071 - mae: 2.1064 - val_loss: 8.6654 - val_mae: 2.2925\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.2340 - mae: 2.1146 - val_loss: 9.0841 - val_mae: 2.4712\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.3603 - mae: 2.1289 - val_loss: 8.9679 - val_mae: 2.4386\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.3151 - mae: 2.2348 - val_loss: 8.9676 - val_mae: 2.1506\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.0507 - mae: 2.1359 - val_loss: 8.7369 - val_mae: 2.3358\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.0140 - mae: 2.1341 - val_loss: 8.6994 - val_mae: 2.2495\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.1287 - mae: 2.1010 - val_loss: 9.2825 - val_mae: 2.5173\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.1587 - mae: 2.1635 - val_loss: 8.6494 - val_mae: 2.2884\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.8480 - mae: 2.1492 - val_loss: 8.6995 - val_mae: 2.3160\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.8815 - mae: 2.1630 - val_loss: 8.8638 - val_mae: 2.2487\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.9518 - mae: 2.0632 - val_loss: 9.8865 - val_mae: 2.6072\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.5778 - mae: 2.1329 - val_loss: 8.9046 - val_mae: 2.3018\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.9259 - mae: 2.1373 - val_loss: 8.7108 - val_mae: 2.2780\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.8260 - mae: 2.1605 - val_loss: 8.7616 - val_mae: 2.2616\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.2540 - mae: 2.1108 - val_loss: 9.0812 - val_mae: 2.3886\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.8211 - mae: 2.0800 - val_loss: 8.8057 - val_mae: 2.3051\n",
      "Epoch 25: early stopping\n",
      "Test Loss (MSE): 8.873567581176758, Test Mean Absolute Error (MAE): 2.209059476852417\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 10.8820 - mae: 2.2012 - val_loss: 11.0404 - val_mae: 2.5730\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.9403 - mae: 2.1643 - val_loss: 11.3262 - val_mae: 2.5466\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.4249 - mae: 2.0086 - val_loss: 10.9201 - val_mae: 2.5652\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.2274 - mae: 2.0867 - val_loss: 11.3327 - val_mae: 2.5324\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.2845 - mae: 2.0025 - val_loss: 10.4999 - val_mae: 2.6185\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 7.9518 - mae: 1.9735 - val_loss: 10.7217 - val_mae: 2.5834\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 7.8488 - mae: 2.0481 - val_loss: 11.1488 - val_mae: 2.5532\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.1450 - mae: 2.0244 - val_loss: 10.7130 - val_mae: 2.5478\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.6802 - mae: 1.9708 - val_loss: 11.6469 - val_mae: 2.8613\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 10.0375 - mae: 2.2599 - val_loss: 11.9176 - val_mae: 2.6012\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.1699 - mae: 2.0916 - val_loss: 10.3587 - val_mae: 2.5923\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.9695 - mae: 1.9458 - val_loss: 10.2664 - val_mae: 2.6390\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.0898 - mae: 2.2375 - val_loss: 11.0942 - val_mae: 2.5522\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.6533 - mae: 1.9928 - val_loss: 10.5656 - val_mae: 2.5686\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.8712 - mae: 1.9539 - val_loss: 11.1264 - val_mae: 2.7677\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.1318 - mae: 2.1085 - val_loss: 13.0159 - val_mae: 2.5829\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.0794 - mae: 2.0048 - val_loss: 10.6764 - val_mae: 2.5869\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.6070 - mae: 1.9856 - val_loss: 10.8272 - val_mae: 2.5922\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.4235 - mae: 1.9675 - val_loss: 11.9304 - val_mae: 2.5437\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.3100 - mae: 1.8779 - val_loss: 10.9365 - val_mae: 2.6158\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.2382 - mae: 1.8845 - val_loss: 10.8590 - val_mae: 2.6135\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.4264 - mae: 1.9206 - val_loss: 11.1321 - val_mae: 2.5784\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.2386 - mae: 1.9480 - val_loss: 11.3833 - val_mae: 2.5989\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.2328 - mae: 1.9551 - val_loss: 11.4279 - val_mae: 2.6153\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.1171 - mae: 1.8442 - val_loss: 12.0251 - val_mae: 2.8308\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 8.0354 - mae: 2.0931 - val_loss: 11.5477 - val_mae: 2.6150\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.8582 - mae: 2.0614 - val_loss: 11.2914 - val_mae: 2.6029\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.4625 - mae: 1.9047 - val_loss: 10.8912 - val_mae: 2.6279\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 7.1192 - mae: 1.9003 - val_loss: 11.3342 - val_mae: 2.5773\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 6.9427 - mae: 1.8418 - val_loss: 10.9286 - val_mae: 2.6524\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 6.9018 - mae: 1.9007 - val_loss: 11.6911 - val_mae: 2.6172\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 6.8133 - mae: 1.8485 - val_loss: 11.6571 - val_mae: 2.6192\n",
      "Epoch 32: early stopping\n",
      "Test Loss (MSE): 8.255454063415527, Test Mean Absolute Error (MAE): 2.0549633502960205\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.0496 - mae: 2.7118 - val_loss: 8.9734 - val_mae: 2.1268\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 10.3850 - mae: 2.5380 - val_loss: 9.0460 - val_mae: 2.1584\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 10.1823 - mae: 2.4193 - val_loss: 9.7962 - val_mae: 2.5847\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 10.0273 - mae: 2.3598 - val_loss: 9.4497 - val_mae: 2.5090\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 10.1211 - mae: 2.4652 - val_loss: 8.6769 - val_mae: 2.2630\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.4090 - mae: 2.4835 - val_loss: 8.8808 - val_mae: 2.2821\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 9.2162 - mae: 2.3786 - val_loss: 8.7791 - val_mae: 2.3995\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 9.2927 - mae: 2.4624 - val_loss: 8.8077 - val_mae: 2.2675\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 9.0037 - mae: 2.4237 - val_loss: 8.5986 - val_mae: 2.1928\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.0639 - mae: 2.3632 - val_loss: 9.0370 - val_mae: 2.4745\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.0524 - mae: 2.4111 - val_loss: 8.7168 - val_mae: 2.2189\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.9933 - mae: 2.4093 - val_loss: 8.4706 - val_mae: 2.2044\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.7690 - mae: 2.3774 - val_loss: 9.4814 - val_mae: 2.5743\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.0162 - mae: 2.4169 - val_loss: 8.6048 - val_mae: 2.2717\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.8231 - mae: 2.4125 - val_loss: 8.9326 - val_mae: 2.4345\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.8679 - mae: 2.3954 - val_loss: 9.1102 - val_mae: 2.4716\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.8375 - mae: 2.3836 - val_loss: 9.1540 - val_mae: 2.4274\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.9241 - mae: 2.3548 - val_loss: 9.4173 - val_mae: 2.5684\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.8741 - mae: 2.3628 - val_loss: 8.7290 - val_mae: 2.0963\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.9633 - mae: 2.4036 - val_loss: 8.8212 - val_mae: 2.1991\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.4939 - mae: 2.3656 - val_loss: 9.0420 - val_mae: 2.3298\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.4281 - mae: 2.3223 - val_loss: 8.7206 - val_mae: 2.2372\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.4144 - mae: 2.2831 - val_loss: 9.6636 - val_mae: 2.5370\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.3209 - mae: 2.3001 - val_loss: 9.1673 - val_mae: 2.0417\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.4411 - mae: 2.3062 - val_loss: 9.0258 - val_mae: 2.3385\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.3042 - mae: 2.3134 - val_loss: 9.1218 - val_mae: 2.3579\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.1800 - mae: 2.2550 - val_loss: 9.1806 - val_mae: 2.3319\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.2933 - mae: 2.3001 - val_loss: 9.1702 - val_mae: 2.3606\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.9611 - mae: 2.2695 - val_loss: 9.1679 - val_mae: 2.2029\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 7.8623 - mae: 2.2155 - val_loss: 9.6996 - val_mae: 2.4351\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.9382 - mae: 2.2610 - val_loss: 9.7070 - val_mae: 2.4666\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.8207 - mae: 2.1472 - val_loss: 9.4773 - val_mae: 2.3052\n",
      "Epoch 32: early stopping\n",
      "Test Loss (MSE): 7.403448581695557, Test Mean Absolute Error (MAE): 2.0356602668762207\n",
      "Epoch 1/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 3.4649 - mae: 0.7393 - val_loss: 4.9993 - val_mae: 1.2577\n",
      "Epoch 2/100\n",
      "45/45 [==============================] - 0s 904us/step - loss: 2.8595 - mae: 0.7288 - val_loss: 4.6549 - val_mae: 1.3331\n",
      "Epoch 3/100\n",
      "45/45 [==============================] - 0s 848us/step - loss: 2.6954 - mae: 0.7113 - val_loss: 4.5621 - val_mae: 1.0725\n",
      "Epoch 4/100\n",
      "45/45 [==============================] - 0s 848us/step - loss: 2.5525 - mae: 0.6728 - val_loss: 4.4855 - val_mae: 1.1094\n",
      "Epoch 5/100\n",
      "45/45 [==============================] - 0s 823us/step - loss: 2.6041 - mae: 0.6997 - val_loss: 4.3208 - val_mae: 1.1020\n",
      "Epoch 6/100\n",
      "45/45 [==============================] - 0s 829us/step - loss: 2.5436 - mae: 0.6848 - val_loss: 4.3062 - val_mae: 1.2023\n",
      "Epoch 7/100\n",
      "45/45 [==============================] - 0s 834us/step - loss: 2.5265 - mae: 0.6850 - val_loss: 4.5157 - val_mae: 1.3096\n",
      "Epoch 8/100\n",
      "45/45 [==============================] - 0s 863us/step - loss: 2.6381 - mae: 0.7073 - val_loss: 4.3356 - val_mae: 1.0639\n",
      "Epoch 9/100\n",
      "45/45 [==============================] - 0s 824us/step - loss: 2.5142 - mae: 0.6751 - val_loss: 4.4094 - val_mae: 1.3508\n",
      "Epoch 10/100\n",
      "45/45 [==============================] - 0s 817us/step - loss: 2.5050 - mae: 0.6991 - val_loss: 4.1779 - val_mae: 1.1966\n",
      "Epoch 11/100\n",
      "45/45 [==============================] - 0s 839us/step - loss: 2.5660 - mae: 0.6721 - val_loss: 4.2052 - val_mae: 1.2144\n",
      "Epoch 12/100\n",
      "45/45 [==============================] - 0s 825us/step - loss: 2.4830 - mae: 0.7049 - val_loss: 4.2887 - val_mae: 1.2524\n",
      "Epoch 13/100\n",
      "45/45 [==============================] - 0s 846us/step - loss: 2.4806 - mae: 0.6704 - val_loss: 4.1794 - val_mae: 1.1486\n",
      "Epoch 14/100\n",
      "45/45 [==============================] - 0s 806us/step - loss: 2.5012 - mae: 0.6810 - val_loss: 4.3149 - val_mae: 1.2690\n",
      "Epoch 15/100\n",
      "45/45 [==============================] - 0s 825us/step - loss: 2.4836 - mae: 0.6873 - val_loss: 4.1568 - val_mae: 1.1216\n",
      "Epoch 16/100\n",
      "45/45 [==============================] - 0s 848us/step - loss: 2.5056 - mae: 0.6644 - val_loss: 4.1832 - val_mae: 1.0988\n",
      "Epoch 17/100\n",
      "45/45 [==============================] - 0s 831us/step - loss: 2.4930 - mae: 0.6958 - val_loss: 4.1819 - val_mae: 1.1549\n",
      "Epoch 18/100\n",
      "45/45 [==============================] - 0s 838us/step - loss: 2.5201 - mae: 0.6658 - val_loss: 4.1596 - val_mae: 1.1923\n",
      "Epoch 19/100\n",
      "45/45 [==============================] - 0s 848us/step - loss: 2.4617 - mae: 0.6854 - val_loss: 4.1451 - val_mae: 1.1572\n",
      "Epoch 20/100\n",
      "45/45 [==============================] - 0s 808us/step - loss: 2.4658 - mae: 0.6771 - val_loss: 4.1854 - val_mae: 1.2013\n",
      "Epoch 21/100\n",
      "45/45 [==============================] - 0s 797us/step - loss: 2.4467 - mae: 0.6640 - val_loss: 4.1449 - val_mae: 1.1676\n",
      "Epoch 22/100\n",
      "45/45 [==============================] - 0s 824us/step - loss: 2.4474 - mae: 0.6661 - val_loss: 4.1685 - val_mae: 1.1666\n",
      "Epoch 23/100\n",
      "45/45 [==============================] - 0s 812us/step - loss: 2.4294 - mae: 0.6922 - val_loss: 4.2503 - val_mae: 1.2243\n",
      "Epoch 24/100\n",
      "45/45 [==============================] - 0s 837us/step - loss: 2.4654 - mae: 0.6689 - val_loss: 4.2855 - val_mae: 1.2723\n",
      "Epoch 25/100\n",
      "45/45 [==============================] - 0s 840us/step - loss: 2.4821 - mae: 0.6800 - val_loss: 4.3530 - val_mae: 1.2381\n",
      "Epoch 26/100\n",
      "45/45 [==============================] - 0s 806us/step - loss: 2.4448 - mae: 0.6700 - val_loss: 4.1652 - val_mae: 1.1167\n",
      "Epoch 27/100\n",
      "45/45 [==============================] - 0s 820us/step - loss: 2.4630 - mae: 0.6892 - val_loss: 4.2034 - val_mae: 1.1746\n",
      "Epoch 28/100\n",
      "45/45 [==============================] - 0s 815us/step - loss: 2.4393 - mae: 0.6755 - val_loss: 4.1723 - val_mae: 1.1451\n",
      "Epoch 29/100\n",
      "45/45 [==============================] - 0s 840us/step - loss: 2.4589 - mae: 0.6727 - val_loss: 4.1562 - val_mae: 1.1831\n",
      "Epoch 30/100\n",
      "45/45 [==============================] - 0s 820us/step - loss: 2.4391 - mae: 0.6757 - val_loss: 4.2768 - val_mae: 1.2141\n",
      "Epoch 31/100\n",
      "45/45 [==============================] - 0s 822us/step - loss: 2.4699 - mae: 0.6759 - val_loss: 4.5310 - val_mae: 1.2843\n",
      "Epoch 32/100\n",
      "45/45 [==============================] - 0s 813us/step - loss: 2.4587 - mae: 0.6892 - val_loss: 4.2198 - val_mae: 1.1527\n",
      "Epoch 33/100\n",
      "45/45 [==============================] - 0s 834us/step - loss: 2.4248 - mae: 0.6739 - val_loss: 4.1558 - val_mae: 1.1819\n",
      "Epoch 34/100\n",
      "45/45 [==============================] - 0s 803us/step - loss: 2.4444 - mae: 0.6687 - val_loss: 4.1298 - val_mae: 1.1533\n",
      "Epoch 35/100\n",
      "45/45 [==============================] - 0s 918us/step - loss: 2.4224 - mae: 0.6820 - val_loss: 4.1825 - val_mae: 1.2234\n",
      "Epoch 36/100\n",
      "45/45 [==============================] - 0s 851us/step - loss: 2.4426 - mae: 0.6750 - val_loss: 4.1795 - val_mae: 1.1619\n",
      "Epoch 37/100\n",
      "45/45 [==============================] - 0s 815us/step - loss: 2.4367 - mae: 0.6974 - val_loss: 4.1941 - val_mae: 1.2093\n",
      "Epoch 38/100\n",
      "45/45 [==============================] - 0s 815us/step - loss: 2.4154 - mae: 0.6708 - val_loss: 4.1818 - val_mae: 1.0884\n",
      "Epoch 39/100\n",
      "45/45 [==============================] - 0s 807us/step - loss: 2.4233 - mae: 0.6779 - val_loss: 4.2410 - val_mae: 1.2116\n",
      "Epoch 40/100\n",
      "45/45 [==============================] - 0s 825us/step - loss: 2.4516 - mae: 0.6537 - val_loss: 4.2450 - val_mae: 1.2139\n",
      "Epoch 41/100\n",
      "45/45 [==============================] - 0s 847us/step - loss: 2.4196 - mae: 0.6832 - val_loss: 4.4466 - val_mae: 1.2578\n",
      "Epoch 42/100\n",
      "45/45 [==============================] - 0s 806us/step - loss: 2.4670 - mae: 0.6667 - val_loss: 4.2124 - val_mae: 1.1664\n",
      "Epoch 43/100\n",
      "45/45 [==============================] - 0s 831us/step - loss: 2.4090 - mae: 0.6647 - val_loss: 4.2132 - val_mae: 1.1978\n",
      "Epoch 44/100\n",
      "45/45 [==============================] - 0s 806us/step - loss: 2.4178 - mae: 0.6756 - val_loss: 4.2073 - val_mae: 1.1034\n",
      "Epoch 45/100\n",
      "45/45 [==============================] - 0s 837us/step - loss: 2.4071 - mae: 0.6651 - val_loss: 4.2277 - val_mae: 1.1735\n",
      "Epoch 46/100\n",
      "45/45 [==============================] - 0s 836us/step - loss: 2.4178 - mae: 0.6639 - val_loss: 4.1921 - val_mae: 1.2142\n",
      "Epoch 47/100\n",
      "45/45 [==============================] - 0s 846us/step - loss: 2.4151 - mae: 0.6728 - val_loss: 4.1704 - val_mae: 1.1641\n",
      "Epoch 48/100\n",
      "45/45 [==============================] - 0s 864us/step - loss: 2.4012 - mae: 0.6834 - val_loss: 4.2029 - val_mae: 1.1430\n",
      "Epoch 49/100\n",
      "45/45 [==============================] - 0s 815us/step - loss: 2.4237 - mae: 0.6638 - val_loss: 4.2254 - val_mae: 1.1860\n",
      "Epoch 50/100\n",
      "45/45 [==============================] - 0s 841us/step - loss: 2.4270 - mae: 0.6713 - val_loss: 4.1578 - val_mae: 1.1562\n",
      "Epoch 51/100\n",
      "45/45 [==============================] - 0s 838us/step - loss: 2.3929 - mae: 0.6769 - val_loss: 4.2469 - val_mae: 1.1171\n",
      "Epoch 52/100\n",
      "45/45 [==============================] - 0s 837us/step - loss: 2.4280 - mae: 0.6658 - val_loss: 4.2943 - val_mae: 1.2041\n",
      "Epoch 53/100\n",
      "45/45 [==============================] - 0s 826us/step - loss: 2.4454 - mae: 0.6957 - val_loss: 4.2225 - val_mae: 1.1231\n",
      "Epoch 54/100\n",
      "45/45 [==============================] - 0s 826us/step - loss: 2.4452 - mae: 0.6604 - val_loss: 4.1884 - val_mae: 1.2179\n",
      "Epoch 54: early stopping\n",
      "Test Loss (MSE): 3.1932966709136963, Test Mean Absolute Error (MAE): 0.9468332529067993\n",
      "Epoch 1/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 3.3990 - mae: 0.7344 - val_loss: 4.3214 - val_mae: 1.0265\n",
      "Epoch 2/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 2.9118 - mae: 0.6883 - val_loss: 4.1236 - val_mae: 1.0144\n",
      "Epoch 3/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 2.7910 - mae: 0.7114 - val_loss: 4.2146 - val_mae: 1.0047\n",
      "Epoch 4/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 2.6960 - mae: 0.6956 - val_loss: 4.0694 - val_mae: 1.0234\n",
      "Epoch 5/100\n",
      "45/45 [==============================] - 0s 950us/step - loss: 2.5833 - mae: 0.6818 - val_loss: 4.0451 - val_mae: 1.1316\n",
      "Epoch 6/100\n",
      "45/45 [==============================] - 0s 882us/step - loss: 2.5955 - mae: 0.6811 - val_loss: 3.9882 - val_mae: 1.0122\n",
      "Epoch 7/100\n",
      "45/45 [==============================] - 0s 913us/step - loss: 2.5978 - mae: 0.6854 - val_loss: 4.0542 - val_mae: 1.1626\n",
      "Epoch 8/100\n",
      "45/45 [==============================] - 0s 817us/step - loss: 2.5414 - mae: 0.7012 - val_loss: 4.0190 - val_mae: 1.1498\n",
      "Epoch 9/100\n",
      "45/45 [==============================] - 0s 883us/step - loss: 2.6460 - mae: 0.7137 - val_loss: 4.5904 - val_mae: 1.2303\n",
      "Epoch 10/100\n",
      "45/45 [==============================] - 0s 889us/step - loss: 2.5595 - mae: 0.6770 - val_loss: 3.9516 - val_mae: 1.0434\n",
      "Epoch 11/100\n",
      "45/45 [==============================] - 0s 873us/step - loss: 2.5601 - mae: 0.7031 - val_loss: 3.9802 - val_mae: 1.0967\n",
      "Epoch 12/100\n",
      "45/45 [==============================] - 0s 894us/step - loss: 2.5952 - mae: 0.6851 - val_loss: 4.2891 - val_mae: 0.9981\n",
      "Epoch 13/100\n",
      "45/45 [==============================] - 0s 878us/step - loss: 2.6267 - mae: 0.7072 - val_loss: 3.9452 - val_mae: 1.0320\n",
      "Epoch 14/100\n",
      "45/45 [==============================] - 0s 889us/step - loss: 2.5846 - mae: 0.6828 - val_loss: 3.9529 - val_mae: 1.0685\n",
      "Epoch 15/100\n",
      "45/45 [==============================] - 0s 890us/step - loss: 2.5009 - mae: 0.6934 - val_loss: 3.9229 - val_mae: 1.0646\n",
      "Epoch 16/100\n",
      "45/45 [==============================] - 0s 870us/step - loss: 2.4937 - mae: 0.6845 - val_loss: 3.9953 - val_mae: 1.1121\n",
      "Epoch 17/100\n",
      "45/45 [==============================] - 0s 888us/step - loss: 2.5416 - mae: 0.6804 - val_loss: 3.8992 - val_mae: 1.0918\n",
      "Epoch 18/100\n",
      "45/45 [==============================] - 0s 847us/step - loss: 2.4941 - mae: 0.6770 - val_loss: 3.9057 - val_mae: 1.1353\n",
      "Epoch 19/100\n",
      "45/45 [==============================] - 0s 877us/step - loss: 2.4931 - mae: 0.6978 - val_loss: 4.0390 - val_mae: 1.0350\n",
      "Epoch 20/100\n",
      "45/45 [==============================] - 0s 838us/step - loss: 2.5129 - mae: 0.6956 - val_loss: 3.9356 - val_mae: 1.0498\n",
      "Epoch 21/100\n",
      "45/45 [==============================] - 0s 960us/step - loss: 2.5132 - mae: 0.6776 - val_loss: 3.9668 - val_mae: 1.0632\n",
      "Epoch 22/100\n",
      "45/45 [==============================] - 0s 908us/step - loss: 2.5066 - mae: 0.6917 - val_loss: 3.9550 - val_mae: 1.0321\n",
      "Epoch 23/100\n",
      "45/45 [==============================] - 0s 880us/step - loss: 2.4854 - mae: 0.6939 - val_loss: 3.9323 - val_mae: 1.0510\n",
      "Epoch 24/100\n",
      "45/45 [==============================] - 0s 871us/step - loss: 2.4992 - mae: 0.6968 - val_loss: 4.0437 - val_mae: 1.0964\n",
      "Epoch 25/100\n",
      "45/45 [==============================] - 0s 884us/step - loss: 2.5957 - mae: 0.6643 - val_loss: 4.0858 - val_mae: 0.9774\n",
      "Epoch 26/100\n",
      "45/45 [==============================] - 0s 914us/step - loss: 2.5470 - mae: 0.7032 - val_loss: 4.1112 - val_mae: 1.1361\n",
      "Epoch 27/100\n",
      "45/45 [==============================] - 0s 874us/step - loss: 2.5078 - mae: 0.6807 - val_loss: 4.1060 - val_mae: 1.0198\n",
      "Epoch 28/100\n",
      "45/45 [==============================] - 0s 880us/step - loss: 2.5406 - mae: 0.6993 - val_loss: 3.9664 - val_mae: 1.0234\n",
      "Epoch 29/100\n",
      "45/45 [==============================] - 0s 854us/step - loss: 2.5520 - mae: 0.6723 - val_loss: 3.9295 - val_mae: 1.0876\n",
      "Epoch 30/100\n",
      "45/45 [==============================] - 0s 905us/step - loss: 2.5292 - mae: 0.6878 - val_loss: 4.0163 - val_mae: 1.1612\n",
      "Epoch 31/100\n",
      "45/45 [==============================] - 0s 876us/step - loss: 2.4485 - mae: 0.6856 - val_loss: 3.9411 - val_mae: 1.0185\n",
      "Epoch 32/100\n",
      "45/45 [==============================] - 0s 847us/step - loss: 2.4787 - mae: 0.6895 - val_loss: 3.9522 - val_mae: 1.0216\n",
      "Epoch 33/100\n",
      "45/45 [==============================] - 0s 879us/step - loss: 2.5056 - mae: 0.6886 - val_loss: 4.0444 - val_mae: 1.1002\n",
      "Epoch 34/100\n",
      "45/45 [==============================] - 0s 865us/step - loss: 2.4470 - mae: 0.6684 - val_loss: 4.5089 - val_mae: 1.2177\n",
      "Epoch 35/100\n",
      "45/45 [==============================] - 0s 887us/step - loss: 2.4706 - mae: 0.6724 - val_loss: 4.8800 - val_mae: 1.2456\n",
      "Epoch 36/100\n",
      "45/45 [==============================] - 0s 864us/step - loss: 2.4824 - mae: 0.6826 - val_loss: 4.0455 - val_mae: 0.9819\n",
      "Epoch 37/100\n",
      "45/45 [==============================] - 0s 886us/step - loss: 2.4449 - mae: 0.6853 - val_loss: 3.9440 - val_mae: 1.0635\n",
      "Epoch 37: early stopping\n",
      "Test Loss (MSE): 3.6538901329040527, Test Mean Absolute Error (MAE): 0.9918479919433594\n",
      "Epoch 1/100\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 4.4922 - mae: 0.9866 - val_loss: 3.2532 - val_mae: 0.8162\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 0s 871us/step - loss: 3.7995 - mae: 0.9528 - val_loss: 3.2658 - val_mae: 0.7219\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 0s 836us/step - loss: 3.6429 - mae: 0.9500 - val_loss: 3.0015 - val_mae: 0.7379\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 0s 853us/step - loss: 3.6205 - mae: 0.9340 - val_loss: 3.0679 - val_mae: 0.7824\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 0s 877us/step - loss: 3.4608 - mae: 0.9288 - val_loss: 2.9852 - val_mae: 0.7694\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 0s 857us/step - loss: 3.3699 - mae: 0.9133 - val_loss: 2.8984 - val_mae: 0.8317\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 0s 925us/step - loss: 3.3510 - mae: 0.9235 - val_loss: 3.0899 - val_mae: 0.8918\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 0s 844us/step - loss: 3.2497 - mae: 0.9447 - val_loss: 3.0909 - val_mae: 0.6261\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 0s 846us/step - loss: 3.2706 - mae: 0.9111 - val_loss: 2.8070 - val_mae: 0.7257\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 0s 892us/step - loss: 3.4192 - mae: 0.9488 - val_loss: 2.9729 - val_mae: 0.6249\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 3.2953 - mae: 0.9194 - val_loss: 2.7899 - val_mae: 0.7039\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 0s 925us/step - loss: 3.2625 - mae: 0.9091 - val_loss: 2.8759 - val_mae: 0.7619\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 0s 877us/step - loss: 3.3258 - mae: 0.9597 - val_loss: 3.1203 - val_mae: 0.6447\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 0s 837us/step - loss: 3.2431 - mae: 0.9120 - val_loss: 2.7793 - val_mae: 0.6858\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 0s 931us/step - loss: 3.2067 - mae: 0.8991 - val_loss: 2.8041 - val_mae: 0.7568\n",
      "Epoch 16/100\n",
      "48/48 [==============================] - 0s 939us/step - loss: 3.3303 - mae: 0.9165 - val_loss: 2.8388 - val_mae: 0.6518\n",
      "Epoch 17/100\n",
      "48/48 [==============================] - 0s 957us/step - loss: 3.1945 - mae: 0.9070 - val_loss: 2.7783 - val_mae: 0.7515\n",
      "Epoch 18/100\n",
      "48/48 [==============================] - 0s 925us/step - loss: 3.1478 - mae: 0.9086 - val_loss: 2.7753 - val_mae: 0.7226\n",
      "Epoch 19/100\n",
      "48/48 [==============================] - 0s 940us/step - loss: 3.1208 - mae: 0.8701 - val_loss: 2.8142 - val_mae: 0.7324\n",
      "Epoch 20/100\n",
      "48/48 [==============================] - 0s 995us/step - loss: 3.1572 - mae: 0.9060 - val_loss: 2.9636 - val_mae: 0.6985\n",
      "Epoch 21/100\n",
      "48/48 [==============================] - 0s 993us/step - loss: 3.1910 - mae: 0.9165 - val_loss: 2.8025 - val_mae: 0.7800\n",
      "Epoch 22/100\n",
      "48/48 [==============================] - 0s 1000us/step - loss: 3.1583 - mae: 0.8764 - val_loss: 2.8917 - val_mae: 0.7080\n",
      "Epoch 23/100\n",
      "48/48 [==============================] - 0s 962us/step - loss: 3.1374 - mae: 0.9048 - val_loss: 2.7932 - val_mae: 0.7699\n",
      "Epoch 24/100\n",
      "48/48 [==============================] - 0s 1ms/step - loss: 3.0977 - mae: 0.8854 - val_loss: 2.8359 - val_mae: 0.6860\n",
      "Epoch 25/100\n",
      "48/48 [==============================] - 0s 929us/step - loss: 3.0828 - mae: 0.8892 - val_loss: 2.8007 - val_mae: 0.6919\n",
      "Epoch 26/100\n",
      "48/48 [==============================] - 0s 865us/step - loss: 3.0867 - mae: 0.8838 - val_loss: 2.7770 - val_mae: 0.7541\n",
      "Epoch 27/100\n",
      "48/48 [==============================] - 0s 874us/step - loss: 3.0743 - mae: 0.8900 - val_loss: 2.8402 - val_mae: 0.6878\n",
      "Epoch 28/100\n",
      "48/48 [==============================] - 0s 881us/step - loss: 3.1249 - mae: 0.8844 - val_loss: 2.8664 - val_mae: 0.7224\n",
      "Epoch 29/100\n",
      "48/48 [==============================] - 0s 870us/step - loss: 3.0770 - mae: 0.8960 - val_loss: 2.8342 - val_mae: 0.8098\n",
      "Epoch 30/100\n",
      "48/48 [==============================] - 0s 837us/step - loss: 3.0907 - mae: 0.8842 - val_loss: 2.7832 - val_mae: 0.6859\n",
      "Epoch 31/100\n",
      "48/48 [==============================] - 0s 869us/step - loss: 3.0601 - mae: 0.8862 - val_loss: 2.8764 - val_mae: 0.6823\n",
      "Epoch 32/100\n",
      "48/48 [==============================] - 0s 865us/step - loss: 3.0714 - mae: 0.8888 - val_loss: 2.8333 - val_mae: 0.7748\n",
      "Epoch 33/100\n",
      "48/48 [==============================] - 0s 822us/step - loss: 3.0386 - mae: 0.8737 - val_loss: 2.8258 - val_mae: 0.8532\n",
      "Epoch 34/100\n",
      "48/48 [==============================] - 0s 867us/step - loss: 3.0401 - mae: 0.8969 - val_loss: 2.9222 - val_mae: 0.7043\n",
      "Epoch 35/100\n",
      "48/48 [==============================] - 0s 858us/step - loss: 3.0393 - mae: 0.8957 - val_loss: 2.8669 - val_mae: 0.6555\n",
      "Epoch 36/100\n",
      "48/48 [==============================] - 0s 886us/step - loss: 3.0284 - mae: 0.8802 - val_loss: 2.9506 - val_mae: 0.7229\n",
      "Epoch 37/100\n",
      "48/48 [==============================] - 0s 883us/step - loss: 3.0823 - mae: 0.8690 - val_loss: 2.8821 - val_mae: 0.7706\n",
      "Epoch 38/100\n",
      "48/48 [==============================] - 0s 813us/step - loss: 3.1182 - mae: 0.8832 - val_loss: 2.9287 - val_mae: 0.6853\n",
      "Epoch 38: early stopping\n",
      "Test Loss (MSE): 2.970918893814087, Test Mean Absolute Error (MAE): 0.7513260245323181\n",
      "Epoch 1/100\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 3.8464 - mae: 0.8744 - val_loss: 4.8322 - val_mae: 1.1125\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 3.2745 - mae: 0.8188 - val_loss: 4.4256 - val_mae: 1.0131\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 3.1488 - mae: 0.7986 - val_loss: 4.2939 - val_mae: 0.9993\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 3.0530 - mae: 0.8131 - val_loss: 4.4387 - val_mae: 0.9692\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 970us/step - loss: 3.0454 - mae: 0.7966 - val_loss: 4.2866 - val_mae: 0.9788\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 968us/step - loss: 2.9200 - mae: 0.7980 - val_loss: 4.6850 - val_mae: 1.2063\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 990us/step - loss: 3.0171 - mae: 0.8269 - val_loss: 4.2527 - val_mae: 0.9767\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 920us/step - loss: 2.8580 - mae: 0.7855 - val_loss: 3.9741 - val_mae: 1.0242\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 863us/step - loss: 2.8835 - mae: 0.7961 - val_loss: 4.0390 - val_mae: 1.0189\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 875us/step - loss: 2.8926 - mae: 0.8109 - val_loss: 3.9193 - val_mae: 1.1525\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 875us/step - loss: 2.8919 - mae: 0.8203 - val_loss: 4.2940 - val_mae: 1.1378\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 853us/step - loss: 2.8443 - mae: 0.8118 - val_loss: 3.8572 - val_mae: 1.0618\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 851us/step - loss: 2.8413 - mae: 0.7928 - val_loss: 3.9419 - val_mae: 1.0960\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 879us/step - loss: 2.7682 - mae: 0.7894 - val_loss: 3.9730 - val_mae: 1.0026\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 897us/step - loss: 2.8299 - mae: 0.7984 - val_loss: 4.3251 - val_mae: 0.9912\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 867us/step - loss: 2.8090 - mae: 0.7944 - val_loss: 3.8618 - val_mae: 0.9899\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 860us/step - loss: 2.7517 - mae: 0.7705 - val_loss: 4.3197 - val_mae: 0.9579\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 854us/step - loss: 2.8061 - mae: 0.7789 - val_loss: 4.2048 - val_mae: 1.0074\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 833us/step - loss: 2.7857 - mae: 0.7909 - val_loss: 4.0583 - val_mae: 1.0677\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 860us/step - loss: 2.7366 - mae: 0.7811 - val_loss: 4.0919 - val_mae: 0.9834\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 866us/step - loss: 2.7340 - mae: 0.7527 - val_loss: 4.0141 - val_mae: 1.0768\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 944us/step - loss: 2.7128 - mae: 0.8049 - val_loss: 4.0957 - val_mae: 0.9637\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 861us/step - loss: 2.7100 - mae: 0.7843 - val_loss: 4.1480 - val_mae: 0.9571\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 853us/step - loss: 2.7427 - mae: 0.7774 - val_loss: 4.2342 - val_mae: 0.9571\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 888us/step - loss: 2.7346 - mae: 0.7714 - val_loss: 4.2185 - val_mae: 1.0846\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 877us/step - loss: 2.7101 - mae: 0.7728 - val_loss: 4.0147 - val_mae: 1.0624\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 864us/step - loss: 2.7526 - mae: 0.8027 - val_loss: 4.2553 - val_mae: 1.0142\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 873us/step - loss: 2.7143 - mae: 0.7721 - val_loss: 4.0729 - val_mae: 1.0596\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 874us/step - loss: 2.8041 - mae: 0.7970 - val_loss: 3.9494 - val_mae: 1.0456\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 857us/step - loss: 2.7473 - mae: 0.7775 - val_loss: 4.4053 - val_mae: 0.9846\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 830us/step - loss: 2.7629 - mae: 0.7675 - val_loss: 4.1130 - val_mae: 1.0917\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 884us/step - loss: 2.7423 - mae: 0.7998 - val_loss: 3.9312 - val_mae: 1.0218\n",
      "Epoch 32: early stopping\n",
      "Test Loss (MSE): 2.343822956085205, Test Mean Absolute Error (MAE): 0.5951002836227417\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 14.1633 - mae: 2.8785 - val_loss: 9.6211 - val_mae: 2.3405\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 11.1710 - mae: 2.3633 - val_loss: 10.6361 - val_mae: 2.7637\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 10.9580 - mae: 2.6051 - val_loss: 7.7778 - val_mae: 1.9335\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 10.4746 - mae: 2.4997 - val_loss: 8.5258 - val_mae: 2.4425\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.7833 - mae: 2.4499 - val_loss: 7.9946 - val_mae: 2.3008\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.7129 - mae: 2.4794 - val_loss: 7.6747 - val_mae: 2.2627\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.6584 - mae: 2.5291 - val_loss: 7.4761 - val_mae: 2.2542\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.6064 - mae: 2.4206 - val_loss: 7.4385 - val_mae: 2.2702\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.5190 - mae: 2.4937 - val_loss: 7.1359 - val_mae: 2.2128\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.7042 - mae: 2.4987 - val_loss: 7.4087 - val_mae: 2.3088\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.4477 - mae: 2.4474 - val_loss: 6.9704 - val_mae: 2.1561\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.3272 - mae: 2.4598 - val_loss: 6.7999 - val_mae: 2.1224\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.3266 - mae: 2.4345 - val_loss: 7.1165 - val_mae: 2.2934\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.3746 - mae: 2.4469 - val_loss: 6.9006 - val_mae: 2.1986\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.4556 - mae: 2.5023 - val_loss: 6.3761 - val_mae: 1.9917\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.8251 - mae: 2.4289 - val_loss: 8.9556 - val_mae: 2.7259\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.6268 - mae: 2.3924 - val_loss: 7.0300 - val_mae: 2.2008\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.4660 - mae: 2.5085 - val_loss: 6.5725 - val_mae: 2.0279\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.2490 - mae: 2.4263 - val_loss: 6.7164 - val_mae: 2.1697\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 9.2065 - mae: 2.4643 - val_loss: 6.5152 - val_mae: 2.0812\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.1551 - mae: 2.4259 - val_loss: 6.9633 - val_mae: 2.2663\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.1761 - mae: 2.4558 - val_loss: 6.2166 - val_mae: 1.9304\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.1457 - mae: 2.3828 - val_loss: 7.2888 - val_mae: 2.3662\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.3065 - mae: 2.5022 - val_loss: 6.3774 - val_mae: 2.0893\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.1925 - mae: 2.4153 - val_loss: 6.6354 - val_mae: 2.1782\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.2793 - mae: 2.4535 - val_loss: 6.2550 - val_mae: 2.0154\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.4972 - mae: 2.4817 - val_loss: 6.3397 - val_mae: 1.8894\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.2491 - mae: 2.4447 - val_loss: 6.4330 - val_mae: 2.1052\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.3207 - mae: 2.4611 - val_loss: 6.2133 - val_mae: 1.9400\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.1146 - mae: 2.3983 - val_loss: 6.9613 - val_mae: 2.2888\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.4561 - mae: 2.4643 - val_loss: 6.3819 - val_mae: 2.0502\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.1190 - mae: 2.4128 - val_loss: 6.7133 - val_mae: 2.2168\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.1511 - mae: 2.4856 - val_loss: 6.2752 - val_mae: 1.9966\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.1985 - mae: 2.4502 - val_loss: 6.8432 - val_mae: 2.2577\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.2498 - mae: 2.4254 - val_loss: 6.3787 - val_mae: 2.1022\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.0572 - mae: 2.4388 - val_loss: 6.3924 - val_mae: 2.0308\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.1266 - mae: 2.3811 - val_loss: 7.0454 - val_mae: 2.3246\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.2534 - mae: 2.4466 - val_loss: 6.3266 - val_mae: 2.0048\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.2829 - mae: 2.4883 - val_loss: 6.0997 - val_mae: 1.8776\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.2988 - mae: 2.4627 - val_loss: 7.0135 - val_mae: 2.2882\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 9.1516 - mae: 2.3763 - val_loss: 6.3757 - val_mae: 2.1032\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 9.0636 - mae: 2.4449 - val_loss: 6.3886 - val_mae: 2.0773\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.0207 - mae: 2.4422 - val_loss: 6.3556 - val_mae: 2.0790\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.0380 - mae: 2.4074 - val_loss: 6.3748 - val_mae: 2.1100\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.9943 - mae: 2.4324 - val_loss: 6.3104 - val_mae: 2.0573\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.1437 - mae: 2.4141 - val_loss: 7.3082 - val_mae: 2.3989\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.3855 - mae: 2.4107 - val_loss: 6.4629 - val_mae: 2.1414\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 9.0896 - mae: 2.4896 - val_loss: 6.2535 - val_mae: 2.0197\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.3148 - mae: 2.4605 - val_loss: 6.7602 - val_mae: 2.2339\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 9.0962 - mae: 2.3572 - val_loss: 6.5560 - val_mae: 2.1675\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.4572 - mae: 2.4554 - val_loss: 6.1217 - val_mae: 1.9427\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.2476 - mae: 2.5069 - val_loss: 6.2562 - val_mae: 1.9346\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.1098 - mae: 2.3726 - val_loss: 6.5560 - val_mae: 2.1823\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.0330 - mae: 2.4551 - val_loss: 6.2386 - val_mae: 1.9909\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.0091 - mae: 2.3675 - val_loss: 6.5525 - val_mae: 2.1906\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.0743 - mae: 2.4484 - val_loss: 6.3290 - val_mae: 2.0891\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.0248 - mae: 2.4624 - val_loss: 6.1953 - val_mae: 2.0119\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.0524 - mae: 2.4314 - val_loss: 6.5668 - val_mae: 2.1735\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.0271 - mae: 2.3972 - val_loss: 6.1289 - val_mae: 1.9986\n",
      "Epoch 59: early stopping\n",
      "Test Loss (MSE): 9.145660400390625, Test Mean Absolute Error (MAE): 2.4545276165008545\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 11.4322 - mae: 2.3884 - val_loss: 9.3656 - val_mae: 2.1018\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.8601 - mae: 2.1689 - val_loss: 9.5069 - val_mae: 2.2660\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.6201 - mae: 2.1671 - val_loss: 9.1267 - val_mae: 2.1910\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.1925 - mae: 2.1606 - val_loss: 9.2631 - val_mae: 2.2394\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.3473 - mae: 2.0782 - val_loss: 9.6920 - val_mae: 2.1877\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.2291 - mae: 2.2027 - val_loss: 9.0634 - val_mae: 2.2167\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.8899 - mae: 2.0572 - val_loss: 9.1728 - val_mae: 2.3212\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.8006 - mae: 2.1387 - val_loss: 9.1620 - val_mae: 2.2370\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.7364 - mae: 2.1002 - val_loss: 9.6033 - val_mae: 2.4907\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.6940 - mae: 2.0415 - val_loss: 9.2709 - val_mae: 2.4192\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.6931 - mae: 2.1601 - val_loss: 9.2141 - val_mae: 2.2516\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.6984 - mae: 2.1010 - val_loss: 9.4223 - val_mae: 2.2966\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.8415 - mae: 2.0670 - val_loss: 9.2930 - val_mae: 2.3796\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.6312 - mae: 2.0670 - val_loss: 9.4293 - val_mae: 2.3870\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.3551 - mae: 2.0750 - val_loss: 9.3677 - val_mae: 2.3640\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.4414 - mae: 2.0686 - val_loss: 9.5229 - val_mae: 2.2015\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.7063 - mae: 2.0766 - val_loss: 9.3617 - val_mae: 2.3318\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 7.3537 - mae: 2.0688 - val_loss: 9.4836 - val_mae: 2.3361\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.3765 - mae: 2.0206 - val_loss: 10.0154 - val_mae: 2.5364\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.3793 - mae: 2.0176 - val_loss: 9.5718 - val_mae: 2.3387\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.1253 - mae: 2.0454 - val_loss: 9.7142 - val_mae: 2.3317\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.1086 - mae: 2.0015 - val_loss: 9.6366 - val_mae: 2.3750\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 7.1266 - mae: 2.0202 - val_loss: 9.7322 - val_mae: 2.3473\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.3017 - mae: 2.0225 - val_loss: 9.8093 - val_mae: 2.2946\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.0153 - mae: 2.0264 - val_loss: 10.0766 - val_mae: 2.2155\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.1071 - mae: 1.9841 - val_loss: 9.8940 - val_mae: 2.4291\n",
      "Epoch 26: early stopping\n",
      "Test Loss (MSE): 11.230788230895996, Test Mean Absolute Error (MAE): 2.6398825645446777\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 11.6659 - mae: 2.5420 - val_loss: 9.3104 - val_mae: 1.9555\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 10.0808 - mae: 2.3072 - val_loss: 8.6128 - val_mae: 2.2082\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.2866 - mae: 2.2992 - val_loss: 8.3604 - val_mae: 2.1021\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.1967 - mae: 2.3061 - val_loss: 8.3025 - val_mae: 2.0781\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.9669 - mae: 2.2420 - val_loss: 8.3247 - val_mae: 2.1451\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.7296 - mae: 2.2740 - val_loss: 8.2237 - val_mae: 2.0549\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.7549 - mae: 2.1901 - val_loss: 8.7197 - val_mae: 2.3344\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.8200 - mae: 2.2941 - val_loss: 8.4209 - val_mae: 2.1165\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.4908 - mae: 2.2126 - val_loss: 8.1923 - val_mae: 2.1260\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.4391 - mae: 2.1404 - val_loss: 9.4145 - val_mae: 2.5200\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.3056 - mae: 2.1405 - val_loss: 8.4383 - val_mae: 2.0621\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.0900 - mae: 2.2069 - val_loss: 8.4039 - val_mae: 2.0681\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.2458 - mae: 2.1626 - val_loss: 8.4994 - val_mae: 2.1133\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.8678 - mae: 2.1286 - val_loss: 8.6612 - val_mae: 2.0358\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.2143 - mae: 2.1522 - val_loss: 8.9748 - val_mae: 2.1232\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.9694 - mae: 2.0901 - val_loss: 9.1838 - val_mae: 2.3102\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.9823 - mae: 2.1151 - val_loss: 9.0445 - val_mae: 2.3554\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.7133 - mae: 2.0720 - val_loss: 8.4894 - val_mae: 2.0653\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.5864 - mae: 2.0737 - val_loss: 8.6557 - val_mae: 2.1302\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.5265 - mae: 2.0419 - val_loss: 8.6591 - val_mae: 2.0535\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.5520 - mae: 2.0626 - val_loss: 8.7098 - val_mae: 2.1445\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.0247 - mae: 1.9667 - val_loss: 8.6769 - val_mae: 2.1180\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 7.1226 - mae: 2.0012 - val_loss: 8.4665 - val_mae: 2.1034\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.1063 - mae: 1.9846 - val_loss: 9.5159 - val_mae: 2.2688\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.2510 - mae: 2.0011 - val_loss: 9.0138 - val_mae: 1.9980\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.2098 - mae: 1.9764 - val_loss: 9.4406 - val_mae: 2.2463\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 6.8263 - mae: 1.9118 - val_loss: 8.8043 - val_mae: 2.1164\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 6.5145 - mae: 1.8935 - val_loss: 9.6989 - val_mae: 2.3085\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 6.3144 - mae: 1.8152 - val_loss: 9.1310 - val_mae: 2.2507\n",
      "Epoch 29: early stopping\n",
      "Test Loss (MSE): 11.882238388061523, Test Mean Absolute Error (MAE): 2.6287035942077637\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 13.2605 - mae: 2.6045 - val_loss: 8.8430 - val_mae: 2.0636\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.6106 - mae: 2.3254 - val_loss: 9.1225 - val_mae: 2.3019\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 9.1630 - mae: 2.3328 - val_loss: 9.3793 - val_mae: 2.2058\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.8612 - mae: 2.3159 - val_loss: 9.3888 - val_mae: 2.3267\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.7895 - mae: 2.2987 - val_loss: 9.1709 - val_mae: 2.2218\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.6476 - mae: 2.3161 - val_loss: 9.2896 - val_mae: 2.3154\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.4250 - mae: 2.2211 - val_loss: 9.4754 - val_mae: 2.3508\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.4288 - mae: 2.2589 - val_loss: 9.1395 - val_mae: 2.2128\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.4049 - mae: 2.2686 - val_loss: 9.4472 - val_mae: 2.2534\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.4681 - mae: 2.2270 - val_loss: 10.1373 - val_mae: 2.5992\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.2466 - mae: 2.2983 - val_loss: 9.2510 - val_mae: 2.2161\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.4019 - mae: 2.2801 - val_loss: 9.2945 - val_mae: 2.3013\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.2382 - mae: 2.1915 - val_loss: 9.9323 - val_mae: 2.4583\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.2499 - mae: 2.2906 - val_loss: 9.6591 - val_mae: 2.3743\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.0405 - mae: 2.2264 - val_loss: 9.7252 - val_mae: 2.3737\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.8533 - mae: 2.2035 - val_loss: 9.5328 - val_mae: 2.3182\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 8.1553 - mae: 2.2140 - val_loss: 9.7657 - val_mae: 2.3719\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.9013 - mae: 2.2639 - val_loss: 9.4462 - val_mae: 2.2346\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 7.9815 - mae: 2.2229 - val_loss: 9.7250 - val_mae: 2.2116\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.8487 - mae: 2.1959 - val_loss: 9.8311 - val_mae: 2.3782\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 7.7403 - mae: 2.1580 - val_loss: 9.9149 - val_mae: 2.4214\n",
      "Epoch 21: early stopping\n",
      "Test Loss (MSE): 8.76331901550293, Test Mean Absolute Error (MAE): 2.367649555206299\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 5.2944 - mae: 1.1255 - val_loss: 3.0489 - val_mae: 1.0408\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 0s 967us/step - loss: 4.5199 - mae: 1.0947 - val_loss: 2.5897 - val_mae: 0.7447\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 0s 973us/step - loss: 3.9905 - mae: 1.0862 - val_loss: 2.4936 - val_mae: 0.6728\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 0s 972us/step - loss: 3.8867 - mae: 1.0193 - val_loss: 2.6132 - val_mae: 0.8589\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 0s 958us/step - loss: 3.7728 - mae: 1.0135 - val_loss: 2.6727 - val_mae: 1.0577\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 0s 976us/step - loss: 3.7635 - mae: 1.0556 - val_loss: 2.5399 - val_mae: 0.8294\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 0s 942us/step - loss: 3.7360 - mae: 1.0455 - val_loss: 2.5071 - val_mae: 0.8148\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 0s 971us/step - loss: 3.7342 - mae: 1.0271 - val_loss: 2.3943 - val_mae: 0.6480\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 3.7887 - mae: 1.0269 - val_loss: 2.4132 - val_mae: 0.7138\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 0s 973us/step - loss: 3.7405 - mae: 1.0253 - val_loss: 2.3986 - val_mae: 0.7648\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 0s 982us/step - loss: 3.7176 - mae: 1.0175 - val_loss: 2.3504 - val_mae: 0.5954\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 0s 936us/step - loss: 3.7354 - mae: 1.0260 - val_loss: 2.3608 - val_mae: 0.6176\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 0s 912us/step - loss: 3.6584 - mae: 1.0235 - val_loss: 2.3977 - val_mae: 0.7735\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 0s 948us/step - loss: 3.6610 - mae: 1.0304 - val_loss: 2.4349 - val_mae: 0.8048\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 0s 916us/step - loss: 3.6625 - mae: 1.0377 - val_loss: 2.5338 - val_mae: 0.9209\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 0s 924us/step - loss: 3.6265 - mae: 1.0501 - val_loss: 2.4449 - val_mae: 0.7962\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 0s 915us/step - loss: 3.7163 - mae: 1.0090 - val_loss: 2.5379 - val_mae: 0.9112\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 0s 946us/step - loss: 3.5955 - mae: 1.0171 - val_loss: 2.3567 - val_mae: 0.6389\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 0s 932us/step - loss: 3.6031 - mae: 0.9972 - val_loss: 2.3816 - val_mae: 0.7010\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 0s 906us/step - loss: 3.6386 - mae: 1.0304 - val_loss: 2.5676 - val_mae: 0.8709\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 0s 921us/step - loss: 3.6399 - mae: 1.0491 - val_loss: 2.5633 - val_mae: 0.7020\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 0s 948us/step - loss: 3.5994 - mae: 1.0198 - val_loss: 2.4227 - val_mae: 0.7823\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 0s 967us/step - loss: 3.6160 - mae: 1.0190 - val_loss: 2.3963 - val_mae: 0.6479\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 0s 917us/step - loss: 3.6648 - mae: 1.0137 - val_loss: 2.4205 - val_mae: 0.7307\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 3.6549 - mae: 0.9743 - val_loss: 2.4232 - val_mae: 0.8610\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 0s 960us/step - loss: 3.6094 - mae: 1.0372 - val_loss: 2.4768 - val_mae: 0.8024\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 0s 936us/step - loss: 3.5655 - mae: 1.0121 - val_loss: 2.3868 - val_mae: 0.6878\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 0s 934us/step - loss: 3.6042 - mae: 1.0044 - val_loss: 2.4699 - val_mae: 0.9252\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 0s 910us/step - loss: 3.5805 - mae: 1.0448 - val_loss: 2.4472 - val_mae: 0.6947\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 0s 939us/step - loss: 3.5177 - mae: 0.9708 - val_loss: 2.3757 - val_mae: 0.6402\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 0s 960us/step - loss: 3.5848 - mae: 1.0171 - val_loss: 2.4466 - val_mae: 0.6808\n",
      "Epoch 31: early stopping\n",
      "Test Loss (MSE): 2.50068736076355, Test Mean Absolute Error (MAE): 0.6262062788009644\n",
      "Epoch 1/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4.7141 - mae: 1.0250 - val_loss: 3.6660 - val_mae: 0.8688\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 3.9834 - mae: 0.9558 - val_loss: 3.4420 - val_mae: 0.6575\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 920us/step - loss: 3.7550 - mae: 0.9388 - val_loss: 2.8980 - val_mae: 0.8139\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 926us/step - loss: 3.4770 - mae: 0.9296 - val_loss: 2.8284 - val_mae: 0.7412\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 984us/step - loss: 3.5932 - mae: 0.9405 - val_loss: 2.9642 - val_mae: 0.8938\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 966us/step - loss: 3.3413 - mae: 0.9262 - val_loss: 2.8328 - val_mae: 0.7968\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 3.3572 - mae: 0.8951 - val_loss: 2.9107 - val_mae: 0.7932\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 3.3158 - mae: 0.9189 - val_loss: 2.9413 - val_mae: 0.7984\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 989us/step - loss: 3.2665 - mae: 0.9048 - val_loss: 2.8349 - val_mae: 0.7533\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 3.3087 - mae: 0.9048 - val_loss: 2.8054 - val_mae: 0.7182\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 999us/step - loss: 3.2600 - mae: 0.8866 - val_loss: 2.8411 - val_mae: 0.8217\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 3.2580 - mae: 0.9493 - val_loss: 3.0665 - val_mae: 0.9027\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 3.3170 - mae: 0.9231 - val_loss: 2.7941 - val_mae: 0.7531\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 3.1772 - mae: 0.8789 - val_loss: 2.8381 - val_mae: 0.7906\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 3.1741 - mae: 0.8901 - val_loss: 2.8844 - val_mae: 0.7339\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 3.2620 - mae: 0.9383 - val_loss: 3.3729 - val_mae: 0.9744\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 3.2277 - mae: 0.9163 - val_loss: 3.2443 - val_mae: 0.9099\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 3.1762 - mae: 0.9065 - val_loss: 2.8807 - val_mae: 0.8379\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 3.1413 - mae: 0.9042 - val_loss: 2.8584 - val_mae: 0.7954\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 3.1993 - mae: 0.9056 - val_loss: 2.8172 - val_mae: 0.7710\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 971us/step - loss: 3.2890 - mae: 0.9264 - val_loss: 2.9143 - val_mae: 0.7325\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 971us/step - loss: 3.2559 - mae: 0.9033 - val_loss: 3.0264 - val_mae: 0.8729\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 984us/step - loss: 3.1162 - mae: 0.8968 - val_loss: 2.8748 - val_mae: 0.7992\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 935us/step - loss: 3.1111 - mae: 0.8833 - val_loss: 2.9020 - val_mae: 0.8260\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 956us/step - loss: 3.0910 - mae: 0.8689 - val_loss: 3.3066 - val_mae: 1.0102\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 970us/step - loss: 3.1509 - mae: 0.9016 - val_loss: 2.8912 - val_mae: 0.7570\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 0s 965us/step - loss: 3.1743 - mae: 0.9016 - val_loss: 2.8917 - val_mae: 0.7905\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 934us/step - loss: 3.1334 - mae: 0.8722 - val_loss: 3.0690 - val_mae: 0.8707\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 0s 924us/step - loss: 3.2463 - mae: 0.9027 - val_loss: 2.9394 - val_mae: 0.8336\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 0s 917us/step - loss: 3.1511 - mae: 0.9015 - val_loss: 2.9786 - val_mae: 0.8575\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 0s 928us/step - loss: 3.0854 - mae: 0.8908 - val_loss: 2.9079 - val_mae: 0.7378\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 0s 933us/step - loss: 3.1272 - mae: 0.8826 - val_loss: 2.9239 - val_mae: 0.8202\n",
      "Epoch 33/100\n",
      "41/41 [==============================] - 0s 945us/step - loss: 3.2061 - mae: 0.8722 - val_loss: 3.0153 - val_mae: 0.8683\n",
      "Epoch 33: early stopping\n",
      "Test Loss (MSE): 3.740295886993408, Test Mean Absolute Error (MAE): 0.9883501529693604\n",
      "Epoch 1/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 4.5243 - mae: 0.9576 - val_loss: 4.0756 - val_mae: 0.9070\n",
      "Epoch 2/100\n",
      "43/43 [==============================] - 0s 876us/step - loss: 3.6939 - mae: 0.8947 - val_loss: 3.7946 - val_mae: 0.9132\n",
      "Epoch 3/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 3.4717 - mae: 0.8584 - val_loss: 3.9647 - val_mae: 1.0785\n",
      "Epoch 4/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 3.1980 - mae: 0.8400 - val_loss: 3.5928 - val_mae: 0.8711\n",
      "Epoch 5/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 3.4292 - mae: 0.8865 - val_loss: 3.6809 - val_mae: 0.8772\n",
      "Epoch 6/100\n",
      "43/43 [==============================] - 0s 989us/step - loss: 3.1171 - mae: 0.8426 - val_loss: 3.5741 - val_mae: 0.9175\n",
      "Epoch 7/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 3.1703 - mae: 0.8506 - val_loss: 3.8547 - val_mae: 0.8975\n",
      "Epoch 8/100\n",
      "43/43 [==============================] - 0s 939us/step - loss: 3.1123 - mae: 0.8466 - val_loss: 3.6173 - val_mae: 0.9592\n",
      "Epoch 9/100\n",
      "43/43 [==============================] - 0s 908us/step - loss: 3.1135 - mae: 0.8404 - val_loss: 3.5792 - val_mae: 0.8977\n",
      "Epoch 10/100\n",
      "43/43 [==============================] - 0s 944us/step - loss: 3.1040 - mae: 0.8389 - val_loss: 3.5947 - val_mae: 0.9320\n",
      "Epoch 11/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 3.1894 - mae: 0.8284 - val_loss: 3.6547 - val_mae: 1.0456\n",
      "Epoch 12/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 3.0838 - mae: 0.8431 - val_loss: 3.8564 - val_mae: 1.1620\n",
      "Epoch 13/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 3.1428 - mae: 0.8628 - val_loss: 3.5602 - val_mae: 0.8971\n",
      "Epoch 14/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 2.9905 - mae: 0.8277 - val_loss: 3.6716 - val_mae: 0.8676\n",
      "Epoch 15/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 3.0232 - mae: 0.8409 - val_loss: 3.7691 - val_mae: 0.9107\n",
      "Epoch 16/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 3.0420 - mae: 0.8433 - val_loss: 3.6546 - val_mae: 1.0149\n",
      "Epoch 17/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 3.0743 - mae: 0.8264 - val_loss: 3.6232 - val_mae: 0.9516\n",
      "Epoch 18/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 2.9901 - mae: 0.8139 - val_loss: 3.6744 - val_mae: 0.9103\n",
      "Epoch 19/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 3.0466 - mae: 0.8607 - val_loss: 3.7371 - val_mae: 1.0379\n",
      "Epoch 20/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 2.9395 - mae: 0.8208 - val_loss: 3.6025 - val_mae: 0.9324\n",
      "Epoch 21/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 2.9315 - mae: 0.8387 - val_loss: 3.6862 - val_mae: 0.9196\n",
      "Epoch 22/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 3.0061 - mae: 0.8382 - val_loss: 3.8380 - val_mae: 1.0590\n",
      "Epoch 23/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 2.9653 - mae: 0.7975 - val_loss: 3.6237 - val_mae: 0.9954\n",
      "Epoch 24/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 2.9365 - mae: 0.8575 - val_loss: 3.8780 - val_mae: 0.8715\n",
      "Epoch 25/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 2.9295 - mae: 0.8075 - val_loss: 3.7477 - val_mae: 1.0344\n",
      "Epoch 26/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 2.9911 - mae: 0.8468 - val_loss: 3.6955 - val_mae: 0.9529\n",
      "Epoch 27/100\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 2.9543 - mae: 0.8196 - val_loss: 3.6663 - val_mae: 0.9999\n",
      "Epoch 28/100\n",
      "43/43 [==============================] - 0s 966us/step - loss: 2.9081 - mae: 0.8244 - val_loss: 3.7163 - val_mae: 0.9611\n",
      "Epoch 29/100\n",
      "43/43 [==============================] - 0s 993us/step - loss: 3.0001 - mae: 0.8109 - val_loss: 4.0885 - val_mae: 1.1233\n",
      "Epoch 30/100\n",
      "43/43 [==============================] - 0s 972us/step - loss: 2.9204 - mae: 0.8204 - val_loss: 3.6395 - val_mae: 0.9403\n",
      "Epoch 31/100\n",
      "43/43 [==============================] - 0s 997us/step - loss: 2.8859 - mae: 0.8267 - val_loss: 3.7090 - val_mae: 0.9714\n",
      "Epoch 32/100\n",
      "43/43 [==============================] - 0s 964us/step - loss: 2.8863 - mae: 0.8033 - val_loss: 3.7759 - val_mae: 0.9095\n",
      "Epoch 33/100\n",
      "43/43 [==============================] - 0s 975us/step - loss: 2.9002 - mae: 0.8146 - val_loss: 3.7047 - val_mae: 1.0548\n",
      "Epoch 33: early stopping\n",
      "Test Loss (MSE): 2.730882406234741, Test Mean Absolute Error (MAE): 0.7860187888145447\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 3.5598 - mae: 0.6954 - val_loss: 5.9447 - val_mae: 1.0401\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.8034 - mae: 0.6507 - val_loss: 4.6540 - val_mae: 1.0866\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.5101 - mae: 0.6352 - val_loss: 4.5373 - val_mae: 1.1502\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.3996 - mae: 0.6590 - val_loss: 4.4605 - val_mae: 1.1534\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.3381 - mae: 0.6603 - val_loss: 5.1062 - val_mae: 1.0368\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.3410 - mae: 0.6313 - val_loss: 4.3962 - val_mae: 1.1448\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.3975 - mae: 0.6749 - val_loss: 4.4773 - val_mae: 1.0813\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.2665 - mae: 0.6328 - val_loss: 4.4217 - val_mae: 1.1683\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.2695 - mae: 0.6414 - val_loss: 4.4222 - val_mae: 1.0915\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.2956 - mae: 0.6440 - val_loss: 4.3702 - val_mae: 1.0985\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.1641 - mae: 0.6373 - val_loss: 4.3348 - val_mae: 1.1307\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.1323 - mae: 0.6160 - val_loss: 4.3874 - val_mae: 1.0775\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.1511 - mae: 0.6077 - val_loss: 4.3876 - val_mae: 1.1087\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.2388 - mae: 0.6290 - val_loss: 4.3068 - val_mae: 1.1068\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.2468 - mae: 0.6359 - val_loss: 4.4133 - val_mae: 1.0535\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 0s 982us/step - loss: 2.1711 - mae: 0.6589 - val_loss: 4.5767 - val_mae: 1.0509\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.0781 - mae: 0.6060 - val_loss: 4.9664 - val_mae: 1.0420\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 0s 976us/step - loss: 2.0987 - mae: 0.6166 - val_loss: 4.4699 - val_mae: 1.0807\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.1262 - mae: 0.6309 - val_loss: 4.4396 - val_mae: 1.0932\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.1303 - mae: 0.6226 - val_loss: 4.3919 - val_mae: 1.0933\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.1724 - mae: 0.6270 - val_loss: 4.3977 - val_mae: 1.1088\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 0s 984us/step - loss: 2.1562 - mae: 0.6378 - val_loss: 4.4786 - val_mae: 1.0838\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.1399 - mae: 0.6350 - val_loss: 4.9959 - val_mae: 1.0371\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.1470 - mae: 0.6136 - val_loss: 4.5306 - val_mae: 1.2025\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 0s 968us/step - loss: 2.2942 - mae: 0.6392 - val_loss: 4.4393 - val_mae: 1.0921\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.1830 - mae: 0.6428 - val_loss: 4.5374 - val_mae: 1.0774\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.1551 - mae: 0.6303 - val_loss: 4.3616 - val_mae: 1.1387\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 0s 976us/step - loss: 2.0953 - mae: 0.6387 - val_loss: 4.6314 - val_mae: 1.0572\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 0s 982us/step - loss: 2.0969 - mae: 0.6142 - val_loss: 4.3760 - val_mae: 1.1048\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 0s 994us/step - loss: 2.1061 - mae: 0.6197 - val_loss: 4.4829 - val_mae: 1.0673\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.0730 - mae: 0.6116 - val_loss: 4.3793 - val_mae: 1.1319\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 0s 959us/step - loss: 2.1101 - mae: 0.6233 - val_loss: 4.3757 - val_mae: 1.0927\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 0s 994us/step - loss: 2.0531 - mae: 0.6250 - val_loss: 4.9316 - val_mae: 1.0406\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 0s 979us/step - loss: 2.2197 - mae: 0.6097 - val_loss: 4.4045 - val_mae: 1.1023\n",
      "Epoch 34: early stopping\n",
      "Test Loss (MSE): 4.715234756469727, Test Mean Absolute Error (MAE): 1.1053227186203003\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 11.7850 - mae: 2.4944 - val_loss: 12.6202 - val_mae: 2.7902\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 9.8868 - mae: 2.2926 - val_loss: 11.0557 - val_mae: 2.7358\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 9.2178 - mae: 2.2799 - val_loss: 10.7650 - val_mae: 2.7360\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.9989 - mae: 2.2685 - val_loss: 10.5744 - val_mae: 2.7427\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.6659 - mae: 2.2729 - val_loss: 10.1188 - val_mae: 2.4577\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.4092 - mae: 2.2477 - val_loss: 10.0118 - val_mae: 2.5079\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.2919 - mae: 2.2346 - val_loss: 10.0852 - val_mae: 2.5442\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.2448 - mae: 2.2386 - val_loss: 9.9829 - val_mae: 2.5676\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.1883 - mae: 2.2316 - val_loss: 10.3105 - val_mae: 2.3777\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.1702 - mae: 2.2226 - val_loss: 10.3213 - val_mae: 2.6612\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.4386 - mae: 2.1685 - val_loss: 11.2334 - val_mae: 2.8829\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.7962 - mae: 2.2918 - val_loss: 10.0895 - val_mae: 2.6413\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.3851 - mae: 2.2104 - val_loss: 9.9985 - val_mae: 2.7006\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.4368 - mae: 2.2319 - val_loss: 10.2516 - val_mae: 2.4196\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.1474 - mae: 2.2265 - val_loss: 10.0407 - val_mae: 2.4049\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.9108 - mae: 2.1514 - val_loss: 10.0894 - val_mae: 2.6916\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.2445 - mae: 2.2629 - val_loss: 10.1286 - val_mae: 2.5108\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.0400 - mae: 2.2016 - val_loss: 10.0596 - val_mae: 2.6372\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.0525 - mae: 2.1771 - val_loss: 10.2402 - val_mae: 2.4052\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.9556 - mae: 2.2092 - val_loss: 10.1211 - val_mae: 2.4097\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.8965 - mae: 2.1661 - val_loss: 9.9696 - val_mae: 2.5200\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.9020 - mae: 2.1681 - val_loss: 10.1440 - val_mae: 2.6627\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.8714 - mae: 2.1745 - val_loss: 10.0661 - val_mae: 2.5265\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.8226 - mae: 2.1765 - val_loss: 10.1849 - val_mae: 2.4621\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.8144 - mae: 2.1717 - val_loss: 10.0672 - val_mae: 2.5806\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.7562 - mae: 2.1263 - val_loss: 10.1821 - val_mae: 2.5689\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.9312 - mae: 2.1481 - val_loss: 10.1957 - val_mae: 2.5879\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.8078 - mae: 2.2061 - val_loss: 10.5636 - val_mae: 2.4377\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.7229 - mae: 2.1463 - val_loss: 10.2097 - val_mae: 2.5916\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.8196 - mae: 2.1628 - val_loss: 10.2827 - val_mae: 2.5355\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.6433 - mae: 2.0971 - val_loss: 10.3336 - val_mae: 2.4988\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.7875 - mae: 2.1774 - val_loss: 11.0674 - val_mae: 2.4099\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.2385 - mae: 2.1476 - val_loss: 10.3037 - val_mae: 2.6339\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.5231 - mae: 2.1152 - val_loss: 10.6020 - val_mae: 2.4998\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.6460 - mae: 2.1194 - val_loss: 10.4034 - val_mae: 2.6020\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.5492 - mae: 2.0726 - val_loss: 10.6731 - val_mae: 2.5531\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.6531 - mae: 2.1538 - val_loss: 10.7521 - val_mae: 2.4632\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.5085 - mae: 2.0908 - val_loss: 10.7903 - val_mae: 2.6538\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 7.6309 - mae: 2.0807 - val_loss: 10.5919 - val_mae: 2.6142\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.5146 - mae: 2.1342 - val_loss: 10.6338 - val_mae: 2.5590\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.5091 - mae: 2.0940 - val_loss: 10.6770 - val_mae: 2.5749\n",
      "Epoch 41: early stopping\n",
      "Test Loss (MSE): 7.920594215393066, Test Mean Absolute Error (MAE): 2.2088820934295654\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 11.1367 - mae: 2.3590 - val_loss: 10.6287 - val_mae: 2.3559\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 9.1288 - mae: 2.2453 - val_loss: 11.5399 - val_mae: 2.2473\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.8504 - mae: 2.1551 - val_loss: 10.5987 - val_mae: 2.5443\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.1003 - mae: 2.1122 - val_loss: 10.2484 - val_mae: 2.3936\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.9919 - mae: 2.1090 - val_loss: 10.0396 - val_mae: 2.4465\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.9605 - mae: 2.1190 - val_loss: 10.2365 - val_mae: 2.4441\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.6967 - mae: 2.1209 - val_loss: 10.2357 - val_mae: 2.4185\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.6546 - mae: 2.0882 - val_loss: 10.0172 - val_mae: 2.4110\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.5543 - mae: 2.0440 - val_loss: 9.9594 - val_mae: 2.4770\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.5432 - mae: 2.1266 - val_loss: 10.5365 - val_mae: 2.3223\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.5500 - mae: 2.0223 - val_loss: 10.7789 - val_mae: 2.6372\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.4409 - mae: 2.0277 - val_loss: 10.1206 - val_mae: 2.5102\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.4066 - mae: 2.0825 - val_loss: 10.4131 - val_mae: 2.5620\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.5436 - mae: 2.0625 - val_loss: 10.4325 - val_mae: 2.4390\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.3304 - mae: 2.0225 - val_loss: 10.3484 - val_mae: 2.3956\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.1261 - mae: 2.0562 - val_loss: 10.3205 - val_mae: 2.3783\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.1358 - mae: 1.9994 - val_loss: 10.6502 - val_mae: 2.4204\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.8937 - mae: 1.9456 - val_loss: 10.9174 - val_mae: 2.5146\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.9137 - mae: 2.0308 - val_loss: 11.3447 - val_mae: 2.3970\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.1553 - mae: 1.9948 - val_loss: 11.0312 - val_mae: 2.4095\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.8770 - mae: 1.9384 - val_loss: 10.8650 - val_mae: 2.4994\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.7505 - mae: 1.9362 - val_loss: 11.8725 - val_mae: 2.7029\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.7746 - mae: 1.9688 - val_loss: 11.4333 - val_mae: 2.5758\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.4939 - mae: 1.8371 - val_loss: 13.5871 - val_mae: 2.9400\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.8433 - mae: 1.9549 - val_loss: 11.7285 - val_mae: 2.6502\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.6895 - mae: 1.9403 - val_loss: 11.8579 - val_mae: 2.5699\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.6947 - mae: 1.9747 - val_loss: 12.2098 - val_mae: 2.5264\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.1180 - mae: 1.7972 - val_loss: 13.2126 - val_mae: 2.8208\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.0211 - mae: 1.8060 - val_loss: 12.2786 - val_mae: 2.6274\n",
      "Epoch 29: early stopping\n",
      "Test Loss (MSE): 13.424915313720703, Test Mean Absolute Error (MAE): 2.7781178951263428\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 11.9733 - mae: 2.4502 - val_loss: 11.4163 - val_mae: 2.4957\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 9.6954 - mae: 2.1980 - val_loss: 10.7655 - val_mae: 2.5230\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.8114 - mae: 2.0993 - val_loss: 10.6994 - val_mae: 2.4883\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.4092 - mae: 2.1496 - val_loss: 10.2745 - val_mae: 2.3429\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.2144 - mae: 2.1114 - val_loss: 10.6334 - val_mae: 2.3364\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.8308 - mae: 2.1236 - val_loss: 11.0577 - val_mae: 2.2907\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.9638 - mae: 2.0997 - val_loss: 10.2533 - val_mae: 2.4399\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.2778 - mae: 1.9750 - val_loss: 10.7215 - val_mae: 2.4855\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.0131 - mae: 1.9382 - val_loss: 10.6292 - val_mae: 2.4443\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.6559 - mae: 1.8915 - val_loss: 10.8831 - val_mae: 2.4604\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.7625 - mae: 1.8993 - val_loss: 10.6766 - val_mae: 2.3953\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.4075 - mae: 1.8505 - val_loss: 11.3499 - val_mae: 2.4127\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.9854 - mae: 1.7895 - val_loss: 11.7144 - val_mae: 2.6404\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.6890 - mae: 1.6952 - val_loss: 11.7691 - val_mae: 2.5267\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.1800 - mae: 1.5948 - val_loss: 12.2802 - val_mae: 2.5873\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.0102 - mae: 1.5781 - val_loss: 12.1459 - val_mae: 2.4955\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.0076 - mae: 1.5092 - val_loss: 13.1743 - val_mae: 2.7105\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.6779 - mae: 1.4078 - val_loss: 12.3206 - val_mae: 2.6030\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.3789 - mae: 1.4150 - val_loss: 12.6490 - val_mae: 2.6832\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.0331 - mae: 1.3290 - val_loss: 12.6309 - val_mae: 2.6027\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.7456 - mae: 1.2306 - val_loss: 13.2350 - val_mae: 2.6119\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.7902 - mae: 1.2463 - val_loss: 13.5129 - val_mae: 2.7175\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.8956 - mae: 1.2592 - val_loss: 13.0467 - val_mae: 2.6451\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.4937 - mae: 1.1533 - val_loss: 13.8882 - val_mae: 2.7323\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2125 - mae: 1.0772 - val_loss: 13.6327 - val_mae: 2.8200\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.3006 - mae: 1.1061 - val_loss: 13.3100 - val_mae: 2.6159\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.0644 - mae: 1.0470 - val_loss: 13.5802 - val_mae: 2.7409\n",
      "Epoch 27: early stopping\n",
      "Test Loss (MSE): 14.44521427154541, Test Mean Absolute Error (MAE): 2.5723702907562256\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 11.8169 - mae: 2.3308 - val_loss: 12.4064 - val_mae: 2.5797\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.0595 - mae: 2.0978 - val_loss: 11.8814 - val_mae: 2.4215\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.5701 - mae: 2.0845 - val_loss: 11.0635 - val_mae: 2.5229\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.1646 - mae: 2.0580 - val_loss: 11.2140 - val_mae: 2.3641\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.8128 - mae: 2.0023 - val_loss: 10.8169 - val_mae: 2.4546\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.5310 - mae: 1.9685 - val_loss: 10.7621 - val_mae: 2.4974\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.3862 - mae: 1.9995 - val_loss: 11.1529 - val_mae: 2.4644\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.6342 - mae: 1.9961 - val_loss: 10.8349 - val_mae: 2.6815\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.3602 - mae: 1.8457 - val_loss: 11.4717 - val_mae: 2.7714\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.5617 - mae: 1.9843 - val_loss: 10.5978 - val_mae: 2.5722\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.1655 - mae: 1.9720 - val_loss: 13.0680 - val_mae: 2.4461\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.5777 - mae: 1.9547 - val_loss: 11.4049 - val_mae: 2.4962\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.7535 - mae: 1.7797 - val_loss: 11.5852 - val_mae: 2.7756\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.7490 - mae: 1.8256 - val_loss: 11.5091 - val_mae: 2.6671\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.3536 - mae: 1.7961 - val_loss: 11.4732 - val_mae: 2.6287\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.2322 - mae: 1.8085 - val_loss: 11.5323 - val_mae: 2.6135\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.0393 - mae: 1.7303 - val_loss: 12.0165 - val_mae: 2.6287\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.9218 - mae: 1.7295 - val_loss: 11.6993 - val_mae: 2.6474\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.9036 - mae: 1.7343 - val_loss: 11.7586 - val_mae: 2.7046\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.9884 - mae: 1.6995 - val_loss: 12.4380 - val_mae: 2.8396\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.5406 - mae: 1.6101 - val_loss: 12.3093 - val_mae: 2.7394\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.4787 - mae: 1.6044 - val_loss: 12.0819 - val_mae: 2.7211\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.3798 - mae: 1.6009 - val_loss: 12.3528 - val_mae: 2.6697\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.3431 - mae: 1.5631 - val_loss: 12.7967 - val_mae: 2.6531\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.3269 - mae: 1.6496 - val_loss: 12.0389 - val_mae: 2.5240\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.1434 - mae: 1.5117 - val_loss: 13.7264 - val_mae: 2.8378\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.8584 - mae: 1.4975 - val_loss: 12.8648 - val_mae: 2.7725\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.4430 - mae: 1.4116 - val_loss: 12.7073 - val_mae: 2.7291\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.3443 - mae: 1.3860 - val_loss: 13.2534 - val_mae: 2.7489\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.5167 - mae: 1.4272 - val_loss: 12.5438 - val_mae: 2.6860\n",
      "Epoch 30: early stopping\n",
      "Test Loss (MSE): 16.851041793823242, Test Mean Absolute Error (MAE): 3.104228973388672\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.1945 - mae: 0.8808 - val_loss: 4.8330 - val_mae: 0.8470\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 0s 936us/step - loss: 3.4070 - mae: 0.8198 - val_loss: 3.8323 - val_mae: 0.8842\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 0s 967us/step - loss: 3.1239 - mae: 0.7805 - val_loss: 3.6839 - val_mae: 0.9992\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 0s 983us/step - loss: 3.0894 - mae: 0.8315 - val_loss: 4.2956 - val_mae: 0.8611\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 0s 958us/step - loss: 3.1071 - mae: 0.7953 - val_loss: 3.5794 - val_mae: 0.8713\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 0s 916us/step - loss: 2.9639 - mae: 0.7742 - val_loss: 3.8126 - val_mae: 0.8642\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 0s 948us/step - loss: 3.0913 - mae: 0.8563 - val_loss: 3.6363 - val_mae: 0.9992\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 0s 906us/step - loss: 2.8975 - mae: 0.8079 - val_loss: 3.7899 - val_mae: 0.8195\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 0s 917us/step - loss: 2.9504 - mae: 0.7723 - val_loss: 3.5434 - val_mae: 0.9427\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 0s 927us/step - loss: 2.9424 - mae: 0.7733 - val_loss: 3.5284 - val_mae: 1.0569\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 0s 859us/step - loss: 2.8376 - mae: 0.7932 - val_loss: 4.0711 - val_mae: 0.8325\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 0s 955us/step - loss: 3.0159 - mae: 0.7703 - val_loss: 3.5398 - val_mae: 0.9600\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 0s 938us/step - loss: 2.8836 - mae: 0.7785 - val_loss: 3.5294 - val_mae: 0.8777\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 0s 949us/step - loss: 2.8260 - mae: 0.7601 - val_loss: 3.7061 - val_mae: 0.8779\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 0s 917us/step - loss: 2.8922 - mae: 0.7786 - val_loss: 3.7626 - val_mae: 0.8167\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 0s 969us/step - loss: 2.8952 - mae: 0.8220 - val_loss: 3.6366 - val_mae: 0.9427\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 0s 944us/step - loss: 2.8172 - mae: 0.7570 - val_loss: 3.7942 - val_mae: 0.8750\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 0s 856us/step - loss: 2.9056 - mae: 0.7635 - val_loss: 3.5267 - val_mae: 0.9031\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 0s 950us/step - loss: 2.8154 - mae: 0.7626 - val_loss: 3.5703 - val_mae: 0.9051\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 0s 898us/step - loss: 2.7884 - mae: 0.7774 - val_loss: 3.5691 - val_mae: 1.0103\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 0s 891us/step - loss: 2.8042 - mae: 0.7613 - val_loss: 3.5487 - val_mae: 0.8963\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 0s 879us/step - loss: 2.7949 - mae: 0.7664 - val_loss: 3.5482 - val_mae: 0.9316\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 0s 937us/step - loss: 2.7999 - mae: 0.7356 - val_loss: 3.8909 - val_mae: 0.9604\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 0s 893us/step - loss: 2.8484 - mae: 0.8539 - val_loss: 3.5402 - val_mae: 0.8962\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 0s 909us/step - loss: 2.7389 - mae: 0.7500 - val_loss: 3.7830 - val_mae: 0.8598\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 0s 978us/step - loss: 2.8039 - mae: 0.7611 - val_loss: 3.5343 - val_mae: 0.8780\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 0s 922us/step - loss: 2.7628 - mae: 0.7457 - val_loss: 3.5819 - val_mae: 0.9512\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 0s 964us/step - loss: 2.7758 - mae: 0.7633 - val_loss: 3.6965 - val_mae: 0.8577\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 0s 935us/step - loss: 2.7779 - mae: 0.7568 - val_loss: 3.7218 - val_mae: 0.8217\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.7804 - mae: 0.7510 - val_loss: 3.5874 - val_mae: 0.8968\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 0s 942us/step - loss: 2.7799 - mae: 0.7829 - val_loss: 3.6221 - val_mae: 0.8968\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 0s 962us/step - loss: 2.7596 - mae: 0.7359 - val_loss: 3.5411 - val_mae: 0.9497\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 0s 923us/step - loss: 2.7359 - mae: 0.7603 - val_loss: 3.5730 - val_mae: 0.9145\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 0s 950us/step - loss: 2.7550 - mae: 0.7748 - val_loss: 3.5274 - val_mae: 0.9574\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 0s 955us/step - loss: 2.7278 - mae: 0.7628 - val_loss: 3.5628 - val_mae: 0.8952\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 0s 930us/step - loss: 2.7331 - mae: 0.7814 - val_loss: 3.5648 - val_mae: 0.8741\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 0s 915us/step - loss: 2.7991 - mae: 0.7595 - val_loss: 3.5678 - val_mae: 0.9501\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 0s 876us/step - loss: 2.7013 - mae: 0.7547 - val_loss: 3.5452 - val_mae: 0.9229\n",
      "Epoch 38: early stopping\n",
      "Test Loss (MSE): 3.6767148971557617, Test Mean Absolute Error (MAE): 0.9705855250358582\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 4.4517 - mae: 0.9167 - val_loss: 4.7707 - val_mae: 0.7934\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.6538 - mae: 0.8555 - val_loss: 3.9098 - val_mae: 0.8401\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.2067 - mae: 0.8472 - val_loss: 3.7746 - val_mae: 0.9506\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.0180 - mae: 0.8149 - val_loss: 3.7176 - val_mae: 0.8830\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.9231 - mae: 0.8125 - val_loss: 3.8985 - val_mae: 0.8500\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.0241 - mae: 0.8117 - val_loss: 3.7134 - val_mae: 0.9422\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.9668 - mae: 0.8120 - val_loss: 3.7905 - val_mae: 0.8699\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.8717 - mae: 0.8118 - val_loss: 3.7600 - val_mae: 0.9067\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.8425 - mae: 0.7757 - val_loss: 3.9080 - val_mae: 0.9805\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 0s 980us/step - loss: 2.7749 - mae: 0.7905 - val_loss: 3.7833 - val_mae: 0.9197\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.7342 - mae: 0.7684 - val_loss: 3.9490 - val_mae: 0.9010\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.7124 - mae: 0.7667 - val_loss: 3.9008 - val_mae: 0.8592\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.6625 - mae: 0.7279 - val_loss: 4.3403 - val_mae: 1.0229\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.7639 - mae: 0.7659 - val_loss: 4.0296 - val_mae: 0.8506\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.6811 - mae: 0.7477 - val_loss: 3.9087 - val_mae: 0.8727\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.6420 - mae: 0.7429 - val_loss: 4.0458 - val_mae: 0.9459\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.6415 - mae: 0.7301 - val_loss: 3.9203 - val_mae: 0.9137\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.6409 - mae: 0.7290 - val_loss: 4.1681 - val_mae: 0.8679\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 0s 995us/step - loss: 2.5566 - mae: 0.7100 - val_loss: 4.0268 - val_mae: 0.9483\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.6012 - mae: 0.7146 - val_loss: 4.3514 - val_mae: 1.0304\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.5689 - mae: 0.7382 - val_loss: 4.2391 - val_mae: 0.8525\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.5953 - mae: 0.7178 - val_loss: 4.2246 - val_mae: 0.9839\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 0s 972us/step - loss: 2.6848 - mae: 0.7280 - val_loss: 4.3250 - val_mae: 0.9742\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 0s 958us/step - loss: 2.4860 - mae: 0.7151 - val_loss: 4.4381 - val_mae: 1.0360\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 0s 996us/step - loss: 2.5275 - mae: 0.7218 - val_loss: 4.3072 - val_mae: 0.8691\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.6177 - mae: 0.7163 - val_loss: 4.3218 - val_mae: 0.9573\n",
      "Epoch 26: early stopping\n",
      "Test Loss (MSE): 3.7851130962371826, Test Mean Absolute Error (MAE): 0.9325560927391052\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.7914 - mae: 1.0109 - val_loss: 3.7199 - val_mae: 0.6816\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 3.8055 - mae: 0.8869 - val_loss: 4.4578 - val_mae: 0.9884\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 0s 994us/step - loss: 3.6021 - mae: 0.8979 - val_loss: 3.4667 - val_mae: 0.7327\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 3.4929 - mae: 0.8963 - val_loss: 3.4959 - val_mae: 0.8334\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 0s 972us/step - loss: 3.3817 - mae: 0.8915 - val_loss: 3.3961 - val_mae: 0.8065\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 0s 900us/step - loss: 3.1409 - mae: 0.8560 - val_loss: 3.4141 - val_mae: 0.9257\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 0s 854us/step - loss: 3.0498 - mae: 0.8331 - val_loss: 3.4591 - val_mae: 0.8120\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 3.2625 - mae: 0.8807 - val_loss: 3.4129 - val_mae: 0.7675\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 0s 936us/step - loss: 3.0819 - mae: 0.8403 - val_loss: 3.3148 - val_mae: 0.7959\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 0s 965us/step - loss: 3.0291 - mae: 0.8634 - val_loss: 3.5036 - val_mae: 0.9231\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 3.0429 - mae: 0.8857 - val_loss: 3.8284 - val_mae: 0.9647\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 0s 910us/step - loss: 3.1022 - mae: 0.8771 - val_loss: 3.6958 - val_mae: 0.7940\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 0s 887us/step - loss: 2.9669 - mae: 0.8500 - val_loss: 3.5070 - val_mae: 0.7348\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 0s 896us/step - loss: 2.9369 - mae: 0.8074 - val_loss: 3.6373 - val_mae: 0.8444\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 0s 967us/step - loss: 2.9668 - mae: 0.8236 - val_loss: 3.7033 - val_mae: 0.8019\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 0s 977us/step - loss: 2.9300 - mae: 0.8123 - val_loss: 3.9131 - val_mae: 0.8480\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 0s 929us/step - loss: 2.8542 - mae: 0.8422 - val_loss: 3.8149 - val_mae: 0.8112\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 0s 907us/step - loss: 2.9038 - mae: 0.7964 - val_loss: 3.7182 - val_mae: 0.8513\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 0s 984us/step - loss: 2.8788 - mae: 0.8262 - val_loss: 3.7999 - val_mae: 0.7814\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.8414 - mae: 0.7812 - val_loss: 3.8693 - val_mae: 0.8361\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 0s 984us/step - loss: 2.7164 - mae: 0.8138 - val_loss: 3.8815 - val_mae: 0.8763\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.8525 - mae: 0.7849 - val_loss: 3.9522 - val_mae: 0.8685\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.9187 - mae: 0.8074 - val_loss: 4.0518 - val_mae: 0.8760\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.7970 - mae: 0.7792 - val_loss: 3.6059 - val_mae: 0.8548\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.6997 - mae: 0.7882 - val_loss: 4.0385 - val_mae: 0.8165\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.6764 - mae: 0.7551 - val_loss: 4.1398 - val_mae: 0.8879\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.6998 - mae: 0.7873 - val_loss: 4.1624 - val_mae: 0.8271\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.6550 - mae: 0.7619 - val_loss: 4.1112 - val_mae: 0.8029\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.6052 - mae: 0.7438 - val_loss: 4.0739 - val_mae: 0.8874\n",
      "Epoch 29: early stopping\n",
      "Test Loss (MSE): 4.879849433898926, Test Mean Absolute Error (MAE): 1.068732738494873\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.6100 - mae: 0.8697 - val_loss: 4.5040 - val_mae: 0.9341\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 0s 919us/step - loss: 3.9696 - mae: 0.8836 - val_loss: 4.2168 - val_mae: 0.9468\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 0s 939us/step - loss: 3.5594 - mae: 0.8391 - val_loss: 4.7155 - val_mae: 0.8917\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 3.4469 - mae: 0.8632 - val_loss: 3.7186 - val_mae: 0.9805\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 3.2088 - mae: 0.8518 - val_loss: 4.0611 - val_mae: 0.9831\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 0s 929us/step - loss: 3.0778 - mae: 0.8278 - val_loss: 3.5416 - val_mae: 0.9488\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 0s 971us/step - loss: 3.0105 - mae: 0.8436 - val_loss: 3.8176 - val_mae: 0.8214\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 0s 975us/step - loss: 3.1286 - mae: 0.8282 - val_loss: 4.1767 - val_mae: 0.9137\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 0s 963us/step - loss: 2.9923 - mae: 0.8317 - val_loss: 3.6517 - val_mae: 0.9450\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.9666 - mae: 0.8503 - val_loss: 3.7708 - val_mae: 0.9084\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.9762 - mae: 0.8069 - val_loss: 3.8156 - val_mae: 0.8751\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.9400 - mae: 0.8474 - val_loss: 4.1010 - val_mae: 0.9101\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 0s 991us/step - loss: 2.9192 - mae: 0.8113 - val_loss: 3.4951 - val_mae: 0.9004\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 0s 955us/step - loss: 3.0703 - mae: 0.8365 - val_loss: 3.4313 - val_mae: 0.9211\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.8051 - mae: 0.8122 - val_loss: 3.7934 - val_mae: 0.9451\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.7790 - mae: 0.8046 - val_loss: 3.6755 - val_mae: 0.9186\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.8094 - mae: 0.7956 - val_loss: 3.7603 - val_mae: 0.9236\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.7660 - mae: 0.7983 - val_loss: 3.5356 - val_mae: 0.8956\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.8009 - mae: 0.7838 - val_loss: 3.7513 - val_mae: 0.8948\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.7621 - mae: 0.7731 - val_loss: 3.6257 - val_mae: 0.9081\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.9410 - mae: 0.8484 - val_loss: 3.9494 - val_mae: 0.8865\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.8135 - mae: 0.7854 - val_loss: 3.6822 - val_mae: 0.8993\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.7925 - mae: 0.8093 - val_loss: 3.6673 - val_mae: 0.9195\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.7362 - mae: 0.7781 - val_loss: 3.7088 - val_mae: 0.9017\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.7430 - mae: 0.7850 - val_loss: 3.7161 - val_mae: 0.9668\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 0s 977us/step - loss: 2.7115 - mae: 0.7918 - val_loss: 3.8601 - val_mae: 0.9503\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 2.7218 - mae: 0.7696 - val_loss: 3.9599 - val_mae: 1.0013\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 0s 986us/step - loss: 2.7240 - mae: 0.7942 - val_loss: 4.2025 - val_mae: 0.9623\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 0s 964us/step - loss: 2.8325 - mae: 0.7880 - val_loss: 3.9150 - val_mae: 1.0307\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 0s 996us/step - loss: 2.8196 - mae: 0.8112 - val_loss: 3.9412 - val_mae: 0.9983\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 0s 976us/step - loss: 2.7852 - mae: 0.7970 - val_loss: 3.8646 - val_mae: 0.9385\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 0s 966us/step - loss: 2.7739 - mae: 0.7892 - val_loss: 3.7535 - val_mae: 0.9025\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 0s 976us/step - loss: 2.7387 - mae: 0.7705 - val_loss: 4.0034 - val_mae: 0.9229\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 0s 994us/step - loss: 2.7009 - mae: 0.7905 - val_loss: 3.9540 - val_mae: 0.8900\n",
      "Epoch 34: early stopping\n",
      "Test Loss (MSE): 3.458367347717285, Test Mean Absolute Error (MAE): 0.8310196995735168\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 11.7838 - mae: 2.4489 - val_loss: 10.3786 - val_mae: 2.4660\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 9.4403 - mae: 2.3372 - val_loss: 10.2806 - val_mae: 2.2857\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 9.0265 - mae: 2.1597 - val_loss: 9.8915 - val_mae: 2.4785\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.9959 - mae: 2.2451 - val_loss: 9.3788 - val_mae: 2.2722\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.9186 - mae: 2.2743 - val_loss: 9.2169 - val_mae: 2.1931\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.6542 - mae: 2.3211 - val_loss: 9.5202 - val_mae: 2.2496\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.7018 - mae: 2.2563 - val_loss: 8.9189 - val_mae: 2.2351\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.3730 - mae: 2.2068 - val_loss: 8.6959 - val_mae: 2.2583\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.1263 - mae: 2.1920 - val_loss: 8.8589 - val_mae: 2.2049\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.0223 - mae: 2.1842 - val_loss: 8.9160 - val_mae: 2.1978\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.3226 - mae: 2.2013 - val_loss: 9.4419 - val_mae: 2.1754\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.2674 - mae: 2.2389 - val_loss: 9.5888 - val_mae: 2.1763\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.0491 - mae: 2.1728 - val_loss: 9.0200 - val_mae: 2.3743\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.8545 - mae: 2.1460 - val_loss: 8.8982 - val_mae: 2.2336\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.7679 - mae: 2.1677 - val_loss: 9.1283 - val_mae: 2.2207\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.8919 - mae: 2.1679 - val_loss: 8.5870 - val_mae: 2.2635\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.8142 - mae: 2.1229 - val_loss: 8.8644 - val_mae: 2.3091\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.6184 - mae: 2.1492 - val_loss: 9.5202 - val_mae: 2.2352\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.6944 - mae: 2.1809 - val_loss: 8.9851 - val_mae: 2.2514\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.5708 - mae: 2.1574 - val_loss: 9.4027 - val_mae: 2.2229\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.7819 - mae: 2.1292 - val_loss: 8.9924 - val_mae: 2.2612\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.5726 - mae: 2.1388 - val_loss: 9.3253 - val_mae: 2.3276\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.0273 - mae: 2.0615 - val_loss: 9.5597 - val_mae: 2.4551\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.9032 - mae: 2.0840 - val_loss: 9.5862 - val_mae: 2.3144\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.6287 - mae: 2.1828 - val_loss: 9.4864 - val_mae: 2.2501\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.5663 - mae: 2.1482 - val_loss: 9.5137 - val_mae: 2.3011\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.5595 - mae: 2.0488 - val_loss: 9.3085 - val_mae: 2.3110\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.3313 - mae: 2.0857 - val_loss: 9.5185 - val_mae: 2.3460\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.2689 - mae: 2.0683 - val_loss: 9.6121 - val_mae: 2.3965\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.2465 - mae: 2.0801 - val_loss: 9.5801 - val_mae: 2.3644\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.2236 - mae: 2.0750 - val_loss: 9.8934 - val_mae: 2.3292\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.1267 - mae: 2.0691 - val_loss: 9.4769 - val_mae: 2.3529\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.1638 - mae: 2.0619 - val_loss: 9.8912 - val_mae: 2.3272\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.3764 - mae: 2.0871 - val_loss: 9.7547 - val_mae: 2.3622\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.1644 - mae: 2.0274 - val_loss: 9.8677 - val_mae: 2.3972\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.2203 - mae: 2.1086 - val_loss: 9.5395 - val_mae: 2.2827\n",
      "Epoch 36: early stopping\n",
      "Test Loss (MSE): 11.023653984069824, Test Mean Absolute Error (MAE): 2.4213504791259766\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 13.0928 - mae: 2.6246 - val_loss: 11.3432 - val_mae: 2.3482\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 9.5274 - mae: 2.2612 - val_loss: 10.7936 - val_mae: 2.4023\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.9817 - mae: 2.2483 - val_loss: 10.8734 - val_mae: 2.4900\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.3898 - mae: 2.1446 - val_loss: 11.1762 - val_mae: 2.4607\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.9484 - mae: 2.0553 - val_loss: 12.0010 - val_mae: 2.7563\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.1807 - mae: 2.1158 - val_loss: 11.6710 - val_mae: 2.5570\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.7707 - mae: 2.0998 - val_loss: 11.8648 - val_mae: 2.4641\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.4607 - mae: 1.9835 - val_loss: 11.6291 - val_mae: 2.6495\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.5627 - mae: 2.0488 - val_loss: 11.4949 - val_mae: 2.5483\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.3970 - mae: 2.0636 - val_loss: 12.9360 - val_mae: 2.4936\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.6653 - mae: 2.0044 - val_loss: 12.9501 - val_mae: 2.5279\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.1375 - mae: 2.0097 - val_loss: 12.1727 - val_mae: 2.5986\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.7457 - mae: 1.9314 - val_loss: 12.5896 - val_mae: 2.6728\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.6487 - mae: 1.9327 - val_loss: 12.6134 - val_mae: 2.6280\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.5534 - mae: 1.9078 - val_loss: 13.2875 - val_mae: 2.6005\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.4688 - mae: 1.8589 - val_loss: 12.9409 - val_mae: 2.7647\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.0773 - mae: 1.8149 - val_loss: 13.4647 - val_mae: 2.6795\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.2694 - mae: 1.8170 - val_loss: 13.4899 - val_mae: 2.7544\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.0320 - mae: 1.7940 - val_loss: 13.3675 - val_mae: 2.7394\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.1438 - mae: 1.8451 - val_loss: 13.8461 - val_mae: 2.7508\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.9309 - mae: 1.7584 - val_loss: 13.9200 - val_mae: 2.7308\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.1543 - mae: 1.9611 - val_loss: 14.0059 - val_mae: 2.7635\n",
      "Epoch 22: early stopping\n",
      "Test Loss (MSE): 10.311485290527344, Test Mean Absolute Error (MAE): 2.201216220855713\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 11.7178 - mae: 2.4739 - val_loss: 10.8307 - val_mae: 2.4357\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.5124 - mae: 2.1369 - val_loss: 10.6983 - val_mae: 2.4471\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.1541 - mae: 2.2426 - val_loss: 10.2348 - val_mae: 2.3088\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.5316 - mae: 2.1506 - val_loss: 10.7741 - val_mae: 2.2691\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.2291 - mae: 2.0900 - val_loss: 10.6117 - val_mae: 2.4889\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.6224 - mae: 1.9569 - val_loss: 10.3626 - val_mae: 2.4757\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.6748 - mae: 2.0119 - val_loss: 11.3690 - val_mae: 2.6620\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.4693 - mae: 2.0204 - val_loss: 10.1314 - val_mae: 2.3306\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.0627 - mae: 1.9210 - val_loss: 10.4848 - val_mae: 2.2316\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.2420 - mae: 1.9568 - val_loss: 10.4222 - val_mae: 2.2774\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.4327 - mae: 1.9335 - val_loss: 10.1803 - val_mae: 2.2007\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.9735 - mae: 1.8384 - val_loss: 10.5892 - val_mae: 2.4087\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.3715 - mae: 1.8192 - val_loss: 10.7098 - val_mae: 2.2431\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.1299 - mae: 1.7130 - val_loss: 11.0916 - val_mae: 2.3582\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.5892 - mae: 1.6323 - val_loss: 10.3830 - val_mae: 2.2509\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.4385 - mae: 1.6236 - val_loss: 11.0638 - val_mae: 2.4132\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.0090 - mae: 1.5269 - val_loss: 11.4316 - val_mae: 2.4175\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.1580 - mae: 1.5132 - val_loss: 12.0990 - val_mae: 2.5991\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.5357 - mae: 1.4175 - val_loss: 11.6278 - val_mae: 2.3814\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.0643 - mae: 1.3173 - val_loss: 12.4936 - val_mae: 2.6584\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.0469 - mae: 1.3270 - val_loss: 11.7542 - val_mae: 2.5103\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.6013 - mae: 1.1810 - val_loss: 12.7729 - val_mae: 2.6300\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.7541 - mae: 1.2303 - val_loss: 12.9398 - val_mae: 2.7403\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.2999 - mae: 1.1111 - val_loss: 12.9891 - val_mae: 2.6802\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.1465 - mae: 1.0873 - val_loss: 12.3313 - val_mae: 2.5030\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.8411 - mae: 0.9767 - val_loss: 13.2134 - val_mae: 2.5873\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.8666 - mae: 0.9865 - val_loss: 12.6862 - val_mae: 2.6115\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 2.6652 - mae: 0.9493 - val_loss: 13.2775 - val_mae: 2.6893\n",
      "Epoch 28: early stopping\n",
      "Test Loss (MSE): 16.103591918945312, Test Mean Absolute Error (MAE): 3.046816349029541\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 12.7630 - mae: 2.5371 - val_loss: 10.9602 - val_mae: 2.1295\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 9.7302 - mae: 2.2698 - val_loss: 10.0399 - val_mae: 2.4553\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.1694 - mae: 2.1614 - val_loss: 9.8106 - val_mae: 2.3683\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.7495 - mae: 2.2209 - val_loss: 9.7558 - val_mae: 2.2110\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.6453 - mae: 2.1442 - val_loss: 10.0205 - val_mae: 2.2767\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.4554 - mae: 2.1465 - val_loss: 9.8101 - val_mae: 2.2703\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.0948 - mae: 2.0928 - val_loss: 9.5648 - val_mae: 2.3879\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.5920 - mae: 2.0864 - val_loss: 11.0316 - val_mae: 2.2995\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.0455 - mae: 2.0465 - val_loss: 10.3071 - val_mae: 2.2707\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.7089 - mae: 2.0706 - val_loss: 10.0113 - val_mae: 2.2840\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.8257 - mae: 2.0392 - val_loss: 9.7817 - val_mae: 2.4409\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.2642 - mae: 1.9515 - val_loss: 11.2993 - val_mae: 2.7286\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.9598 - mae: 1.9152 - val_loss: 10.2539 - val_mae: 2.4195\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.9076 - mae: 1.9305 - val_loss: 10.6867 - val_mae: 2.3256\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.6347 - mae: 1.8955 - val_loss: 10.6069 - val_mae: 2.4407\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.2783 - mae: 1.7938 - val_loss: 10.7406 - val_mae: 2.5463\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.7264 - mae: 1.7287 - val_loss: 10.8636 - val_mae: 2.4976\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.8449 - mae: 1.7277 - val_loss: 11.2826 - val_mae: 2.4601\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.6423 - mae: 1.6891 - val_loss: 10.7254 - val_mae: 2.4740\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.7748 - mae: 1.6949 - val_loss: 12.3018 - val_mae: 2.7676\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.8284 - mae: 1.7408 - val_loss: 12.0753 - val_mae: 2.6330\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.8351 - mae: 1.5645 - val_loss: 11.6257 - val_mae: 2.5197\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.8332 - mae: 1.5175 - val_loss: 12.1120 - val_mae: 2.5262\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.7628 - mae: 1.4927 - val_loss: 11.6243 - val_mae: 2.5115\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.7013 - mae: 1.4721 - val_loss: 12.9540 - val_mae: 2.7320\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.7161 - mae: 1.4892 - val_loss: 12.9198 - val_mae: 2.7840\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.1612 - mae: 1.3975 - val_loss: 12.6735 - val_mae: 2.6155\n",
      "Epoch 27: early stopping\n",
      "Test Loss (MSE): 11.629579544067383, Test Mean Absolute Error (MAE): 2.3064398765563965\n",
      "Epoch 1/100\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 4.3525 - mae: 0.8839 - val_loss: 4.1466 - val_mae: 1.0111\n",
      "Epoch 2/100\n",
      "43/43 [==============================] - 0s 908us/step - loss: 3.6460 - mae: 0.8535 - val_loss: 3.9217 - val_mae: 1.0468\n",
      "Epoch 3/100\n",
      "43/43 [==============================] - 0s 886us/step - loss: 3.3712 - mae: 0.8776 - val_loss: 3.6649 - val_mae: 0.9827\n",
      "Epoch 4/100\n",
      "43/43 [==============================] - 0s 889us/step - loss: 3.3513 - mae: 0.8660 - val_loss: 3.7011 - val_mae: 0.9557\n",
      "Epoch 5/100\n",
      "43/43 [==============================] - 0s 864us/step - loss: 3.3662 - mae: 0.8480 - val_loss: 3.7237 - val_mae: 0.9473\n",
      "Epoch 6/100\n",
      "43/43 [==============================] - 0s 851us/step - loss: 3.1894 - mae: 0.8136 - val_loss: 3.7589 - val_mae: 1.0839\n",
      "Epoch 7/100\n",
      "43/43 [==============================] - 0s 860us/step - loss: 3.1809 - mae: 0.8687 - val_loss: 3.6987 - val_mae: 0.9856\n",
      "Epoch 8/100\n",
      "43/43 [==============================] - 0s 876us/step - loss: 3.0673 - mae: 0.8343 - val_loss: 3.6251 - val_mae: 0.9221\n",
      "Epoch 9/100\n",
      "43/43 [==============================] - 0s 928us/step - loss: 3.1374 - mae: 0.8372 - val_loss: 3.7799 - val_mae: 0.9262\n",
      "Epoch 10/100\n",
      "43/43 [==============================] - 0s 879us/step - loss: 3.2413 - mae: 0.7956 - val_loss: 3.8083 - val_mae: 0.9395\n",
      "Epoch 11/100\n",
      "43/43 [==============================] - 0s 871us/step - loss: 3.1157 - mae: 0.8840 - val_loss: 3.7881 - val_mae: 1.1442\n",
      "Epoch 12/100\n",
      "43/43 [==============================] - 0s 852us/step - loss: 3.0663 - mae: 0.8590 - val_loss: 3.5482 - val_mae: 1.0392\n",
      "Epoch 13/100\n",
      "43/43 [==============================] - 0s 852us/step - loss: 3.0251 - mae: 0.8248 - val_loss: 3.6069 - val_mae: 1.0521\n",
      "Epoch 14/100\n",
      "43/43 [==============================] - 0s 852us/step - loss: 2.9653 - mae: 0.8257 - val_loss: 3.9590 - val_mae: 1.1351\n",
      "Epoch 15/100\n",
      "43/43 [==============================] - 0s 833us/step - loss: 3.0309 - mae: 0.8378 - val_loss: 3.6448 - val_mae: 1.0040\n",
      "Epoch 16/100\n",
      "43/43 [==============================] - 0s 858us/step - loss: 3.0528 - mae: 0.8133 - val_loss: 3.5869 - val_mae: 0.9936\n",
      "Epoch 17/100\n",
      "43/43 [==============================] - 0s 836us/step - loss: 2.9725 - mae: 0.8161 - val_loss: 3.7139 - val_mae: 0.9535\n",
      "Epoch 18/100\n",
      "43/43 [==============================] - 0s 882us/step - loss: 2.9967 - mae: 0.7909 - val_loss: 3.7357 - val_mae: 0.9579\n",
      "Epoch 19/100\n",
      "43/43 [==============================] - 0s 827us/step - loss: 2.9515 - mae: 0.7903 - val_loss: 3.7911 - val_mae: 1.0490\n",
      "Epoch 20/100\n",
      "43/43 [==============================] - 0s 923us/step - loss: 3.0288 - mae: 0.8388 - val_loss: 3.7850 - val_mae: 0.9673\n",
      "Epoch 21/100\n",
      "43/43 [==============================] - 0s 913us/step - loss: 3.0422 - mae: 0.8013 - val_loss: 3.5835 - val_mae: 0.9987\n",
      "Epoch 22/100\n",
      "43/43 [==============================] - 0s 895us/step - loss: 3.0772 - mae: 0.8225 - val_loss: 3.8004 - val_mae: 1.0654\n",
      "Epoch 23/100\n",
      "43/43 [==============================] - 0s 870us/step - loss: 2.9521 - mae: 0.8197 - val_loss: 3.5986 - val_mae: 0.9533\n",
      "Epoch 24/100\n",
      "43/43 [==============================] - 0s 858us/step - loss: 2.9535 - mae: 0.8043 - val_loss: 3.6447 - val_mae: 1.0071\n",
      "Epoch 25/100\n",
      "43/43 [==============================] - 0s 845us/step - loss: 2.9527 - mae: 0.7981 - val_loss: 3.5849 - val_mae: 1.0338\n",
      "Epoch 26/100\n",
      "43/43 [==============================] - 0s 881us/step - loss: 3.0586 - mae: 0.8095 - val_loss: 3.6152 - val_mae: 0.9553\n",
      "Epoch 27/100\n",
      "43/43 [==============================] - 0s 873us/step - loss: 2.9648 - mae: 0.7952 - val_loss: 3.6216 - val_mae: 0.9883\n",
      "Epoch 28/100\n",
      "43/43 [==============================] - 0s 850us/step - loss: 2.9363 - mae: 0.8081 - val_loss: 3.5753 - val_mae: 1.0090\n",
      "Epoch 29/100\n",
      "43/43 [==============================] - 0s 883us/step - loss: 2.9483 - mae: 0.7920 - val_loss: 3.6353 - val_mae: 1.0197\n",
      "Epoch 30/100\n",
      "43/43 [==============================] - 0s 873us/step - loss: 2.9044 - mae: 0.8087 - val_loss: 3.6553 - val_mae: 0.9777\n",
      "Epoch 31/100\n",
      "43/43 [==============================] - 0s 954us/step - loss: 2.9356 - mae: 0.7932 - val_loss: 3.6902 - val_mae: 1.0135\n",
      "Epoch 32/100\n",
      "43/43 [==============================] - 0s 908us/step - loss: 2.9541 - mae: 0.8116 - val_loss: 3.7259 - val_mae: 0.9854\n",
      "Epoch 32: early stopping\n",
      "Test Loss (MSE): 2.9064524173736572, Test Mean Absolute Error (MAE): 0.8860824108123779\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 4.8058 - mae: 1.0637 - val_loss: 2.7517 - val_mae: 0.7458\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 0s 967us/step - loss: 3.9465 - mae: 0.9378 - val_loss: 2.4072 - val_mae: 0.8514\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 0s 955us/step - loss: 3.7936 - mae: 0.9633 - val_loss: 2.0610 - val_mae: 0.5169\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 3.9121 - mae: 0.9292 - val_loss: 2.1196 - val_mae: 0.5579\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 0s 937us/step - loss: 3.6095 - mae: 0.9384 - val_loss: 2.0536 - val_mae: 0.5349\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 0s 938us/step - loss: 3.6006 - mae: 0.9234 - val_loss: 1.9961 - val_mae: 0.4665\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 3.4813 - mae: 0.9279 - val_loss: 1.9691 - val_mae: 0.5106\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 3.4478 - mae: 0.9159 - val_loss: 2.1470 - val_mae: 0.6006\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 3.4374 - mae: 0.9270 - val_loss: 2.4104 - val_mae: 0.6934\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 0s 994us/step - loss: 3.5316 - mae: 0.9085 - val_loss: 2.0951 - val_mae: 0.5587\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 0s 949us/step - loss: 3.3590 - mae: 0.9205 - val_loss: 2.0267 - val_mae: 0.5450\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 0s 965us/step - loss: 3.3307 - mae: 0.8795 - val_loss: 2.1450 - val_mae: 0.5879\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 0s 979us/step - loss: 3.3005 - mae: 0.8667 - val_loss: 2.1126 - val_mae: 0.6094\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 0s 968us/step - loss: 3.2766 - mae: 0.8815 - val_loss: 2.1138 - val_mae: 0.5409\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 3.2281 - mae: 0.8782 - val_loss: 2.1372 - val_mae: 0.5652\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 3.1871 - mae: 0.8624 - val_loss: 2.0884 - val_mae: 0.5231\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 0s 993us/step - loss: 3.1768 - mae: 0.8453 - val_loss: 2.5503 - val_mae: 0.6864\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 3.1694 - mae: 0.8575 - val_loss: 2.1774 - val_mae: 0.5279\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 3.1301 - mae: 0.8356 - val_loss: 2.1694 - val_mae: 0.6007\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 3.1000 - mae: 0.8543 - val_loss: 2.1983 - val_mae: 0.5133\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 3.0889 - mae: 0.8498 - val_loss: 2.6899 - val_mae: 0.6850\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 0s 981us/step - loss: 3.0614 - mae: 0.8366 - val_loss: 2.3577 - val_mae: 0.5492\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 0s 926us/step - loss: 2.9468 - mae: 0.8262 - val_loss: 2.2343 - val_mae: 0.5420\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 0s 982us/step - loss: 3.0060 - mae: 0.8108 - val_loss: 2.1911 - val_mae: 0.6349\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 0s 982us/step - loss: 3.0076 - mae: 0.8382 - val_loss: 2.1792 - val_mae: 0.6426\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 0s 943us/step - loss: 2.9534 - mae: 0.8061 - val_loss: 2.2815 - val_mae: 0.5463\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 0s 932us/step - loss: 2.8876 - mae: 0.7901 - val_loss: 2.6242 - val_mae: 0.6296\n",
      "Epoch 27: early stopping\n",
      "Test Loss (MSE): 4.759065628051758, Test Mean Absolute Error (MAE): 1.1500166654586792\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.1042 - mae: 0.8813 - val_loss: 4.7442 - val_mae: 1.0150\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 0s 971us/step - loss: 3.3244 - mae: 0.8010 - val_loss: 4.1512 - val_mae: 0.9015\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 0s 904us/step - loss: 3.0864 - mae: 0.7915 - val_loss: 4.1465 - val_mae: 0.9018\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 0s 942us/step - loss: 3.1224 - mae: 0.7712 - val_loss: 4.0839 - val_mae: 0.9701\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 0s 934us/step - loss: 2.8517 - mae: 0.7898 - val_loss: 3.9921 - val_mae: 0.9621\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 0s 917us/step - loss: 2.8045 - mae: 0.7776 - val_loss: 4.3534 - val_mae: 0.9208\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.8254 - mae: 0.7683 - val_loss: 3.9263 - val_mae: 1.0162\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 0s 987us/step - loss: 2.7707 - mae: 0.7559 - val_loss: 4.0345 - val_mae: 0.9285\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 0s 937us/step - loss: 2.7404 - mae: 0.7536 - val_loss: 4.0100 - val_mae: 0.9660\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 0s 977us/step - loss: 2.7503 - mae: 0.7428 - val_loss: 3.9497 - val_mae: 1.0111\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 0s 933us/step - loss: 2.7574 - mae: 0.7980 - val_loss: 4.0559 - val_mae: 0.8924\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 0s 919us/step - loss: 2.6962 - mae: 0.7458 - val_loss: 4.3794 - val_mae: 0.9599\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 0s 948us/step - loss: 2.7944 - mae: 0.7701 - val_loss: 4.0856 - val_mae: 0.9693\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 0s 936us/step - loss: 2.6120 - mae: 0.7437 - val_loss: 4.2090 - val_mae: 1.0194\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 0s 890us/step - loss: 2.8053 - mae: 0.7396 - val_loss: 4.3211 - val_mae: 1.1905\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 0s 933us/step - loss: 2.6562 - mae: 0.7804 - val_loss: 4.3703 - val_mae: 0.9317\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.5332 - mae: 0.7213 - val_loss: 4.2704 - val_mae: 0.9623\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 0s 995us/step - loss: 2.5114 - mae: 0.7258 - val_loss: 4.6490 - val_mae: 1.0605\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.7968 - mae: 0.7244 - val_loss: 4.2812 - val_mae: 0.9744\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.4760 - mae: 0.7173 - val_loss: 4.4210 - val_mae: 0.9958\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 0s 979us/step - loss: 2.4105 - mae: 0.7031 - val_loss: 4.5877 - val_mae: 1.0538\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 0s 957us/step - loss: 2.5207 - mae: 0.7436 - val_loss: 4.4921 - val_mae: 1.0579\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.7267 - mae: 0.7280 - val_loss: 4.3101 - val_mae: 1.0830\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.4143 - mae: 0.7026 - val_loss: 4.5412 - val_mae: 1.0502\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.4325 - mae: 0.6840 - val_loss: 4.5737 - val_mae: 1.0457\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 0s 975us/step - loss: 2.4081 - mae: 0.6787 - val_loss: 4.5227 - val_mae: 1.0747\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 0s 988us/step - loss: 2.3761 - mae: 0.6917 - val_loss: 4.4851 - val_mae: 1.0703\n",
      "Epoch 27: early stopping\n",
      "Test Loss (MSE): 4.103752136230469, Test Mean Absolute Error (MAE): 1.0774154663085938\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 4.3239 - mae: 0.9102 - val_loss: 4.3346 - val_mae: 1.0197\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 3.7489 - mae: 0.8768 - val_loss: 4.1139 - val_mae: 0.9966\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 0s 962us/step - loss: 3.2201 - mae: 0.8209 - val_loss: 4.0358 - val_mae: 0.9921\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 0s 955us/step - loss: 3.1215 - mae: 0.8112 - val_loss: 3.8516 - val_mae: 1.0564\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 0s 985us/step - loss: 3.1473 - mae: 0.8074 - val_loss: 4.0563 - val_mae: 0.9800\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 3.1121 - mae: 0.8148 - val_loss: 4.4520 - val_mae: 0.9059\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 3.1417 - mae: 0.8598 - val_loss: 4.3823 - val_mae: 0.9458\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 3.1355 - mae: 0.8218 - val_loss: 3.9318 - val_mae: 0.8529\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 3.0874 - mae: 0.8130 - val_loss: 3.7467 - val_mae: 0.9129\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 3.0235 - mae: 0.7790 - val_loss: 3.8660 - val_mae: 0.9726\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.9510 - mae: 0.8239 - val_loss: 3.9245 - val_mae: 0.8642\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 0s 999us/step - loss: 2.9040 - mae: 0.7659 - val_loss: 3.8966 - val_mae: 0.9916\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 3.0693 - mae: 0.8139 - val_loss: 3.8958 - val_mae: 0.9631\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 0s 977us/step - loss: 2.9739 - mae: 0.8126 - val_loss: 3.8360 - val_mae: 0.9509\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.9092 - mae: 0.7614 - val_loss: 3.8851 - val_mae: 1.0050\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 0s 953us/step - loss: 2.8712 - mae: 0.7965 - val_loss: 3.9269 - val_mae: 0.9225\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 0s 960us/step - loss: 2.7517 - mae: 0.7597 - val_loss: 3.9476 - val_mae: 0.9490\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 0s 966us/step - loss: 2.7900 - mae: 0.7539 - val_loss: 3.9720 - val_mae: 1.0492\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 0s 966us/step - loss: 2.8181 - mae: 0.8022 - val_loss: 3.9296 - val_mae: 0.9690\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 0s 912us/step - loss: 2.8124 - mae: 0.7743 - val_loss: 3.7849 - val_mae: 0.8864\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 0s 899us/step - loss: 2.7163 - mae: 0.7781 - val_loss: 3.8600 - val_mae: 0.8818\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 0s 938us/step - loss: 2.7156 - mae: 0.7529 - val_loss: 4.1819 - val_mae: 0.9833\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 0s 946us/step - loss: 2.7459 - mae: 0.7794 - val_loss: 3.8949 - val_mae: 0.9164\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 0s 938us/step - loss: 2.7246 - mae: 0.7843 - val_loss: 4.1870 - val_mae: 1.0376\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 0s 915us/step - loss: 2.7591 - mae: 0.7703 - val_loss: 3.9678 - val_mae: 0.9345\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 0s 890us/step - loss: 2.6864 - mae: 0.7478 - val_loss: 4.2278 - val_mae: 1.0781\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 0s 986us/step - loss: 2.7722 - mae: 0.7961 - val_loss: 4.2609 - val_mae: 1.0409\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 0s 977us/step - loss: 2.7718 - mae: 0.7521 - val_loss: 3.9062 - val_mae: 0.9436\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 0s 943us/step - loss: 2.6277 - mae: 0.7694 - val_loss: 3.8858 - val_mae: 0.8850\n",
      "Epoch 29: early stopping\n",
      "Test Loss (MSE): 3.1058576107025146, Test Mean Absolute Error (MAE): 0.7749799489974976\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 11.9168 - mae: 2.4457 - val_loss: 10.5749 - val_mae: 2.1987\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 10.3147 - mae: 2.3707 - val_loss: 9.4197 - val_mae: 2.1524\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.2806 - mae: 2.2189 - val_loss: 8.9049 - val_mae: 2.4250\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.9861 - mae: 2.2212 - val_loss: 8.6914 - val_mae: 2.1652\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.9351 - mae: 2.2333 - val_loss: 8.4946 - val_mae: 2.2242\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.6289 - mae: 2.2480 - val_loss: 8.7751 - val_mae: 2.0900\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.6562 - mae: 2.2347 - val_loss: 8.3532 - val_mae: 2.3292\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.6987 - mae: 2.2210 - val_loss: 8.4375 - val_mae: 2.4056\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.4228 - mae: 2.1696 - val_loss: 8.2813 - val_mae: 2.3786\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.2207 - mae: 2.1558 - val_loss: 8.2162 - val_mae: 2.3107\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.1228 - mae: 2.1758 - val_loss: 8.0460 - val_mae: 2.2246\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.2332 - mae: 2.1638 - val_loss: 8.6753 - val_mae: 2.5732\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.2549 - mae: 2.1807 - val_loss: 8.1064 - val_mae: 2.2963\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.2271 - mae: 2.1665 - val_loss: 8.3629 - val_mae: 2.3778\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.7320 - mae: 2.1166 - val_loss: 8.0491 - val_mae: 2.2640\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.6097 - mae: 2.2814 - val_loss: 9.7352 - val_mae: 2.0906\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.8213 - mae: 2.1940 - val_loss: 8.2713 - val_mae: 2.4110\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.0918 - mae: 2.1709 - val_loss: 8.0958 - val_mae: 2.1995\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.1552 - mae: 2.1920 - val_loss: 8.0097 - val_mae: 2.2012\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.0544 - mae: 2.1267 - val_loss: 8.0324 - val_mae: 2.3154\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.9370 - mae: 2.1476 - val_loss: 8.0915 - val_mae: 2.1476\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.9360 - mae: 2.1505 - val_loss: 8.1769 - val_mae: 2.1861\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.8730 - mae: 2.1203 - val_loss: 8.0732 - val_mae: 2.2365\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.8230 - mae: 2.1270 - val_loss: 8.1294 - val_mae: 2.2252\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.9113 - mae: 2.1936 - val_loss: 9.2355 - val_mae: 2.1373\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.1907 - mae: 2.1035 - val_loss: 8.2662 - val_mae: 2.3466\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.7432 - mae: 2.0954 - val_loss: 8.1102 - val_mae: 2.2942\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.0767 - mae: 2.1667 - val_loss: 9.1088 - val_mae: 2.1484\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.9517 - mae: 2.1630 - val_loss: 8.2211 - val_mae: 2.2688\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.8157 - mae: 2.0534 - val_loss: 8.2622 - val_mae: 2.3016\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.6933 - mae: 2.1319 - val_loss: 8.1535 - val_mae: 2.2752\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.7051 - mae: 2.0781 - val_loss: 8.7105 - val_mae: 2.4675\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.9794 - mae: 2.1393 - val_loss: 8.2807 - val_mae: 2.1882\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.6975 - mae: 2.1810 - val_loss: 8.5422 - val_mae: 2.1981\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.7916 - mae: 2.0534 - val_loss: 8.5968 - val_mae: 2.3852\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.7638 - mae: 2.1050 - val_loss: 8.2773 - val_mae: 2.2639\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.5512 - mae: 2.1210 - val_loss: 8.3254 - val_mae: 2.2317\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.6192 - mae: 2.1355 - val_loss: 8.4521 - val_mae: 2.1947\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.9144 - mae: 2.1089 - val_loss: 9.0326 - val_mae: 2.5351\n",
      "Epoch 39: early stopping\n",
      "Test Loss (MSE): 11.504789352416992, Test Mean Absolute Error (MAE): 2.8055830001831055\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 11.1093 - mae: 2.3998 - val_loss: 9.6656 - val_mae: 2.2365\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 9.2416 - mae: 2.2191 - val_loss: 9.9491 - val_mae: 2.1520\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.4513 - mae: 2.1693 - val_loss: 10.1210 - val_mae: 2.1582\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.8422 - mae: 2.0501 - val_loss: 9.7276 - val_mae: 2.3174\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.6296 - mae: 1.9855 - val_loss: 9.7843 - val_mae: 2.2216\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.3411 - mae: 2.0525 - val_loss: 10.7037 - val_mae: 2.1936\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.3337 - mae: 1.9654 - val_loss: 10.3437 - val_mae: 2.2512\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.8021 - mae: 1.9380 - val_loss: 10.0897 - val_mae: 2.2906\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.7855 - mae: 1.9221 - val_loss: 10.6595 - val_mae: 2.3304\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.3468 - mae: 1.8371 - val_loss: 10.6440 - val_mae: 2.2499\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.2278 - mae: 1.7770 - val_loss: 10.9512 - val_mae: 2.4460\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.9743 - mae: 1.7774 - val_loss: 11.4590 - val_mae: 2.5210\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.7949 - mae: 1.7525 - val_loss: 11.1667 - val_mae: 2.3167\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.7330 - mae: 1.7050 - val_loss: 11.7762 - val_mae: 2.4040\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.3957 - mae: 1.6390 - val_loss: 12.2764 - val_mae: 2.4153\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.2533 - mae: 1.5933 - val_loss: 11.6616 - val_mae: 2.4479\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.7437 - mae: 1.6906 - val_loss: 12.2993 - val_mae: 2.6074\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.2399 - mae: 1.5597 - val_loss: 12.4187 - val_mae: 2.5607\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.9418 - mae: 1.5561 - val_loss: 12.6310 - val_mae: 2.4487\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.4905 - mae: 1.4523 - val_loss: 12.0513 - val_mae: 2.4817\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.2943 - mae: 1.4355 - val_loss: 13.1530 - val_mae: 2.6196\n",
      "Epoch 21: early stopping\n",
      "Test Loss (MSE): 16.758480072021484, Test Mean Absolute Error (MAE): 2.8649747371673584\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 12.4416 - mae: 2.5537 - val_loss: 9.3538 - val_mae: 2.2684\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 9.7068 - mae: 2.2303 - val_loss: 9.1908 - val_mae: 2.1045\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 9.3763 - mae: 2.2549 - val_loss: 9.8701 - val_mae: 2.0255\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.2600 - mae: 2.1727 - val_loss: 8.7320 - val_mae: 2.0144\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.8709 - mae: 2.1764 - val_loss: 8.7755 - val_mae: 2.0934\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.0453 - mae: 1.9717 - val_loss: 9.3341 - val_mae: 2.3432\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.0127 - mae: 2.1065 - val_loss: 8.7743 - val_mae: 2.1725\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.5362 - mae: 1.9145 - val_loss: 10.1974 - val_mae: 2.4147\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.2553 - mae: 1.9518 - val_loss: 8.9284 - val_mae: 2.2036\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.1618 - mae: 1.9199 - val_loss: 9.5970 - val_mae: 2.2913\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.6449 - mae: 1.8233 - val_loss: 10.2103 - val_mae: 2.4261\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.6168 - mae: 1.8445 - val_loss: 10.2228 - val_mae: 2.4153\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.9920 - mae: 1.7184 - val_loss: 10.3643 - val_mae: 2.3964\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.7121 - mae: 1.7091 - val_loss: 10.7586 - val_mae: 2.3816\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.1314 - mae: 1.5894 - val_loss: 10.1627 - val_mae: 2.2522\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 5.0499 - mae: 1.5133 - val_loss: 10.3881 - val_mae: 2.3323\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 4.6790 - mae: 1.4642 - val_loss: 10.7403 - val_mae: 2.2345\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.4016 - mae: 1.4118 - val_loss: 11.1955 - val_mae: 2.4393\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.2144 - mae: 1.3693 - val_loss: 10.9205 - val_mae: 2.2529\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.9494 - mae: 1.2885 - val_loss: 10.0865 - val_mae: 2.1630\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.2116 - mae: 1.3575 - val_loss: 10.5443 - val_mae: 2.2223\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.7644 - mae: 1.2707 - val_loss: 10.0532 - val_mae: 2.1405\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 3.5253 - mae: 1.2174 - val_loss: 11.0485 - val_mae: 2.2417\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.1079 - mae: 1.0874 - val_loss: 10.9431 - val_mae: 2.2336\n",
      "Epoch 24: early stopping\n",
      "Test Loss (MSE): 14.348372459411621, Test Mean Absolute Error (MAE): 2.8152549266815186\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 13.1335 - mae: 2.6366 - val_loss: 10.0824 - val_mae: 2.4479\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 10.1958 - mae: 2.3679 - val_loss: 10.2131 - val_mae: 2.5534\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 9.5075 - mae: 2.3121 - val_loss: 9.2775 - val_mae: 2.3197\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.9276 - mae: 2.2563 - val_loss: 9.5478 - val_mae: 2.4867\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.6798 - mae: 2.2190 - val_loss: 9.2134 - val_mae: 2.3853\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.7760 - mae: 2.1874 - val_loss: 11.0467 - val_mae: 2.7617\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.7567 - mae: 2.2195 - val_loss: 9.0430 - val_mae: 2.3325\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.9799 - mae: 2.1341 - val_loss: 8.9407 - val_mae: 2.3044\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.9887 - mae: 2.1492 - val_loss: 9.1515 - val_mae: 2.1040\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 8.4770 - mae: 2.1688 - val_loss: 10.7666 - val_mae: 2.1336\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 9.2731 - mae: 2.2926 - val_loss: 8.7122 - val_mae: 2.2483\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.7102 - mae: 2.0757 - val_loss: 8.8904 - val_mae: 2.2522\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.2968 - mae: 2.0483 - val_loss: 8.9790 - val_mae: 2.2449\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.1945 - mae: 1.9914 - val_loss: 9.2216 - val_mae: 2.3639\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.0298 - mae: 2.0100 - val_loss: 9.3528 - val_mae: 2.3351\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.6205 - mae: 1.8767 - val_loss: 9.9877 - val_mae: 2.4684\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.6311 - mae: 1.9054 - val_loss: 9.3788 - val_mae: 2.2057\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.9421 - mae: 2.0544 - val_loss: 9.8521 - val_mae: 2.1384\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 7.5882 - mae: 2.0704 - val_loss: 10.1356 - val_mae: 2.1648\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.4177 - mae: 1.9807 - val_loss: 9.8622 - val_mae: 2.3737\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.3133 - mae: 1.8207 - val_loss: 10.1134 - val_mae: 2.3508\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.1040 - mae: 1.7878 - val_loss: 9.9866 - val_mae: 2.1947\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 6.0854 - mae: 1.7623 - val_loss: 9.8413 - val_mae: 2.2649\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.7820 - mae: 1.7223 - val_loss: 10.3779 - val_mae: 2.4026\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.3935 - mae: 1.6626 - val_loss: 10.4922 - val_mae: 2.3657\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.1731 - mae: 1.6053 - val_loss: 10.7968 - val_mae: 2.3716\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.0963 - mae: 1.5588 - val_loss: 12.4290 - val_mae: 2.6619\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.9773 - mae: 1.5557 - val_loss: 11.1584 - val_mae: 2.4515\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 4.8455 - mae: 1.5071 - val_loss: 10.2274 - val_mae: 2.2945\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.0790 - mae: 1.5716 - val_loss: 12.2528 - val_mae: 2.6218\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 5.3045 - mae: 1.5899 - val_loss: 12.7807 - val_mae: 2.6972\n",
      "Epoch 31: early stopping\n",
      "Test Loss (MSE): 12.55118179321289, Test Mean Absolute Error (MAE): 2.5470824241638184\n",
      "Epoch 1/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.1067 - mae: 0.8306 - val_loss: 4.1805 - val_mae: 1.0040\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.3014 - mae: 0.8206 - val_loss: 3.9337 - val_mae: 1.0249\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.1441 - mae: 0.8106 - val_loss: 3.8642 - val_mae: 1.0815\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.0256 - mae: 0.8952 - val_loss: 3.8136 - val_mae: 1.1694\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.1554 - mae: 0.9208 - val_loss: 3.6604 - val_mae: 1.0379\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.0101 - mae: 0.8889 - val_loss: 3.7422 - val_mae: 1.0750\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.9186 - mae: 0.8099 - val_loss: 3.6139 - val_mae: 0.9006\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.8803 - mae: 0.8297 - val_loss: 3.6490 - val_mae: 0.9580\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.9143 - mae: 0.8226 - val_loss: 3.5945 - val_mae: 1.0431\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.8698 - mae: 0.8057 - val_loss: 3.6155 - val_mae: 0.9875\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.8187 - mae: 0.7787 - val_loss: 3.7868 - val_mae: 0.8842\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.8249 - mae: 0.7780 - val_loss: 3.5697 - val_mae: 0.8957\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.8175 - mae: 0.7791 - val_loss: 3.6364 - val_mae: 0.8793\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7745 - mae: 0.7906 - val_loss: 3.6185 - val_mae: 0.9821\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.8032 - mae: 0.7857 - val_loss: 3.6387 - val_mae: 1.0694\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.8069 - mae: 0.7954 - val_loss: 3.6048 - val_mae: 0.9678\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.1049 - mae: 0.8223 - val_loss: 4.0484 - val_mae: 1.0229\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.8623 - mae: 0.8199 - val_loss: 3.6436 - val_mae: 0.8784\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7364 - mae: 0.7486 - val_loss: 4.2057 - val_mae: 1.1376\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.8565 - mae: 0.7938 - val_loss: 3.5485 - val_mae: 0.9309\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7577 - mae: 0.7939 - val_loss: 3.5295 - val_mae: 0.9377\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7377 - mae: 0.7610 - val_loss: 3.5618 - val_mae: 1.0293\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.8032 - mae: 0.8066 - val_loss: 3.7660 - val_mae: 1.0121\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7331 - mae: 0.8216 - val_loss: 3.5409 - val_mae: 0.9026\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7547 - mae: 0.8623 - val_loss: 3.5286 - val_mae: 1.0225\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7155 - mae: 0.7850 - val_loss: 3.5658 - val_mae: 0.9285\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7332 - mae: 0.7786 - val_loss: 3.5630 - val_mae: 1.0809\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7148 - mae: 0.7984 - val_loss: 3.5729 - val_mae: 1.0706\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7199 - mae: 0.8521 - val_loss: 3.5349 - val_mae: 1.0161\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7387 - mae: 0.7692 - val_loss: 3.5753 - val_mae: 0.9664\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7449 - mae: 0.7873 - val_loss: 3.5602 - val_mae: 0.9719\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7874 - mae: 0.8390 - val_loss: 3.5614 - val_mae: 0.9376\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.6972 - mae: 0.7774 - val_loss: 3.5841 - val_mae: 0.9719\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.6623 - mae: 0.7991 - val_loss: 3.7532 - val_mae: 1.0362\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7098 - mae: 0.8663 - val_loss: 3.5852 - val_mae: 1.0116\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.6816 - mae: 0.7918 - val_loss: 3.5920 - val_mae: 1.0398\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.6812 - mae: 0.7839 - val_loss: 3.8240 - val_mae: 1.1196\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7187 - mae: 0.8667 - val_loss: 3.5479 - val_mae: 0.9125\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.6838 - mae: 0.7916 - val_loss: 3.5714 - val_mae: 0.9962\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.6253 - mae: 0.7966 - val_loss: 3.7849 - val_mae: 1.0725\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7037 - mae: 0.8688 - val_loss: 3.5605 - val_mae: 0.9826\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.6365 - mae: 0.7704 - val_loss: 3.5940 - val_mae: 0.9941\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.6467 - mae: 0.7875 - val_loss: 3.6542 - val_mae: 1.0170\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.6417 - mae: 0.7953 - val_loss: 3.5816 - val_mae: 0.9794\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.6175 - mae: 0.8045 - val_loss: 3.5903 - val_mae: 0.9461\n",
      "Epoch 45: early stopping\n",
      "Test Loss (MSE): 3.7674148082733154, Test Mean Absolute Error (MAE): 0.9544459581375122\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.9183 - mae: 0.8575 - val_loss: 5.3487 - val_mae: 1.0816\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.6866 - mae: 0.7798 - val_loss: 4.8056 - val_mae: 1.2581\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.1619 - mae: 0.7894 - val_loss: 4.6060 - val_mae: 1.1304\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.1147 - mae: 0.7767 - val_loss: 5.0860 - val_mae: 1.2910\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.9621 - mae: 0.7613 - val_loss: 6.2733 - val_mae: 1.4968\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.9939 - mae: 0.7759 - val_loss: 4.6941 - val_mae: 1.2507\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.9563 - mae: 0.7737 - val_loss: 4.7166 - val_mae: 1.2293\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.0732 - mae: 0.7949 - val_loss: 4.8704 - val_mae: 1.1004\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.8068 - mae: 0.7573 - val_loss: 4.6576 - val_mae: 1.1222\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.7406 - mae: 0.7313 - val_loss: 4.7694 - val_mae: 1.1942\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.6959 - mae: 0.7315 - val_loss: 5.3868 - val_mae: 1.3474\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.6542 - mae: 0.7300 - val_loss: 4.8706 - val_mae: 1.1579\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.5528 - mae: 0.7169 - val_loss: 5.1867 - val_mae: 1.1622\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.5585 - mae: 0.7100 - val_loss: 5.0048 - val_mae: 1.1913\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.4528 - mae: 0.7102 - val_loss: 5.0087 - val_mae: 1.0987\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.3542 - mae: 0.6661 - val_loss: 5.1215 - val_mae: 1.2045\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.2612 - mae: 0.6450 - val_loss: 5.2828 - val_mae: 1.2313\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.2708 - mae: 0.6240 - val_loss: 5.1560 - val_mae: 1.2593\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.3883 - mae: 0.6652 - val_loss: 5.7638 - val_mae: 1.3275\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.2468 - mae: 0.6540 - val_loss: 5.5264 - val_mae: 1.2494\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.1833 - mae: 0.6036 - val_loss: 5.4873 - val_mae: 1.2217\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.1327 - mae: 0.6581 - val_loss: 5.1776 - val_mae: 1.1011\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.9984 - mae: 0.5831 - val_loss: 5.7042 - val_mae: 1.2204\n",
      "Epoch 23: early stopping\n",
      "Test Loss (MSE): 3.3157575130462646, Test Mean Absolute Error (MAE): 0.6026126742362976\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.8712 - mae: 0.9070 - val_loss: 4.3882 - val_mae: 0.9848\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.7440 - mae: 0.8560 - val_loss: 4.3015 - val_mae: 1.0704\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.5256 - mae: 0.8895 - val_loss: 4.1475 - val_mae: 1.1308\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.4433 - mae: 0.8574 - val_loss: 4.0690 - val_mae: 1.0108\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.2333 - mae: 0.8628 - val_loss: 3.9349 - val_mae: 1.1014\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.1102 - mae: 0.8155 - val_loss: 3.9329 - val_mae: 1.0195\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.1329 - mae: 0.8313 - val_loss: 3.9610 - val_mae: 1.0403\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.0770 - mae: 0.8094 - val_loss: 4.1584 - val_mae: 0.9177\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.1042 - mae: 0.7871 - val_loss: 3.9250 - val_mae: 0.9791\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.0058 - mae: 0.8003 - val_loss: 4.0251 - val_mae: 1.0744\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.0105 - mae: 0.7905 - val_loss: 3.9333 - val_mae: 1.0506\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.9279 - mae: 0.7874 - val_loss: 4.0261 - val_mae: 1.0567\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.9398 - mae: 0.8027 - val_loss: 4.1331 - val_mae: 1.0791\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.8376 - mae: 0.7703 - val_loss: 4.0833 - val_mae: 0.9393\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.8861 - mae: 0.8081 - val_loss: 4.2045 - val_mae: 1.0140\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.8363 - mae: 0.7745 - val_loss: 4.2363 - val_mae: 1.0583\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.7428 - mae: 0.7285 - val_loss: 4.1853 - val_mae: 1.0207\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.7862 - mae: 0.7756 - val_loss: 4.3019 - val_mae: 0.9919\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.7316 - mae: 0.7310 - val_loss: 4.6335 - val_mae: 1.1922\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.7279 - mae: 0.7759 - val_loss: 4.3371 - val_mae: 1.0365\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.8129 - mae: 0.7722 - val_loss: 4.2306 - val_mae: 1.0392\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.6239 - mae: 0.7368 - val_loss: 4.5728 - val_mae: 1.1312\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.5017 - mae: 0.7048 - val_loss: 4.6530 - val_mae: 1.1039\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.5444 - mae: 0.6967 - val_loss: 4.6813 - val_mae: 1.1120\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.4091 - mae: 0.6813 - val_loss: 4.6313 - val_mae: 1.1437\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.3261 - mae: 0.6999 - val_loss: 4.9787 - val_mae: 1.2017\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.4764 - mae: 0.6877 - val_loss: 4.6060 - val_mae: 0.9866\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.3952 - mae: 0.6799 - val_loss: 5.0937 - val_mae: 1.1061\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.3437 - mae: 0.6598 - val_loss: 4.9891 - val_mae: 1.0850\n",
      "Epoch 29: early stopping\n",
      "Test Loss (MSE): 3.5178284645080566, Test Mean Absolute Error (MAE): 0.820155918598175\n",
      "Epoch 1/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4.7764 - mae: 0.9069 - val_loss: 4.5937 - val_mae: 1.1478\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 3.8617 - mae: 0.8291 - val_loss: 4.4824 - val_mae: 1.2213\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 3.3499 - mae: 0.8226 - val_loss: 4.1528 - val_mae: 1.1791\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 3.2291 - mae: 0.8290 - val_loss: 3.9757 - val_mae: 1.0930\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 3.2291 - mae: 0.7960 - val_loss: 5.3277 - val_mae: 1.4258\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 3.0386 - mae: 0.8201 - val_loss: 4.4782 - val_mae: 1.0234\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.9737 - mae: 0.7946 - val_loss: 4.0602 - val_mae: 1.0747\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 3.0326 - mae: 0.7630 - val_loss: 4.2580 - val_mae: 1.1574\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2.8198 - mae: 0.7485 - val_loss: 4.0985 - val_mae: 1.1037\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.9615 - mae: 0.7638 - val_loss: 4.5517 - val_mae: 1.3059\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.7928 - mae: 0.7462 - val_loss: 4.2298 - val_mae: 1.1689\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.8905 - mae: 0.8002 - val_loss: 4.2151 - val_mae: 1.1316\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.8178 - mae: 0.7334 - val_loss: 4.4572 - val_mae: 1.0735\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.7781 - mae: 0.7614 - val_loss: 4.4338 - val_mae: 1.1617\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.7213 - mae: 0.7431 - val_loss: 4.5567 - val_mae: 1.3003\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2.6930 - mae: 0.7768 - val_loss: 4.3216 - val_mae: 1.1743\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.6737 - mae: 0.7174 - val_loss: 4.4605 - val_mae: 1.1999\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.7060 - mae: 0.7330 - val_loss: 4.3309 - val_mae: 1.1373\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.6209 - mae: 0.7150 - val_loss: 4.4747 - val_mae: 1.0975\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.6225 - mae: 0.7383 - val_loss: 4.6421 - val_mae: 1.2241\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.6865 - mae: 0.7424 - val_loss: 4.5630 - val_mae: 1.1532\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.6688 - mae: 0.7486 - val_loss: 4.4395 - val_mae: 1.1930\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.6311 - mae: 0.7449 - val_loss: 4.5491 - val_mae: 1.1575\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.8084 - mae: 0.7387 - val_loss: 4.7026 - val_mae: 1.1150\n",
      "Epoch 24: early stopping\n",
      "Test Loss (MSE): 3.560725212097168, Test Mean Absolute Error (MAE): 0.7642289400100708\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 12.5549 - mae: 2.5170 - val_loss: 13.1417 - val_mae: 2.4515\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 10.7511 - mae: 2.2016 - val_loss: 10.6701 - val_mae: 2.4449\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.2712 - mae: 2.1595 - val_loss: 10.2475 - val_mae: 2.6204\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.7538 - mae: 2.1439 - val_loss: 10.0123 - val_mae: 2.4272\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.5734 - mae: 2.1992 - val_loss: 11.7933 - val_mae: 2.3969\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.9870 - mae: 2.1544 - val_loss: 9.6041 - val_mae: 2.5813\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.8399 - mae: 2.0679 - val_loss: 9.5961 - val_mae: 2.5099\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.1489 - mae: 2.2117 - val_loss: 10.6533 - val_mae: 2.3653\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.2064 - mae: 2.0627 - val_loss: 9.2100 - val_mae: 2.5268\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.9639 - mae: 2.0634 - val_loss: 9.0710 - val_mae: 2.4540\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.7123 - mae: 2.1410 - val_loss: 9.4404 - val_mae: 2.3499\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5866 - mae: 2.0892 - val_loss: 9.0496 - val_mae: 2.4022\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.6586 - mae: 2.0540 - val_loss: 9.1374 - val_mae: 2.3761\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.6066 - mae: 2.1037 - val_loss: 9.1451 - val_mae: 2.4374\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5189 - mae: 2.0088 - val_loss: 9.0823 - val_mae: 2.4133\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.6975 - mae: 2.0969 - val_loss: 9.2363 - val_mae: 2.4103\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5222 - mae: 2.0500 - val_loss: 9.1480 - val_mae: 2.4510\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5126 - mae: 2.0870 - val_loss: 9.3049 - val_mae: 2.3643\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.4976 - mae: 2.0841 - val_loss: 9.6426 - val_mae: 2.3326\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.6593 - mae: 2.0762 - val_loss: 9.9650 - val_mae: 2.3285\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.6025 - mae: 2.0753 - val_loss: 9.4479 - val_mae: 2.3727\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5329 - mae: 2.0308 - val_loss: 9.2109 - val_mae: 2.3526\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.4187 - mae: 2.0900 - val_loss: 9.9258 - val_mae: 2.3455\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5142 - mae: 2.0719 - val_loss: 9.5125 - val_mae: 2.3587\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.4005 - mae: 2.0211 - val_loss: 9.2688 - val_mae: 2.4187\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.6957 - mae: 2.1020 - val_loss: 9.0178 - val_mae: 2.4521\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5617 - mae: 2.0831 - val_loss: 9.4370 - val_mae: 2.3816\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.6708 - mae: 2.0269 - val_loss: 9.2596 - val_mae: 2.4177\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5577 - mae: 2.0000 - val_loss: 9.3239 - val_mae: 2.5160\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.4105 - mae: 2.0529 - val_loss: 10.1925 - val_mae: 2.3400\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.4108 - mae: 2.0066 - val_loss: 9.3511 - val_mae: 2.4392\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.4665 - mae: 2.0705 - val_loss: 10.0364 - val_mae: 2.3436\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.4512 - mae: 2.0719 - val_loss: 9.8730 - val_mae: 2.3372\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.4164 - mae: 1.9834 - val_loss: 9.2208 - val_mae: 2.4674\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2656 - mae: 2.0090 - val_loss: 9.6070 - val_mae: 2.3826\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.3645 - mae: 2.0613 - val_loss: 10.6968 - val_mae: 2.3628\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.3056 - mae: 1.9882 - val_loss: 9.4487 - val_mae: 2.4703\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.1870 - mae: 2.0472 - val_loss: 9.6763 - val_mae: 2.3589\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2042 - mae: 1.9302 - val_loss: 9.6254 - val_mae: 2.5735\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5265 - mae: 2.0128 - val_loss: 9.5908 - val_mae: 2.5353\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.3351 - mae: 2.0781 - val_loss: 10.3238 - val_mae: 2.3428\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.1062 - mae: 1.9582 - val_loss: 9.6777 - val_mae: 2.4336\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.1980 - mae: 2.0017 - val_loss: 10.5170 - val_mae: 2.3706\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.0215 - mae: 1.9265 - val_loss: 9.6439 - val_mae: 2.5197\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.0629 - mae: 2.0261 - val_loss: 9.8874 - val_mae: 2.3844\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.9337 - mae: 1.9426 - val_loss: 9.8353 - val_mae: 2.4338\n",
      "Epoch 46: early stopping\n",
      "Test Loss (MSE): 9.768586158752441, Test Mean Absolute Error (MAE): 2.4384665489196777\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 11.4405 - mae: 2.4084 - val_loss: 12.2489 - val_mae: 2.7554\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.9309 - mae: 2.2516 - val_loss: 11.8517 - val_mae: 2.7355\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.1807 - mae: 2.1743 - val_loss: 10.5399 - val_mae: 2.3160\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.9714 - mae: 2.2347 - val_loss: 10.2764 - val_mae: 2.2372\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.4738 - mae: 2.2121 - val_loss: 10.4072 - val_mae: 2.1379\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.3922 - mae: 2.1585 - val_loss: 10.2168 - val_mae: 2.4304\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.7559 - mae: 2.0771 - val_loss: 10.5867 - val_mae: 2.4482\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.4531 - mae: 2.0236 - val_loss: 10.3521 - val_mae: 2.3554\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.3415 - mae: 2.0550 - val_loss: 10.1012 - val_mae: 2.3776\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2398 - mae: 2.0203 - val_loss: 11.0020 - val_mae: 2.5032\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2885 - mae: 2.0631 - val_loss: 10.5763 - val_mae: 2.4739\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2247 - mae: 2.0431 - val_loss: 9.9923 - val_mae: 2.2967\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2005 - mae: 2.0044 - val_loss: 10.3491 - val_mae: 2.3620\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.0891 - mae: 1.9752 - val_loss: 10.1326 - val_mae: 2.2709\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.7910 - mae: 1.9520 - val_loss: 10.4026 - val_mae: 2.3193\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.7947 - mae: 1.9649 - val_loss: 13.1836 - val_mae: 2.7532\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.9275 - mae: 1.9857 - val_loss: 10.3563 - val_mae: 2.2608\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4234 - mae: 1.8177 - val_loss: 10.6507 - val_mae: 2.3868\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.9572 - mae: 1.7844 - val_loss: 10.8759 - val_mae: 2.3824\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.0672 - mae: 1.7985 - val_loss: 11.3736 - val_mae: 2.4644\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.2714 - mae: 1.8469 - val_loss: 11.5118 - val_mae: 2.5558\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.0095 - mae: 1.7248 - val_loss: 11.6791 - val_mae: 2.5265\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.4744 - mae: 1.6518 - val_loss: 11.8741 - val_mae: 2.5140\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.1934 - mae: 1.5843 - val_loss: 11.8073 - val_mae: 2.5578\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.9327 - mae: 1.5412 - val_loss: 12.7548 - val_mae: 2.6409\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.7422 - mae: 1.5149 - val_loss: 12.0834 - val_mae: 2.5541\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.3316 - mae: 1.3928 - val_loss: 12.3363 - val_mae: 2.5495\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.2890 - mae: 1.4286 - val_loss: 15.0573 - val_mae: 2.9785\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.1358 - mae: 1.3583 - val_loss: 12.5283 - val_mae: 2.5985\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.8500 - mae: 1.2906 - val_loss: 12.7500 - val_mae: 2.5677\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.8780 - mae: 1.3120 - val_loss: 12.6918 - val_mae: 2.5955\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.7329 - mae: 1.2753 - val_loss: 13.3470 - val_mae: 2.7381\n",
      "Epoch 32: early stopping\n",
      "Test Loss (MSE): 14.356050491333008, Test Mean Absolute Error (MAE): 2.8322179317474365\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 12.8253 - mae: 2.4358 - val_loss: 12.4770 - val_mae: 2.8497\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 10.3091 - mae: 2.2904 - val_loss: 10.2656 - val_mae: 2.4431\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.2432 - mae: 2.1776 - val_loss: 9.8367 - val_mae: 2.1215\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.7538 - mae: 2.0987 - val_loss: 10.2239 - val_mae: 2.4290\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.0279 - mae: 2.0147 - val_loss: 9.9500 - val_mae: 2.1102\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.0506 - mae: 2.0353 - val_loss: 9.8728 - val_mae: 2.3748\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5333 - mae: 1.9225 - val_loss: 10.4180 - val_mae: 2.4460\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.9311 - mae: 1.8277 - val_loss: 10.2303 - val_mae: 2.3681\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.5725 - mae: 1.8136 - val_loss: 10.5605 - val_mae: 2.3849\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.1343 - mae: 1.6985 - val_loss: 10.7820 - val_mae: 2.4422\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.7847 - mae: 1.6274 - val_loss: 11.6715 - val_mae: 2.6654\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.3324 - mae: 1.5309 - val_loss: 11.9842 - val_mae: 2.6150\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.1417 - mae: 1.4571 - val_loss: 14.8143 - val_mae: 3.0416\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.0882 - mae: 1.5103 - val_loss: 12.4742 - val_mae: 2.6662\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.3523 - mae: 1.2696 - val_loss: 13.9293 - val_mae: 2.8558\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.2641 - mae: 1.3182 - val_loss: 12.1330 - val_mae: 2.5160\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.6068 - mae: 1.1196 - val_loss: 12.7273 - val_mae: 2.5799\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.3090 - mae: 1.0238 - val_loss: 12.8479 - val_mae: 2.6061\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.1445 - mae: 0.9831 - val_loss: 14.2146 - val_mae: 2.8195\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.2902 - mae: 1.0347 - val_loss: 14.6441 - val_mae: 2.8566\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.1243 - mae: 0.9595 - val_loss: 13.7733 - val_mae: 2.7680\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.8773 - mae: 0.9370 - val_loss: 13.3998 - val_mae: 2.5785\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.6255 - mae: 0.8267 - val_loss: 14.6851 - val_mae: 2.8967\n",
      "Epoch 23: early stopping\n",
      "Test Loss (MSE): 18.24700355529785, Test Mean Absolute Error (MAE): 3.1544973850250244\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 12.5984 - mae: 2.5570 - val_loss: 13.2108 - val_mae: 2.5613\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.2631 - mae: 2.1033 - val_loss: 12.5591 - val_mae: 2.5860\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.5777 - mae: 2.0898 - val_loss: 12.4948 - val_mae: 2.3983\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.2923 - mae: 2.0016 - val_loss: 12.0531 - val_mae: 2.5328\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.9058 - mae: 1.9628 - val_loss: 12.1220 - val_mae: 2.4741\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.4372 - mae: 1.9120 - val_loss: 11.6659 - val_mae: 2.6054\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.4119 - mae: 1.9164 - val_loss: 12.5866 - val_mae: 2.7448\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.0054 - mae: 1.8645 - val_loss: 11.2204 - val_mae: 2.4550\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.7930 - mae: 1.8710 - val_loss: 11.9784 - val_mae: 2.5377\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4844 - mae: 1.8519 - val_loss: 11.5429 - val_mae: 2.4987\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.3586 - mae: 1.7531 - val_loss: 12.5440 - val_mae: 2.6380\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.0756 - mae: 1.7216 - val_loss: 12.0332 - val_mae: 2.6573\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.8038 - mae: 1.7062 - val_loss: 11.9606 - val_mae: 2.6130\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.7546 - mae: 1.6524 - val_loss: 13.5534 - val_mae: 2.6744\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.8663 - mae: 1.6914 - val_loss: 12.2299 - val_mae: 2.6363\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.0360 - mae: 1.5451 - val_loss: 14.0358 - val_mae: 2.8889\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.8417 - mae: 1.4883 - val_loss: 13.3968 - val_mae: 2.7667\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.6484 - mae: 1.4293 - val_loss: 13.5624 - val_mae: 2.7238\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.3721 - mae: 1.3931 - val_loss: 14.6626 - val_mae: 2.8361\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.9130 - mae: 1.2663 - val_loss: 13.9004 - val_mae: 2.7164\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.8097 - mae: 1.2536 - val_loss: 14.5360 - val_mae: 2.8406\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.6556 - mae: 1.2128 - val_loss: 15.2508 - val_mae: 2.9468\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.2838 - mae: 1.1132 - val_loss: 14.2936 - val_mae: 2.8082\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.5116 - mae: 1.1384 - val_loss: 16.1658 - val_mae: 3.0609\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.4632 - mae: 1.1902 - val_loss: 14.9500 - val_mae: 2.9440\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.1705 - mae: 1.0914 - val_loss: 14.2672 - val_mae: 2.8551\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.3332 - mae: 1.1418 - val_loss: 15.7757 - val_mae: 2.9539\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.2882 - mae: 1.1132 - val_loss: 16.3901 - val_mae: 3.0524\n",
      "Epoch 28: early stopping\n",
      "Test Loss (MSE): 15.26564884185791, Test Mean Absolute Error (MAE): 2.889878988265991\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.2331 - mae: 0.8460 - val_loss: 4.2744 - val_mae: 0.9533\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 990us/step - loss: 3.4046 - mae: 0.7796 - val_loss: 5.1489 - val_mae: 0.9808\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.2485 - mae: 0.7959 - val_loss: 4.0969 - val_mae: 1.0616\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.9505 - mae: 0.8095 - val_loss: 3.7337 - val_mae: 0.9859\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.0407 - mae: 0.7782 - val_loss: 3.8793 - val_mae: 0.8968\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.9017 - mae: 0.7893 - val_loss: 4.1402 - val_mae: 0.9170\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 947us/step - loss: 2.9216 - mae: 0.7676 - val_loss: 3.8400 - val_mae: 0.9245\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.8200 - mae: 0.7653 - val_loss: 3.7313 - val_mae: 0.9815\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.7818 - mae: 0.7450 - val_loss: 3.6470 - val_mae: 0.9597\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.7733 - mae: 0.7589 - val_loss: 3.6829 - val_mae: 1.1307\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.7932 - mae: 0.7561 - val_loss: 3.5937 - val_mae: 0.9518\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.7620 - mae: 0.7341 - val_loss: 3.5946 - val_mae: 1.0535\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 985us/step - loss: 2.7403 - mae: 0.8016 - val_loss: 3.6816 - val_mae: 1.0726\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 992us/step - loss: 2.7101 - mae: 0.7548 - val_loss: 3.6815 - val_mae: 1.0440\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 976us/step - loss: 2.8905 - mae: 0.7741 - val_loss: 4.4123 - val_mae: 0.9750\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 977us/step - loss: 2.9029 - mae: 0.7471 - val_loss: 3.7567 - val_mae: 0.9130\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 982us/step - loss: 2.6919 - mae: 0.7327 - val_loss: 3.6244 - val_mae: 1.0029\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.6965 - mae: 0.7397 - val_loss: 3.6747 - val_mae: 0.9541\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.7140 - mae: 0.7339 - val_loss: 3.5828 - val_mae: 1.0155\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 950us/step - loss: 2.7316 - mae: 0.8365 - val_loss: 3.6136 - val_mae: 0.9452\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.7308 - mae: 0.7278 - val_loss: 3.6730 - val_mae: 1.0268\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.6825 - mae: 0.7607 - val_loss: 3.8671 - val_mae: 0.9059\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 995us/step - loss: 2.6824 - mae: 0.7211 - val_loss: 3.7693 - val_mae: 1.0471\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 972us/step - loss: 2.7277 - mae: 0.7819 - val_loss: 3.7043 - val_mae: 1.0485\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.6001 - mae: 0.7827 - val_loss: 4.1500 - val_mae: 0.9047\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.8067 - mae: 0.7308 - val_loss: 3.7157 - val_mae: 1.0396\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.6637 - mae: 0.7494 - val_loss: 3.6784 - val_mae: 0.9794\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.6419 - mae: 0.7339 - val_loss: 3.7435 - val_mae: 0.9911\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.6161 - mae: 0.7364 - val_loss: 4.0965 - val_mae: 0.9187\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.6614 - mae: 0.7132 - val_loss: 3.9227 - val_mae: 0.9922\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.6497 - mae: 0.7372 - val_loss: 3.8919 - val_mae: 1.0901\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.5965 - mae: 0.7651 - val_loss: 3.8152 - val_mae: 0.9370\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.6346 - mae: 0.7529 - val_loss: 3.7475 - val_mae: 0.9687\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.6922 - mae: 0.7768 - val_loss: 3.7966 - val_mae: 1.0291\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.6328 - mae: 0.7559 - val_loss: 3.7874 - val_mae: 1.0079\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.6892 - mae: 0.7393 - val_loss: 3.9007 - val_mae: 1.0314\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 968us/step - loss: 2.6976 - mae: 0.7637 - val_loss: 3.9770 - val_mae: 0.9693\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 991us/step - loss: 2.6628 - mae: 0.7592 - val_loss: 3.9632 - val_mae: 1.0073\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.6363 - mae: 0.7549 - val_loss: 3.7944 - val_mae: 1.0439\n",
      "Epoch 39: early stopping\n",
      "Test Loss (MSE): 4.040721416473389, Test Mean Absolute Error (MAE): 1.1284927129745483\n",
      "Epoch 1/100\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 4.7066 - mae: 0.9143 - val_loss: 4.0431 - val_mae: 0.8380\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.5627 - mae: 0.8133 - val_loss: 3.7790 - val_mae: 0.7771\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.1992 - mae: 0.8283 - val_loss: 3.7199 - val_mae: 0.9467\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.1227 - mae: 0.8090 - val_loss: 3.8360 - val_mae: 0.7750\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.0748 - mae: 0.7710 - val_loss: 3.5788 - val_mae: 0.9309\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.1160 - mae: 0.8267 - val_loss: 3.4713 - val_mae: 0.8744\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.7577 - mae: 0.8169 - val_loss: 3.5458 - val_mae: 0.8460\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.9466 - mae: 0.7872 - val_loss: 3.8273 - val_mae: 0.9943\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.0348 - mae: 0.8255 - val_loss: 3.5996 - val_mae: 1.0067\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.9992 - mae: 0.8745 - val_loss: 3.6027 - val_mae: 0.8872\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.7664 - mae: 0.7962 - val_loss: 3.5324 - val_mae: 0.8473\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 965us/step - loss: 2.7008 - mae: 0.7698 - val_loss: 3.6676 - val_mae: 0.8349\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.7282 - mae: 0.7970 - val_loss: 3.7208 - val_mae: 0.8708\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.5440 - mae: 0.7524 - val_loss: 3.7625 - val_mae: 0.8873\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.5412 - mae: 0.7287 - val_loss: 3.8195 - val_mae: 0.8258\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.8180 - mae: 0.7643 - val_loss: 4.1543 - val_mae: 1.0247\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.5233 - mae: 0.7434 - val_loss: 4.0185 - val_mae: 0.8652\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.6173 - mae: 0.7286 - val_loss: 4.1905 - val_mae: 0.9655\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.5887 - mae: 0.7435 - val_loss: 4.0147 - val_mae: 0.8831\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 0s 995us/step - loss: 2.6931 - mae: 0.7528 - val_loss: 4.1367 - val_mae: 1.0337\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.5320 - mae: 0.7398 - val_loss: 4.3055 - val_mae: 0.9523\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.4428 - mae: 0.7023 - val_loss: 4.7579 - val_mae: 1.0643\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.4209 - mae: 0.6978 - val_loss: 4.6084 - val_mae: 1.0479\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.6498 - mae: 0.7527 - val_loss: 4.1010 - val_mae: 0.9513\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.3554 - mae: 0.6949 - val_loss: 4.2609 - val_mae: 0.8920\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.2829 - mae: 0.6668 - val_loss: 4.5818 - val_mae: 0.9957\n",
      "Epoch 26: early stopping\n",
      "Test Loss (MSE): 5.215311527252197, Test Mean Absolute Error (MAE): 1.1260215044021606\n",
      "Epoch 1/100\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 5.1466 - mae: 0.9918 - val_loss: 4.4114 - val_mae: 0.9462\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.8693 - mae: 0.8748 - val_loss: 4.3015 - val_mae: 1.1907\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.4847 - mae: 0.9006 - val_loss: 4.1990 - val_mae: 1.0245\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.4594 - mae: 0.8567 - val_loss: 4.1500 - val_mae: 0.9898\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.2893 - mae: 0.8930 - val_loss: 4.2234 - val_mae: 1.0402\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.1217 - mae: 0.8441 - val_loss: 4.2080 - val_mae: 1.0090\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.1102 - mae: 0.8287 - val_loss: 4.5131 - val_mae: 1.0884\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.9485 - mae: 0.8295 - val_loss: 4.2631 - val_mae: 1.0119\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.8709 - mae: 0.8113 - val_loss: 4.5815 - val_mae: 0.9612\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.0143 - mae: 0.8162 - val_loss: 4.6361 - val_mae: 1.1019\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.9895 - mae: 0.8211 - val_loss: 4.4427 - val_mae: 1.0392\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.0062 - mae: 0.8022 - val_loss: 4.4537 - val_mae: 1.0635\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.7929 - mae: 0.7999 - val_loss: 4.6844 - val_mae: 1.0531\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.9433 - mae: 0.7758 - val_loss: 4.9734 - val_mae: 1.0242\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.7301 - mae: 0.7904 - val_loss: 4.6688 - val_mae: 1.0160\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.5957 - mae: 0.7442 - val_loss: 4.8046 - val_mae: 1.0293\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.5200 - mae: 0.7420 - val_loss: 5.0614 - val_mae: 1.0927\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.4757 - mae: 0.7210 - val_loss: 4.9838 - val_mae: 1.0266\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.4716 - mae: 0.7116 - val_loss: 5.1375 - val_mae: 1.0345\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.3597 - mae: 0.6695 - val_loss: 4.8983 - val_mae: 0.9822\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.3721 - mae: 0.6860 - val_loss: 5.2547 - val_mae: 1.0503\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.2723 - mae: 0.6878 - val_loss: 5.4376 - val_mae: 1.1247\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.3359 - mae: 0.6747 - val_loss: 5.5402 - val_mae: 1.1349\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.2445 - mae: 0.6583 - val_loss: 5.5733 - val_mae: 1.1166\n",
      "Epoch 24: early stopping\n",
      "Test Loss (MSE): 2.5995419025421143, Test Mean Absolute Error (MAE): 0.5834296345710754\n",
      "Epoch 1/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 4.7993 - mae: 0.9058 - val_loss: 4.5233 - val_mae: 0.8722\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.8951 - mae: 0.8202 - val_loss: 4.3469 - val_mae: 0.8507\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.2281 - mae: 0.7930 - val_loss: 4.0530 - val_mae: 0.9303\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.0105 - mae: 0.7609 - val_loss: 4.0673 - val_mae: 0.8800\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 3.0884 - mae: 0.7840 - val_loss: 3.9475 - val_mae: 0.8385\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.9786 - mae: 0.7743 - val_loss: 3.8787 - val_mae: 0.9258\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.9245 - mae: 0.7560 - val_loss: 3.9098 - val_mae: 0.9548\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7906 - mae: 0.7381 - val_loss: 3.9015 - val_mae: 0.9531\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.6795 - mae: 0.7470 - val_loss: 4.3457 - val_mae: 1.0371\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.7443 - mae: 0.7500 - val_loss: 4.2436 - val_mae: 0.9454\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.5861 - mae: 0.7113 - val_loss: 4.2340 - val_mae: 0.9036\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.5857 - mae: 0.7123 - val_loss: 4.3173 - val_mae: 0.9540\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.5929 - mae: 0.6816 - val_loss: 4.1861 - val_mae: 0.9810\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.4058 - mae: 0.7129 - val_loss: 4.4451 - val_mae: 0.9001\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.4862 - mae: 0.6630 - val_loss: 4.2581 - val_mae: 0.9614\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.3921 - mae: 0.7094 - val_loss: 4.5127 - val_mae: 1.0129\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.3341 - mae: 0.6961 - val_loss: 4.3553 - val_mae: 0.9158\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.2922 - mae: 0.6939 - val_loss: 4.6808 - val_mae: 0.9980\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.4220 - mae: 0.6511 - val_loss: 4.5638 - val_mae: 1.0184\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.2905 - mae: 0.6483 - val_loss: 4.5164 - val_mae: 0.9698\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.2127 - mae: 0.6429 - val_loss: 4.7479 - val_mae: 1.0072\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.1796 - mae: 0.6228 - val_loss: 4.6724 - val_mae: 0.9440\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.1400 - mae: 0.6051 - val_loss: 4.8907 - val_mae: 0.9682\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.1282 - mae: 0.6292 - val_loss: 4.6224 - val_mae: 1.0673\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2.0647 - mae: 0.5994 - val_loss: 5.0782 - val_mae: 1.1483\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1.9675 - mae: 0.5914 - val_loss: 5.0113 - val_mae: 1.0207\n",
      "Epoch 26: early stopping\n",
      "Test Loss (MSE): 4.556506156921387, Test Mean Absolute Error (MAE): 1.0203771591186523\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 12.0214 - mae: 2.3997 - val_loss: 11.6629 - val_mae: 2.2968\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.5422 - mae: 2.2257 - val_loss: 10.2998 - val_mae: 2.3777\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.0660 - mae: 2.1918 - val_loss: 9.9200 - val_mae: 2.3551\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.7277 - mae: 2.1033 - val_loss: 9.5621 - val_mae: 2.2013\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.3682 - mae: 2.2053 - val_loss: 9.2045 - val_mae: 2.2782\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.1369 - mae: 2.0950 - val_loss: 9.8491 - val_mae: 2.4886\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.7261 - mae: 2.1356 - val_loss: 9.7679 - val_mae: 2.6245\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.0395 - mae: 2.2595 - val_loss: 10.4374 - val_mae: 2.0966\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.1677 - mae: 2.1573 - val_loss: 9.4379 - val_mae: 2.4337\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.8964 - mae: 2.0851 - val_loss: 8.9784 - val_mae: 2.2460\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.8143 - mae: 2.1894 - val_loss: 9.3232 - val_mae: 2.1118\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.9281 - mae: 2.0968 - val_loss: 8.8392 - val_mae: 2.2483\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.7269 - mae: 2.0775 - val_loss: 8.8893 - val_mae: 2.3203\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.8201 - mae: 2.0339 - val_loss: 9.0026 - val_mae: 2.3786\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.8031 - mae: 2.1811 - val_loss: 8.9109 - val_mae: 2.1646\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.4974 - mae: 2.0168 - val_loss: 9.2268 - val_mae: 2.3729\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5495 - mae: 2.1185 - val_loss: 9.1658 - val_mae: 2.1404\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5710 - mae: 2.0772 - val_loss: 8.7107 - val_mae: 2.2644\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5742 - mae: 2.0004 - val_loss: 9.1307 - val_mae: 2.3353\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5578 - mae: 2.0596 - val_loss: 9.0087 - val_mae: 2.2279\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.3658 - mae: 2.0521 - val_loss: 8.9712 - val_mae: 2.2121\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.4123 - mae: 2.0585 - val_loss: 8.8654 - val_mae: 2.2552\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2411 - mae: 2.0555 - val_loss: 9.2134 - val_mae: 2.2117\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.1877 - mae: 2.0104 - val_loss: 9.1516 - val_mae: 2.2361\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.0562 - mae: 1.9922 - val_loss: 9.3068 - val_mae: 2.2449\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2510 - mae: 2.0762 - val_loss: 10.3882 - val_mae: 2.1432\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.4265 - mae: 2.0122 - val_loss: 9.0960 - val_mae: 2.2164\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.3798 - mae: 1.9934 - val_loss: 9.7511 - val_mae: 2.4832\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2875 - mae: 1.9898 - val_loss: 9.9372 - val_mae: 2.2176\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.0969 - mae: 2.0293 - val_loss: 9.9158 - val_mae: 2.1449\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.7997 - mae: 1.8602 - val_loss: 10.5158 - val_mae: 2.5345\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.3517 - mae: 1.9870 - val_loss: 9.6879 - val_mae: 2.1890\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.1086 - mae: 2.0720 - val_loss: 9.9125 - val_mae: 2.1368\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.7601 - mae: 1.8918 - val_loss: 9.7399 - val_mae: 2.2690\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.6136 - mae: 1.8799 - val_loss: 9.7196 - val_mae: 2.2879\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4585 - mae: 1.8972 - val_loss: 9.6501 - val_mae: 2.1741\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.2520 - mae: 1.8488 - val_loss: 9.9467 - val_mae: 2.2827\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.5409 - mae: 1.8870 - val_loss: 10.3797 - val_mae: 2.1824\n",
      "Epoch 38: early stopping\n",
      "Test Loss (MSE): 11.950101852416992, Test Mean Absolute Error (MAE): 2.543337821960449\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 13.5066 - mae: 2.5320 - val_loss: 10.0952 - val_mae: 2.1995\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 10.2997 - mae: 2.3361 - val_loss: 9.7430 - val_mae: 2.2018\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.3413 - mae: 2.2612 - val_loss: 10.1251 - val_mae: 2.1090\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.0291 - mae: 2.1336 - val_loss: 10.3115 - val_mae: 2.1140\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.5301 - mae: 2.1451 - val_loss: 10.2770 - val_mae: 2.0641\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.2311 - mae: 2.1070 - val_loss: 9.9002 - val_mae: 2.0645\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.9914 - mae: 2.0018 - val_loss: 9.4548 - val_mae: 2.2270\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.7226 - mae: 2.0260 - val_loss: 9.4866 - val_mae: 2.1057\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.3370 - mae: 1.9476 - val_loss: 9.5499 - val_mae: 2.1604\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2318 - mae: 1.9543 - val_loss: 10.7753 - val_mae: 2.1637\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.4135 - mae: 1.9804 - val_loss: 10.8411 - val_mae: 2.1590\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.3669 - mae: 1.9426 - val_loss: 11.4681 - val_mae: 2.1749\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.6801 - mae: 1.8937 - val_loss: 9.9965 - val_mae: 2.1287\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.3803 - mae: 1.7495 - val_loss: 10.8156 - val_mae: 2.2390\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.7909 - mae: 1.6740 - val_loss: 10.6434 - val_mae: 2.1746\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.1509 - mae: 1.5528 - val_loss: 11.4755 - val_mae: 2.4312\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.3546 - mae: 1.5857 - val_loss: 11.0089 - val_mae: 2.2484\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.8831 - mae: 1.5122 - val_loss: 11.1228 - val_mae: 2.2931\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.5381 - mae: 1.3929 - val_loss: 10.9892 - val_mae: 2.2482\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.3320 - mae: 1.3816 - val_loss: 11.2530 - val_mae: 2.2868\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.9846 - mae: 1.2548 - val_loss: 11.4441 - val_mae: 2.3788\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.5583 - mae: 1.2074 - val_loss: 11.2864 - val_mae: 2.2376\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.4560 - mae: 1.1501 - val_loss: 11.6315 - val_mae: 2.3357\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.2559 - mae: 1.1025 - val_loss: 11.8310 - val_mae: 2.3336\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.0120 - mae: 1.0347 - val_loss: 11.9775 - val_mae: 2.3311\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.3396 - mae: 1.1148 - val_loss: 11.8282 - val_mae: 2.2629\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.3566 - mae: 1.0846 - val_loss: 11.6428 - val_mae: 2.3543\n",
      "Epoch 27: early stopping\n",
      "Test Loss (MSE): 12.986176490783691, Test Mean Absolute Error (MAE): 2.5520989894866943\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 14.0289 - mae: 2.5662 - val_loss: 10.0257 - val_mae: 2.0391\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 10.2166 - mae: 2.3362 - val_loss: 9.9725 - val_mae: 1.9738\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.4292 - mae: 2.1063 - val_loss: 9.8659 - val_mae: 2.2535\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.7240 - mae: 2.0845 - val_loss: 9.8339 - val_mae: 2.3494\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.4853 - mae: 2.0506 - val_loss: 9.7086 - val_mae: 2.2973\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.7231 - mae: 2.0341 - val_loss: 10.1776 - val_mae: 2.2576\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.0059 - mae: 1.8791 - val_loss: 10.9120 - val_mae: 2.5112\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.8191 - mae: 1.8372 - val_loss: 11.2200 - val_mae: 2.4989\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4989 - mae: 1.7996 - val_loss: 10.9673 - val_mae: 2.4303\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.9997 - mae: 1.6897 - val_loss: 11.2304 - val_mae: 2.3520\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.8762 - mae: 1.6700 - val_loss: 11.9490 - val_mae: 2.6142\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.7573 - mae: 1.6568 - val_loss: 11.7467 - val_mae: 2.4741\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.1211 - mae: 1.5456 - val_loss: 12.4168 - val_mae: 2.5262\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.6748 - mae: 1.4404 - val_loss: 12.6275 - val_mae: 2.5728\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.2475 - mae: 1.3660 - val_loss: 13.2124 - val_mae: 2.6788\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.1878 - mae: 1.3278 - val_loss: 13.4647 - val_mae: 2.7306\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.9575 - mae: 1.2760 - val_loss: 14.2461 - val_mae: 2.7413\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.7808 - mae: 1.2210 - val_loss: 13.5290 - val_mae: 2.6325\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.1349 - mae: 1.0872 - val_loss: 14.1470 - val_mae: 2.7157\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.1233 - mae: 1.0754 - val_loss: 13.5032 - val_mae: 2.6380\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.0805 - mae: 1.0272 - val_loss: 14.1140 - val_mae: 2.7504\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.8443 - mae: 0.9921 - val_loss: 17.1273 - val_mae: 3.0178\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.2288 - mae: 1.0841 - val_loss: 16.7398 - val_mae: 3.0942\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.4154 - mae: 1.1095 - val_loss: 16.7014 - val_mae: 3.0361\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.0190 - mae: 0.9804 - val_loss: 16.1983 - val_mae: 2.9780\n",
      "Epoch 25: early stopping\n",
      "Test Loss (MSE): 17.70037078857422, Test Mean Absolute Error (MAE): 3.143955707550049\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 11.9640 - mae: 2.4762 - val_loss: 8.6819 - val_mae: 2.1579\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.1351 - mae: 2.0961 - val_loss: 10.1331 - val_mae: 2.4972\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.7743 - mae: 2.0637 - val_loss: 8.9099 - val_mae: 2.3160\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.0750 - mae: 2.0963 - val_loss: 8.4313 - val_mae: 2.0845\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.6153 - mae: 1.9619 - val_loss: 8.7383 - val_mae: 2.0194\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.1919 - mae: 1.9485 - val_loss: 8.4820 - val_mae: 2.0536\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.5454 - mae: 1.8651 - val_loss: 8.8925 - val_mae: 2.1287\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.1585 - mae: 1.7551 - val_loss: 9.0944 - val_mae: 2.0930\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.2921 - mae: 1.7475 - val_loss: 8.7827 - val_mae: 2.0838\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.9839 - mae: 1.6934 - val_loss: 9.3519 - val_mae: 2.1912\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.5118 - mae: 1.6493 - val_loss: 9.1246 - val_mae: 2.1005\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.0052 - mae: 1.5205 - val_loss: 9.5352 - val_mae: 2.1786\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.8466 - mae: 1.4488 - val_loss: 9.5292 - val_mae: 2.2008\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.8874 - mae: 1.4752 - val_loss: 9.4550 - val_mae: 2.1776\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.0746 - mae: 1.3073 - val_loss: 10.4915 - val_mae: 2.4077\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.3456 - mae: 1.3239 - val_loss: 9.7774 - val_mae: 2.2350\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.8672 - mae: 1.2757 - val_loss: 10.7725 - val_mae: 2.3616\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.7125 - mae: 1.2039 - val_loss: 9.9312 - val_mae: 2.1799\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.4950 - mae: 1.1186 - val_loss: 10.2915 - val_mae: 2.2656\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.1774 - mae: 1.0717 - val_loss: 10.5294 - val_mae: 2.3561\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.1166 - mae: 1.0330 - val_loss: 10.3548 - val_mae: 2.2964\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.1387 - mae: 1.0410 - val_loss: 10.7908 - val_mae: 2.3625\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.8861 - mae: 0.9595 - val_loss: 10.3397 - val_mae: 2.2652\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.9437 - mae: 0.9705 - val_loss: 10.6573 - val_mae: 2.2838\n",
      "Epoch 24: early stopping\n",
      "Test Loss (MSE): 19.87813949584961, Test Mean Absolute Error (MAE): 3.323599338531494\n",
      "Epoch 1/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 5.1909 - mae: 1.0459 - val_loss: 4.2492 - val_mae: 1.1914\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 4.0498 - mae: 0.9700 - val_loss: 3.0897 - val_mae: 0.7739\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 1000us/step - loss: 3.7478 - mae: 0.9545 - val_loss: 2.9813 - val_mae: 0.6890\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 989us/step - loss: 3.6154 - mae: 0.9608 - val_loss: 2.9876 - val_mae: 0.7674\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 995us/step - loss: 3.5694 - mae: 0.9574 - val_loss: 3.0983 - val_mae: 0.8039\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 986us/step - loss: 3.5567 - mae: 0.9247 - val_loss: 2.8861 - val_mae: 0.8176\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.5163 - mae: 0.9488 - val_loss: 2.8353 - val_mae: 0.7118\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.5415 - mae: 0.9690 - val_loss: 2.8631 - val_mae: 0.7704\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.5505 - mae: 0.9791 - val_loss: 2.9192 - val_mae: 0.8531\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.4270 - mae: 0.9473 - val_loss: 2.9434 - val_mae: 0.7536\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.4039 - mae: 0.9388 - val_loss: 2.8280 - val_mae: 0.8010\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.4264 - mae: 0.9041 - val_loss: 2.9442 - val_mae: 0.8736\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.3811 - mae: 0.9302 - val_loss: 2.8997 - val_mae: 0.6949\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.4061 - mae: 0.9247 - val_loss: 2.9996 - val_mae: 0.8327\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.3840 - mae: 0.9145 - val_loss: 2.7932 - val_mae: 0.7677\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.2990 - mae: 0.9229 - val_loss: 3.0205 - val_mae: 0.6625\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.4155 - mae: 0.9624 - val_loss: 2.8274 - val_mae: 0.7611\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.3490 - mae: 0.9372 - val_loss: 2.7908 - val_mae: 0.8440\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.3604 - mae: 0.9453 - val_loss: 2.8847 - val_mae: 0.8255\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.3309 - mae: 0.9064 - val_loss: 2.9415 - val_mae: 0.8182\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 0s 949us/step - loss: 3.3092 - mae: 0.8985 - val_loss: 2.8640 - val_mae: 0.6991\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 0s 979us/step - loss: 3.3500 - mae: 0.9281 - val_loss: 2.8691 - val_mae: 0.8012\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.3498 - mae: 0.9285 - val_loss: 2.9353 - val_mae: 0.8532\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 0s 948us/step - loss: 3.3577 - mae: 0.9353 - val_loss: 2.8282 - val_mae: 0.7668\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.2654 - mae: 0.9222 - val_loss: 2.9472 - val_mae: 1.0113\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.2965 - mae: 0.9490 - val_loss: 2.8768 - val_mae: 0.8090\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.3073 - mae: 0.9017 - val_loss: 2.9362 - val_mae: 0.7930\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.2594 - mae: 0.9370 - val_loss: 2.8542 - val_mae: 0.7333\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - 0s 976us/step - loss: 3.2792 - mae: 0.9237 - val_loss: 2.9024 - val_mae: 0.8551\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - 0s 971us/step - loss: 3.3220 - mae: 0.9752 - val_loss: 2.8949 - val_mae: 0.6995\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.2226 - mae: 0.9049 - val_loss: 2.9133 - val_mae: 0.8540\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.2689 - mae: 0.9126 - val_loss: 3.0758 - val_mae: 0.8918\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - 0s 972us/step - loss: 3.2510 - mae: 0.9665 - val_loss: 2.9508 - val_mae: 0.9324\n",
      "Epoch 34/100\n",
      "39/39 [==============================] - 0s 989us/step - loss: 3.2382 - mae: 0.9159 - val_loss: 2.9113 - val_mae: 0.7759\n",
      "Epoch 35/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.2297 - mae: 0.9268 - val_loss: 2.9468 - val_mae: 0.8547\n",
      "Epoch 36/100\n",
      "39/39 [==============================] - 0s 987us/step - loss: 3.2325 - mae: 0.9650 - val_loss: 2.9859 - val_mae: 0.9046\n",
      "Epoch 37/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.1896 - mae: 0.8956 - val_loss: 2.9173 - val_mae: 0.8889\n",
      "Epoch 38/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.3182 - mae: 0.9487 - val_loss: 2.8593 - val_mae: 0.7518\n",
      "Epoch 38: early stopping\n",
      "Test Loss (MSE): 2.6042487621307373, Test Mean Absolute Error (MAE): 0.7137632369995117\n",
      "Epoch 1/100\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 4.5755 - mae: 0.8935 - val_loss: 4.1119 - val_mae: 1.0476\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.6019 - mae: 0.8873 - val_loss: 4.1088 - val_mae: 0.9410\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.3475 - mae: 0.8541 - val_loss: 3.8229 - val_mae: 1.0773\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.1212 - mae: 0.8575 - val_loss: 3.7357 - val_mae: 1.0048\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.0853 - mae: 0.8432 - val_loss: 3.9108 - val_mae: 1.0442\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 3.2422 - mae: 0.8254 - val_loss: 3.8352 - val_mae: 0.9933\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.9630 - mae: 0.8286 - val_loss: 3.6419 - val_mae: 1.0095\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.8710 - mae: 0.8046 - val_loss: 3.9962 - val_mae: 0.9285\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.8654 - mae: 0.7859 - val_loss: 3.8195 - val_mae: 0.9686\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.7853 - mae: 0.7687 - val_loss: 4.4888 - val_mae: 1.1259\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.7695 - mae: 0.7718 - val_loss: 3.8389 - val_mae: 0.9406\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.6806 - mae: 0.7464 - val_loss: 4.1888 - val_mae: 0.9804\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.7010 - mae: 0.7495 - val_loss: 4.1031 - val_mae: 0.9872\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.5114 - mae: 0.7137 - val_loss: 4.3405 - val_mae: 0.9527\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.4789 - mae: 0.6952 - val_loss: 4.3699 - val_mae: 1.0003\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.5302 - mae: 0.7106 - val_loss: 4.3914 - val_mae: 0.9741\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.4760 - mae: 0.6888 - val_loss: 4.9979 - val_mae: 1.1318\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.5722 - mae: 0.7227 - val_loss: 5.6363 - val_mae: 1.1674\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.4754 - mae: 0.6951 - val_loss: 4.6381 - val_mae: 1.0328\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.3775 - mae: 0.6838 - val_loss: 4.8873 - val_mae: 1.0286\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.3748 - mae: 0.6715 - val_loss: 5.0821 - val_mae: 1.0834\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.1971 - mae: 0.6354 - val_loss: 4.9617 - val_mae: 1.1035\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.2225 - mae: 0.6248 - val_loss: 5.0422 - val_mae: 1.0412\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.1353 - mae: 0.6285 - val_loss: 5.5012 - val_mae: 1.1233\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.0547 - mae: 0.5967 - val_loss: 6.0360 - val_mae: 1.1942\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.2044 - mae: 0.6450 - val_loss: 6.1960 - val_mae: 1.2030\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.0763 - mae: 0.5965 - val_loss: 5.1507 - val_mae: 1.0629\n",
      "Epoch 27: early stopping\n",
      "Test Loss (MSE): 3.4770631790161133, Test Mean Absolute Error (MAE): 0.7394633889198303\n",
      "Epoch 1/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 5.2954 - mae: 1.0401 - val_loss: 4.3386 - val_mae: 0.7773\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 4.2112 - mae: 0.9708 - val_loss: 3.6679 - val_mae: 0.8160\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 3.8239 - mae: 0.9178 - val_loss: 3.7107 - val_mae: 0.7709\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 3.9013 - mae: 0.9460 - val_loss: 3.8049 - val_mae: 0.9405\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 3.6919 - mae: 0.9212 - val_loss: 3.9843 - val_mae: 0.8181\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 3.3499 - mae: 0.9236 - val_loss: 3.5351 - val_mae: 0.8570\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 3.2353 - mae: 0.8727 - val_loss: 3.5234 - val_mae: 0.8346\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 3.2209 - mae: 0.8388 - val_loss: 3.6256 - val_mae: 0.9569\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.9698 - mae: 0.8355 - val_loss: 3.7940 - val_mae: 0.9352\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 3.0512 - mae: 0.8398 - val_loss: 3.9134 - val_mae: 0.9360\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.9472 - mae: 0.8183 - val_loss: 3.7190 - val_mae: 0.9282\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.9110 - mae: 0.8011 - val_loss: 3.9250 - val_mae: 0.8957\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.7793 - mae: 0.7870 - val_loss: 3.8903 - val_mae: 0.8714\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.7247 - mae: 0.7780 - val_loss: 3.9318 - val_mae: 0.9292\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.4910 - mae: 0.7408 - val_loss: 3.9767 - val_mae: 0.9031\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.3380 - mae: 0.6930 - val_loss: 4.0471 - val_mae: 0.9096\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.4877 - mae: 0.7169 - val_loss: 4.4900 - val_mae: 0.9567\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.3488 - mae: 0.6958 - val_loss: 3.9644 - val_mae: 0.8539\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.4496 - mae: 0.6878 - val_loss: 4.4330 - val_mae: 0.8648\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.4600 - mae: 0.7109 - val_loss: 4.1306 - val_mae: 0.8951\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.2839 - mae: 0.6726 - val_loss: 4.4342 - val_mae: 0.9308\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.2978 - mae: 0.6642 - val_loss: 4.5073 - val_mae: 0.9248\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.1769 - mae: 0.6461 - val_loss: 4.5885 - val_mae: 0.9279\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.1906 - mae: 0.6370 - val_loss: 4.3742 - val_mae: 0.8629\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 2.0852 - mae: 0.6188 - val_loss: 4.6576 - val_mae: 0.9452\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.9911 - mae: 0.6242 - val_loss: 4.6263 - val_mae: 0.9274\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 1.9327 - mae: 0.5772 - val_loss: 4.9470 - val_mae: 0.9867\n",
      "Epoch 27: early stopping\n",
      "Test Loss (MSE): 4.979254722595215, Test Mean Absolute Error (MAE): 0.9015785455703735\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.6200 - mae: 0.9645 - val_loss: 4.4626 - val_mae: 0.9373\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.9149 - mae: 0.8393 - val_loss: 4.1797 - val_mae: 0.9664\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.6345 - mae: 0.8138 - val_loss: 4.0009 - val_mae: 1.0271\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.5724 - mae: 0.8550 - val_loss: 4.3831 - val_mae: 1.0838\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.2144 - mae: 0.7787 - val_loss: 3.9232 - val_mae: 0.9663\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.1747 - mae: 0.7833 - val_loss: 4.8156 - val_mae: 0.9525\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 3.0284 - mae: 0.7854 - val_loss: 4.5147 - val_mae: 1.1798\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.8045 - mae: 0.7415 - val_loss: 4.0602 - val_mae: 1.0531\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.7257 - mae: 0.7408 - val_loss: 3.9685 - val_mae: 0.9693\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.7777 - mae: 0.7284 - val_loss: 4.0686 - val_mae: 1.0570\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.7860 - mae: 0.7398 - val_loss: 3.9977 - val_mae: 1.0294\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.6056 - mae: 0.7124 - val_loss: 4.0666 - val_mae: 0.9873\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.5135 - mae: 0.7081 - val_loss: 4.3118 - val_mae: 1.0596\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.5992 - mae: 0.6926 - val_loss: 4.1772 - val_mae: 1.1185\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.6002 - mae: 0.6914 - val_loss: 5.0571 - val_mae: 1.2253\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.3702 - mae: 0.6710 - val_loss: 4.6414 - val_mae: 1.0786\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.4207 - mae: 0.6596 - val_loss: 4.3763 - val_mae: 0.9814\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.4058 - mae: 0.6496 - val_loss: 4.7188 - val_mae: 0.9639\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.4882 - mae: 0.6676 - val_loss: 4.8101 - val_mae: 1.1397\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.3908 - mae: 0.6864 - val_loss: 4.7115 - val_mae: 1.0968\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.2508 - mae: 0.6435 - val_loss: 5.2941 - val_mae: 1.1712\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.0494 - mae: 0.6063 - val_loss: 4.7965 - val_mae: 1.0198\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.9759 - mae: 0.5967 - val_loss: 4.6020 - val_mae: 1.0637\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.0880 - mae: 0.5996 - val_loss: 4.8645 - val_mae: 1.0568\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 2.1465 - mae: 0.6130 - val_loss: 4.8414 - val_mae: 1.1097\n",
      "Epoch 25: early stopping\n",
      "Test Loss (MSE): 3.5289664268493652, Test Mean Absolute Error (MAE): 0.8036512732505798\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 11.3458 - mae: 2.3922 - val_loss: 11.7799 - val_mae: 2.3451\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.4141 - mae: 2.1984 - val_loss: 10.9188 - val_mae: 2.2978\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.0004 - mae: 2.1444 - val_loss: 10.4371 - val_mae: 2.5252\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.6080 - mae: 2.1924 - val_loss: 10.8347 - val_mae: 2.2814\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.5702 - mae: 2.1895 - val_loss: 10.2025 - val_mae: 2.2808\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.3259 - mae: 2.1491 - val_loss: 9.7640 - val_mae: 2.4856\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.8626 - mae: 2.1147 - val_loss: 10.0661 - val_mae: 2.2551\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.8429 - mae: 2.1223 - val_loss: 9.4282 - val_mae: 2.3256\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.6798 - mae: 2.1374 - val_loss: 9.6140 - val_mae: 2.3771\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.8216 - mae: 2.0682 - val_loss: 9.8138 - val_mae: 2.2827\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.7098 - mae: 2.0429 - val_loss: 9.3078 - val_mae: 2.4029\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.5333 - mae: 2.1115 - val_loss: 10.1127 - val_mae: 2.2569\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.4009 - mae: 2.0654 - val_loss: 10.0740 - val_mae: 2.2281\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.6765 - mae: 2.0457 - val_loss: 9.7503 - val_mae: 2.2634\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.4055 - mae: 2.0486 - val_loss: 9.4967 - val_mae: 2.3015\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.3207 - mae: 1.9853 - val_loss: 9.4345 - val_mae: 2.4152\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.9875 - mae: 1.9542 - val_loss: 9.7900 - val_mae: 2.3845\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.8120 - mae: 1.8965 - val_loss: 9.5463 - val_mae: 2.2996\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.5614 - mae: 1.8805 - val_loss: 9.8089 - val_mae: 2.4437\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.5738 - mae: 1.8671 - val_loss: 10.1156 - val_mae: 2.4321\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4647 - mae: 1.8928 - val_loss: 11.0706 - val_mae: 2.3276\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.9803 - mae: 1.9050 - val_loss: 10.2912 - val_mae: 2.4105\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.2476 - mae: 1.7788 - val_loss: 10.2919 - val_mae: 2.5356\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.2298 - mae: 1.7600 - val_loss: 10.4551 - val_mae: 2.5140\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.5716 - mae: 1.8723 - val_loss: 10.7589 - val_mae: 2.3745\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.6499 - mae: 1.8904 - val_loss: 10.5453 - val_mae: 2.2797\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.2971 - mae: 1.7863 - val_loss: 10.7785 - val_mae: 2.5332\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.9921 - mae: 1.7561 - val_loss: 10.9611 - val_mae: 2.5212\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.6491 - mae: 1.6889 - val_loss: 10.7622 - val_mae: 2.4375\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.6115 - mae: 1.6302 - val_loss: 11.0432 - val_mae: 2.4608\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.4476 - mae: 1.6562 - val_loss: 10.6174 - val_mae: 2.4727\n",
      "Epoch 31: early stopping\n",
      "Test Loss (MSE): 13.057684898376465, Test Mean Absolute Error (MAE): 2.6764211654663086\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 11.1908 - mae: 2.3172 - val_loss: 11.5636 - val_mae: 2.5185\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.0521 - mae: 2.1343 - val_loss: 11.6067 - val_mae: 2.6921\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.2006 - mae: 1.9995 - val_loss: 10.8100 - val_mae: 2.3898\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.3801 - mae: 1.9399 - val_loss: 12.2505 - val_mae: 2.4061\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.1719 - mae: 1.8609 - val_loss: 11.7559 - val_mae: 2.4006\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4825 - mae: 1.7387 - val_loss: 12.3313 - val_mae: 2.5671\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.9835 - mae: 1.6239 - val_loss: 12.4877 - val_mae: 2.6031\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.7150 - mae: 1.6209 - val_loss: 12.4882 - val_mae: 2.5669\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.3633 - mae: 1.5512 - val_loss: 13.6147 - val_mae: 2.7773\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.8344 - mae: 1.4551 - val_loss: 14.3748 - val_mae: 2.8554\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.3302 - mae: 1.3825 - val_loss: 14.1505 - val_mae: 2.7870\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.9253 - mae: 1.2386 - val_loss: 15.6287 - val_mae: 3.0512\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.2630 - mae: 1.2783 - val_loss: 16.3521 - val_mae: 3.0263\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.9752 - mae: 1.3002 - val_loss: 15.0955 - val_mae: 2.8904\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.4695 - mae: 1.1319 - val_loss: 14.1114 - val_mae: 2.7430\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.1677 - mae: 1.0549 - val_loss: 15.4470 - val_mae: 2.9144\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.0631 - mae: 1.0579 - val_loss: 14.7789 - val_mae: 2.8100\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.7415 - mae: 0.9313 - val_loss: 15.6290 - val_mae: 2.8543\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.8010 - mae: 0.9486 - val_loss: 15.2375 - val_mae: 2.8493\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.7463 - mae: 0.9313 - val_loss: 14.0568 - val_mae: 2.6739\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.9186 - mae: 1.0056 - val_loss: 16.0464 - val_mae: 2.8875\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.5203 - mae: 0.8669 - val_loss: 14.3783 - val_mae: 2.7171\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.2015 - mae: 0.7522 - val_loss: 14.4274 - val_mae: 2.7203\n",
      "Epoch 23: early stopping\n",
      "Test Loss (MSE): 14.917543411254883, Test Mean Absolute Error (MAE): 2.65372633934021\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 12.8279 - mae: 2.5155 - val_loss: 10.5473 - val_mae: 2.3796\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 10.1821 - mae: 2.3161 - val_loss: 10.2898 - val_mae: 2.2431\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.2776 - mae: 2.1713 - val_loss: 9.9997 - val_mae: 2.2837\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.0440 - mae: 2.0196 - val_loss: 10.6866 - val_mae: 2.6350\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.4202 - mae: 1.9676 - val_loss: 11.0373 - val_mae: 2.3701\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.8582 - mae: 1.8400 - val_loss: 11.0388 - val_mae: 2.4250\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.5726 - mae: 1.8040 - val_loss: 11.4269 - val_mae: 2.3836\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.4598 - mae: 1.7654 - val_loss: 11.5390 - val_mae: 2.5660\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.4381 - mae: 1.6481 - val_loss: 11.8950 - val_mae: 2.6061\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.3917 - mae: 1.5906 - val_loss: 12.2284 - val_mae: 2.5746\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.4409 - mae: 1.5936 - val_loss: 12.7337 - val_mae: 2.4066\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.6740 - mae: 1.6299 - val_loss: 11.5944 - val_mae: 2.4673\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.9038 - mae: 1.4917 - val_loss: 12.8093 - val_mae: 2.6902\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.9143 - mae: 1.3157 - val_loss: 12.3264 - val_mae: 2.4978\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.7674 - mae: 1.2687 - val_loss: 13.2121 - val_mae: 2.6827\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.5508 - mae: 1.2113 - val_loss: 13.4814 - val_mae: 2.7683\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.9980 - mae: 1.0886 - val_loss: 13.4898 - val_mae: 2.7672\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.7872 - mae: 1.0456 - val_loss: 13.3680 - val_mae: 2.6920\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.5504 - mae: 0.9477 - val_loss: 12.8967 - val_mae: 2.6334\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.3965 - mae: 0.9153 - val_loss: 13.1425 - val_mae: 2.6737\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.1376 - mae: 0.8249 - val_loss: 14.3263 - val_mae: 2.8343\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.1538 - mae: 0.8186 - val_loss: 13.9263 - val_mae: 2.7808\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.1803 - mae: 0.8230 - val_loss: 13.4480 - val_mae: 2.7359\n",
      "Epoch 23: early stopping\n",
      "Test Loss (MSE): 13.371855735778809, Test Mean Absolute Error (MAE): 2.5081448554992676\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 12.2015 - mae: 2.4419 - val_loss: 10.3518 - val_mae: 2.3519\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 9.5240 - mae: 2.1484 - val_loss: 9.9489 - val_mae: 2.1969\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 8.6068 - mae: 2.0956 - val_loss: 9.9419 - val_mae: 2.3798\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.9334 - mae: 1.9755 - val_loss: 10.0211 - val_mae: 2.2508\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.7525 - mae: 1.9614 - val_loss: 10.5287 - val_mae: 2.1983\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 7.2519 - mae: 1.8777 - val_loss: 9.8244 - val_mae: 2.2164\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.8211 - mae: 1.8135 - val_loss: 10.0260 - val_mae: 2.2295\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.5259 - mae: 1.7712 - val_loss: 10.3079 - val_mae: 2.2698\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 6.6238 - mae: 1.7550 - val_loss: 10.2364 - val_mae: 2.4084\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.8744 - mae: 1.6637 - val_loss: 10.9783 - val_mae: 2.4642\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.3957 - mae: 1.5805 - val_loss: 10.5971 - val_mae: 2.3082\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.3473 - mae: 1.5206 - val_loss: 11.7038 - val_mae: 2.4955\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.4238 - mae: 1.5417 - val_loss: 11.2379 - val_mae: 2.4795\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.9135 - mae: 1.4303 - val_loss: 12.3354 - val_mae: 2.6077\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.6313 - mae: 1.4112 - val_loss: 12.4754 - val_mae: 2.6633\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.7940 - mae: 1.4349 - val_loss: 11.7604 - val_mae: 2.5909\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.4839 - mae: 1.3572 - val_loss: 11.8803 - val_mae: 2.3889\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 4.3271 - mae: 1.2981 - val_loss: 11.7589 - val_mae: 2.4144\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.7415 - mae: 1.1763 - val_loss: 13.1766 - val_mae: 2.5998\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.4942 - mae: 1.1246 - val_loss: 12.0328 - val_mae: 2.4114\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.3187 - mae: 1.0792 - val_loss: 13.0910 - val_mae: 2.5493\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.4648 - mae: 1.1135 - val_loss: 11.7870 - val_mae: 2.3834\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.6539 - mae: 1.1494 - val_loss: 13.8434 - val_mae: 2.7253\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.1148 - mae: 1.0244 - val_loss: 13.0641 - val_mae: 2.6394\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.8596 - mae: 0.9414 - val_loss: 13.2632 - val_mae: 2.6710\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.6329 - mae: 0.8482 - val_loss: 13.8810 - val_mae: 2.7393\n",
      "Epoch 26: early stopping\n",
      "Test Loss (MSE): 12.599236488342285, Test Mean Absolute Error (MAE): 2.499445915222168\n",
      "Epoch 1/100\n",
      "146/146 [==============================] - 0s 1ms/step - loss: 4.9867 - mae: 1.2759 - val_loss: 5.6694 - val_mae: 1.4653\n",
      "Epoch 2/100\n",
      "146/146 [==============================] - 0s 708us/step - loss: 4.6211 - mae: 1.2616 - val_loss: 5.3309 - val_mae: 1.4375\n",
      "Epoch 3/100\n",
      "146/146 [==============================] - 0s 656us/step - loss: 4.5593 - mae: 1.2420 - val_loss: 5.6334 - val_mae: 1.2815\n",
      "Epoch 4/100\n",
      "146/146 [==============================] - 0s 768us/step - loss: 4.5444 - mae: 1.2470 - val_loss: 5.3635 - val_mae: 1.3367\n",
      "Epoch 5/100\n",
      "146/146 [==============================] - 0s 740us/step - loss: 4.5414 - mae: 1.2534 - val_loss: 5.4446 - val_mae: 1.2126\n",
      "Epoch 6/100\n",
      "146/146 [==============================] - 0s 757us/step - loss: 4.4786 - mae: 1.2400 - val_loss: 5.2477 - val_mae: 1.3449\n",
      "Epoch 7/100\n",
      "146/146 [==============================] - 0s 738us/step - loss: 4.4559 - mae: 1.2316 - val_loss: 5.2177 - val_mae: 1.4635\n",
      "Epoch 8/100\n",
      "146/146 [==============================] - 0s 809us/step - loss: 4.4705 - mae: 1.2409 - val_loss: 5.2565 - val_mae: 1.4285\n",
      "Epoch 9/100\n",
      "146/146 [==============================] - 0s 715us/step - loss: 4.4229 - mae: 1.2277 - val_loss: 5.2803 - val_mae: 1.4247\n",
      "Epoch 10/100\n",
      "146/146 [==============================] - 0s 686us/step - loss: 4.4498 - mae: 1.2401 - val_loss: 5.2678 - val_mae: 1.2546\n",
      "Epoch 11/100\n",
      "146/146 [==============================] - 0s 679us/step - loss: 4.4447 - mae: 1.2313 - val_loss: 5.1799 - val_mae: 1.3536\n",
      "Epoch 12/100\n",
      "146/146 [==============================] - 0s 712us/step - loss: 4.4227 - mae: 1.2292 - val_loss: 5.2242 - val_mae: 1.3107\n",
      "Epoch 13/100\n",
      "146/146 [==============================] - 0s 694us/step - loss: 4.4107 - mae: 1.2224 - val_loss: 5.2363 - val_mae: 1.3648\n",
      "Epoch 14/100\n",
      "146/146 [==============================] - 0s 684us/step - loss: 4.4247 - mae: 1.2330 - val_loss: 5.2034 - val_mae: 1.3724\n",
      "Epoch 15/100\n",
      "146/146 [==============================] - 0s 679us/step - loss: 4.4426 - mae: 1.2290 - val_loss: 5.2708 - val_mae: 1.3319\n",
      "Epoch 16/100\n",
      "146/146 [==============================] - 0s 709us/step - loss: 4.4149 - mae: 1.2372 - val_loss: 5.2352 - val_mae: 1.4053\n",
      "Epoch 17/100\n",
      "146/146 [==============================] - 0s 740us/step - loss: 4.4114 - mae: 1.2323 - val_loss: 5.1844 - val_mae: 1.4451\n",
      "Epoch 18/100\n",
      "146/146 [==============================] - 0s 676us/step - loss: 4.4259 - mae: 1.2354 - val_loss: 5.1585 - val_mae: 1.4016\n",
      "Epoch 19/100\n",
      "146/146 [==============================] - 0s 715us/step - loss: 4.3952 - mae: 1.2237 - val_loss: 5.3171 - val_mae: 1.2779\n",
      "Epoch 20/100\n",
      "146/146 [==============================] - 0s 698us/step - loss: 4.4011 - mae: 1.2309 - val_loss: 5.3716 - val_mae: 1.2700\n",
      "Epoch 21/100\n",
      "146/146 [==============================] - 0s 703us/step - loss: 4.4280 - mae: 1.2453 - val_loss: 5.2031 - val_mae: 1.3168\n",
      "Epoch 22/100\n",
      "146/146 [==============================] - 0s 699us/step - loss: 4.4023 - mae: 1.2261 - val_loss: 5.1725 - val_mae: 1.3877\n",
      "Epoch 23/100\n",
      "146/146 [==============================] - 0s 678us/step - loss: 4.4126 - mae: 1.2337 - val_loss: 5.2576 - val_mae: 1.2896\n",
      "Epoch 24/100\n",
      "146/146 [==============================] - 0s 696us/step - loss: 4.3952 - mae: 1.2330 - val_loss: 5.3207 - val_mae: 1.2278\n",
      "Epoch 25/100\n",
      "146/146 [==============================] - 0s 714us/step - loss: 4.4180 - mae: 1.2350 - val_loss: 5.1981 - val_mae: 1.3339\n",
      "Epoch 26/100\n",
      "146/146 [==============================] - 0s 721us/step - loss: 4.4034 - mae: 1.2267 - val_loss: 5.1638 - val_mae: 1.3989\n",
      "Epoch 27/100\n",
      "146/146 [==============================] - 0s 692us/step - loss: 4.3935 - mae: 1.2206 - val_loss: 5.2535 - val_mae: 1.3517\n",
      "Epoch 28/100\n",
      "146/146 [==============================] - 0s 677us/step - loss: 4.3961 - mae: 1.2261 - val_loss: 5.2347 - val_mae: 1.3788\n",
      "Epoch 29/100\n",
      "146/146 [==============================] - 0s 675us/step - loss: 4.3914 - mae: 1.2277 - val_loss: 5.1641 - val_mae: 1.4075\n",
      "Epoch 30/100\n",
      "146/146 [==============================] - 0s 760us/step - loss: 4.4057 - mae: 1.2277 - val_loss: 5.1763 - val_mae: 1.3758\n",
      "Epoch 31/100\n",
      "146/146 [==============================] - 0s 731us/step - loss: 4.3985 - mae: 1.2238 - val_loss: 5.1901 - val_mae: 1.4622\n",
      "Epoch 32/100\n",
      "146/146 [==============================] - 0s 686us/step - loss: 4.3986 - mae: 1.2443 - val_loss: 5.2084 - val_mae: 1.2563\n",
      "Epoch 33/100\n",
      "146/146 [==============================] - 0s 718us/step - loss: 4.3850 - mae: 1.2233 - val_loss: 5.1956 - val_mae: 1.3475\n",
      "Epoch 34/100\n",
      "146/146 [==============================] - 0s 686us/step - loss: 4.3889 - mae: 1.2322 - val_loss: 5.2313 - val_mae: 1.3147\n",
      "Epoch 35/100\n",
      "146/146 [==============================] - 0s 676us/step - loss: 4.3835 - mae: 1.2191 - val_loss: 5.2248 - val_mae: 1.5041\n",
      "Epoch 36/100\n",
      "146/146 [==============================] - 0s 668us/step - loss: 4.3815 - mae: 1.2267 - val_loss: 5.1761 - val_mae: 1.3690\n",
      "Epoch 37/100\n",
      "146/146 [==============================] - 0s 734us/step - loss: 4.3938 - mae: 1.2317 - val_loss: 5.2060 - val_mae: 1.3151\n",
      "Epoch 38/100\n",
      "146/146 [==============================] - 0s 683us/step - loss: 4.3926 - mae: 1.2278 - val_loss: 5.2266 - val_mae: 1.2715\n",
      "Epoch 38: early stopping\n",
      "Test Loss (MSE): 4.947828769683838, Test Mean Absolute Error (MAE): 1.2203190326690674\n",
      "Epoch 1/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 5.2935 - mae: 1.2507 - val_loss: 5.0872 - val_mae: 1.3327\n",
      "Epoch 2/100\n",
      "148/148 [==============================] - 0s 717us/step - loss: 4.8060 - mae: 1.2678 - val_loss: 4.9841 - val_mae: 1.2395\n",
      "Epoch 3/100\n",
      "148/148 [==============================] - 0s 705us/step - loss: 4.7832 - mae: 1.2531 - val_loss: 4.8261 - val_mae: 1.3211\n",
      "Epoch 4/100\n",
      "148/148 [==============================] - 0s 749us/step - loss: 4.7211 - mae: 1.2498 - val_loss: 5.0706 - val_mae: 1.2246\n",
      "Epoch 5/100\n",
      "148/148 [==============================] - 0s 715us/step - loss: 4.7560 - mae: 1.2477 - val_loss: 4.9605 - val_mae: 1.2611\n",
      "Epoch 6/100\n",
      "148/148 [==============================] - 0s 699us/step - loss: 4.6930 - mae: 1.2471 - val_loss: 4.9716 - val_mae: 1.5026\n",
      "Epoch 7/100\n",
      "148/148 [==============================] - 0s 710us/step - loss: 4.8060 - mae: 1.2634 - val_loss: 4.7558 - val_mae: 1.3454\n",
      "Epoch 8/100\n",
      "148/148 [==============================] - 0s 729us/step - loss: 4.6755 - mae: 1.2513 - val_loss: 4.7507 - val_mae: 1.3668\n",
      "Epoch 9/100\n",
      "148/148 [==============================] - 0s 681us/step - loss: 4.6692 - mae: 1.2410 - val_loss: 4.8000 - val_mae: 1.3288\n",
      "Epoch 10/100\n",
      "148/148 [==============================] - 0s 688us/step - loss: 4.6479 - mae: 1.2427 - val_loss: 4.7774 - val_mae: 1.2959\n",
      "Epoch 11/100\n",
      "148/148 [==============================] - 0s 698us/step - loss: 4.6362 - mae: 1.2432 - val_loss: 4.7448 - val_mae: 1.3496\n",
      "Epoch 12/100\n",
      "148/148 [==============================] - 0s 741us/step - loss: 4.6343 - mae: 1.2429 - val_loss: 4.8970 - val_mae: 1.4214\n",
      "Epoch 13/100\n",
      "148/148 [==============================] - 0s 729us/step - loss: 4.6654 - mae: 1.2448 - val_loss: 4.8190 - val_mae: 1.4003\n",
      "Epoch 14/100\n",
      "148/148 [==============================] - 0s 696us/step - loss: 4.6285 - mae: 1.2497 - val_loss: 4.9246 - val_mae: 1.2110\n",
      "Epoch 15/100\n",
      "148/148 [==============================] - 0s 668us/step - loss: 4.6519 - mae: 1.2430 - val_loss: 4.7479 - val_mae: 1.2919\n",
      "Epoch 16/100\n",
      "148/148 [==============================] - 0s 755us/step - loss: 4.6509 - mae: 1.2472 - val_loss: 4.8400 - val_mae: 1.4098\n",
      "Epoch 17/100\n",
      "148/148 [==============================] - 0s 721us/step - loss: 4.6500 - mae: 1.2458 - val_loss: 4.8202 - val_mae: 1.2883\n",
      "Epoch 18/100\n",
      "148/148 [==============================] - 0s 712us/step - loss: 4.6296 - mae: 1.2398 - val_loss: 4.7734 - val_mae: 1.3490\n",
      "Epoch 19/100\n",
      "148/148 [==============================] - 0s 684us/step - loss: 4.6160 - mae: 1.2459 - val_loss: 4.8751 - val_mae: 1.2206\n",
      "Epoch 20/100\n",
      "148/148 [==============================] - 0s 746us/step - loss: 4.6263 - mae: 1.2362 - val_loss: 4.8607 - val_mae: 1.2665\n",
      "Epoch 21/100\n",
      "148/148 [==============================] - 0s 692us/step - loss: 4.6264 - mae: 1.2442 - val_loss: 4.7945 - val_mae: 1.3756\n",
      "Epoch 22/100\n",
      "148/148 [==============================] - 0s 702us/step - loss: 4.6224 - mae: 1.2512 - val_loss: 4.8474 - val_mae: 1.2076\n",
      "Epoch 23/100\n",
      "148/148 [==============================] - 0s 714us/step - loss: 4.6344 - mae: 1.2393 - val_loss: 4.7948 - val_mae: 1.3037\n",
      "Epoch 24/100\n",
      "148/148 [==============================] - 0s 733us/step - loss: 4.6111 - mae: 1.2396 - val_loss: 4.7914 - val_mae: 1.2793\n",
      "Epoch 25/100\n",
      "148/148 [==============================] - 0s 744us/step - loss: 4.6020 - mae: 1.2346 - val_loss: 4.7936 - val_mae: 1.3839\n",
      "Epoch 26/100\n",
      "148/148 [==============================] - 0s 834us/step - loss: 4.6387 - mae: 1.2562 - val_loss: 4.8206 - val_mae: 1.2616\n",
      "Epoch 27/100\n",
      "148/148 [==============================] - 0s 747us/step - loss: 4.6111 - mae: 1.2406 - val_loss: 4.8201 - val_mae: 1.3153\n",
      "Epoch 28/100\n",
      "148/148 [==============================] - 0s 698us/step - loss: 4.5985 - mae: 1.2470 - val_loss: 4.7791 - val_mae: 1.3471\n",
      "Epoch 29/100\n",
      "148/148 [==============================] - 0s 732us/step - loss: 4.6006 - mae: 1.2465 - val_loss: 4.7897 - val_mae: 1.2923\n",
      "Epoch 30/100\n",
      "148/148 [==============================] - 0s 691us/step - loss: 4.6149 - mae: 1.2357 - val_loss: 4.8203 - val_mae: 1.3446\n",
      "Epoch 31/100\n",
      "148/148 [==============================] - 0s 668us/step - loss: 4.6278 - mae: 1.2489 - val_loss: 4.7619 - val_mae: 1.3048\n",
      "Epoch 31: early stopping\n",
      "Test Loss (MSE): 4.392259120941162, Test Mean Absolute Error (MAE): 1.2733829021453857\n",
      "Epoch 1/100\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 5.4101 - mae: 1.3118 - val_loss: 4.9118 - val_mae: 1.2326\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 0s 776us/step - loss: 4.9417 - mae: 1.3089 - val_loss: 4.8528 - val_mae: 1.1877\n",
      "Epoch 3/100\n",
      "145/145 [==============================] - 0s 753us/step - loss: 4.7698 - mae: 1.3115 - val_loss: 5.0129 - val_mae: 1.1611\n",
      "Epoch 4/100\n",
      "145/145 [==============================] - 0s 765us/step - loss: 4.7323 - mae: 1.3111 - val_loss: 4.7096 - val_mae: 1.3137\n",
      "Epoch 5/100\n",
      "145/145 [==============================] - 0s 712us/step - loss: 4.6987 - mae: 1.2896 - val_loss: 4.8594 - val_mae: 1.2236\n",
      "Epoch 6/100\n",
      "145/145 [==============================] - 0s 747us/step - loss: 4.6786 - mae: 1.3064 - val_loss: 4.6810 - val_mae: 1.2384\n",
      "Epoch 7/100\n",
      "145/145 [==============================] - 0s 747us/step - loss: 4.6453 - mae: 1.3005 - val_loss: 4.6714 - val_mae: 1.2351\n",
      "Epoch 8/100\n",
      "145/145 [==============================] - 0s 751us/step - loss: 4.6623 - mae: 1.2881 - val_loss: 4.7355 - val_mae: 1.1584\n",
      "Epoch 9/100\n",
      "145/145 [==============================] - 0s 735us/step - loss: 4.6371 - mae: 1.2976 - val_loss: 4.6652 - val_mae: 1.2792\n",
      "Epoch 10/100\n",
      "145/145 [==============================] - 0s 733us/step - loss: 4.6488 - mae: 1.2948 - val_loss: 4.6560 - val_mae: 1.2666\n",
      "Epoch 11/100\n",
      "145/145 [==============================] - 0s 722us/step - loss: 4.6267 - mae: 1.2883 - val_loss: 4.8017 - val_mae: 1.3864\n",
      "Epoch 12/100\n",
      "145/145 [==============================] - 0s 780us/step - loss: 4.6460 - mae: 1.2877 - val_loss: 4.6581 - val_mae: 1.2257\n",
      "Epoch 13/100\n",
      "145/145 [==============================] - 0s 733us/step - loss: 4.6225 - mae: 1.2871 - val_loss: 4.6585 - val_mae: 1.3124\n",
      "Epoch 14/100\n",
      "145/145 [==============================] - 0s 718us/step - loss: 4.6226 - mae: 1.2917 - val_loss: 4.6851 - val_mae: 1.1692\n",
      "Epoch 15/100\n",
      "145/145 [==============================] - 0s 748us/step - loss: 4.6352 - mae: 1.2922 - val_loss: 4.7745 - val_mae: 1.1131\n",
      "Epoch 16/100\n",
      "145/145 [==============================] - 0s 800us/step - loss: 4.6218 - mae: 1.2851 - val_loss: 4.7718 - val_mae: 1.2031\n",
      "Epoch 17/100\n",
      "145/145 [==============================] - 0s 722us/step - loss: 4.6142 - mae: 1.2857 - val_loss: 4.6668 - val_mae: 1.2272\n",
      "Epoch 18/100\n",
      "145/145 [==============================] - 0s 739us/step - loss: 4.6121 - mae: 1.3004 - val_loss: 4.6694 - val_mae: 1.2431\n",
      "Epoch 19/100\n",
      "145/145 [==============================] - 0s 736us/step - loss: 4.6163 - mae: 1.2890 - val_loss: 4.6621 - val_mae: 1.2452\n",
      "Epoch 20/100\n",
      "145/145 [==============================] - 0s 777us/step - loss: 4.6066 - mae: 1.2917 - val_loss: 4.6813 - val_mae: 1.2170\n",
      "Epoch 21/100\n",
      "145/145 [==============================] - 0s 731us/step - loss: 4.6061 - mae: 1.2849 - val_loss: 4.7601 - val_mae: 1.2018\n",
      "Epoch 22/100\n",
      "145/145 [==============================] - 0s 731us/step - loss: 4.5910 - mae: 1.2871 - val_loss: 4.6584 - val_mae: 1.2547\n",
      "Epoch 23/100\n",
      "145/145 [==============================] - 0s 764us/step - loss: 4.5868 - mae: 1.2845 - val_loss: 4.6661 - val_mae: 1.1902\n",
      "Epoch 24/100\n",
      "145/145 [==============================] - 0s 759us/step - loss: 4.6204 - mae: 1.2826 - val_loss: 4.6815 - val_mae: 1.3521\n",
      "Epoch 25/100\n",
      "145/145 [==============================] - 0s 752us/step - loss: 4.6041 - mae: 1.3001 - val_loss: 4.6954 - val_mae: 1.1542\n",
      "Epoch 26/100\n",
      "145/145 [==============================] - 0s 752us/step - loss: 4.6004 - mae: 1.2854 - val_loss: 4.7082 - val_mae: 1.3217\n",
      "Epoch 27/100\n",
      "145/145 [==============================] - 0s 740us/step - loss: 4.6103 - mae: 1.2878 - val_loss: 4.6766 - val_mae: 1.3152\n",
      "Epoch 28/100\n",
      "145/145 [==============================] - 0s 775us/step - loss: 4.5987 - mae: 1.2905 - val_loss: 4.6936 - val_mae: 1.2333\n",
      "Epoch 29/100\n",
      "145/145 [==============================] - 0s 762us/step - loss: 4.5772 - mae: 1.2842 - val_loss: 4.6884 - val_mae: 1.2488\n",
      "Epoch 30/100\n",
      "145/145 [==============================] - 0s 738us/step - loss: 4.5932 - mae: 1.2842 - val_loss: 4.6887 - val_mae: 1.1950\n",
      "Epoch 30: early stopping\n",
      "Test Loss (MSE): 4.621291160583496, Test Mean Absolute Error (MAE): 1.2063796520233154\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 5.6716 - mae: 1.3392 - val_loss: 4.4785 - val_mae: 1.0663\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 772us/step - loss: 5.0369 - mae: 1.3298 - val_loss: 4.3154 - val_mae: 1.1726\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 861us/step - loss: 4.9171 - mae: 1.3334 - val_loss: 4.2298 - val_mae: 1.0786\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 757us/step - loss: 4.8575 - mae: 1.3181 - val_loss: 4.1680 - val_mae: 1.1241\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 785us/step - loss: 4.7898 - mae: 1.3114 - val_loss: 4.1907 - val_mae: 1.1796\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 899us/step - loss: 4.8147 - mae: 1.3148 - val_loss: 4.2339 - val_mae: 1.0917\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 833us/step - loss: 4.7647 - mae: 1.3034 - val_loss: 4.1910 - val_mae: 1.1839\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 821us/step - loss: 4.7586 - mae: 1.3133 - val_loss: 4.2952 - val_mae: 1.2737\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 821us/step - loss: 4.7715 - mae: 1.3103 - val_loss: 4.1845 - val_mae: 1.1674\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 738us/step - loss: 4.7395 - mae: 1.3118 - val_loss: 4.2051 - val_mae: 1.1811\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 777us/step - loss: 4.7701 - mae: 1.3151 - val_loss: 4.1572 - val_mae: 1.0633\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 769us/step - loss: 4.7798 - mae: 1.3137 - val_loss: 4.1582 - val_mae: 1.0908\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 792us/step - loss: 4.7255 - mae: 1.3035 - val_loss: 4.2037 - val_mae: 1.2266\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 748us/step - loss: 4.7152 - mae: 1.3181 - val_loss: 4.2096 - val_mae: 1.0993\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 0s 763us/step - loss: 4.7258 - mae: 1.3119 - val_loss: 4.1863 - val_mae: 1.2266\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 0s 775us/step - loss: 4.7142 - mae: 1.3094 - val_loss: 4.1593 - val_mae: 1.1481\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 0s 850us/step - loss: 4.7029 - mae: 1.2999 - val_loss: 4.2024 - val_mae: 1.1258\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 0s 797us/step - loss: 4.7508 - mae: 1.3188 - val_loss: 4.1501 - val_mae: 1.1865\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 0s 752us/step - loss: 4.7272 - mae: 1.3069 - val_loss: 4.1800 - val_mae: 1.1230\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 0s 761us/step - loss: 4.7090 - mae: 1.3009 - val_loss: 4.1716 - val_mae: 1.2242\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 0s 824us/step - loss: 4.7077 - mae: 1.3165 - val_loss: 4.2004 - val_mae: 1.1265\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 0s 811us/step - loss: 4.7353 - mae: 1.3095 - val_loss: 4.2685 - val_mae: 1.0579\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 0s 767us/step - loss: 4.7058 - mae: 1.2997 - val_loss: 4.1958 - val_mae: 1.1291\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 0s 783us/step - loss: 4.7095 - mae: 1.3180 - val_loss: 4.2031 - val_mae: 1.1573\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 0s 784us/step - loss: 4.7074 - mae: 1.3115 - val_loss: 4.1909 - val_mae: 1.1478\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 0s 770us/step - loss: 4.7057 - mae: 1.2963 - val_loss: 4.2112 - val_mae: 1.1712\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 0s 752us/step - loss: 4.7119 - mae: 1.3025 - val_loss: 4.2231 - val_mae: 1.1971\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 0s 764us/step - loss: 4.6832 - mae: 1.3043 - val_loss: 4.2228 - val_mae: 1.1018\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 0s 770us/step - loss: 4.7058 - mae: 1.3106 - val_loss: 4.1584 - val_mae: 1.1456\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 0s 761us/step - loss: 4.6750 - mae: 1.2989 - val_loss: 4.1672 - val_mae: 1.1497\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 0s 740us/step - loss: 4.6880 - mae: 1.3005 - val_loss: 4.2574 - val_mae: 1.2430\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 0s 758us/step - loss: 4.6810 - mae: 1.3055 - val_loss: 4.2187 - val_mae: 1.1488\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 0s 787us/step - loss: 4.7031 - mae: 1.3055 - val_loss: 4.1990 - val_mae: 1.1512\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 0s 748us/step - loss: 4.7045 - mae: 1.3078 - val_loss: 4.2006 - val_mae: 1.1171\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 0s 756us/step - loss: 4.6611 - mae: 1.2973 - val_loss: 4.2158 - val_mae: 1.1177\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 0s 742us/step - loss: 4.6767 - mae: 1.2968 - val_loss: 4.2219 - val_mae: 1.1893\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 0s 787us/step - loss: 4.6656 - mae: 1.3034 - val_loss: 4.2650 - val_mae: 1.1330\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 0s 754us/step - loss: 4.6899 - mae: 1.3008 - val_loss: 4.2069 - val_mae: 1.1378\n",
      "Epoch 38: early stopping\n",
      "Test Loss (MSE): 5.150086402893066, Test Mean Absolute Error (MAE): 1.3005659580230713\n",
      "Epoch 1/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 9.0189 - mae: 2.1336 - val_loss: 8.4005 - val_mae: 1.9983\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 763us/step - loss: 8.1949 - mae: 2.1095 - val_loss: 8.0556 - val_mae: 2.0743\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 754us/step - loss: 8.0559 - mae: 2.0763 - val_loss: 8.0101 - val_mae: 2.2026\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 768us/step - loss: 8.0265 - mae: 2.1044 - val_loss: 7.9445 - val_mae: 2.1841\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 754us/step - loss: 8.0262 - mae: 2.0704 - val_loss: 8.0942 - val_mae: 2.3360\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 783us/step - loss: 7.9862 - mae: 2.1170 - val_loss: 8.1971 - val_mae: 1.9568\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 881us/step - loss: 7.9944 - mae: 2.0735 - val_loss: 7.8129 - val_mae: 2.1466\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 806us/step - loss: 7.8645 - mae: 2.0869 - val_loss: 7.9848 - val_mae: 1.9959\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 759us/step - loss: 7.8815 - mae: 2.0736 - val_loss: 7.8353 - val_mae: 2.0614\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 767us/step - loss: 7.8464 - mae: 2.0636 - val_loss: 7.8832 - val_mae: 2.2576\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 779us/step - loss: 7.8234 - mae: 2.0818 - val_loss: 7.9509 - val_mae: 2.0014\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 766us/step - loss: 7.7936 - mae: 2.0655 - val_loss: 7.7979 - val_mae: 2.1259\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 837us/step - loss: 7.7773 - mae: 2.0635 - val_loss: 7.8237 - val_mae: 2.0782\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 770us/step - loss: 7.8191 - mae: 2.0735 - val_loss: 7.8080 - val_mae: 2.1627\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 769us/step - loss: 7.8368 - mae: 2.0686 - val_loss: 7.8682 - val_mae: 2.1695\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 744us/step - loss: 7.8239 - mae: 2.0689 - val_loss: 7.8737 - val_mae: 2.1590\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 784us/step - loss: 7.8072 - mae: 2.0715 - val_loss: 7.8053 - val_mae: 2.1205\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 766us/step - loss: 7.7846 - mae: 2.0644 - val_loss: 7.8402 - val_mae: 2.2092\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 805us/step - loss: 7.8051 - mae: 2.0750 - val_loss: 7.7973 - val_mae: 2.1280\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 746us/step - loss: 7.7681 - mae: 2.0815 - val_loss: 7.8261 - val_mae: 2.0897\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 771us/step - loss: 7.7213 - mae: 2.0644 - val_loss: 8.0077 - val_mae: 2.2835\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 756us/step - loss: 7.7647 - mae: 2.0629 - val_loss: 7.8232 - val_mae: 2.1287\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 809us/step - loss: 7.7508 - mae: 2.0771 - val_loss: 7.8520 - val_mae: 2.0846\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 785us/step - loss: 7.7558 - mae: 2.0649 - val_loss: 7.7737 - val_mae: 2.1396\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 810us/step - loss: 7.7269 - mae: 2.0620 - val_loss: 7.8460 - val_mae: 2.1372\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 795us/step - loss: 7.7240 - mae: 2.0645 - val_loss: 7.8842 - val_mae: 2.1691\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 783us/step - loss: 7.7315 - mae: 2.0596 - val_loss: 7.9184 - val_mae: 2.1432\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 729us/step - loss: 7.7272 - mae: 2.0652 - val_loss: 7.7631 - val_mae: 2.1243\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 754us/step - loss: 7.7194 - mae: 2.0776 - val_loss: 7.8369 - val_mae: 2.1400\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 735us/step - loss: 7.7392 - mae: 2.0594 - val_loss: 7.8447 - val_mae: 2.1882\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 847us/step - loss: 7.7197 - mae: 2.0732 - val_loss: 7.7880 - val_mae: 2.1124\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 781us/step - loss: 7.7190 - mae: 2.0704 - val_loss: 7.7674 - val_mae: 2.1139\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 758us/step - loss: 7.7399 - mae: 2.0636 - val_loss: 7.7955 - val_mae: 2.1458\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 754us/step - loss: 7.7261 - mae: 2.0658 - val_loss: 7.8630 - val_mae: 2.1475\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 798us/step - loss: 7.7173 - mae: 2.0734 - val_loss: 7.8504 - val_mae: 2.1154\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 771us/step - loss: 7.7234 - mae: 2.0625 - val_loss: 7.8028 - val_mae: 2.0893\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 818us/step - loss: 7.7315 - mae: 2.0709 - val_loss: 8.0052 - val_mae: 1.9931\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 806us/step - loss: 7.7346 - mae: 2.0585 - val_loss: 7.7748 - val_mae: 2.1295\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 771us/step - loss: 7.7216 - mae: 2.0542 - val_loss: 7.8594 - val_mae: 2.2372\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 767us/step - loss: 7.7602 - mae: 2.0754 - val_loss: 7.7971 - val_mae: 2.0884\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 794us/step - loss: 7.6880 - mae: 2.0709 - val_loss: 7.8138 - val_mae: 2.0824\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 799us/step - loss: 7.6905 - mae: 2.0486 - val_loss: 7.8948 - val_mae: 2.2610\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 775us/step - loss: 7.7273 - mae: 2.0622 - val_loss: 7.8165 - val_mae: 2.1607\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 745us/step - loss: 7.7129 - mae: 2.0860 - val_loss: 7.8119 - val_mae: 2.1537\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 754us/step - loss: 7.6612 - mae: 2.0453 - val_loss: 7.7888 - val_mae: 2.1657\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 764us/step - loss: 7.6832 - mae: 2.0726 - val_loss: 7.7879 - val_mae: 2.0874\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 813us/step - loss: 7.6786 - mae: 2.0664 - val_loss: 7.8452 - val_mae: 2.1327\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 754us/step - loss: 7.7222 - mae: 2.0635 - val_loss: 7.8013 - val_mae: 2.1824\n",
      "Epoch 48: early stopping\n",
      "Test Loss (MSE): 9.682883262634277, Test Mean Absolute Error (MAE): 2.41139817237854\n",
      "Epoch 1/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 9.2178 - mae: 2.1602 - val_loss: 8.0973 - val_mae: 2.0945\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 805us/step - loss: 8.4474 - mae: 2.1401 - val_loss: 7.8157 - val_mae: 1.9670\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 769us/step - loss: 8.2581 - mae: 2.1324 - val_loss: 7.6403 - val_mae: 2.0318\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 790us/step - loss: 8.1267 - mae: 2.1414 - val_loss: 7.5982 - val_mae: 2.0424\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 865us/step - loss: 8.1612 - mae: 2.1441 - val_loss: 7.6137 - val_mae: 2.0405\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 806us/step - loss: 8.0976 - mae: 2.1296 - val_loss: 7.8789 - val_mae: 2.2326\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 744us/step - loss: 8.1061 - mae: 2.1456 - val_loss: 7.5935 - val_mae: 2.0108\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 793us/step - loss: 8.0149 - mae: 2.1381 - val_loss: 7.5679 - val_mae: 2.0006\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 842us/step - loss: 8.0059 - mae: 2.1338 - val_loss: 7.5705 - val_mae: 2.0343\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 769us/step - loss: 8.0831 - mae: 2.1488 - val_loss: 7.6258 - val_mae: 2.1380\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 812us/step - loss: 8.0083 - mae: 2.1504 - val_loss: 7.5835 - val_mae: 2.0834\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 773us/step - loss: 8.0187 - mae: 2.1435 - val_loss: 7.5638 - val_mae: 2.0116\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 760us/step - loss: 8.0333 - mae: 2.1239 - val_loss: 7.5673 - val_mae: 2.0299\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 746us/step - loss: 7.9356 - mae: 2.1505 - val_loss: 7.8043 - val_mae: 2.1353\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 809us/step - loss: 8.0412 - mae: 2.1421 - val_loss: 7.7114 - val_mae: 2.1400\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 766us/step - loss: 7.9775 - mae: 2.1272 - val_loss: 7.6060 - val_mae: 2.1213\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 784us/step - loss: 8.0074 - mae: 2.1295 - val_loss: 7.5631 - val_mae: 2.0510\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 832us/step - loss: 7.9673 - mae: 2.1462 - val_loss: 7.5619 - val_mae: 2.0057\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 787us/step - loss: 8.0282 - mae: 2.1311 - val_loss: 7.5796 - val_mae: 2.0188\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 814us/step - loss: 7.9988 - mae: 2.1470 - val_loss: 7.6031 - val_mae: 2.0796\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 792us/step - loss: 7.9646 - mae: 2.1319 - val_loss: 7.8022 - val_mae: 2.1890\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 762us/step - loss: 7.9591 - mae: 2.1446 - val_loss: 7.6890 - val_mae: 2.1272\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 779us/step - loss: 7.9252 - mae: 2.1342 - val_loss: 7.8055 - val_mae: 2.2285\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 765us/step - loss: 7.9526 - mae: 2.1594 - val_loss: 7.6099 - val_mae: 2.1261\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 755us/step - loss: 7.9260 - mae: 2.1413 - val_loss: 7.6761 - val_mae: 2.1583\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 810us/step - loss: 7.9673 - mae: 2.1484 - val_loss: 7.5747 - val_mae: 2.1002\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 841us/step - loss: 7.9504 - mae: 2.1420 - val_loss: 7.5606 - val_mae: 2.0769\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 793us/step - loss: 7.9520 - mae: 2.1578 - val_loss: 7.5601 - val_mae: 2.0553\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 774us/step - loss: 7.9572 - mae: 2.1281 - val_loss: 7.5394 - val_mae: 2.0036\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 794us/step - loss: 7.9102 - mae: 2.1484 - val_loss: 7.7423 - val_mae: 2.1831\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 774us/step - loss: 7.9584 - mae: 2.1369 - val_loss: 7.5615 - val_mae: 2.0447\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 837us/step - loss: 7.9124 - mae: 2.1454 - val_loss: 7.5716 - val_mae: 2.0896\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 779us/step - loss: 7.9115 - mae: 2.1311 - val_loss: 7.5470 - val_mae: 2.0568\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 791us/step - loss: 7.9039 - mae: 2.1464 - val_loss: 7.6837 - val_mae: 2.1514\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 795us/step - loss: 7.9011 - mae: 2.1324 - val_loss: 7.7050 - val_mae: 2.1828\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 796us/step - loss: 7.9019 - mae: 2.1399 - val_loss: 7.6477 - val_mae: 2.1368\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 807us/step - loss: 7.9192 - mae: 2.1513 - val_loss: 7.5236 - val_mae: 2.0271\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 773us/step - loss: 7.8983 - mae: 2.1336 - val_loss: 7.5612 - val_mae: 2.0601\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 813us/step - loss: 7.9194 - mae: 2.1303 - val_loss: 7.6641 - val_mae: 2.1485\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 809us/step - loss: 7.9172 - mae: 2.1495 - val_loss: 7.5509 - val_mae: 1.9851\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 800us/step - loss: 7.9250 - mae: 2.1254 - val_loss: 7.5545 - val_mae: 2.0726\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 976us/step - loss: 7.8996 - mae: 2.1336 - val_loss: 7.6271 - val_mae: 2.1127\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 832us/step - loss: 7.8971 - mae: 2.1311 - val_loss: 7.6195 - val_mae: 2.1475\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 808us/step - loss: 7.9276 - mae: 2.1375 - val_loss: 7.5167 - val_mae: 2.0254\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 797us/step - loss: 7.8974 - mae: 2.1411 - val_loss: 7.5729 - val_mae: 2.0167\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 814us/step - loss: 7.9028 - mae: 2.1226 - val_loss: 7.6572 - val_mae: 2.1434\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 914us/step - loss: 7.9137 - mae: 2.1609 - val_loss: 7.5810 - val_mae: 2.0491\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 806us/step - loss: 7.8995 - mae: 2.1346 - val_loss: 7.5954 - val_mae: 2.0435\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 763us/step - loss: 7.8843 - mae: 2.1274 - val_loss: 7.6053 - val_mae: 2.0960\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 751us/step - loss: 7.9165 - mae: 2.1513 - val_loss: 7.6657 - val_mae: 2.1233\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 772us/step - loss: 7.9044 - mae: 2.1291 - val_loss: 7.6042 - val_mae: 2.0534\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 775us/step - loss: 7.9063 - mae: 2.1110 - val_loss: 7.8221 - val_mae: 2.2077\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 774us/step - loss: 7.9184 - mae: 2.1576 - val_loss: 7.5684 - val_mae: 2.0709\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 774us/step - loss: 7.8909 - mae: 2.1388 - val_loss: 7.5859 - val_mae: 2.0886\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 733us/step - loss: 7.8675 - mae: 2.1353 - val_loss: 7.5700 - val_mae: 2.0101\n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 760us/step - loss: 7.8894 - mae: 2.1302 - val_loss: 7.5607 - val_mae: 2.0674\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 733us/step - loss: 7.8870 - mae: 2.1359 - val_loss: 7.6326 - val_mae: 2.0859\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 803us/step - loss: 7.9399 - mae: 2.1369 - val_loss: 7.5514 - val_mae: 2.0251\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 772us/step - loss: 7.9024 - mae: 2.1286 - val_loss: 7.6066 - val_mae: 2.0876\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 756us/step - loss: 7.8810 - mae: 2.1329 - val_loss: 7.6507 - val_mae: 2.1308\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s 773us/step - loss: 7.8995 - mae: 2.1400 - val_loss: 7.5694 - val_mae: 2.0588\n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s 721us/step - loss: 7.8992 - mae: 2.1397 - val_loss: 7.6242 - val_mae: 2.0299\n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s 760us/step - loss: 7.9143 - mae: 2.1306 - val_loss: 7.5745 - val_mae: 2.0610\n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s 834us/step - loss: 7.8676 - mae: 2.1377 - val_loss: 7.8024 - val_mae: 2.1877\n",
      "Epoch 64: early stopping\n",
      "Test Loss (MSE): 8.783378601074219, Test Mean Absolute Error (MAE): 2.297100782394409\n",
      "Epoch 1/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 8.8270 - mae: 2.0936 - val_loss: 9.2099 - val_mae: 1.9509\n",
      "Epoch 2/100\n",
      "76/76 [==============================] - 0s 816us/step - loss: 8.1111 - mae: 2.0421 - val_loss: 8.6965 - val_mae: 2.0445\n",
      "Epoch 3/100\n",
      "76/76 [==============================] - 0s 832us/step - loss: 7.8952 - mae: 2.0743 - val_loss: 8.5286 - val_mae: 2.0751\n",
      "Epoch 4/100\n",
      "76/76 [==============================] - 0s 769us/step - loss: 7.7511 - mae: 2.0333 - val_loss: 8.3913 - val_mae: 2.1222\n",
      "Epoch 5/100\n",
      "76/76 [==============================] - 0s 773us/step - loss: 7.9085 - mae: 2.0775 - val_loss: 8.5424 - val_mae: 2.0072\n",
      "Epoch 6/100\n",
      "76/76 [==============================] - 0s 821us/step - loss: 7.7169 - mae: 2.0543 - val_loss: 8.5061 - val_mae: 2.0412\n",
      "Epoch 7/100\n",
      "76/76 [==============================] - 0s 784us/step - loss: 7.7010 - mae: 2.0756 - val_loss: 8.4685 - val_mae: 2.0353\n",
      "Epoch 8/100\n",
      "76/76 [==============================] - 0s 787us/step - loss: 7.6410 - mae: 2.0676 - val_loss: 8.3020 - val_mae: 2.1186\n",
      "Epoch 9/100\n",
      "76/76 [==============================] - 0s 794us/step - loss: 7.6711 - mae: 2.0869 - val_loss: 8.2851 - val_mae: 2.1330\n",
      "Epoch 10/100\n",
      "76/76 [==============================] - 0s 788us/step - loss: 7.6936 - mae: 2.0575 - val_loss: 8.5719 - val_mae: 1.9912\n",
      "Epoch 11/100\n",
      "76/76 [==============================] - 0s 812us/step - loss: 7.6775 - mae: 2.0581 - val_loss: 8.2772 - val_mae: 2.1179\n",
      "Epoch 12/100\n",
      "76/76 [==============================] - 0s 786us/step - loss: 7.6203 - mae: 2.0450 - val_loss: 8.2797 - val_mae: 2.1401\n",
      "Epoch 13/100\n",
      "76/76 [==============================] - 0s 852us/step - loss: 7.6021 - mae: 2.0617 - val_loss: 8.3221 - val_mae: 2.1493\n",
      "Epoch 14/100\n",
      "76/76 [==============================] - 0s 813us/step - loss: 7.6323 - mae: 2.0613 - val_loss: 8.3218 - val_mae: 2.1397\n",
      "Epoch 15/100\n",
      "76/76 [==============================] - 0s 790us/step - loss: 7.5458 - mae: 2.0379 - val_loss: 8.3306 - val_mae: 2.1557\n",
      "Epoch 16/100\n",
      "76/76 [==============================] - 0s 793us/step - loss: 7.6175 - mae: 2.0595 - val_loss: 8.4068 - val_mae: 2.0595\n",
      "Epoch 17/100\n",
      "76/76 [==============================] - 0s 841us/step - loss: 7.5998 - mae: 2.0410 - val_loss: 8.2741 - val_mae: 2.1475\n",
      "Epoch 18/100\n",
      "76/76 [==============================] - 0s 796us/step - loss: 7.5791 - mae: 2.0734 - val_loss: 8.4638 - val_mae: 2.0093\n",
      "Epoch 19/100\n",
      "76/76 [==============================] - 0s 786us/step - loss: 7.6595 - mae: 2.0323 - val_loss: 8.2714 - val_mae: 2.1713\n",
      "Epoch 20/100\n",
      "76/76 [==============================] - 0s 798us/step - loss: 7.5833 - mae: 2.0639 - val_loss: 8.2914 - val_mae: 2.1294\n",
      "Epoch 21/100\n",
      "76/76 [==============================] - 0s 773us/step - loss: 7.5650 - mae: 2.0731 - val_loss: 8.3122 - val_mae: 2.1431\n",
      "Epoch 22/100\n",
      "76/76 [==============================] - 0s 811us/step - loss: 7.5847 - mae: 2.0436 - val_loss: 8.4242 - val_mae: 2.2704\n",
      "Epoch 23/100\n",
      "76/76 [==============================] - 0s 831us/step - loss: 7.6287 - mae: 2.0903 - val_loss: 8.2726 - val_mae: 2.1611\n",
      "Epoch 24/100\n",
      "76/76 [==============================] - 0s 771us/step - loss: 7.5888 - mae: 2.0495 - val_loss: 8.3063 - val_mae: 2.1040\n",
      "Epoch 25/100\n",
      "76/76 [==============================] - 0s 807us/step - loss: 7.5308 - mae: 2.0439 - val_loss: 8.3367 - val_mae: 2.2431\n",
      "Epoch 26/100\n",
      "76/76 [==============================] - 0s 807us/step - loss: 7.5658 - mae: 2.0447 - val_loss: 8.5940 - val_mae: 2.3628\n",
      "Epoch 27/100\n",
      "76/76 [==============================] - 0s 817us/step - loss: 7.6225 - mae: 2.0755 - val_loss: 8.2728 - val_mae: 2.1771\n",
      "Epoch 28/100\n",
      "76/76 [==============================] - 0s 922us/step - loss: 7.5493 - mae: 2.0586 - val_loss: 8.2985 - val_mae: 2.1882\n",
      "Epoch 29/100\n",
      "76/76 [==============================] - 0s 825us/step - loss: 7.4916 - mae: 2.0280 - val_loss: 8.2790 - val_mae: 2.1816\n",
      "Epoch 30/100\n",
      "76/76 [==============================] - 0s 752us/step - loss: 7.5204 - mae: 2.0515 - val_loss: 8.3232 - val_mae: 2.1100\n",
      "Epoch 31/100\n",
      "76/76 [==============================] - 0s 778us/step - loss: 7.5412 - mae: 2.0530 - val_loss: 8.3203 - val_mae: 2.1593\n",
      "Epoch 32/100\n",
      "76/76 [==============================] - 0s 780us/step - loss: 7.5356 - mae: 2.0423 - val_loss: 8.3240 - val_mae: 2.2253\n",
      "Epoch 33/100\n",
      "76/76 [==============================] - 0s 833us/step - loss: 7.5677 - mae: 2.0482 - val_loss: 8.2974 - val_mae: 2.1809\n",
      "Epoch 34/100\n",
      "76/76 [==============================] - 0s 792us/step - loss: 7.5305 - mae: 2.0490 - val_loss: 8.3346 - val_mae: 2.2028\n",
      "Epoch 35/100\n",
      "76/76 [==============================] - 0s 817us/step - loss: 7.5372 - mae: 2.0543 - val_loss: 8.2860 - val_mae: 2.1685\n",
      "Epoch 36/100\n",
      "76/76 [==============================] - 0s 812us/step - loss: 7.5064 - mae: 2.0281 - val_loss: 8.3548 - val_mae: 2.2140\n",
      "Epoch 37/100\n",
      "76/76 [==============================] - 0s 840us/step - loss: 7.5133 - mae: 2.0572 - val_loss: 8.3690 - val_mae: 2.0700\n",
      "Epoch 38/100\n",
      "76/76 [==============================] - 0s 837us/step - loss: 7.4826 - mae: 2.0242 - val_loss: 8.3307 - val_mae: 2.1598\n",
      "Epoch 39/100\n",
      "76/76 [==============================] - 0s 849us/step - loss: 7.5285 - mae: 2.0586 - val_loss: 8.4532 - val_mae: 2.0407\n",
      "Epoch 39: early stopping\n",
      "Test Loss (MSE): 9.222573280334473, Test Mean Absolute Error (MAE): 2.1132702827453613\n",
      "Epoch 1/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 8.9394 - mae: 2.0514 - val_loss: 9.7546 - val_mae: 2.2585\n",
      "Epoch 2/100\n",
      "76/76 [==============================] - 0s 848us/step - loss: 8.1222 - mae: 2.0120 - val_loss: 9.4992 - val_mae: 2.2286\n",
      "Epoch 3/100\n",
      "76/76 [==============================] - 0s 850us/step - loss: 7.7767 - mae: 2.0144 - val_loss: 9.4438 - val_mae: 2.1732\n",
      "Epoch 4/100\n",
      "76/76 [==============================] - 0s 893us/step - loss: 7.6570 - mae: 2.0179 - val_loss: 9.2985 - val_mae: 2.1593\n",
      "Epoch 5/100\n",
      "76/76 [==============================] - 0s 901us/step - loss: 7.5922 - mae: 1.9915 - val_loss: 9.7909 - val_mae: 2.0589\n",
      "Epoch 6/100\n",
      "76/76 [==============================] - 0s 840us/step - loss: 7.5854 - mae: 2.0183 - val_loss: 9.1328 - val_mae: 2.2359\n",
      "Epoch 7/100\n",
      "76/76 [==============================] - 0s 825us/step - loss: 7.5352 - mae: 2.0099 - val_loss: 9.4280 - val_mae: 2.1447\n",
      "Epoch 8/100\n",
      "76/76 [==============================] - 0s 836us/step - loss: 7.4957 - mae: 2.0107 - val_loss: 9.1313 - val_mae: 2.2957\n",
      "Epoch 9/100\n",
      "76/76 [==============================] - 0s 819us/step - loss: 7.5393 - mae: 2.0060 - val_loss: 9.1598 - val_mae: 2.2166\n",
      "Epoch 10/100\n",
      "76/76 [==============================] - 0s 862us/step - loss: 7.4407 - mae: 2.0161 - val_loss: 9.0726 - val_mae: 2.2651\n",
      "Epoch 11/100\n",
      "76/76 [==============================] - 0s 794us/step - loss: 7.3987 - mae: 1.9989 - val_loss: 9.2101 - val_mae: 2.2591\n",
      "Epoch 12/100\n",
      "76/76 [==============================] - 0s 815us/step - loss: 7.4377 - mae: 1.9925 - val_loss: 9.1899 - val_mae: 2.2229\n",
      "Epoch 13/100\n",
      "76/76 [==============================] - 0s 830us/step - loss: 7.4091 - mae: 2.0041 - val_loss: 9.1593 - val_mae: 2.2730\n",
      "Epoch 14/100\n",
      "76/76 [==============================] - 0s 806us/step - loss: 7.3997 - mae: 1.9906 - val_loss: 9.1768 - val_mae: 2.2261\n",
      "Epoch 15/100\n",
      "76/76 [==============================] - 0s 830us/step - loss: 7.3683 - mae: 2.0083 - val_loss: 9.3178 - val_mae: 2.1586\n",
      "Epoch 16/100\n",
      "76/76 [==============================] - 0s 808us/step - loss: 7.4189 - mae: 1.9742 - val_loss: 9.0949 - val_mae: 2.2541\n",
      "Epoch 17/100\n",
      "76/76 [==============================] - 0s 808us/step - loss: 7.3865 - mae: 2.0153 - val_loss: 9.1223 - val_mae: 2.2637\n",
      "Epoch 18/100\n",
      "76/76 [==============================] - 0s 850us/step - loss: 7.3863 - mae: 1.9954 - val_loss: 9.2217 - val_mae: 2.3818\n",
      "Epoch 19/100\n",
      "76/76 [==============================] - 0s 819us/step - loss: 7.3650 - mae: 2.0101 - val_loss: 9.1495 - val_mae: 2.2406\n",
      "Epoch 20/100\n",
      "76/76 [==============================] - 0s 966us/step - loss: 7.3523 - mae: 2.0056 - val_loss: 9.1732 - val_mae: 2.2338\n",
      "Epoch 21/100\n",
      "76/76 [==============================] - 0s 878us/step - loss: 7.3659 - mae: 2.0009 - val_loss: 9.2021 - val_mae: 2.2203\n",
      "Epoch 22/100\n",
      "76/76 [==============================] - 0s 810us/step - loss: 7.3491 - mae: 1.9880 - val_loss: 9.4263 - val_mae: 2.4359\n",
      "Epoch 23/100\n",
      "76/76 [==============================] - 0s 820us/step - loss: 7.3984 - mae: 1.9964 - val_loss: 9.1656 - val_mae: 2.2814\n",
      "Epoch 24/100\n",
      "76/76 [==============================] - 0s 875us/step - loss: 7.3137 - mae: 2.0002 - val_loss: 9.2292 - val_mae: 2.2063\n",
      "Epoch 25/100\n",
      "76/76 [==============================] - 0s 876us/step - loss: 7.3566 - mae: 1.9935 - val_loss: 9.2929 - val_mae: 2.2255\n",
      "Epoch 26/100\n",
      "76/76 [==============================] - 0s 813us/step - loss: 7.4241 - mae: 1.9829 - val_loss: 9.2889 - val_mae: 2.1910\n",
      "Epoch 27/100\n",
      "76/76 [==============================] - 0s 826us/step - loss: 7.3244 - mae: 2.0170 - val_loss: 9.3645 - val_mae: 2.1641\n",
      "Epoch 28/100\n",
      "76/76 [==============================] - 0s 839us/step - loss: 7.2793 - mae: 1.9794 - val_loss: 9.3400 - val_mae: 2.3790\n",
      "Epoch 29/100\n",
      "76/76 [==============================] - 0s 841us/step - loss: 7.2660 - mae: 1.9964 - val_loss: 9.2572 - val_mae: 2.2634\n",
      "Epoch 30/100\n",
      "76/76 [==============================] - 0s 837us/step - loss: 7.3727 - mae: 1.9852 - val_loss: 9.2728 - val_mae: 2.3185\n",
      "Epoch 30: early stopping\n",
      "Test Loss (MSE): 8.695573806762695, Test Mean Absolute Error (MAE): 2.2535927295684814\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 5.5024 - mae: 1.3493 - val_loss: 4.9451 - val_mae: 1.2795\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 687us/step - loss: 4.9498 - mae: 1.3238 - val_loss: 4.8327 - val_mae: 1.2595\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 707us/step - loss: 4.9489 - mae: 1.3170 - val_loss: 4.8396 - val_mae: 1.3342\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 768us/step - loss: 4.9083 - mae: 1.3304 - val_loss: 4.8272 - val_mae: 1.5238\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 737us/step - loss: 4.8864 - mae: 1.3361 - val_loss: 4.8264 - val_mae: 1.2976\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 700us/step - loss: 4.8535 - mae: 1.3235 - val_loss: 4.7125 - val_mae: 1.3687\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 727us/step - loss: 4.8308 - mae: 1.3335 - val_loss: 4.7268 - val_mae: 1.2458\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 729us/step - loss: 4.8190 - mae: 1.3183 - val_loss: 4.7039 - val_mae: 1.2939\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 679us/step - loss: 4.8081 - mae: 1.3132 - val_loss: 4.7604 - val_mae: 1.2717\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 721us/step - loss: 4.8216 - mae: 1.3116 - val_loss: 4.7066 - val_mae: 1.3453\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 737us/step - loss: 4.8000 - mae: 1.3178 - val_loss: 4.7891 - val_mae: 1.2369\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 699us/step - loss: 4.8070 - mae: 1.3119 - val_loss: 4.8179 - val_mae: 1.4382\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 730us/step - loss: 4.8231 - mae: 1.3214 - val_loss: 4.7158 - val_mae: 1.3229\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 711us/step - loss: 4.7882 - mae: 1.3188 - val_loss: 4.7338 - val_mae: 1.2480\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 0s 731us/step - loss: 4.7732 - mae: 1.3120 - val_loss: 4.6819 - val_mae: 1.2715\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 0s 744us/step - loss: 4.7946 - mae: 1.3076 - val_loss: 4.7010 - val_mae: 1.3701\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 0s 853us/step - loss: 4.7749 - mae: 1.3113 - val_loss: 4.7140 - val_mae: 1.4026\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 0s 759us/step - loss: 4.7980 - mae: 1.3146 - val_loss: 4.7225 - val_mae: 1.2621\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 0s 704us/step - loss: 4.7766 - mae: 1.3054 - val_loss: 4.7029 - val_mae: 1.2772\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 0s 728us/step - loss: 4.7748 - mae: 1.3124 - val_loss: 4.6944 - val_mae: 1.3780\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 0s 693us/step - loss: 4.7865 - mae: 1.3202 - val_loss: 4.6952 - val_mae: 1.2626\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 0s 708us/step - loss: 4.7869 - mae: 1.3089 - val_loss: 4.7015 - val_mae: 1.3009\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 0s 682us/step - loss: 4.7946 - mae: 1.3089 - val_loss: 4.6825 - val_mae: 1.3052\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 0s 770us/step - loss: 4.7775 - mae: 1.3118 - val_loss: 4.7180 - val_mae: 1.3082\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 0s 725us/step - loss: 4.7758 - mae: 1.3122 - val_loss: 4.7004 - val_mae: 1.3287\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 0s 704us/step - loss: 4.7804 - mae: 1.3000 - val_loss: 4.7102 - val_mae: 1.4014\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 0s 705us/step - loss: 4.7747 - mae: 1.3246 - val_loss: 4.6891 - val_mae: 1.3193\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 0s 736us/step - loss: 4.7697 - mae: 1.3144 - val_loss: 4.7074 - val_mae: 1.3102\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 0s 697us/step - loss: 4.7725 - mae: 1.3052 - val_loss: 4.7469 - val_mae: 1.4118\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 0s 703us/step - loss: 4.7988 - mae: 1.3209 - val_loss: 4.7074 - val_mae: 1.2834\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 0s 720us/step - loss: 4.7745 - mae: 1.3133 - val_loss: 4.7031 - val_mae: 1.3324\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 0s 701us/step - loss: 4.7625 - mae: 1.3074 - val_loss: 4.7194 - val_mae: 1.3064\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 0s 691us/step - loss: 4.7823 - mae: 1.3005 - val_loss: 4.6933 - val_mae: 1.4028\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 0s 728us/step - loss: 4.7748 - mae: 1.3172 - val_loss: 4.6780 - val_mae: 1.3148\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 0s 684us/step - loss: 4.7800 - mae: 1.3147 - val_loss: 4.6991 - val_mae: 1.2879\n",
      "Epoch 36/100\n",
      "144/144 [==============================] - 0s 673us/step - loss: 4.7754 - mae: 1.3061 - val_loss: 4.6960 - val_mae: 1.3480\n",
      "Epoch 37/100\n",
      "144/144 [==============================] - 0s 817us/step - loss: 4.7638 - mae: 1.3105 - val_loss: 4.7091 - val_mae: 1.3465\n",
      "Epoch 38/100\n",
      "144/144 [==============================] - 0s 704us/step - loss: 4.7779 - mae: 1.3181 - val_loss: 4.7528 - val_mae: 1.2155\n",
      "Epoch 39/100\n",
      "144/144 [==============================] - 0s 699us/step - loss: 4.7859 - mae: 1.3047 - val_loss: 4.7139 - val_mae: 1.2719\n",
      "Epoch 40/100\n",
      "144/144 [==============================] - 0s 759us/step - loss: 4.7690 - mae: 1.3084 - val_loss: 4.6776 - val_mae: 1.3355\n",
      "Epoch 41/100\n",
      "144/144 [==============================] - 0s 746us/step - loss: 4.7719 - mae: 1.3039 - val_loss: 4.7200 - val_mae: 1.3135\n",
      "Epoch 42/100\n",
      "144/144 [==============================] - 0s 728us/step - loss: 4.7703 - mae: 1.3194 - val_loss: 4.6922 - val_mae: 1.3825\n",
      "Epoch 43/100\n",
      "144/144 [==============================] - 0s 745us/step - loss: 4.7796 - mae: 1.3152 - val_loss: 4.6940 - val_mae: 1.3005\n",
      "Epoch 44/100\n",
      "144/144 [==============================] - 0s 752us/step - loss: 4.7784 - mae: 1.3139 - val_loss: 4.6809 - val_mae: 1.2963\n",
      "Epoch 45/100\n",
      "144/144 [==============================] - 0s 699us/step - loss: 4.7625 - mae: 1.3016 - val_loss: 4.7117 - val_mae: 1.2890\n",
      "Epoch 46/100\n",
      "144/144 [==============================] - 0s 698us/step - loss: 4.7795 - mae: 1.3120 - val_loss: 4.7082 - val_mae: 1.4029\n",
      "Epoch 47/100\n",
      "144/144 [==============================] - 0s 730us/step - loss: 4.7741 - mae: 1.3153 - val_loss: 4.6770 - val_mae: 1.3265\n",
      "Epoch 48/100\n",
      "144/144 [==============================] - 0s 701us/step - loss: 4.7650 - mae: 1.3164 - val_loss: 4.7130 - val_mae: 1.2623\n",
      "Epoch 49/100\n",
      "144/144 [==============================] - 0s 742us/step - loss: 4.7707 - mae: 1.2994 - val_loss: 4.7035 - val_mae: 1.2782\n",
      "Epoch 50/100\n",
      "144/144 [==============================] - 0s 719us/step - loss: 4.7777 - mae: 1.3157 - val_loss: 4.6959 - val_mae: 1.3118\n",
      "Epoch 51/100\n",
      "144/144 [==============================] - 0s 661us/step - loss: 4.7717 - mae: 1.3187 - val_loss: 4.6922 - val_mae: 1.2658\n",
      "Epoch 52/100\n",
      "144/144 [==============================] - 0s 749us/step - loss: 4.7593 - mae: 1.2939 - val_loss: 4.6920 - val_mae: 1.3336\n",
      "Epoch 53/100\n",
      "144/144 [==============================] - 0s 752us/step - loss: 4.7717 - mae: 1.3148 - val_loss: 4.7119 - val_mae: 1.2967\n",
      "Epoch 54/100\n",
      "144/144 [==============================] - 0s 735us/step - loss: 4.7724 - mae: 1.3066 - val_loss: 4.6751 - val_mae: 1.3220\n",
      "Epoch 55/100\n",
      "144/144 [==============================] - 0s 817us/step - loss: 4.7784 - mae: 1.3147 - val_loss: 4.7124 - val_mae: 1.2783\n",
      "Epoch 56/100\n",
      "144/144 [==============================] - 0s 731us/step - loss: 4.7684 - mae: 1.3023 - val_loss: 4.7298 - val_mae: 1.4166\n",
      "Epoch 57/100\n",
      "144/144 [==============================] - 0s 725us/step - loss: 4.7736 - mae: 1.3131 - val_loss: 4.6883 - val_mae: 1.3411\n",
      "Epoch 58/100\n",
      "144/144 [==============================] - 0s 680us/step - loss: 4.7782 - mae: 1.3089 - val_loss: 4.6975 - val_mae: 1.2964\n",
      "Epoch 59/100\n",
      "144/144 [==============================] - 0s 727us/step - loss: 4.7794 - mae: 1.3077 - val_loss: 4.7222 - val_mae: 1.3528\n",
      "Epoch 60/100\n",
      "144/144 [==============================] - 0s 693us/step - loss: 4.7640 - mae: 1.3131 - val_loss: 4.6929 - val_mae: 1.3390\n",
      "Epoch 61/100\n",
      "144/144 [==============================] - 0s 681us/step - loss: 4.7807 - mae: 1.3054 - val_loss: 4.6857 - val_mae: 1.3695\n",
      "Epoch 62/100\n",
      "144/144 [==============================] - 0s 700us/step - loss: 4.7809 - mae: 1.3163 - val_loss: 4.6821 - val_mae: 1.3110\n",
      "Epoch 63/100\n",
      "144/144 [==============================] - 0s 706us/step - loss: 4.7767 - mae: 1.3088 - val_loss: 4.7149 - val_mae: 1.2874\n",
      "Epoch 64/100\n",
      "144/144 [==============================] - 0s 701us/step - loss: 4.7759 - mae: 1.3056 - val_loss: 4.6854 - val_mae: 1.3145\n",
      "Epoch 65/100\n",
      "144/144 [==============================] - 0s 702us/step - loss: 4.7808 - mae: 1.3146 - val_loss: 4.6861 - val_mae: 1.3271\n",
      "Epoch 66/100\n",
      "144/144 [==============================] - 0s 706us/step - loss: 4.7639 - mae: 1.3045 - val_loss: 4.6978 - val_mae: 1.3323\n",
      "Epoch 67/100\n",
      "144/144 [==============================] - 0s 690us/step - loss: 4.7742 - mae: 1.3155 - val_loss: 4.7093 - val_mae: 1.2768\n",
      "Epoch 68/100\n",
      "144/144 [==============================] - 0s 697us/step - loss: 4.7834 - mae: 1.3016 - val_loss: 4.6827 - val_mae: 1.3432\n",
      "Epoch 69/100\n",
      "144/144 [==============================] - 0s 766us/step - loss: 4.7680 - mae: 1.3064 - val_loss: 4.7181 - val_mae: 1.3847\n",
      "Epoch 70/100\n",
      "144/144 [==============================] - 0s 682us/step - loss: 4.7713 - mae: 1.3164 - val_loss: 4.6825 - val_mae: 1.3411\n",
      "Epoch 71/100\n",
      "144/144 [==============================] - 0s 684us/step - loss: 4.7712 - mae: 1.3071 - val_loss: 4.6746 - val_mae: 1.3183\n",
      "Epoch 72/100\n",
      "144/144 [==============================] - 0s 675us/step - loss: 4.7674 - mae: 1.2976 - val_loss: 4.7091 - val_mae: 1.4043\n",
      "Epoch 73/100\n",
      "144/144 [==============================] - 0s 730us/step - loss: 4.7683 - mae: 1.3132 - val_loss: 4.6812 - val_mae: 1.3342\n",
      "Epoch 74/100\n",
      "144/144 [==============================] - 0s 710us/step - loss: 4.7670 - mae: 1.3064 - val_loss: 4.6887 - val_mae: 1.3156\n",
      "Epoch 75/100\n",
      "144/144 [==============================] - 0s 701us/step - loss: 4.7693 - mae: 1.3034 - val_loss: 4.6837 - val_mae: 1.3276\n",
      "Epoch 76/100\n",
      "144/144 [==============================] - 0s 763us/step - loss: 4.7787 - mae: 1.3208 - val_loss: 4.6896 - val_mae: 1.3244\n",
      "Epoch 77/100\n",
      "144/144 [==============================] - 0s 669us/step - loss: 4.7820 - mae: 1.3037 - val_loss: 4.6868 - val_mae: 1.3335\n",
      "Epoch 78/100\n",
      "144/144 [==============================] - 0s 671us/step - loss: 4.7626 - mae: 1.3087 - val_loss: 4.6977 - val_mae: 1.3237\n",
      "Epoch 79/100\n",
      "144/144 [==============================] - 0s 798us/step - loss: 4.7758 - mae: 1.3116 - val_loss: 4.7043 - val_mae: 1.2909\n",
      "Epoch 80/100\n",
      "144/144 [==============================] - 0s 712us/step - loss: 4.7852 - mae: 1.3110 - val_loss: 4.6872 - val_mae: 1.3448\n",
      "Epoch 81/100\n",
      "144/144 [==============================] - 0s 711us/step - loss: 4.7648 - mae: 1.3100 - val_loss: 4.7016 - val_mae: 1.3085\n",
      "Epoch 82/100\n",
      "144/144 [==============================] - 0s 654us/step - loss: 4.7776 - mae: 1.3104 - val_loss: 4.7114 - val_mae: 1.2811\n",
      "Epoch 83/100\n",
      "144/144 [==============================] - 0s 741us/step - loss: 4.7741 - mae: 1.3071 - val_loss: 4.6979 - val_mae: 1.2889\n",
      "Epoch 84/100\n",
      "144/144 [==============================] - 0s 695us/step - loss: 4.7614 - mae: 1.3133 - val_loss: 4.7202 - val_mae: 1.2645\n",
      "Epoch 85/100\n",
      "144/144 [==============================] - 0s 698us/step - loss: 4.7540 - mae: 1.2996 - val_loss: 4.6799 - val_mae: 1.3213\n",
      "Epoch 86/100\n",
      "144/144 [==============================] - 0s 714us/step - loss: 4.7697 - mae: 1.3126 - val_loss: 4.6915 - val_mae: 1.3056\n",
      "Epoch 87/100\n",
      "144/144 [==============================] - 0s 679us/step - loss: 4.7634 - mae: 1.3059 - val_loss: 4.7213 - val_mae: 1.2625\n",
      "Epoch 88/100\n",
      "144/144 [==============================] - 0s 738us/step - loss: 4.7632 - mae: 1.3051 - val_loss: 4.6899 - val_mae: 1.3192\n",
      "Epoch 89/100\n",
      "144/144 [==============================] - 0s 729us/step - loss: 4.7597 - mae: 1.3047 - val_loss: 4.7072 - val_mae: 1.2994\n",
      "Epoch 90/100\n",
      "144/144 [==============================] - 0s 720us/step - loss: 4.7690 - mae: 1.3057 - val_loss: 4.6823 - val_mae: 1.3373\n",
      "Epoch 91/100\n",
      "144/144 [==============================] - 0s 678us/step - loss: 4.7656 - mae: 1.3075 - val_loss: 4.6914 - val_mae: 1.3025\n",
      "Epoch 91: early stopping\n",
      "Test Loss (MSE): 4.378522872924805, Test Mean Absolute Error (MAE): 1.2225948572158813\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 5.1561 - mae: 1.2529 - val_loss: 5.3297 - val_mae: 1.2298\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 867us/step - loss: 4.7855 - mae: 1.2565 - val_loss: 4.9807 - val_mae: 1.3308\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 760us/step - loss: 4.6610 - mae: 1.2711 - val_loss: 4.9800 - val_mae: 1.2918\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 753us/step - loss: 4.5931 - mae: 1.2594 - val_loss: 4.9154 - val_mae: 1.3397\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 749us/step - loss: 4.5906 - mae: 1.2488 - val_loss: 5.0344 - val_mae: 1.4122\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 797us/step - loss: 4.5754 - mae: 1.2530 - val_loss: 5.1903 - val_mae: 1.2619\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 792us/step - loss: 4.5492 - mae: 1.2425 - val_loss: 4.9416 - val_mae: 1.2764\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 757us/step - loss: 4.5382 - mae: 1.2518 - val_loss: 5.0980 - val_mae: 1.2207\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 847us/step - loss: 4.5470 - mae: 1.2445 - val_loss: 4.9179 - val_mae: 1.2818\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 728us/step - loss: 4.5585 - mae: 1.2456 - val_loss: 4.9401 - val_mae: 1.2736\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 756us/step - loss: 4.5353 - mae: 1.2484 - val_loss: 4.9154 - val_mae: 1.3610\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 752us/step - loss: 4.5317 - mae: 1.2493 - val_loss: 4.9054 - val_mae: 1.3563\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 819us/step - loss: 4.5147 - mae: 1.2456 - val_loss: 4.9483 - val_mae: 1.3581\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 750us/step - loss: 4.5408 - mae: 1.2512 - val_loss: 4.9024 - val_mae: 1.3438\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 0s 746us/step - loss: 4.5226 - mae: 1.2464 - val_loss: 4.8693 - val_mae: 1.3355\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 0s 791us/step - loss: 4.5087 - mae: 1.2399 - val_loss: 4.9056 - val_mae: 1.3124\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 0s 790us/step - loss: 4.5314 - mae: 1.2361 - val_loss: 4.9144 - val_mae: 1.2768\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 0s 736us/step - loss: 4.5261 - mae: 1.2472 - val_loss: 4.8749 - val_mae: 1.3371\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 0s 799us/step - loss: 4.4956 - mae: 1.2534 - val_loss: 4.9521 - val_mae: 1.2542\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 0s 777us/step - loss: 4.5086 - mae: 1.2299 - val_loss: 4.8848 - val_mae: 1.3107\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 0s 784us/step - loss: 4.4960 - mae: 1.2493 - val_loss: 4.9165 - val_mae: 1.2745\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 0s 754us/step - loss: 4.5032 - mae: 1.2309 - val_loss: 4.8769 - val_mae: 1.3450\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 0s 751us/step - loss: 4.5061 - mae: 1.2359 - val_loss: 5.0821 - val_mae: 1.4402\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 0s 873us/step - loss: 4.5161 - mae: 1.2482 - val_loss: 4.9038 - val_mae: 1.2850\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 0s 746us/step - loss: 4.5243 - mae: 1.2364 - val_loss: 4.8800 - val_mae: 1.3372\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 0s 752us/step - loss: 4.5021 - mae: 1.2406 - val_loss: 4.8798 - val_mae: 1.3058\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 0s 730us/step - loss: 4.5060 - mae: 1.2455 - val_loss: 4.9068 - val_mae: 1.2701\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 0s 795us/step - loss: 4.4925 - mae: 1.2329 - val_loss: 4.8729 - val_mae: 1.3186\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 0s 752us/step - loss: 4.5264 - mae: 1.2340 - val_loss: 4.9883 - val_mae: 1.4256\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 0s 744us/step - loss: 4.4861 - mae: 1.2465 - val_loss: 4.8988 - val_mae: 1.3479\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 0s 738us/step - loss: 4.4869 - mae: 1.2379 - val_loss: 5.0027 - val_mae: 1.2176\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 0s 786us/step - loss: 4.5149 - mae: 1.2340 - val_loss: 4.9027 - val_mae: 1.3166\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 0s 793us/step - loss: 4.4848 - mae: 1.2405 - val_loss: 5.0714 - val_mae: 1.4139\n",
      "Epoch 34/100\n",
      "144/144 [==============================] - 0s 838us/step - loss: 4.5079 - mae: 1.2352 - val_loss: 4.8772 - val_mae: 1.3436\n",
      "Epoch 35/100\n",
      "144/144 [==============================] - 0s 810us/step - loss: 4.4892 - mae: 1.2342 - val_loss: 4.9022 - val_mae: 1.3771\n",
      "Epoch 35: early stopping\n",
      "Test Loss (MSE): 4.633941650390625, Test Mean Absolute Error (MAE): 1.3931233882904053\n",
      "Epoch 1/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 5.7609 - mae: 1.3406 - val_loss: 4.4755 - val_mae: 1.4162\n",
      "Epoch 2/100\n",
      "148/148 [==============================] - 0s 716us/step - loss: 5.2706 - mae: 1.3388 - val_loss: 4.2541 - val_mae: 1.2646\n",
      "Epoch 3/100\n",
      "148/148 [==============================] - 0s 744us/step - loss: 5.1671 - mae: 1.3418 - val_loss: 4.2609 - val_mae: 1.3081\n",
      "Epoch 4/100\n",
      "148/148 [==============================] - 0s 744us/step - loss: 5.1590 - mae: 1.3427 - val_loss: 4.1891 - val_mae: 1.2425\n",
      "Epoch 5/100\n",
      "148/148 [==============================] - 0s 755us/step - loss: 5.1017 - mae: 1.3512 - val_loss: 4.1877 - val_mae: 1.2266\n",
      "Epoch 6/100\n",
      "148/148 [==============================] - 0s 846us/step - loss: 5.0894 - mae: 1.3506 - val_loss: 4.1868 - val_mae: 1.2423\n",
      "Epoch 7/100\n",
      "148/148 [==============================] - 0s 719us/step - loss: 5.0640 - mae: 1.3392 - val_loss: 4.2339 - val_mae: 1.3519\n",
      "Epoch 8/100\n",
      "148/148 [==============================] - 0s 763us/step - loss: 5.0885 - mae: 1.3394 - val_loss: 4.1667 - val_mae: 1.3015\n",
      "Epoch 9/100\n",
      "148/148 [==============================] - 0s 761us/step - loss: 5.0648 - mae: 1.3368 - val_loss: 4.1907 - val_mae: 1.2506\n",
      "Epoch 10/100\n",
      "148/148 [==============================] - 0s 711us/step - loss: 5.0617 - mae: 1.3503 - val_loss: 4.1623 - val_mae: 1.2500\n",
      "Epoch 11/100\n",
      "148/148 [==============================] - 0s 724us/step - loss: 5.0178 - mae: 1.3323 - val_loss: 4.1522 - val_mae: 1.2662\n",
      "Epoch 12/100\n",
      "148/148 [==============================] - 0s 771us/step - loss: 5.0187 - mae: 1.3297 - val_loss: 4.1956 - val_mae: 1.3117\n",
      "Epoch 13/100\n",
      "148/148 [==============================] - 0s 733us/step - loss: 5.0580 - mae: 1.3448 - val_loss: 4.1306 - val_mae: 1.2494\n",
      "Epoch 14/100\n",
      "148/148 [==============================] - 0s 756us/step - loss: 5.0015 - mae: 1.3251 - val_loss: 4.3195 - val_mae: 1.3671\n",
      "Epoch 15/100\n",
      "148/148 [==============================] - 0s 714us/step - loss: 5.0145 - mae: 1.3338 - val_loss: 4.1585 - val_mae: 1.2329\n",
      "Epoch 16/100\n",
      "148/148 [==============================] - 0s 828us/step - loss: 5.0037 - mae: 1.3238 - val_loss: 4.1865 - val_mae: 1.2262\n",
      "Epoch 17/100\n",
      "148/148 [==============================] - 0s 808us/step - loss: 5.0257 - mae: 1.3327 - val_loss: 4.1369 - val_mae: 1.2128\n",
      "Epoch 18/100\n",
      "148/148 [==============================] - 0s 800us/step - loss: 5.0396 - mae: 1.3249 - val_loss: 4.1937 - val_mae: 1.2884\n",
      "Epoch 19/100\n",
      "148/148 [==============================] - 0s 909us/step - loss: 5.0207 - mae: 1.3336 - val_loss: 4.1635 - val_mae: 1.2268\n",
      "Epoch 20/100\n",
      "148/148 [==============================] - 0s 770us/step - loss: 5.0181 - mae: 1.3176 - val_loss: 4.2579 - val_mae: 1.3530\n",
      "Epoch 21/100\n",
      "148/148 [==============================] - 0s 738us/step - loss: 5.0635 - mae: 1.3303 - val_loss: 4.3039 - val_mae: 1.3613\n",
      "Epoch 22/100\n",
      "148/148 [==============================] - 0s 762us/step - loss: 5.0276 - mae: 1.3297 - val_loss: 4.3003 - val_mae: 1.3593\n",
      "Epoch 23/100\n",
      "148/148 [==============================] - 0s 708us/step - loss: 4.9943 - mae: 1.3270 - val_loss: 4.2146 - val_mae: 1.3321\n",
      "Epoch 24/100\n",
      "148/148 [==============================] - 0s 731us/step - loss: 5.0155 - mae: 1.3268 - val_loss: 4.1649 - val_mae: 1.2364\n",
      "Epoch 25/100\n",
      "148/148 [==============================] - 0s 709us/step - loss: 5.0059 - mae: 1.3280 - val_loss: 4.1760 - val_mae: 1.2614\n",
      "Epoch 26/100\n",
      "148/148 [==============================] - 0s 775us/step - loss: 5.0052 - mae: 1.3310 - val_loss: 4.1803 - val_mae: 1.2183\n",
      "Epoch 27/100\n",
      "148/148 [==============================] - 0s 729us/step - loss: 4.9974 - mae: 1.3199 - val_loss: 4.1900 - val_mae: 1.2477\n",
      "Epoch 28/100\n",
      "148/148 [==============================] - 0s 745us/step - loss: 4.9844 - mae: 1.3180 - val_loss: 4.1966 - val_mae: 1.2606\n",
      "Epoch 29/100\n",
      "148/148 [==============================] - 0s 743us/step - loss: 4.9836 - mae: 1.3216 - val_loss: 4.1998 - val_mae: 1.1711\n",
      "Epoch 30/100\n",
      "148/148 [==============================] - 0s 733us/step - loss: 5.0395 - mae: 1.3242 - val_loss: 4.1618 - val_mae: 1.2334\n",
      "Epoch 31/100\n",
      "148/148 [==============================] - 0s 717us/step - loss: 4.9949 - mae: 1.3162 - val_loss: 4.1853 - val_mae: 1.2631\n",
      "Epoch 32/100\n",
      "148/148 [==============================] - 0s 767us/step - loss: 4.9851 - mae: 1.3264 - val_loss: 4.1802 - val_mae: 1.2179\n",
      "Epoch 33/100\n",
      "148/148 [==============================] - 0s 761us/step - loss: 4.9875 - mae: 1.3144 - val_loss: 4.2047 - val_mae: 1.2811\n",
      "Epoch 33: early stopping\n",
      "Test Loss (MSE): 3.9064316749572754, Test Mean Absolute Error (MAE): 1.2139644622802734\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 5.3942 - mae: 1.2816 - val_loss: 5.0622 - val_mae: 1.4942\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 729us/step - loss: 4.9586 - mae: 1.2898 - val_loss: 4.9985 - val_mae: 1.4671\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 803us/step - loss: 4.8279 - mae: 1.2892 - val_loss: 4.8668 - val_mae: 1.5281\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 720us/step - loss: 4.8471 - mae: 1.3122 - val_loss: 4.7522 - val_mae: 1.2993\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 744us/step - loss: 4.7639 - mae: 1.2868 - val_loss: 4.7513 - val_mae: 1.3521\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 758us/step - loss: 4.7524 - mae: 1.2975 - val_loss: 4.9003 - val_mae: 1.5227\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 753us/step - loss: 4.7104 - mae: 1.2965 - val_loss: 4.6835 - val_mae: 1.3078\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 798us/step - loss: 4.7477 - mae: 1.2938 - val_loss: 4.6873 - val_mae: 1.3225\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 4.7247 - mae: 1.2923 - val_loss: 4.7290 - val_mae: 1.3690\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 862us/step - loss: 4.6832 - mae: 1.2732 - val_loss: 4.6960 - val_mae: 1.3409\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 820us/step - loss: 4.6747 - mae: 1.2794 - val_loss: 4.7481 - val_mae: 1.3543\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 798us/step - loss: 4.6545 - mae: 1.2635 - val_loss: 4.7624 - val_mae: 1.4070\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 781us/step - loss: 4.6952 - mae: 1.2660 - val_loss: 4.6718 - val_mae: 1.3613\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 755us/step - loss: 4.6577 - mae: 1.2814 - val_loss: 4.6988 - val_mae: 1.2571\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 0s 765us/step - loss: 4.6493 - mae: 1.2649 - val_loss: 4.6778 - val_mae: 1.3221\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 0s 771us/step - loss: 4.6435 - mae: 1.2721 - val_loss: 4.6996 - val_mae: 1.2188\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 0s 748us/step - loss: 4.6585 - mae: 1.2626 - val_loss: 4.6802 - val_mae: 1.2944\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 0s 739us/step - loss: 4.6486 - mae: 1.2635 - val_loss: 4.7200 - val_mae: 1.2858\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 0s 734us/step - loss: 4.6470 - mae: 1.2670 - val_loss: 4.7200 - val_mae: 1.3622\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 0s 733us/step - loss: 4.6549 - mae: 1.2719 - val_loss: 4.7588 - val_mae: 1.1868\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 0s 739us/step - loss: 4.6298 - mae: 1.2536 - val_loss: 4.7137 - val_mae: 1.4302\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 0s 768us/step - loss: 4.6343 - mae: 1.2654 - val_loss: 4.7367 - val_mae: 1.3214\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 0s 736us/step - loss: 4.6380 - mae: 1.2703 - val_loss: 4.6909 - val_mae: 1.3592\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 0s 742us/step - loss: 4.6347 - mae: 1.2678 - val_loss: 4.7155 - val_mae: 1.2574\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 0s 773us/step - loss: 4.6382 - mae: 1.2663 - val_loss: 4.7027 - val_mae: 1.2532\n",
      "Epoch 26/100\n",
      "144/144 [==============================] - 0s 750us/step - loss: 4.6269 - mae: 1.2576 - val_loss: 4.7296 - val_mae: 1.3495\n",
      "Epoch 27/100\n",
      "144/144 [==============================] - 0s 744us/step - loss: 4.6273 - mae: 1.2694 - val_loss: 4.7093 - val_mae: 1.2407\n",
      "Epoch 28/100\n",
      "144/144 [==============================] - 0s 833us/step - loss: 4.6178 - mae: 1.2643 - val_loss: 4.6774 - val_mae: 1.3418\n",
      "Epoch 29/100\n",
      "144/144 [==============================] - 0s 729us/step - loss: 4.6291 - mae: 1.2617 - val_loss: 4.7400 - val_mae: 1.3497\n",
      "Epoch 30/100\n",
      "144/144 [==============================] - 0s 744us/step - loss: 4.6180 - mae: 1.2626 - val_loss: 4.6818 - val_mae: 1.3552\n",
      "Epoch 31/100\n",
      "144/144 [==============================] - 0s 782us/step - loss: 4.6022 - mae: 1.2681 - val_loss: 4.7030 - val_mae: 1.3040\n",
      "Epoch 32/100\n",
      "144/144 [==============================] - 0s 748us/step - loss: 4.6052 - mae: 1.2595 - val_loss: 4.7019 - val_mae: 1.2669\n",
      "Epoch 33/100\n",
      "144/144 [==============================] - 0s 729us/step - loss: 4.6328 - mae: 1.2584 - val_loss: 4.7280 - val_mae: 1.2520\n",
      "Epoch 33: early stopping\n",
      "Test Loss (MSE): 4.684822082519531, Test Mean Absolute Error (MAE): 1.1428276300430298\n",
      "Epoch 1/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 9.5492 - mae: 2.2235 - val_loss: 8.6260 - val_mae: 2.2246\n",
      "Epoch 2/100\n",
      "76/76 [==============================] - 0s 803us/step - loss: 8.7875 - mae: 2.2175 - val_loss: 8.5955 - val_mae: 2.1767\n",
      "Epoch 3/100\n",
      "76/76 [==============================] - 0s 752us/step - loss: 8.6570 - mae: 2.2095 - val_loss: 8.5165 - val_mae: 2.1005\n",
      "Epoch 4/100\n",
      "76/76 [==============================] - 0s 747us/step - loss: 8.5410 - mae: 2.2003 - val_loss: 8.5724 - val_mae: 2.4277\n",
      "Epoch 5/100\n",
      "76/76 [==============================] - 0s 813us/step - loss: 8.4671 - mae: 2.1882 - val_loss: 8.5478 - val_mae: 2.4370\n",
      "Epoch 6/100\n",
      "76/76 [==============================] - 0s 779us/step - loss: 8.5171 - mae: 2.1974 - val_loss: 8.2710 - val_mae: 2.1663\n",
      "Epoch 7/100\n",
      "76/76 [==============================] - 0s 729us/step - loss: 8.5054 - mae: 2.1976 - val_loss: 8.2068 - val_mae: 2.1575\n",
      "Epoch 8/100\n",
      "76/76 [==============================] - 0s 718us/step - loss: 8.3419 - mae: 2.1921 - val_loss: 8.1975 - val_mae: 2.2054\n",
      "Epoch 9/100\n",
      "76/76 [==============================] - 0s 737us/step - loss: 8.3756 - mae: 2.1950 - val_loss: 8.2242 - val_mae: 2.1031\n",
      "Epoch 10/100\n",
      "76/76 [==============================] - 0s 767us/step - loss: 8.3635 - mae: 2.1965 - val_loss: 8.2164 - val_mae: 2.0690\n",
      "Epoch 11/100\n",
      "76/76 [==============================] - 0s 789us/step - loss: 8.3747 - mae: 2.1921 - val_loss: 8.2682 - val_mae: 2.0589\n",
      "Epoch 12/100\n",
      "76/76 [==============================] - 0s 799us/step - loss: 8.3173 - mae: 2.1878 - val_loss: 8.1846 - val_mae: 2.2510\n",
      "Epoch 13/100\n",
      "76/76 [==============================] - 0s 786us/step - loss: 8.3377 - mae: 2.1783 - val_loss: 8.1597 - val_mae: 2.1647\n",
      "Epoch 14/100\n",
      "76/76 [==============================] - 0s 748us/step - loss: 8.2906 - mae: 2.1986 - val_loss: 8.1603 - val_mae: 2.1044\n",
      "Epoch 15/100\n",
      "76/76 [==============================] - 0s 728us/step - loss: 8.3351 - mae: 2.1771 - val_loss: 8.1977 - val_mae: 2.2591\n",
      "Epoch 16/100\n",
      "76/76 [==============================] - 0s 743us/step - loss: 8.3010 - mae: 2.1911 - val_loss: 8.1770 - val_mae: 2.2472\n",
      "Epoch 17/100\n",
      "76/76 [==============================] - 0s 743us/step - loss: 8.3092 - mae: 2.1876 - val_loss: 8.1781 - val_mae: 2.1948\n",
      "Epoch 18/100\n",
      "76/76 [==============================] - 0s 787us/step - loss: 8.3371 - mae: 2.1976 - val_loss: 8.2023 - val_mae: 2.1588\n",
      "Epoch 19/100\n",
      "76/76 [==============================] - 0s 774us/step - loss: 8.3211 - mae: 2.1708 - val_loss: 8.1019 - val_mae: 2.1839\n",
      "Epoch 20/100\n",
      "76/76 [==============================] - 0s 730us/step - loss: 8.2992 - mae: 2.1869 - val_loss: 8.1130 - val_mae: 2.1603\n",
      "Epoch 21/100\n",
      "76/76 [==============================] - 0s 742us/step - loss: 8.2829 - mae: 2.1874 - val_loss: 8.1938 - val_mae: 2.2532\n",
      "Epoch 22/100\n",
      "76/76 [==============================] - 0s 772us/step - loss: 8.3060 - mae: 2.1813 - val_loss: 8.0859 - val_mae: 2.1580\n",
      "Epoch 23/100\n",
      "76/76 [==============================] - 0s 744us/step - loss: 8.2754 - mae: 2.1803 - val_loss: 8.2636 - val_mae: 2.3466\n",
      "Epoch 24/100\n",
      "76/76 [==============================] - 0s 800us/step - loss: 8.2902 - mae: 2.2062 - val_loss: 8.1658 - val_mae: 2.1036\n",
      "Epoch 25/100\n",
      "76/76 [==============================] - 0s 953us/step - loss: 8.3152 - mae: 2.1657 - val_loss: 8.2951 - val_mae: 2.3194\n",
      "Epoch 26/100\n",
      "76/76 [==============================] - 0s 739us/step - loss: 8.2945 - mae: 2.1967 - val_loss: 8.1445 - val_mae: 2.1267\n",
      "Epoch 27/100\n",
      "76/76 [==============================] - 0s 748us/step - loss: 8.3178 - mae: 2.1714 - val_loss: 8.1008 - val_mae: 2.1632\n",
      "Epoch 28/100\n",
      "76/76 [==============================] - 0s 744us/step - loss: 8.2958 - mae: 2.1873 - val_loss: 8.1689 - val_mae: 2.1649\n",
      "Epoch 29/100\n",
      "76/76 [==============================] - 0s 748us/step - loss: 8.2853 - mae: 2.2043 - val_loss: 8.1662 - val_mae: 2.1192\n",
      "Epoch 30/100\n",
      "76/76 [==============================] - 0s 822us/step - loss: 8.2808 - mae: 2.1579 - val_loss: 8.1826 - val_mae: 2.2483\n",
      "Epoch 31/100\n",
      "76/76 [==============================] - 0s 726us/step - loss: 8.2417 - mae: 2.1964 - val_loss: 8.1989 - val_mae: 2.0954\n",
      "Epoch 32/100\n",
      "76/76 [==============================] - 0s 679us/step - loss: 8.3365 - mae: 2.1818 - val_loss: 8.1354 - val_mae: 2.2179\n",
      "Epoch 33/100\n",
      "76/76 [==============================] - 0s 708us/step - loss: 8.3647 - mae: 2.1714 - val_loss: 8.1289 - val_mae: 2.1227\n",
      "Epoch 34/100\n",
      "76/76 [==============================] - 0s 775us/step - loss: 8.3204 - mae: 2.1779 - val_loss: 8.1044 - val_mae: 2.1963\n",
      "Epoch 35/100\n",
      "76/76 [==============================] - 0s 802us/step - loss: 8.2705 - mae: 2.1918 - val_loss: 8.1242 - val_mae: 2.2129\n",
      "Epoch 36/100\n",
      "76/76 [==============================] - 0s 774us/step - loss: 8.2738 - mae: 2.1769 - val_loss: 8.1258 - val_mae: 2.1798\n",
      "Epoch 37/100\n",
      "76/76 [==============================] - 0s 760us/step - loss: 8.2701 - mae: 2.1902 - val_loss: 8.1389 - val_mae: 2.1687\n",
      "Epoch 38/100\n",
      "76/76 [==============================] - 0s 828us/step - loss: 8.3047 - mae: 2.1872 - val_loss: 8.3017 - val_mae: 2.0723\n",
      "Epoch 39/100\n",
      "76/76 [==============================] - 0s 821us/step - loss: 8.2823 - mae: 2.1862 - val_loss: 8.1859 - val_mae: 2.1039\n",
      "Epoch 40/100\n",
      "76/76 [==============================] - 0s 762us/step - loss: 8.2897 - mae: 2.1825 - val_loss: 8.1236 - val_mae: 2.2275\n",
      "Epoch 41/100\n",
      "76/76 [==============================] - 0s 704us/step - loss: 8.2594 - mae: 2.1820 - val_loss: 8.2610 - val_mae: 2.0825\n",
      "Epoch 42/100\n",
      "76/76 [==============================] - 0s 743us/step - loss: 8.2835 - mae: 2.1607 - val_loss: 8.1673 - val_mae: 2.2864\n",
      "Epoch 42: early stopping\n",
      "Test Loss (MSE): 7.126760005950928, Test Mean Absolute Error (MAE): 2.089733362197876\n",
      "Epoch 1/100\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 8.9902 - mae: 2.1121 - val_loss: 9.2214 - val_mae: 2.0786\n",
      "Epoch 2/100\n",
      "76/76 [==============================] - 0s 881us/step - loss: 8.2006 - mae: 2.0746 - val_loss: 9.5475 - val_mae: 1.9482\n",
      "Epoch 3/100\n",
      "76/76 [==============================] - 0s 792us/step - loss: 8.2431 - mae: 2.0565 - val_loss: 8.8761 - val_mae: 2.0534\n",
      "Epoch 4/100\n",
      "76/76 [==============================] - 0s 780us/step - loss: 8.0210 - mae: 2.0802 - val_loss: 8.8192 - val_mae: 2.0472\n",
      "Epoch 5/100\n",
      "76/76 [==============================] - 0s 780us/step - loss: 7.9880 - mae: 2.0857 - val_loss: 8.6627 - val_mae: 2.3173\n",
      "Epoch 6/100\n",
      "76/76 [==============================] - 0s 793us/step - loss: 7.9815 - mae: 2.0901 - val_loss: 8.7944 - val_mae: 2.2976\n",
      "Epoch 7/100\n",
      "76/76 [==============================] - 0s 827us/step - loss: 7.9603 - mae: 2.0964 - val_loss: 8.5563 - val_mae: 2.0932\n",
      "Epoch 8/100\n",
      "76/76 [==============================] - 0s 793us/step - loss: 7.8534 - mae: 2.0696 - val_loss: 8.5545 - val_mae: 2.1383\n",
      "Epoch 9/100\n",
      "76/76 [==============================] - 0s 791us/step - loss: 7.8608 - mae: 2.0827 - val_loss: 8.6122 - val_mae: 2.1178\n",
      "Epoch 10/100\n",
      "76/76 [==============================] - 0s 868us/step - loss: 7.8309 - mae: 2.0598 - val_loss: 8.6070 - val_mae: 2.2093\n",
      "Epoch 11/100\n",
      "76/76 [==============================] - 0s 777us/step - loss: 7.8312 - mae: 2.0793 - val_loss: 8.5249 - val_mae: 2.1388\n",
      "Epoch 12/100\n",
      "76/76 [==============================] - 0s 840us/step - loss: 7.8396 - mae: 2.0720 - val_loss: 8.5836 - val_mae: 2.1803\n",
      "Epoch 13/100\n",
      "76/76 [==============================] - 0s 798us/step - loss: 7.8237 - mae: 2.0661 - val_loss: 8.5293 - val_mae: 2.1484\n",
      "Epoch 14/100\n",
      "76/76 [==============================] - 0s 783us/step - loss: 7.7084 - mae: 2.0581 - val_loss: 8.6077 - val_mae: 2.1937\n",
      "Epoch 15/100\n",
      "76/76 [==============================] - 0s 807us/step - loss: 7.7320 - mae: 2.0866 - val_loss: 8.5859 - val_mae: 2.2368\n",
      "Epoch 16/100\n",
      "76/76 [==============================] - 0s 787us/step - loss: 7.7157 - mae: 2.0651 - val_loss: 8.6381 - val_mae: 2.0727\n",
      "Epoch 17/100\n",
      "76/76 [==============================] - 0s 788us/step - loss: 7.7486 - mae: 2.0683 - val_loss: 8.4955 - val_mae: 2.1335\n",
      "Epoch 18/100\n",
      "76/76 [==============================] - 0s 889us/step - loss: 7.7082 - mae: 2.0385 - val_loss: 8.5922 - val_mae: 2.2277\n",
      "Epoch 19/100\n",
      "76/76 [==============================] - 0s 792us/step - loss: 7.7387 - mae: 2.0642 - val_loss: 8.5597 - val_mae: 2.2054\n",
      "Epoch 20/100\n",
      "76/76 [==============================] - 0s 778us/step - loss: 7.7555 - mae: 2.0644 - val_loss: 8.5962 - val_mae: 2.2370\n",
      "Epoch 21/100\n",
      "76/76 [==============================] - 0s 786us/step - loss: 7.6964 - mae: 2.0788 - val_loss: 8.5480 - val_mae: 2.1314\n",
      "Epoch 22/100\n",
      "76/76 [==============================] - 0s 749us/step - loss: 7.8332 - mae: 2.0538 - val_loss: 8.5300 - val_mae: 2.1575\n",
      "Epoch 23/100\n",
      "76/76 [==============================] - 0s 842us/step - loss: 7.7200 - mae: 2.0713 - val_loss: 8.4876 - val_mae: 2.1932\n",
      "Epoch 24/100\n",
      "76/76 [==============================] - 0s 826us/step - loss: 7.6974 - mae: 2.0747 - val_loss: 8.5531 - val_mae: 2.1999\n",
      "Epoch 25/100\n",
      "76/76 [==============================] - 0s 811us/step - loss: 7.7401 - mae: 2.0696 - val_loss: 8.9044 - val_mae: 2.0117\n",
      "Epoch 26/100\n",
      "76/76 [==============================] - 0s 784us/step - loss: 7.7384 - mae: 2.0576 - val_loss: 8.5305 - val_mae: 2.2457\n",
      "Epoch 27/100\n",
      "76/76 [==============================] - 0s 806us/step - loss: 7.6869 - mae: 2.0710 - val_loss: 8.5026 - val_mae: 2.1753\n",
      "Epoch 28/100\n",
      "76/76 [==============================] - 0s 967us/step - loss: 7.6881 - mae: 2.0683 - val_loss: 8.5029 - val_mae: 2.1089\n",
      "Epoch 29/100\n",
      "76/76 [==============================] - 0s 764us/step - loss: 7.7281 - mae: 2.0588 - val_loss: 8.5443 - val_mae: 2.2125\n",
      "Epoch 30/100\n",
      "76/76 [==============================] - 0s 729us/step - loss: 7.7056 - mae: 2.0546 - val_loss: 8.5926 - val_mae: 2.2099\n",
      "Epoch 31/100\n",
      "76/76 [==============================] - 0s 790us/step - loss: 7.6814 - mae: 2.0600 - val_loss: 8.6169 - val_mae: 2.2547\n",
      "Epoch 32/100\n",
      "76/76 [==============================] - 0s 830us/step - loss: 7.7176 - mae: 2.0712 - val_loss: 8.6254 - val_mae: 2.2340\n",
      "Epoch 33/100\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 7.6481 - mae: 2.0580 - val_loss: 8.4975 - val_mae: 2.1764\n",
      "Epoch 34/100\n",
      "76/76 [==============================] - 0s 866us/step - loss: 7.6608 - mae: 2.0603 - val_loss: 8.6400 - val_mae: 2.2779\n",
      "Epoch 35/100\n",
      "76/76 [==============================] - 0s 843us/step - loss: 7.6826 - mae: 2.0576 - val_loss: 8.6225 - val_mae: 2.2292\n",
      "Epoch 36/100\n",
      "76/76 [==============================] - 0s 898us/step - loss: 7.6635 - mae: 2.0505 - val_loss: 8.4958 - val_mae: 2.1750\n",
      "Epoch 37/100\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 7.6547 - mae: 2.0593 - val_loss: 8.5437 - val_mae: 2.1545\n",
      "Epoch 38/100\n",
      "76/76 [==============================] - 0s 852us/step - loss: 7.6684 - mae: 2.0571 - val_loss: 8.5237 - val_mae: 2.2199\n",
      "Epoch 39/100\n",
      "76/76 [==============================] - 0s 822us/step - loss: 7.6694 - mae: 2.0598 - val_loss: 8.5435 - val_mae: 2.2329\n",
      "Epoch 40/100\n",
      "76/76 [==============================] - 0s 779us/step - loss: 7.6499 - mae: 2.0559 - val_loss: 8.5174 - val_mae: 2.2027\n",
      "Epoch 41/100\n",
      "76/76 [==============================] - 0s 844us/step - loss: 7.6620 - mae: 2.0639 - val_loss: 8.5712 - val_mae: 2.0890\n",
      "Epoch 42/100\n",
      "76/76 [==============================] - 0s 744us/step - loss: 7.6911 - mae: 2.0503 - val_loss: 8.6273 - val_mae: 2.2888\n",
      "Epoch 43/100\n",
      "76/76 [==============================] - 0s 782us/step - loss: 7.6210 - mae: 2.0540 - val_loss: 8.5728 - val_mae: 2.1316\n",
      "Epoch 43: early stopping\n",
      "Test Loss (MSE): 8.30772590637207, Test Mean Absolute Error (MAE): 2.1620116233825684\n",
      "Epoch 1/100\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 9.3470 - mae: 2.1813 - val_loss: 8.2647 - val_mae: 2.0451\n",
      "Epoch 2/100\n",
      "76/76 [==============================] - 0s 821us/step - loss: 8.6383 - mae: 2.1789 - val_loss: 7.8396 - val_mae: 2.0283\n",
      "Epoch 3/100\n",
      "76/76 [==============================] - 0s 809us/step - loss: 8.5007 - mae: 2.1619 - val_loss: 7.7528 - val_mae: 1.9930\n",
      "Epoch 4/100\n",
      "76/76 [==============================] - 0s 795us/step - loss: 8.4014 - mae: 2.1610 - val_loss: 7.9750 - val_mae: 2.0115\n",
      "Epoch 5/100\n",
      "76/76 [==============================] - 0s 799us/step - loss: 8.4292 - mae: 2.1712 - val_loss: 7.7830 - val_mae: 2.1086\n",
      "Epoch 6/100\n",
      "76/76 [==============================] - 0s 826us/step - loss: 8.4897 - mae: 2.1819 - val_loss: 7.7524 - val_mae: 2.0768\n",
      "Epoch 7/100\n",
      "76/76 [==============================] - 0s 807us/step - loss: 8.2863 - mae: 2.1752 - val_loss: 8.0064 - val_mae: 2.0851\n",
      "Epoch 8/100\n",
      "76/76 [==============================] - 0s 793us/step - loss: 8.2542 - mae: 2.1732 - val_loss: 7.7450 - val_mae: 2.0733\n",
      "Epoch 9/100\n",
      "76/76 [==============================] - 0s 792us/step - loss: 8.2818 - mae: 2.1694 - val_loss: 7.7090 - val_mae: 1.9457\n",
      "Epoch 10/100\n",
      "76/76 [==============================] - 0s 820us/step - loss: 8.2566 - mae: 2.1514 - val_loss: 8.0923 - val_mae: 2.1697\n",
      "Epoch 11/100\n",
      "76/76 [==============================] - 0s 839us/step - loss: 8.1680 - mae: 2.1563 - val_loss: 7.7633 - val_mae: 2.1191\n",
      "Epoch 12/100\n",
      "76/76 [==============================] - 0s 772us/step - loss: 8.1848 - mae: 2.1718 - val_loss: 7.7044 - val_mae: 2.0535\n",
      "Epoch 13/100\n",
      "76/76 [==============================] - 0s 775us/step - loss: 8.1624 - mae: 2.1656 - val_loss: 7.7222 - val_mae: 1.9967\n",
      "Epoch 14/100\n",
      "76/76 [==============================] - 0s 832us/step - loss: 8.2389 - mae: 2.1574 - val_loss: 7.9318 - val_mae: 2.1018\n",
      "Epoch 15/100\n",
      "76/76 [==============================] - 0s 922us/step - loss: 8.1683 - mae: 2.1585 - val_loss: 7.7248 - val_mae: 2.0678\n",
      "Epoch 16/100\n",
      "76/76 [==============================] - 0s 809us/step - loss: 8.1336 - mae: 2.1740 - val_loss: 7.7255 - val_mae: 1.9268\n",
      "Epoch 17/100\n",
      "76/76 [==============================] - 0s 786us/step - loss: 8.1528 - mae: 2.1534 - val_loss: 7.7351 - val_mae: 2.0427\n",
      "Epoch 18/100\n",
      "76/76 [==============================] - 0s 804us/step - loss: 8.1372 - mae: 2.1675 - val_loss: 7.9652 - val_mae: 2.1666\n",
      "Epoch 19/100\n",
      "76/76 [==============================] - 0s 798us/step - loss: 8.1281 - mae: 2.1594 - val_loss: 7.7672 - val_mae: 2.1064\n",
      "Epoch 20/100\n",
      "76/76 [==============================] - 0s 797us/step - loss: 8.1244 - mae: 2.1480 - val_loss: 7.7384 - val_mae: 2.0436\n",
      "Epoch 21/100\n",
      "76/76 [==============================] - 0s 894us/step - loss: 8.0739 - mae: 2.1480 - val_loss: 7.8405 - val_mae: 2.1004\n",
      "Epoch 22/100\n",
      "76/76 [==============================] - 0s 904us/step - loss: 8.1246 - mae: 2.1574 - val_loss: 7.8831 - val_mae: 2.0475\n",
      "Epoch 23/100\n",
      "76/76 [==============================] - 0s 778us/step - loss: 8.0797 - mae: 2.1456 - val_loss: 7.7356 - val_mae: 2.0446\n",
      "Epoch 24/100\n",
      "76/76 [==============================] - 0s 772us/step - loss: 8.0807 - mae: 2.1551 - val_loss: 7.6847 - val_mae: 2.0038\n",
      "Epoch 25/100\n",
      "76/76 [==============================] - 0s 796us/step - loss: 8.1047 - mae: 2.1467 - val_loss: 7.6114 - val_mae: 1.9576\n",
      "Epoch 26/100\n",
      "76/76 [==============================] - 0s 857us/step - loss: 8.0880 - mae: 2.1406 - val_loss: 7.9061 - val_mae: 1.9715\n",
      "Epoch 27/100\n",
      "76/76 [==============================] - 0s 800us/step - loss: 8.1312 - mae: 2.1383 - val_loss: 7.8125 - val_mae: 1.8666\n",
      "Epoch 28/100\n",
      "76/76 [==============================] - 0s 819us/step - loss: 8.2036 - mae: 2.1436 - val_loss: 7.7873 - val_mae: 2.0970\n",
      "Epoch 29/100\n",
      "76/76 [==============================] - 0s 803us/step - loss: 8.0944 - mae: 2.1500 - val_loss: 7.8501 - val_mae: 2.0507\n",
      "Epoch 30/100\n",
      "76/76 [==============================] - 0s 766us/step - loss: 8.1244 - mae: 2.1352 - val_loss: 7.7322 - val_mae: 1.9959\n",
      "Epoch 31/100\n",
      "76/76 [==============================] - 0s 786us/step - loss: 8.0453 - mae: 2.1416 - val_loss: 7.7503 - val_mae: 2.0723\n",
      "Epoch 32/100\n",
      "76/76 [==============================] - 0s 793us/step - loss: 8.0386 - mae: 2.1515 - val_loss: 7.7739 - val_mae: 1.9989\n",
      "Epoch 33/100\n",
      "76/76 [==============================] - 0s 803us/step - loss: 8.0794 - mae: 2.1337 - val_loss: 7.8662 - val_mae: 2.1038\n",
      "Epoch 34/100\n",
      "76/76 [==============================] - 0s 895us/step - loss: 8.0042 - mae: 2.1381 - val_loss: 8.0715 - val_mae: 2.1499\n",
      "Epoch 35/100\n",
      "76/76 [==============================] - 0s 848us/step - loss: 8.0569 - mae: 2.1396 - val_loss: 7.8605 - val_mae: 2.0434\n",
      "Epoch 36/100\n",
      "76/76 [==============================] - 0s 804us/step - loss: 8.0031 - mae: 2.1225 - val_loss: 8.0575 - val_mae: 2.1495\n",
      "Epoch 37/100\n",
      "76/76 [==============================] - 0s 775us/step - loss: 8.0443 - mae: 2.1334 - val_loss: 7.9326 - val_mae: 2.1152\n",
      "Epoch 38/100\n",
      "76/76 [==============================] - 0s 835us/step - loss: 8.0536 - mae: 2.1354 - val_loss: 7.8093 - val_mae: 1.9458\n",
      "Epoch 39/100\n",
      "76/76 [==============================] - 0s 894us/step - loss: 8.0744 - mae: 2.1422 - val_loss: 7.7625 - val_mae: 2.0517\n",
      "Epoch 40/100\n",
      "76/76 [==============================] - 0s 855us/step - loss: 8.0357 - mae: 2.1293 - val_loss: 7.8072 - val_mae: 2.0731\n",
      "Epoch 41/100\n",
      "76/76 [==============================] - 0s 893us/step - loss: 8.0134 - mae: 2.1414 - val_loss: 7.7533 - val_mae: 1.9885\n",
      "Epoch 42/100\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 8.0001 - mae: 2.1236 - val_loss: 7.8017 - val_mae: 2.0252\n",
      "Epoch 43/100\n",
      "76/76 [==============================] - 0s 932us/step - loss: 8.0629 - mae: 2.1268 - val_loss: 7.6961 - val_mae: 1.9660\n",
      "Epoch 44/100\n",
      "76/76 [==============================] - 0s 829us/step - loss: 8.0081 - mae: 2.1338 - val_loss: 7.7802 - val_mae: 1.9718\n",
      "Epoch 45/100\n",
      "76/76 [==============================] - 0s 761us/step - loss: 7.9779 - mae: 2.1363 - val_loss: 7.9782 - val_mae: 2.0898\n",
      "Epoch 45: early stopping\n",
      "Test Loss (MSE): 7.877382278442383, Test Mean Absolute Error (MAE): 2.180027723312378\n",
      "Epoch 1/100\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 9.2117 - mae: 2.1394 - val_loss: 8.9406 - val_mae: 2.2250\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 910us/step - loss: 8.3136 - mae: 2.0821 - val_loss: 8.7298 - val_mae: 2.0621\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 886us/step - loss: 8.1991 - mae: 2.1064 - val_loss: 8.6196 - val_mae: 2.1246\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 820us/step - loss: 8.1801 - mae: 2.0894 - val_loss: 8.5122 - val_mae: 2.0572\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 780us/step - loss: 7.9530 - mae: 2.0864 - val_loss: 8.5481 - val_mae: 2.1621\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 807us/step - loss: 7.9329 - mae: 2.0809 - val_loss: 8.7266 - val_mae: 2.2537\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 845us/step - loss: 7.9591 - mae: 2.0750 - val_loss: 8.7400 - val_mae: 2.3304\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 847us/step - loss: 7.8650 - mae: 2.0953 - val_loss: 8.5400 - val_mae: 2.0814\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 822us/step - loss: 7.8337 - mae: 2.0523 - val_loss: 8.4875 - val_mae: 2.0697\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 814us/step - loss: 7.8739 - mae: 2.0929 - val_loss: 8.5973 - val_mae: 2.0244\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 805us/step - loss: 7.8597 - mae: 2.0574 - val_loss: 8.5656 - val_mae: 2.0563\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 858us/step - loss: 7.8497 - mae: 2.0741 - val_loss: 8.4447 - val_mae: 2.1065\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 830us/step - loss: 7.7622 - mae: 2.0903 - val_loss: 8.4250 - val_mae: 2.0446\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 802us/step - loss: 7.7542 - mae: 2.0584 - val_loss: 8.4376 - val_mae: 2.1845\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 903us/step - loss: 7.7822 - mae: 2.0729 - val_loss: 8.5504 - val_mae: 2.0690\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 799us/step - loss: 7.7435 - mae: 2.0827 - val_loss: 8.5313 - val_mae: 2.1896\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 895us/step - loss: 7.7354 - mae: 2.0865 - val_loss: 8.3935 - val_mae: 2.1031\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 865us/step - loss: 7.7392 - mae: 2.0504 - val_loss: 8.3625 - val_mae: 2.1304\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 820us/step - loss: 7.7991 - mae: 2.0760 - val_loss: 8.4469 - val_mae: 2.1740\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 796us/step - loss: 7.7057 - mae: 2.0617 - val_loss: 8.5952 - val_mae: 2.1630\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 809us/step - loss: 7.6686 - mae: 2.0656 - val_loss: 8.4406 - val_mae: 2.1564\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 895us/step - loss: 7.7249 - mae: 2.0698 - val_loss: 8.4639 - val_mae: 2.1426\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 831us/step - loss: 7.6908 - mae: 2.0666 - val_loss: 8.4542 - val_mae: 2.1574\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 839us/step - loss: 7.6718 - mae: 2.0533 - val_loss: 8.6313 - val_mae: 2.0655\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 828us/step - loss: 7.6637 - mae: 2.0720 - val_loss: 8.4448 - val_mae: 2.1121\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 857us/step - loss: 7.6756 - mae: 2.0618 - val_loss: 8.5938 - val_mae: 2.0196\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 918us/step - loss: 7.6496 - mae: 2.0517 - val_loss: 8.5827 - val_mae: 2.1497\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 821us/step - loss: 7.6442 - mae: 2.0457 - val_loss: 8.5585 - val_mae: 2.1912\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 807us/step - loss: 7.6449 - mae: 2.0490 - val_loss: 8.7194 - val_mae: 2.1691\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 811us/step - loss: 7.6347 - mae: 2.0488 - val_loss: 8.4622 - val_mae: 2.1290\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 777us/step - loss: 7.5821 - mae: 2.0572 - val_loss: 8.8537 - val_mae: 2.1389\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 927us/step - loss: 7.6147 - mae: 2.0340 - val_loss: 8.5408 - val_mae: 2.1802\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 879us/step - loss: 7.6366 - mae: 2.0519 - val_loss: 8.6572 - val_mae: 2.1625\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 864us/step - loss: 7.5445 - mae: 2.0246 - val_loss: 8.6422 - val_mae: 2.1511\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 822us/step - loss: 7.5238 - mae: 2.0385 - val_loss: 8.5790 - val_mae: 2.0538\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 873us/step - loss: 7.5735 - mae: 2.0299 - val_loss: 8.6217 - val_mae: 2.1762\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 886us/step - loss: 7.5079 - mae: 2.0322 - val_loss: 8.8251 - val_mae: 2.1221\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 871us/step - loss: 7.5612 - mae: 2.0271 - val_loss: 8.6842 - val_mae: 2.1316\n",
      "Epoch 38: early stopping\n",
      "Test Loss (MSE): 8.318923950195312, Test Mean Absolute Error (MAE): 2.0721850395202637\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 5.4189 - mae: 1.3333 - val_loss: 4.6467 - val_mae: 1.1405\n",
      "Epoch 2/100\n",
      "134/134 [==============================] - 0s 746us/step - loss: 4.9408 - mae: 1.3248 - val_loss: 4.4811 - val_mae: 1.2276\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 0s 802us/step - loss: 4.8853 - mae: 1.3260 - val_loss: 4.4598 - val_mae: 1.2922\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 0s 773us/step - loss: 4.8786 - mae: 1.3348 - val_loss: 4.4398 - val_mae: 1.3356\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 0s 801us/step - loss: 4.8554 - mae: 1.3337 - val_loss: 4.3958 - val_mae: 1.2145\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 0s 841us/step - loss: 4.8470 - mae: 1.3358 - val_loss: 4.4128 - val_mae: 1.1950\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 0s 767us/step - loss: 4.8105 - mae: 1.3239 - val_loss: 4.4524 - val_mae: 1.3627\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 0s 785us/step - loss: 4.7763 - mae: 1.3200 - val_loss: 4.5270 - val_mae: 1.4830\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 0s 747us/step - loss: 4.7697 - mae: 1.3125 - val_loss: 4.3824 - val_mae: 1.2097\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 0s 773us/step - loss: 4.8464 - mae: 1.3335 - val_loss: 4.4553 - val_mae: 1.1638\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 0s 833us/step - loss: 4.7675 - mae: 1.3088 - val_loss: 4.3408 - val_mae: 1.2285\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 0s 743us/step - loss: 4.7372 - mae: 1.2981 - val_loss: 4.9212 - val_mae: 1.6671\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 0s 764us/step - loss: 4.7529 - mae: 1.3121 - val_loss: 4.4104 - val_mae: 1.1787\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 0s 868us/step - loss: 4.7467 - mae: 1.3088 - val_loss: 4.3717 - val_mae: 1.1598\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 0s 839us/step - loss: 4.7337 - mae: 1.3036 - val_loss: 4.3075 - val_mae: 1.2226\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 0s 857us/step - loss: 4.7166 - mae: 1.3016 - val_loss: 4.3447 - val_mae: 1.2705\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 0s 989us/step - loss: 4.7260 - mae: 1.3123 - val_loss: 4.3357 - val_mae: 1.1863\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 0s 823us/step - loss: 4.7202 - mae: 1.2924 - val_loss: 4.3716 - val_mae: 1.3503\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 0s 775us/step - loss: 4.7146 - mae: 1.2963 - val_loss: 4.3153 - val_mae: 1.1890\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 0s 797us/step - loss: 4.7157 - mae: 1.2967 - val_loss: 4.3075 - val_mae: 1.2562\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 0s 769us/step - loss: 4.7177 - mae: 1.2996 - val_loss: 4.3150 - val_mae: 1.2213\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 0s 773us/step - loss: 4.6949 - mae: 1.2966 - val_loss: 4.3414 - val_mae: 1.2411\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 0s 894us/step - loss: 4.7038 - mae: 1.2857 - val_loss: 4.3414 - val_mae: 1.2838\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 0s 751us/step - loss: 4.6780 - mae: 1.2997 - val_loss: 4.3420 - val_mae: 1.3224\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 0s 775us/step - loss: 4.7033 - mae: 1.2937 - val_loss: 4.3657 - val_mae: 1.1377\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 0s 801us/step - loss: 4.7024 - mae: 1.2913 - val_loss: 4.3459 - val_mae: 1.3064\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 0s 744us/step - loss: 4.6876 - mae: 1.2891 - val_loss: 4.3148 - val_mae: 1.2775\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 0s 761us/step - loss: 4.7175 - mae: 1.2952 - val_loss: 4.2957 - val_mae: 1.2047\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 0s 861us/step - loss: 4.6817 - mae: 1.2970 - val_loss: 4.2889 - val_mae: 1.2175\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 0s 801us/step - loss: 4.6839 - mae: 1.2857 - val_loss: 4.2874 - val_mae: 1.2362\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 0s 758us/step - loss: 4.6766 - mae: 1.2910 - val_loss: 4.3271 - val_mae: 1.1487\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 0s 802us/step - loss: 4.6810 - mae: 1.2875 - val_loss: 4.3061 - val_mae: 1.1759\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 0s 738us/step - loss: 4.6811 - mae: 1.2879 - val_loss: 4.3155 - val_mae: 1.1917\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 0s 757us/step - loss: 4.6936 - mae: 1.2943 - val_loss: 4.3081 - val_mae: 1.2235\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 0s 809us/step - loss: 4.6799 - mae: 1.2773 - val_loss: 4.3264 - val_mae: 1.2974\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 0s 772us/step - loss: 4.6866 - mae: 1.2996 - val_loss: 4.3969 - val_mae: 1.1225\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 0s 799us/step - loss: 4.6854 - mae: 1.2923 - val_loss: 4.3157 - val_mae: 1.1743\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 0s 930us/step - loss: 4.6810 - mae: 1.2749 - val_loss: 4.3272 - val_mae: 1.3092\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 0s 760us/step - loss: 4.6614 - mae: 1.2859 - val_loss: 4.3266 - val_mae: 1.3217\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 0s 805us/step - loss: 4.6950 - mae: 1.2983 - val_loss: 4.3413 - val_mae: 1.1598\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 0s 945us/step - loss: 4.6674 - mae: 1.2856 - val_loss: 4.3113 - val_mae: 1.1742\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 0s 969us/step - loss: 4.6665 - mae: 1.2741 - val_loss: 4.2961 - val_mae: 1.1959\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 0s 869us/step - loss: 4.6867 - mae: 1.2889 - val_loss: 4.3067 - val_mae: 1.2018\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 0s 859us/step - loss: 4.6617 - mae: 1.2956 - val_loss: 4.3159 - val_mae: 1.1803\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 0s 818us/step - loss: 4.6615 - mae: 1.2811 - val_loss: 4.2950 - val_mae: 1.2301\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 0s 756us/step - loss: 4.6559 - mae: 1.2803 - val_loss: 4.3082 - val_mae: 1.2613\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 0s 765us/step - loss: 4.6521 - mae: 1.2831 - val_loss: 4.3233 - val_mae: 1.2705\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 0s 873us/step - loss: 4.6646 - mae: 1.2844 - val_loss: 4.3005 - val_mae: 1.2090\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 0s 775us/step - loss: 4.6683 - mae: 1.2866 - val_loss: 4.3415 - val_mae: 1.1728\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 0s 768us/step - loss: 4.6577 - mae: 1.2887 - val_loss: 4.3019 - val_mae: 1.2051\n",
      "Epoch 50: early stopping\n",
      "Test Loss (MSE): 4.950355529785156, Test Mean Absolute Error (MAE): 1.2912821769714355\n",
      "Epoch 1/100\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 5.4928 - mae: 1.2934 - val_loss: 4.8669 - val_mae: 1.2403\n",
      "Epoch 2/100\n",
      "133/133 [==============================] - 0s 818us/step - loss: 4.8745 - mae: 1.2910 - val_loss: 4.6931 - val_mae: 1.1542\n",
      "Epoch 3/100\n",
      "133/133 [==============================] - 0s 777us/step - loss: 4.6438 - mae: 1.2851 - val_loss: 4.6555 - val_mae: 1.2102\n",
      "Epoch 4/100\n",
      "133/133 [==============================] - 0s 773us/step - loss: 4.5715 - mae: 1.2771 - val_loss: 4.7134 - val_mae: 1.1327\n",
      "Epoch 5/100\n",
      "133/133 [==============================] - 0s 793us/step - loss: 4.6158 - mae: 1.2661 - val_loss: 4.7084 - val_mae: 1.1173\n",
      "Epoch 6/100\n",
      "133/133 [==============================] - 0s 755us/step - loss: 4.5803 - mae: 1.2827 - val_loss: 4.6542 - val_mae: 1.1579\n",
      "Epoch 7/100\n",
      "133/133 [==============================] - 0s 750us/step - loss: 4.5643 - mae: 1.2674 - val_loss: 4.6132 - val_mae: 1.1523\n",
      "Epoch 8/100\n",
      "133/133 [==============================] - 0s 816us/step - loss: 4.5212 - mae: 1.2727 - val_loss: 4.6058 - val_mae: 1.1981\n",
      "Epoch 9/100\n",
      "133/133 [==============================] - 0s 817us/step - loss: 4.5177 - mae: 1.2680 - val_loss: 4.6163 - val_mae: 1.1912\n",
      "Epoch 10/100\n",
      "133/133 [==============================] - 0s 802us/step - loss: 4.5033 - mae: 1.2610 - val_loss: 4.5880 - val_mae: 1.1951\n",
      "Epoch 11/100\n",
      "133/133 [==============================] - 0s 815us/step - loss: 4.5029 - mae: 1.2762 - val_loss: 4.6070 - val_mae: 1.1622\n",
      "Epoch 12/100\n",
      "133/133 [==============================] - 0s 838us/step - loss: 4.5309 - mae: 1.2577 - val_loss: 4.7340 - val_mae: 1.2409\n",
      "Epoch 13/100\n",
      "133/133 [==============================] - 0s 834us/step - loss: 4.5320 - mae: 1.2701 - val_loss: 4.6060 - val_mae: 1.1823\n",
      "Epoch 14/100\n",
      "133/133 [==============================] - 0s 940us/step - loss: 4.5180 - mae: 1.2745 - val_loss: 4.6129 - val_mae: 1.2458\n",
      "Epoch 15/100\n",
      "133/133 [==============================] - 0s 857us/step - loss: 4.4754 - mae: 1.2627 - val_loss: 4.7206 - val_mae: 1.2675\n",
      "Epoch 16/100\n",
      "133/133 [==============================] - 0s 819us/step - loss: 4.4815 - mae: 1.2672 - val_loss: 4.6306 - val_mae: 1.1485\n",
      "Epoch 17/100\n",
      "133/133 [==============================] - 0s 798us/step - loss: 4.5398 - mae: 1.2791 - val_loss: 4.6057 - val_mae: 1.1773\n",
      "Epoch 18/100\n",
      "133/133 [==============================] - 0s 784us/step - loss: 4.5164 - mae: 1.2665 - val_loss: 4.7048 - val_mae: 1.1124\n",
      "Epoch 19/100\n",
      "133/133 [==============================] - 0s 744us/step - loss: 4.5169 - mae: 1.2706 - val_loss: 4.5960 - val_mae: 1.2170\n",
      "Epoch 20/100\n",
      "133/133 [==============================] - 0s 832us/step - loss: 4.4782 - mae: 1.2622 - val_loss: 4.7109 - val_mae: 1.2176\n",
      "Epoch 21/100\n",
      "133/133 [==============================] - 0s 753us/step - loss: 4.4939 - mae: 1.2764 - val_loss: 4.6153 - val_mae: 1.1674\n",
      "Epoch 22/100\n",
      "133/133 [==============================] - 0s 732us/step - loss: 4.4747 - mae: 1.2566 - val_loss: 4.7236 - val_mae: 1.3830\n",
      "Epoch 23/100\n",
      "133/133 [==============================] - 0s 803us/step - loss: 4.5136 - mae: 1.2873 - val_loss: 4.6298 - val_mae: 1.1540\n",
      "Epoch 24/100\n",
      "133/133 [==============================] - 0s 767us/step - loss: 4.4758 - mae: 1.2647 - val_loss: 4.7196 - val_mae: 1.1152\n",
      "Epoch 25/100\n",
      "133/133 [==============================] - 0s 756us/step - loss: 4.4738 - mae: 1.2590 - val_loss: 4.6066 - val_mae: 1.1460\n",
      "Epoch 26/100\n",
      "133/133 [==============================] - 0s 762us/step - loss: 4.4840 - mae: 1.2649 - val_loss: 4.6580 - val_mae: 1.2155\n",
      "Epoch 27/100\n",
      "133/133 [==============================] - 0s 798us/step - loss: 4.4450 - mae: 1.2647 - val_loss: 4.6255 - val_mae: 1.1521\n",
      "Epoch 28/100\n",
      "133/133 [==============================] - 0s 768us/step - loss: 4.4631 - mae: 1.2587 - val_loss: 4.6082 - val_mae: 1.2169\n",
      "Epoch 29/100\n",
      "133/133 [==============================] - 0s 790us/step - loss: 4.4799 - mae: 1.2689 - val_loss: 4.6373 - val_mae: 1.2185\n",
      "Epoch 30/100\n",
      "133/133 [==============================] - 0s 767us/step - loss: 4.4782 - mae: 1.2746 - val_loss: 4.6221 - val_mae: 1.2316\n",
      "Epoch 30: early stopping\n",
      "Test Loss (MSE): 4.798921585083008, Test Mean Absolute Error (MAE): 1.3359708786010742\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 5.4733 - mae: 1.2309 - val_loss: 5.3719 - val_mae: 1.2438\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 834us/step - loss: 4.7035 - mae: 1.2123 - val_loss: 5.0456 - val_mae: 1.2781\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 813us/step - loss: 4.5687 - mae: 1.2129 - val_loss: 5.0571 - val_mae: 1.2936\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 882us/step - loss: 4.4894 - mae: 1.2164 - val_loss: 4.7876 - val_mae: 1.3993\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 859us/step - loss: 4.4966 - mae: 1.2263 - val_loss: 4.8499 - val_mae: 1.3719\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 876us/step - loss: 4.4636 - mae: 1.2054 - val_loss: 4.8193 - val_mae: 1.4868\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 4.4219 - mae: 1.2442 - val_loss: 4.9415 - val_mae: 1.3127\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 878us/step - loss: 4.4738 - mae: 1.2322 - val_loss: 4.9043 - val_mae: 1.2843\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 791us/step - loss: 4.4200 - mae: 1.1961 - val_loss: 4.8142 - val_mae: 1.3386\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 816us/step - loss: 4.4240 - mae: 1.2016 - val_loss: 4.7521 - val_mae: 1.3996\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 798us/step - loss: 4.3849 - mae: 1.1947 - val_loss: 4.7548 - val_mae: 1.3856\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 781us/step - loss: 4.4094 - mae: 1.1951 - val_loss: 4.8485 - val_mae: 1.4658\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 823us/step - loss: 4.3790 - mae: 1.2026 - val_loss: 4.7624 - val_mae: 1.3272\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 792us/step - loss: 4.3759 - mae: 1.1912 - val_loss: 4.7725 - val_mae: 1.3897\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 774us/step - loss: 4.3939 - mae: 1.2017 - val_loss: 4.7578 - val_mae: 1.3615\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 806us/step - loss: 4.3653 - mae: 1.1906 - val_loss: 4.7795 - val_mae: 1.3566\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 772us/step - loss: 4.3766 - mae: 1.2045 - val_loss: 4.8882 - val_mae: 1.3918\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 795us/step - loss: 4.3630 - mae: 1.1999 - val_loss: 4.9159 - val_mae: 1.3109\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 800us/step - loss: 4.3737 - mae: 1.1982 - val_loss: 4.8513 - val_mae: 1.4660\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 793us/step - loss: 4.3708 - mae: 1.1956 - val_loss: 4.8021 - val_mae: 1.3912\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 791us/step - loss: 4.3504 - mae: 1.1859 - val_loss: 4.7856 - val_mae: 1.4141\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 817us/step - loss: 4.3531 - mae: 1.1848 - val_loss: 4.8763 - val_mae: 1.3653\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 805us/step - loss: 4.3323 - mae: 1.1895 - val_loss: 4.9528 - val_mae: 1.4947\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 806us/step - loss: 4.3554 - mae: 1.1853 - val_loss: 4.8216 - val_mae: 1.3399\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 818us/step - loss: 4.3425 - mae: 1.1895 - val_loss: 4.8508 - val_mae: 1.3693\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 791us/step - loss: 4.3360 - mae: 1.1935 - val_loss: 4.9761 - val_mae: 1.2833\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 787us/step - loss: 4.3311 - mae: 1.1830 - val_loss: 5.0751 - val_mae: 1.2496\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 826us/step - loss: 4.3496 - mae: 1.1768 - val_loss: 4.8308 - val_mae: 1.3256\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 776us/step - loss: 4.3164 - mae: 1.1855 - val_loss: 4.8710 - val_mae: 1.3664\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 782us/step - loss: 4.3267 - mae: 1.1956 - val_loss: 4.9829 - val_mae: 1.2494\n",
      "Epoch 30: early stopping\n",
      "Test Loss (MSE): 5.114834308624268, Test Mean Absolute Error (MAE): 1.1995141506195068\n",
      "Epoch 1/100\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 5.9490 - mae: 1.3273 - val_loss: 5.2568 - val_mae: 1.4197\n",
      "Epoch 2/100\n",
      "133/133 [==============================] - 0s 816us/step - loss: 5.0234 - mae: 1.2921 - val_loss: 5.0129 - val_mae: 1.2366\n",
      "Epoch 3/100\n",
      "133/133 [==============================] - 0s 872us/step - loss: 4.8904 - mae: 1.3015 - val_loss: 4.8614 - val_mae: 1.2796\n",
      "Epoch 4/100\n",
      "133/133 [==============================] - 0s 819us/step - loss: 4.8173 - mae: 1.2957 - val_loss: 5.0826 - val_mae: 1.1972\n",
      "Epoch 5/100\n",
      "133/133 [==============================] - 0s 855us/step - loss: 4.7943 - mae: 1.2857 - val_loss: 4.8124 - val_mae: 1.2707\n",
      "Epoch 6/100\n",
      "133/133 [==============================] - 0s 885us/step - loss: 4.7794 - mae: 1.2892 - val_loss: 4.9440 - val_mae: 1.2503\n",
      "Epoch 7/100\n",
      "133/133 [==============================] - 0s 849us/step - loss: 4.7523 - mae: 1.2900 - val_loss: 4.8472 - val_mae: 1.2553\n",
      "Epoch 8/100\n",
      "133/133 [==============================] - 0s 864us/step - loss: 4.6977 - mae: 1.2839 - val_loss: 4.7703 - val_mae: 1.2652\n",
      "Epoch 9/100\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 4.7280 - mae: 1.2812 - val_loss: 4.8161 - val_mae: 1.3242\n",
      "Epoch 10/100\n",
      "133/133 [==============================] - 0s 900us/step - loss: 4.6866 - mae: 1.2821 - val_loss: 4.8098 - val_mae: 1.2484\n",
      "Epoch 11/100\n",
      "133/133 [==============================] - 0s 922us/step - loss: 4.6699 - mae: 1.2661 - val_loss: 4.7976 - val_mae: 1.3235\n",
      "Epoch 12/100\n",
      "133/133 [==============================] - 0s 879us/step - loss: 4.7024 - mae: 1.2784 - val_loss: 4.7892 - val_mae: 1.2373\n",
      "Epoch 13/100\n",
      "133/133 [==============================] - 0s 829us/step - loss: 4.6865 - mae: 1.2727 - val_loss: 4.8559 - val_mae: 1.3852\n",
      "Epoch 14/100\n",
      "133/133 [==============================] - 0s 819us/step - loss: 4.6667 - mae: 1.2543 - val_loss: 4.8276 - val_mae: 1.3143\n",
      "Epoch 15/100\n",
      "133/133 [==============================] - 0s 862us/step - loss: 4.6961 - mae: 1.2852 - val_loss: 4.8074 - val_mae: 1.3241\n",
      "Epoch 16/100\n",
      "133/133 [==============================] - 0s 810us/step - loss: 4.6627 - mae: 1.2686 - val_loss: 4.8205 - val_mae: 1.2094\n",
      "Epoch 17/100\n",
      "133/133 [==============================] - 0s 802us/step - loss: 4.6465 - mae: 1.2624 - val_loss: 4.7845 - val_mae: 1.2759\n",
      "Epoch 18/100\n",
      "133/133 [==============================] - 0s 862us/step - loss: 4.6485 - mae: 1.2545 - val_loss: 4.8046 - val_mae: 1.3270\n",
      "Epoch 19/100\n",
      "133/133 [==============================] - 0s 812us/step - loss: 4.6386 - mae: 1.2698 - val_loss: 4.8191 - val_mae: 1.2642\n",
      "Epoch 20/100\n",
      "133/133 [==============================] - 0s 812us/step - loss: 4.6283 - mae: 1.2560 - val_loss: 4.8117 - val_mae: 1.2928\n",
      "Epoch 21/100\n",
      "133/133 [==============================] - 0s 851us/step - loss: 4.6346 - mae: 1.2557 - val_loss: 4.7870 - val_mae: 1.3161\n",
      "Epoch 22/100\n",
      "133/133 [==============================] - 0s 822us/step - loss: 4.6351 - mae: 1.2657 - val_loss: 4.8339 - val_mae: 1.2742\n",
      "Epoch 23/100\n",
      "133/133 [==============================] - 0s 835us/step - loss: 4.5839 - mae: 1.2473 - val_loss: 5.0632 - val_mae: 1.3397\n",
      "Epoch 24/100\n",
      "133/133 [==============================] - 0s 878us/step - loss: 4.6838 - mae: 1.2672 - val_loss: 4.7970 - val_mae: 1.2486\n",
      "Epoch 25/100\n",
      "133/133 [==============================] - 0s 818us/step - loss: 4.6191 - mae: 1.2614 - val_loss: 4.8272 - val_mae: 1.3488\n",
      "Epoch 26/100\n",
      "133/133 [==============================] - 0s 817us/step - loss: 4.6696 - mae: 1.2560 - val_loss: 4.8190 - val_mae: 1.2723\n",
      "Epoch 27/100\n",
      "133/133 [==============================] - 0s 868us/step - loss: 4.6480 - mae: 1.2671 - val_loss: 4.8101 - val_mae: 1.2778\n",
      "Epoch 28/100\n",
      "133/133 [==============================] - 0s 796us/step - loss: 4.6006 - mae: 1.2607 - val_loss: 4.9297 - val_mae: 1.2370\n",
      "Epoch 28: early stopping\n",
      "Test Loss (MSE): 3.9960525035858154, Test Mean Absolute Error (MAE): 1.2037092447280884\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 9.0655 - mae: 2.1356 - val_loss: 9.6829 - val_mae: 2.0936\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 0s 840us/step - loss: 8.0079 - mae: 2.0987 - val_loss: 9.2439 - val_mae: 2.2041\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 0s 874us/step - loss: 7.8425 - mae: 2.0957 - val_loss: 9.8949 - val_mae: 2.0059\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 0s 821us/step - loss: 7.9311 - mae: 2.0891 - val_loss: 9.5767 - val_mae: 2.5501\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 0s 853us/step - loss: 8.0235 - mae: 2.1489 - val_loss: 9.3242 - val_mae: 2.0718\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 0s 857us/step - loss: 7.7662 - mae: 2.0852 - val_loss: 9.4619 - val_mae: 2.0328\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 0s 827us/step - loss: 7.7713 - mae: 2.0810 - val_loss: 9.1684 - val_mae: 2.1071\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 0s 833us/step - loss: 7.7068 - mae: 2.0840 - val_loss: 9.0951 - val_mae: 2.1400\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 0s 784us/step - loss: 7.8165 - mae: 2.0746 - val_loss: 9.0890 - val_mae: 2.1618\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 0s 920us/step - loss: 7.6964 - mae: 2.0858 - val_loss: 9.1054 - val_mae: 2.1941\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 0s 834us/step - loss: 7.7026 - mae: 2.0945 - val_loss: 9.0130 - val_mae: 2.2506\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 0s 832us/step - loss: 7.8293 - mae: 2.0879 - val_loss: 8.9978 - val_mae: 2.2589\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 0s 807us/step - loss: 7.6547 - mae: 2.1017 - val_loss: 9.0592 - val_mae: 2.1328\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 0s 829us/step - loss: 7.7060 - mae: 2.0678 - val_loss: 9.0052 - val_mae: 2.1589\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 0s 863us/step - loss: 7.7117 - mae: 2.0819 - val_loss: 8.9744 - val_mae: 2.2128\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 0s 852us/step - loss: 7.6334 - mae: 2.1005 - val_loss: 8.9583 - val_mae: 2.2146\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 0s 825us/step - loss: 7.7180 - mae: 2.0846 - val_loss: 9.0809 - val_mae: 2.3255\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 0s 809us/step - loss: 7.6764 - mae: 2.0951 - val_loss: 8.9617 - val_mae: 2.2292\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 0s 845us/step - loss: 7.6043 - mae: 2.0789 - val_loss: 8.9880 - val_mae: 2.2915\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 0s 830us/step - loss: 7.6707 - mae: 2.0838 - val_loss: 8.9679 - val_mae: 2.2835\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 0s 800us/step - loss: 7.8454 - mae: 2.1156 - val_loss: 8.9849 - val_mae: 2.2613\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 0s 856us/step - loss: 7.6280 - mae: 2.0831 - val_loss: 9.0350 - val_mae: 2.3528\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 0s 902us/step - loss: 7.7191 - mae: 2.1455 - val_loss: 8.9613 - val_mae: 2.2100\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 0s 836us/step - loss: 7.6252 - mae: 2.1042 - val_loss: 9.0600 - val_mae: 2.1175\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 0s 843us/step - loss: 7.6491 - mae: 2.1014 - val_loss: 9.0116 - val_mae: 2.1343\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 0s 830us/step - loss: 7.6088 - mae: 2.0872 - val_loss: 8.9587 - val_mae: 2.2142\n",
      "Epoch 27/100\n",
      "69/69 [==============================] - 0s 785us/step - loss: 7.6234 - mae: 2.0906 - val_loss: 9.0781 - val_mae: 2.1151\n",
      "Epoch 28/100\n",
      "69/69 [==============================] - 0s 826us/step - loss: 7.6129 - mae: 2.0910 - val_loss: 8.9382 - val_mae: 2.2056\n",
      "Epoch 29/100\n",
      "69/69 [==============================] - 0s 954us/step - loss: 7.6083 - mae: 2.1041 - val_loss: 8.9859 - val_mae: 2.1825\n",
      "Epoch 30/100\n",
      "69/69 [==============================] - 0s 882us/step - loss: 7.6711 - mae: 2.1218 - val_loss: 9.1117 - val_mae: 2.3688\n",
      "Epoch 31/100\n",
      "69/69 [==============================] - 0s 876us/step - loss: 7.7802 - mae: 2.1534 - val_loss: 9.1349 - val_mae: 2.1195\n",
      "Epoch 32/100\n",
      "69/69 [==============================] - 0s 855us/step - loss: 7.5999 - mae: 2.0835 - val_loss: 9.0231 - val_mae: 2.1593\n",
      "Epoch 33/100\n",
      "69/69 [==============================] - 0s 820us/step - loss: 7.6026 - mae: 2.0997 - val_loss: 8.9872 - val_mae: 2.1710\n",
      "Epoch 34/100\n",
      "69/69 [==============================] - 0s 902us/step - loss: 7.6692 - mae: 2.1270 - val_loss: 8.9875 - val_mae: 2.2253\n",
      "Epoch 35/100\n",
      "69/69 [==============================] - 0s 867us/step - loss: 7.5725 - mae: 2.0973 - val_loss: 8.9770 - val_mae: 2.2150\n",
      "Epoch 36/100\n",
      "69/69 [==============================] - 0s 893us/step - loss: 7.5707 - mae: 2.0849 - val_loss: 8.9448 - val_mae: 2.2311\n",
      "Epoch 37/100\n",
      "69/69 [==============================] - 0s 852us/step - loss: 7.6083 - mae: 2.1121 - val_loss: 8.9617 - val_mae: 2.1996\n",
      "Epoch 38/100\n",
      "69/69 [==============================] - 0s 878us/step - loss: 7.5860 - mae: 2.0837 - val_loss: 8.9296 - val_mae: 2.2029\n",
      "Epoch 39/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 7.6058 - mae: 2.1096 - val_loss: 8.9663 - val_mae: 2.3011\n",
      "Epoch 40/100\n",
      "69/69 [==============================] - 0s 916us/step - loss: 7.6245 - mae: 2.0840 - val_loss: 8.9207 - val_mae: 2.2615\n",
      "Epoch 41/100\n",
      "69/69 [==============================] - 0s 920us/step - loss: 7.6010 - mae: 2.0967 - val_loss: 8.9610 - val_mae: 2.1681\n",
      "Epoch 42/100\n",
      "69/69 [==============================] - 0s 926us/step - loss: 7.6137 - mae: 2.0797 - val_loss: 8.9718 - val_mae: 2.1744\n",
      "Epoch 43/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 7.5932 - mae: 2.0719 - val_loss: 8.9608 - val_mae: 2.2327\n",
      "Epoch 44/100\n",
      "69/69 [==============================] - 0s 875us/step - loss: 7.6313 - mae: 2.0969 - val_loss: 8.9712 - val_mae: 2.2385\n",
      "Epoch 45/100\n",
      "69/69 [==============================] - 0s 854us/step - loss: 7.6140 - mae: 2.1003 - val_loss: 8.9562 - val_mae: 2.1847\n",
      "Epoch 46/100\n",
      "69/69 [==============================] - 0s 845us/step - loss: 7.5640 - mae: 2.0915 - val_loss: 8.9786 - val_mae: 2.1790\n",
      "Epoch 47/100\n",
      "69/69 [==============================] - 0s 865us/step - loss: 7.5670 - mae: 2.0838 - val_loss: 8.9426 - val_mae: 2.1985\n",
      "Epoch 48/100\n",
      "69/69 [==============================] - 0s 866us/step - loss: 7.5768 - mae: 2.1000 - val_loss: 9.0493 - val_mae: 2.1332\n",
      "Epoch 49/100\n",
      "69/69 [==============================] - 0s 818us/step - loss: 7.5785 - mae: 2.0948 - val_loss: 8.9893 - val_mae: 2.1591\n",
      "Epoch 50/100\n",
      "69/69 [==============================] - 0s 808us/step - loss: 7.6501 - mae: 2.1191 - val_loss: 8.9734 - val_mae: 2.1675\n",
      "Epoch 51/100\n",
      "69/69 [==============================] - 0s 807us/step - loss: 7.6039 - mae: 2.1206 - val_loss: 8.9591 - val_mae: 2.1688\n",
      "Epoch 52/100\n",
      "69/69 [==============================] - 0s 820us/step - loss: 7.5773 - mae: 2.0930 - val_loss: 8.9488 - val_mae: 2.2660\n",
      "Epoch 53/100\n",
      "69/69 [==============================] - 0s 927us/step - loss: 7.6083 - mae: 2.1247 - val_loss: 8.9387 - val_mae: 2.2271\n",
      "Epoch 54/100\n",
      "69/69 [==============================] - 0s 818us/step - loss: 7.5613 - mae: 2.0954 - val_loss: 9.0210 - val_mae: 2.1410\n",
      "Epoch 55/100\n",
      "69/69 [==============================] - 0s 805us/step - loss: 7.6868 - mae: 2.0776 - val_loss: 8.9319 - val_mae: 2.2039\n",
      "Epoch 56/100\n",
      "69/69 [==============================] - 0s 824us/step - loss: 7.5631 - mae: 2.0762 - val_loss: 8.9321 - val_mae: 2.2039\n",
      "Epoch 57/100\n",
      "69/69 [==============================] - 0s 831us/step - loss: 7.5527 - mae: 2.1089 - val_loss: 8.9829 - val_mae: 2.1501\n",
      "Epoch 58/100\n",
      "69/69 [==============================] - 0s 789us/step - loss: 7.5622 - mae: 2.0789 - val_loss: 8.9541 - val_mae: 2.1759\n",
      "Epoch 59/100\n",
      "69/69 [==============================] - 0s 871us/step - loss: 7.5605 - mae: 2.0738 - val_loss: 8.9882 - val_mae: 2.1566\n",
      "Epoch 60/100\n",
      "69/69 [==============================] - 0s 813us/step - loss: 7.5694 - mae: 2.0810 - val_loss: 8.9451 - val_mae: 2.2065\n",
      "Epoch 60: early stopping\n",
      "Test Loss (MSE): 7.752743721008301, Test Mean Absolute Error (MAE): 2.175264835357666\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 9.5281 - mae: 2.1113 - val_loss: 8.5954 - val_mae: 1.9712\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 0s 868us/step - loss: 8.2058 - mae: 2.0345 - val_loss: 8.2151 - val_mae: 1.9919\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 0s 794us/step - loss: 8.0010 - mae: 2.0605 - val_loss: 7.9734 - val_mae: 2.1896\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 0s 821us/step - loss: 7.8931 - mae: 2.0454 - val_loss: 7.9552 - val_mae: 2.0459\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 0s 884us/step - loss: 7.8482 - mae: 2.0576 - val_loss: 7.8894 - val_mae: 2.1383\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 0s 822us/step - loss: 7.8995 - mae: 2.0538 - val_loss: 8.0742 - val_mae: 1.9977\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 0s 816us/step - loss: 7.7327 - mae: 2.0603 - val_loss: 7.8771 - val_mae: 2.1755\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 0s 810us/step - loss: 7.7046 - mae: 2.0360 - val_loss: 7.9376 - val_mae: 2.0692\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 0s 809us/step - loss: 7.7048 - mae: 2.0472 - val_loss: 8.1774 - val_mae: 1.9909\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 0s 877us/step - loss: 7.7760 - mae: 2.0593 - val_loss: 7.8912 - val_mae: 2.0547\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 0s 770us/step - loss: 7.7682 - mae: 2.0378 - val_loss: 7.8988 - val_mae: 2.0216\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 0s 784us/step - loss: 7.6708 - mae: 2.0442 - val_loss: 7.8323 - val_mae: 2.1087\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 0s 822us/step - loss: 7.7113 - mae: 2.0640 - val_loss: 8.0556 - val_mae: 1.9769\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 0s 909us/step - loss: 7.6778 - mae: 2.0407 - val_loss: 7.8383 - val_mae: 2.1500\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 0s 863us/step - loss: 7.6656 - mae: 2.0480 - val_loss: 8.1299 - val_mae: 2.2852\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 0s 817us/step - loss: 7.6665 - mae: 2.0514 - val_loss: 7.8277 - val_mae: 2.0951\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 0s 792us/step - loss: 7.6548 - mae: 2.0417 - val_loss: 7.8525 - val_mae: 2.1728\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 0s 781us/step - loss: 7.6737 - mae: 2.0428 - val_loss: 7.8520 - val_mae: 2.2146\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 0s 876us/step - loss: 7.6363 - mae: 2.0723 - val_loss: 8.0265 - val_mae: 2.0000\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 0s 867us/step - loss: 7.6700 - mae: 2.0438 - val_loss: 8.1523 - val_mae: 1.9538\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 0s 823us/step - loss: 7.6179 - mae: 2.0359 - val_loss: 8.0778 - val_mae: 2.2999\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 0s 838us/step - loss: 7.6725 - mae: 2.0597 - val_loss: 7.8788 - val_mae: 2.1998\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 0s 841us/step - loss: 7.6524 - mae: 2.0573 - val_loss: 7.8158 - val_mae: 2.0929\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 0s 869us/step - loss: 7.6194 - mae: 2.0215 - val_loss: 7.9567 - val_mae: 2.2635\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 0s 882us/step - loss: 7.6309 - mae: 2.0743 - val_loss: 7.8836 - val_mae: 2.0393\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 0s 808us/step - loss: 7.5958 - mae: 2.0406 - val_loss: 7.8489 - val_mae: 2.1210\n",
      "Epoch 27/100\n",
      "70/70 [==============================] - 0s 775us/step - loss: 7.6198 - mae: 2.0356 - val_loss: 7.8685 - val_mae: 2.1728\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 0s 816us/step - loss: 7.5772 - mae: 2.0498 - val_loss: 7.8039 - val_mae: 2.1131\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 0s 848us/step - loss: 7.6071 - mae: 2.0367 - val_loss: 7.8882 - val_mae: 2.0496\n",
      "Epoch 30/100\n",
      "70/70 [==============================] - 0s 952us/step - loss: 7.6431 - mae: 2.0487 - val_loss: 7.8360 - val_mae: 2.0936\n",
      "Epoch 31/100\n",
      "70/70 [==============================] - 0s 867us/step - loss: 7.5816 - mae: 2.0447 - val_loss: 7.8757 - val_mae: 2.1625\n",
      "Epoch 32/100\n",
      "70/70 [==============================] - 0s 910us/step - loss: 7.6120 - mae: 2.0574 - val_loss: 7.8608 - val_mae: 2.0312\n",
      "Epoch 33/100\n",
      "70/70 [==============================] - 0s 790us/step - loss: 7.5834 - mae: 2.0425 - val_loss: 7.8587 - val_mae: 2.2194\n",
      "Epoch 34/100\n",
      "70/70 [==============================] - 0s 766us/step - loss: 7.6009 - mae: 2.0578 - val_loss: 7.8474 - val_mae: 2.1473\n",
      "Epoch 35/100\n",
      "70/70 [==============================] - 0s 928us/step - loss: 7.5452 - mae: 2.0263 - val_loss: 7.9819 - val_mae: 2.0042\n",
      "Epoch 36/100\n",
      "70/70 [==============================] - 0s 868us/step - loss: 7.6561 - mae: 2.0578 - val_loss: 7.8686 - val_mae: 2.1586\n",
      "Epoch 37/100\n",
      "70/70 [==============================] - 0s 858us/step - loss: 7.6009 - mae: 2.0490 - val_loss: 7.8878 - val_mae: 2.0679\n",
      "Epoch 38/100\n",
      "70/70 [==============================] - 0s 893us/step - loss: 7.5727 - mae: 2.0365 - val_loss: 7.8315 - val_mae: 2.0875\n",
      "Epoch 39/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 7.5742 - mae: 2.0304 - val_loss: 7.8425 - val_mae: 2.1283\n",
      "Epoch 40/100\n",
      "70/70 [==============================] - 0s 934us/step - loss: 7.5464 - mae: 2.0543 - val_loss: 7.9657 - val_mae: 2.0054\n",
      "Epoch 41/100\n",
      "70/70 [==============================] - 0s 894us/step - loss: 7.6751 - mae: 2.0328 - val_loss: 7.9092 - val_mae: 2.0573\n",
      "Epoch 42/100\n",
      "70/70 [==============================] - 0s 919us/step - loss: 7.5979 - mae: 2.0593 - val_loss: 7.8733 - val_mae: 2.0800\n",
      "Epoch 43/100\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 7.5070 - mae: 2.0275 - val_loss: 7.8469 - val_mae: 2.1270\n",
      "Epoch 44/100\n",
      "70/70 [==============================] - 0s 896us/step - loss: 7.5405 - mae: 2.0387 - val_loss: 7.9399 - val_mae: 2.0368\n",
      "Epoch 45/100\n",
      "70/70 [==============================] - 0s 836us/step - loss: 7.5441 - mae: 2.0358 - val_loss: 7.8987 - val_mae: 2.1047\n",
      "Epoch 46/100\n",
      "70/70 [==============================] - 0s 828us/step - loss: 7.5856 - mae: 2.0287 - val_loss: 7.8949 - val_mae: 2.1968\n",
      "Epoch 47/100\n",
      "70/70 [==============================] - 0s 802us/step - loss: 7.5121 - mae: 2.0294 - val_loss: 7.8845 - val_mae: 2.1336\n",
      "Epoch 48/100\n",
      "70/70 [==============================] - 0s 858us/step - loss: 7.5285 - mae: 2.0274 - val_loss: 7.9252 - val_mae: 2.1642\n",
      "Epoch 48: early stopping\n",
      "Test Loss (MSE): 9.175814628601074, Test Mean Absolute Error (MAE): 2.327378988265991\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 9.4470 - mae: 2.1109 - val_loss: 9.4265 - val_mae: 2.1449\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 0s 888us/step - loss: 8.2547 - mae: 2.0550 - val_loss: 9.3564 - val_mae: 2.0854\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 0s 854us/step - loss: 8.1576 - mae: 2.0433 - val_loss: 9.2197 - val_mae: 2.3081\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 0s 858us/step - loss: 8.1412 - mae: 2.0341 - val_loss: 9.3548 - val_mae: 2.0727\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 0s 929us/step - loss: 8.0202 - mae: 2.0575 - val_loss: 9.1464 - val_mae: 2.0970\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 0s 900us/step - loss: 7.8791 - mae: 2.0100 - val_loss: 8.8988 - val_mae: 2.2076\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 0s 860us/step - loss: 7.8329 - mae: 2.0236 - val_loss: 9.1053 - val_mae: 2.2446\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 0s 837us/step - loss: 7.7513 - mae: 2.0200 - val_loss: 9.2609 - val_mae: 2.0663\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 0s 849us/step - loss: 7.7391 - mae: 1.9822 - val_loss: 8.8880 - val_mae: 2.2439\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 0s 943us/step - loss: 7.6393 - mae: 1.9993 - val_loss: 9.3264 - val_mae: 2.0938\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 0s 846us/step - loss: 7.7156 - mae: 2.0091 - val_loss: 9.0264 - val_mae: 2.1886\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 0s 836us/step - loss: 7.7172 - mae: 1.9964 - val_loss: 9.2234 - val_mae: 2.2002\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 0s 863us/step - loss: 7.6024 - mae: 2.0023 - val_loss: 9.0532 - val_mae: 2.2330\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 0s 834us/step - loss: 7.5052 - mae: 1.9723 - val_loss: 9.1874 - val_mae: 2.2297\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 0s 909us/step - loss: 7.5230 - mae: 1.9686 - val_loss: 9.4061 - val_mae: 2.3466\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 0s 844us/step - loss: 7.4744 - mae: 1.9901 - val_loss: 9.7852 - val_mae: 2.0657\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 0s 797us/step - loss: 7.4680 - mae: 1.9674 - val_loss: 9.4930 - val_mae: 2.2057\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 0s 869us/step - loss: 7.3934 - mae: 1.9502 - val_loss: 9.3670 - val_mae: 2.2157\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 0s 880us/step - loss: 7.3157 - mae: 1.9466 - val_loss: 9.6420 - val_mae: 2.2746\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 0s 910us/step - loss: 7.2432 - mae: 1.9341 - val_loss: 9.4526 - val_mae: 2.1505\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 0s 848us/step - loss: 7.3027 - mae: 1.9049 - val_loss: 9.9453 - val_mae: 2.3668\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 0s 851us/step - loss: 7.2351 - mae: 1.9249 - val_loss: 9.6609 - val_mae: 2.2105\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 0s 832us/step - loss: 7.1585 - mae: 1.9096 - val_loss: 9.7394 - val_mae: 2.1563\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 0s 865us/step - loss: 7.2388 - mae: 1.8949 - val_loss: 9.7626 - val_mae: 2.2884\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 0s 848us/step - loss: 7.0863 - mae: 1.8764 - val_loss: 9.6771 - val_mae: 2.2420\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 0s 849us/step - loss: 7.1105 - mae: 1.8775 - val_loss: 10.1241 - val_mae: 2.1863\n",
      "Epoch 27/100\n",
      "69/69 [==============================] - 0s 884us/step - loss: 7.0844 - mae: 1.8797 - val_loss: 9.7925 - val_mae: 2.1781\n",
      "Epoch 28/100\n",
      "69/69 [==============================] - 0s 897us/step - loss: 6.9299 - mae: 1.8695 - val_loss: 9.9125 - val_mae: 2.1258\n",
      "Epoch 29/100\n",
      "69/69 [==============================] - 0s 875us/step - loss: 6.8694 - mae: 1.8419 - val_loss: 10.2282 - val_mae: 2.2375\n",
      "Epoch 29: early stopping\n",
      "Test Loss (MSE): 8.824761390686035, Test Mean Absolute Error (MAE): 2.0858893394470215\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 9.8725 - mae: 2.1300 - val_loss: 8.7739 - val_mae: 2.0567\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 0s 907us/step - loss: 8.7343 - mae: 2.0814 - val_loss: 8.2731 - val_mae: 2.1949\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 0s 913us/step - loss: 8.4517 - mae: 2.1004 - val_loss: 8.1137 - val_mae: 2.0366\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 0s 902us/step - loss: 8.3385 - mae: 2.0980 - val_loss: 7.9562 - val_mae: 2.0624\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 0s 983us/step - loss: 8.1909 - mae: 2.0588 - val_loss: 8.0880 - val_mae: 1.9992\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 0s 921us/step - loss: 8.0151 - mae: 2.0796 - val_loss: 8.0215 - val_mae: 2.0445\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 0s 908us/step - loss: 7.9702 - mae: 2.0280 - val_loss: 7.7748 - val_mae: 2.0717\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 0s 882us/step - loss: 7.9263 - mae: 2.0694 - val_loss: 7.8429 - val_mae: 2.1233\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 0s 955us/step - loss: 7.9212 - mae: 2.0476 - val_loss: 7.8284 - val_mae: 2.1659\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 0s 903us/step - loss: 7.8319 - mae: 2.0507 - val_loss: 8.0572 - val_mae: 2.1680\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 0s 883us/step - loss: 7.7730 - mae: 2.0309 - val_loss: 8.3125 - val_mae: 2.0428\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 0s 935us/step - loss: 7.7504 - mae: 2.0101 - val_loss: 8.0429 - val_mae: 1.9945\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 0s 854us/step - loss: 7.6820 - mae: 2.0174 - val_loss: 7.9932 - val_mae: 2.0026\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 0s 904us/step - loss: 7.7025 - mae: 1.9988 - val_loss: 8.0647 - val_mae: 2.0334\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 0s 910us/step - loss: 7.6709 - mae: 1.9953 - val_loss: 8.1189 - val_mae: 2.0113\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 0s 892us/step - loss: 7.5318 - mae: 1.9657 - val_loss: 8.3852 - val_mae: 2.2015\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 0s 894us/step - loss: 7.6504 - mae: 2.0052 - val_loss: 8.1995 - val_mae: 2.1531\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 0s 894us/step - loss: 7.4443 - mae: 1.9861 - val_loss: 8.3050 - val_mae: 2.0093\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 0s 937us/step - loss: 7.4565 - mae: 1.9637 - val_loss: 8.3223 - val_mae: 2.0753\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 0s 913us/step - loss: 7.4342 - mae: 1.9477 - val_loss: 8.2406 - val_mae: 2.0405\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 0s 877us/step - loss: 7.4705 - mae: 1.9452 - val_loss: 8.2922 - val_mae: 2.1517\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 0s 923us/step - loss: 7.3203 - mae: 1.9412 - val_loss: 8.6288 - val_mae: 2.2542\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 0s 891us/step - loss: 7.4256 - mae: 1.9509 - val_loss: 8.1969 - val_mae: 2.1488\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 7.3349 - mae: 1.9340 - val_loss: 8.5248 - val_mae: 2.0383\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 0s 866us/step - loss: 7.2187 - mae: 1.9231 - val_loss: 8.4647 - val_mae: 2.0731\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 0s 855us/step - loss: 7.1856 - mae: 1.8889 - val_loss: 8.5422 - val_mae: 2.1438\n",
      "Epoch 27/100\n",
      "69/69 [==============================] - 0s 927us/step - loss: 7.1701 - mae: 1.9169 - val_loss: 8.3071 - val_mae: 2.1004\n",
      "Epoch 27: early stopping\n",
      "Test Loss (MSE): 9.3383150100708, Test Mean Absolute Error (MAE): 2.1878602504730225\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 5.6924 - mae: 1.3647 - val_loss: 4.8418 - val_mae: 1.5216\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 0s 841us/step - loss: 5.0936 - mae: 1.3536 - val_loss: 4.7667 - val_mae: 1.1427\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 0s 769us/step - loss: 4.9914 - mae: 1.3406 - val_loss: 4.6256 - val_mae: 1.1978\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 0s 741us/step - loss: 5.0096 - mae: 1.3506 - val_loss: 4.4850 - val_mae: 1.2434\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 0s 791us/step - loss: 4.8907 - mae: 1.3370 - val_loss: 4.4981 - val_mae: 1.3153\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 0s 787us/step - loss: 4.8888 - mae: 1.3292 - val_loss: 4.4520 - val_mae: 1.2695\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 0s 783us/step - loss: 4.9049 - mae: 1.3357 - val_loss: 4.4680 - val_mae: 1.3634\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 0s 931us/step - loss: 4.8514 - mae: 1.3419 - val_loss: 4.4777 - val_mae: 1.2092\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 0s 804us/step - loss: 4.8679 - mae: 1.3274 - val_loss: 4.5482 - val_mae: 1.1522\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 0s 780us/step - loss: 4.8667 - mae: 1.3274 - val_loss: 4.4674 - val_mae: 1.1944\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 0s 765us/step - loss: 4.8531 - mae: 1.3246 - val_loss: 4.4702 - val_mae: 1.1777\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 0s 731us/step - loss: 4.8475 - mae: 1.3141 - val_loss: 4.4334 - val_mae: 1.2360\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 0s 721us/step - loss: 4.8351 - mae: 1.3298 - val_loss: 4.4160 - val_mae: 1.2526\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 0s 760us/step - loss: 4.8062 - mae: 1.3101 - val_loss: 4.4599 - val_mae: 1.3199\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 0s 740us/step - loss: 4.8349 - mae: 1.3252 - val_loss: 4.4879 - val_mae: 1.1809\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 0s 722us/step - loss: 4.8351 - mae: 1.3185 - val_loss: 4.4149 - val_mae: 1.2637\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 0s 745us/step - loss: 4.8243 - mae: 1.3183 - val_loss: 4.4736 - val_mae: 1.2732\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 0s 740us/step - loss: 4.8598 - mae: 1.3203 - val_loss: 4.4885 - val_mae: 1.3391\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 0s 726us/step - loss: 4.8187 - mae: 1.3240 - val_loss: 4.5865 - val_mae: 1.3622\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 0s 751us/step - loss: 4.8013 - mae: 1.3195 - val_loss: 4.4486 - val_mae: 1.1846\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 0s 722us/step - loss: 4.8276 - mae: 1.3099 - val_loss: 4.6173 - val_mae: 1.4184\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 0s 706us/step - loss: 4.8349 - mae: 1.3133 - val_loss: 4.4502 - val_mae: 1.2187\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 0s 759us/step - loss: 4.8213 - mae: 1.3163 - val_loss: 4.4406 - val_mae: 1.2495\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 0s 722us/step - loss: 4.8093 - mae: 1.3075 - val_loss: 4.4433 - val_mae: 1.2337\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 0s 709us/step - loss: 4.8047 - mae: 1.3110 - val_loss: 4.4346 - val_mae: 1.2378\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 0s 739us/step - loss: 4.7974 - mae: 1.3093 - val_loss: 4.4459 - val_mae: 1.2912\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 0s 727us/step - loss: 4.8304 - mae: 1.3202 - val_loss: 4.4550 - val_mae: 1.3180\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 0s 713us/step - loss: 4.8073 - mae: 1.3168 - val_loss: 4.4508 - val_mae: 1.2337\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 0s 737us/step - loss: 4.8103 - mae: 1.3139 - val_loss: 4.4495 - val_mae: 1.2178\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 0s 742us/step - loss: 4.8005 - mae: 1.3044 - val_loss: 4.4423 - val_mae: 1.2413\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 0s 750us/step - loss: 4.8156 - mae: 1.3183 - val_loss: 4.4664 - val_mae: 1.2956\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 0s 777us/step - loss: 4.8084 - mae: 1.3068 - val_loss: 4.4447 - val_mae: 1.2505\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 0s 725us/step - loss: 4.8192 - mae: 1.3064 - val_loss: 4.4369 - val_mae: 1.2847\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 0s 725us/step - loss: 4.7904 - mae: 1.3223 - val_loss: 4.4580 - val_mae: 1.2280\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 0s 764us/step - loss: 4.8422 - mae: 1.3007 - val_loss: 4.4394 - val_mae: 1.2448\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 0s 730us/step - loss: 4.7902 - mae: 1.3132 - val_loss: 4.4734 - val_mae: 1.2805\n",
      "Epoch 36: early stopping\n",
      "Test Loss (MSE): 4.313805103302002, Test Mean Absolute Error (MAE): 1.2703086137771606\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 5.6405 - mae: 1.3041 - val_loss: 4.9545 - val_mae: 1.2835\n",
      "Epoch 2/100\n",
      "134/134 [==============================] - 0s 777us/step - loss: 4.8945 - mae: 1.2784 - val_loss: 5.1346 - val_mae: 1.4324\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 0s 812us/step - loss: 4.8068 - mae: 1.3091 - val_loss: 4.8244 - val_mae: 1.2764\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 0s 779us/step - loss: 4.6886 - mae: 1.2861 - val_loss: 4.8353 - val_mae: 1.3517\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 0s 762us/step - loss: 4.6740 - mae: 1.2922 - val_loss: 4.7508 - val_mae: 1.3024\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 0s 802us/step - loss: 4.6256 - mae: 1.2814 - val_loss: 4.7666 - val_mae: 1.2420\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 0s 772us/step - loss: 4.6898 - mae: 1.2743 - val_loss: 4.9703 - val_mae: 1.4219\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 0s 773us/step - loss: 4.6271 - mae: 1.2893 - val_loss: 4.7860 - val_mae: 1.2261\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 0s 864us/step - loss: 4.6129 - mae: 1.2661 - val_loss: 4.7788 - val_mae: 1.3586\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 0s 813us/step - loss: 4.6623 - mae: 1.2858 - val_loss: 4.7845 - val_mae: 1.2284\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 0s 759us/step - loss: 4.6188 - mae: 1.2740 - val_loss: 4.7738 - val_mae: 1.2205\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 0s 852us/step - loss: 4.6039 - mae: 1.2666 - val_loss: 4.7530 - val_mae: 1.2958\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 0s 830us/step - loss: 4.6302 - mae: 1.2769 - val_loss: 4.7653 - val_mae: 1.3359\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 0s 829us/step - loss: 4.5721 - mae: 1.2728 - val_loss: 4.8413 - val_mae: 1.1913\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 0s 990us/step - loss: 4.5818 - mae: 1.2610 - val_loss: 4.7407 - val_mae: 1.2836\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 0s 868us/step - loss: 4.5747 - mae: 1.2675 - val_loss: 4.7468 - val_mae: 1.2559\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 0s 805us/step - loss: 4.5911 - mae: 1.2663 - val_loss: 4.7409 - val_mae: 1.2976\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 0s 769us/step - loss: 4.5696 - mae: 1.2644 - val_loss: 4.8461 - val_mae: 1.2513\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 0s 765us/step - loss: 4.5739 - mae: 1.2663 - val_loss: 4.9129 - val_mae: 1.1810\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 0s 818us/step - loss: 4.5797 - mae: 1.2749 - val_loss: 4.7823 - val_mae: 1.2627\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 0s 754us/step - loss: 4.6010 - mae: 1.2609 - val_loss: 4.7749 - val_mae: 1.2543\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 0s 779us/step - loss: 4.5945 - mae: 1.2770 - val_loss: 4.7597 - val_mae: 1.2276\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 0s 795us/step - loss: 4.6020 - mae: 1.2530 - val_loss: 4.7565 - val_mae: 1.3124\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 0s 759us/step - loss: 4.5566 - mae: 1.2603 - val_loss: 4.7757 - val_mae: 1.3100\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 0s 770us/step - loss: 4.5558 - mae: 1.2640 - val_loss: 4.7511 - val_mae: 1.2960\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 0s 795us/step - loss: 4.6095 - mae: 1.2611 - val_loss: 4.8037 - val_mae: 1.3260\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 0s 742us/step - loss: 4.5801 - mae: 1.2606 - val_loss: 4.7817 - val_mae: 1.2257\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 0s 764us/step - loss: 4.5713 - mae: 1.2728 - val_loss: 4.7977 - val_mae: 1.2406\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 0s 809us/step - loss: 4.5574 - mae: 1.2571 - val_loss: 4.7480 - val_mae: 1.2518\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 0s 766us/step - loss: 4.5547 - mae: 1.2522 - val_loss: 4.7764 - val_mae: 1.2761\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 0s 781us/step - loss: 4.5549 - mae: 1.2609 - val_loss: 4.8426 - val_mae: 1.3202\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 0s 814us/step - loss: 4.5279 - mae: 1.2562 - val_loss: 4.7749 - val_mae: 1.2408\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 0s 784us/step - loss: 4.5659 - mae: 1.2510 - val_loss: 4.7760 - val_mae: 1.2720\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 0s 778us/step - loss: 4.5384 - mae: 1.2624 - val_loss: 4.8560 - val_mae: 1.3294\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 0s 818us/step - loss: 4.5672 - mae: 1.2636 - val_loss: 4.7868 - val_mae: 1.2830\n",
      "Epoch 35: early stopping\n",
      "Test Loss (MSE): 4.360530853271484, Test Mean Absolute Error (MAE): 1.1934871673583984\n",
      "Epoch 1/100\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 5.2340 - mae: 1.1726 - val_loss: 5.7110 - val_mae: 1.5376\n",
      "Epoch 2/100\n",
      "131/131 [==============================] - 0s 817us/step - loss: 4.5232 - mae: 1.1475 - val_loss: 5.6110 - val_mae: 1.6098\n",
      "Epoch 3/100\n",
      "131/131 [==============================] - 0s 859us/step - loss: 4.3668 - mae: 1.1880 - val_loss: 5.6410 - val_mae: 1.3778\n",
      "Epoch 4/100\n",
      "131/131 [==============================] - 0s 797us/step - loss: 4.3265 - mae: 1.1697 - val_loss: 5.5090 - val_mae: 1.3941\n",
      "Epoch 5/100\n",
      "131/131 [==============================] - 0s 802us/step - loss: 4.2784 - mae: 1.1524 - val_loss: 5.4737 - val_mae: 1.4178\n",
      "Epoch 6/100\n",
      "131/131 [==============================] - 0s 883us/step - loss: 4.2325 - mae: 1.1553 - val_loss: 5.4500 - val_mae: 1.4050\n",
      "Epoch 7/100\n",
      "131/131 [==============================] - 0s 853us/step - loss: 4.2214 - mae: 1.1494 - val_loss: 5.4494 - val_mae: 1.5413\n",
      "Epoch 8/100\n",
      "131/131 [==============================] - 0s 822us/step - loss: 4.1664 - mae: 1.1467 - val_loss: 5.4503 - val_mae: 1.4151\n",
      "Epoch 9/100\n",
      "131/131 [==============================] - 0s 927us/step - loss: 4.2093 - mae: 1.1432 - val_loss: 5.4027 - val_mae: 1.5462\n",
      "Epoch 10/100\n",
      "131/131 [==============================] - 0s 878us/step - loss: 4.1881 - mae: 1.1346 - val_loss: 5.3642 - val_mae: 1.5297\n",
      "Epoch 11/100\n",
      "131/131 [==============================] - 0s 897us/step - loss: 4.2703 - mae: 1.1540 - val_loss: 5.5766 - val_mae: 1.3753\n",
      "Epoch 12/100\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 4.2109 - mae: 1.1625 - val_loss: 5.4001 - val_mae: 1.4023\n",
      "Epoch 13/100\n",
      "131/131 [==============================] - 0s 886us/step - loss: 4.1510 - mae: 1.1278 - val_loss: 5.4303 - val_mae: 1.4253\n",
      "Epoch 14/100\n",
      "131/131 [==============================] - 0s 784us/step - loss: 4.1388 - mae: 1.1408 - val_loss: 5.3935 - val_mae: 1.4958\n",
      "Epoch 15/100\n",
      "131/131 [==============================] - 0s 823us/step - loss: 4.1346 - mae: 1.1318 - val_loss: 5.7093 - val_mae: 1.3563\n",
      "Epoch 16/100\n",
      "131/131 [==============================] - 0s 818us/step - loss: 4.1601 - mae: 1.1327 - val_loss: 5.4047 - val_mae: 1.4602\n",
      "Epoch 17/100\n",
      "131/131 [==============================] - 0s 813us/step - loss: 4.1200 - mae: 1.1385 - val_loss: 5.4035 - val_mae: 1.4332\n",
      "Epoch 18/100\n",
      "131/131 [==============================] - 0s 838us/step - loss: 4.1162 - mae: 1.1286 - val_loss: 5.4087 - val_mae: 1.4480\n",
      "Epoch 19/100\n",
      "131/131 [==============================] - 0s 806us/step - loss: 4.1210 - mae: 1.1345 - val_loss: 5.4567 - val_mae: 1.4315\n",
      "Epoch 20/100\n",
      "131/131 [==============================] - 0s 770us/step - loss: 4.1212 - mae: 1.1213 - val_loss: 5.5108 - val_mae: 1.3773\n",
      "Epoch 21/100\n",
      "131/131 [==============================] - 0s 834us/step - loss: 4.1180 - mae: 1.1324 - val_loss: 5.4883 - val_mae: 1.4009\n",
      "Epoch 22/100\n",
      "131/131 [==============================] - 0s 798us/step - loss: 4.1235 - mae: 1.1174 - val_loss: 5.4717 - val_mae: 1.4202\n",
      "Epoch 23/100\n",
      "131/131 [==============================] - 0s 799us/step - loss: 4.1096 - mae: 1.1311 - val_loss: 5.4674 - val_mae: 1.4191\n",
      "Epoch 24/100\n",
      "131/131 [==============================] - 0s 820us/step - loss: 4.1390 - mae: 1.1234 - val_loss: 5.4976 - val_mae: 1.5357\n",
      "Epoch 25/100\n",
      "131/131 [==============================] - 0s 795us/step - loss: 4.1077 - mae: 1.1221 - val_loss: 5.4316 - val_mae: 1.4310\n",
      "Epoch 26/100\n",
      "131/131 [==============================] - 0s 816us/step - loss: 4.1028 - mae: 1.1283 - val_loss: 5.4713 - val_mae: 1.4950\n",
      "Epoch 27/100\n",
      "131/131 [==============================] - 0s 841us/step - loss: 4.1265 - mae: 1.1170 - val_loss: 6.0278 - val_mae: 1.6859\n",
      "Epoch 28/100\n",
      "131/131 [==============================] - 0s 804us/step - loss: 4.1309 - mae: 1.1316 - val_loss: 5.4989 - val_mae: 1.4870\n",
      "Epoch 29/100\n",
      "131/131 [==============================] - 0s 801us/step - loss: 4.1051 - mae: 1.1252 - val_loss: 5.6440 - val_mae: 1.3759\n",
      "Epoch 30/100\n",
      "131/131 [==============================] - 0s 835us/step - loss: 4.1617 - mae: 1.1242 - val_loss: 5.6221 - val_mae: 1.3736\n",
      "Epoch 30: early stopping\n",
      "Test Loss (MSE): 5.151729583740234, Test Mean Absolute Error (MAE): 1.227612018585205\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 5.8024 - mae: 1.2768 - val_loss: 5.1618 - val_mae: 1.2136\n",
      "Epoch 2/100\n",
      "134/134 [==============================] - 0s 789us/step - loss: 4.9117 - mae: 1.2375 - val_loss: 4.7076 - val_mae: 1.3212\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 0s 858us/step - loss: 4.7435 - mae: 1.2270 - val_loss: 4.6083 - val_mae: 1.3108\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 0s 787us/step - loss: 4.7253 - mae: 1.2371 - val_loss: 4.6927 - val_mae: 1.1879\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 0s 793us/step - loss: 4.6486 - mae: 1.2358 - val_loss: 4.6529 - val_mae: 1.4310\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 0s 854us/step - loss: 4.5973 - mae: 1.2383 - val_loss: 4.5757 - val_mae: 1.2936\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 0s 807us/step - loss: 4.5069 - mae: 1.2297 - val_loss: 4.9139 - val_mae: 1.1681\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 0s 855us/step - loss: 4.5488 - mae: 1.2148 - val_loss: 4.7274 - val_mae: 1.2202\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 0s 858us/step - loss: 4.5366 - mae: 1.2066 - val_loss: 4.8476 - val_mae: 1.2238\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 0s 810us/step - loss: 4.5263 - mae: 1.2219 - val_loss: 4.7200 - val_mae: 1.2220\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 0s 885us/step - loss: 4.5627 - mae: 1.2103 - val_loss: 4.5641 - val_mae: 1.2575\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 0s 992us/step - loss: 4.5120 - mae: 1.2148 - val_loss: 4.6103 - val_mae: 1.3288\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 0s 925us/step - loss: 4.4844 - mae: 1.2305 - val_loss: 4.6452 - val_mae: 1.3328\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 0s 893us/step - loss: 4.4870 - mae: 1.2266 - val_loss: 4.7057 - val_mae: 1.2735\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 0s 799us/step - loss: 4.4446 - mae: 1.2077 - val_loss: 4.7701 - val_mae: 1.3168\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 0s 798us/step - loss: 4.4903 - mae: 1.2089 - val_loss: 4.7110 - val_mae: 1.3371\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 0s 847us/step - loss: 4.4415 - mae: 1.2127 - val_loss: 4.9326 - val_mae: 1.2661\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 0s 778us/step - loss: 4.4617 - mae: 1.1927 - val_loss: 4.6778 - val_mae: 1.2310\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 0s 791us/step - loss: 4.4102 - mae: 1.1988 - val_loss: 4.7938 - val_mae: 1.3439\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 0s 827us/step - loss: 4.4665 - mae: 1.2195 - val_loss: 4.7790 - val_mae: 1.3341\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 0s 790us/step - loss: 4.4075 - mae: 1.1983 - val_loss: 4.7801 - val_mae: 1.3029\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 0s 792us/step - loss: 4.4626 - mae: 1.1983 - val_loss: 4.7946 - val_mae: 1.2667\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 0s 835us/step - loss: 4.4342 - mae: 1.2003 - val_loss: 4.8469 - val_mae: 1.3567\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 0s 780us/step - loss: 4.3600 - mae: 1.1836 - val_loss: 5.0014 - val_mae: 1.4243\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 0s 776us/step - loss: 4.4620 - mae: 1.2119 - val_loss: 4.9700 - val_mae: 1.3735\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 0s 855us/step - loss: 4.4097 - mae: 1.1872 - val_loss: 5.0219 - val_mae: 1.2891\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 0s 777us/step - loss: 4.3878 - mae: 1.1874 - val_loss: 5.1028 - val_mae: 1.3255\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 0s 778us/step - loss: 4.3190 - mae: 1.1778 - val_loss: 5.1531 - val_mae: 1.3240\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 0s 841us/step - loss: 4.3234 - mae: 1.1927 - val_loss: 5.0294 - val_mae: 1.2713\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 0s 781us/step - loss: 4.2426 - mae: 1.1701 - val_loss: 4.9997 - val_mae: 1.2249\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 0s 775us/step - loss: 4.3090 - mae: 1.1828 - val_loss: 5.1115 - val_mae: 1.2594\n",
      "Epoch 31: early stopping\n",
      "Test Loss (MSE): 5.475844383239746, Test Mean Absolute Error (MAE): 1.262294054031372\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 9.6347 - mae: 2.1985 - val_loss: 8.2342 - val_mae: 2.1321\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 0s 820us/step - loss: 8.5963 - mae: 2.1769 - val_loss: 7.8995 - val_mae: 2.1054\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 0s 809us/step - loss: 8.4648 - mae: 2.1553 - val_loss: 8.5668 - val_mae: 2.3989\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 0s 789us/step - loss: 8.4286 - mae: 2.1687 - val_loss: 7.9119 - val_mae: 2.0502\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 0s 821us/step - loss: 8.4056 - mae: 2.1576 - val_loss: 7.8043 - val_mae: 2.1220\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 0s 794us/step - loss: 8.3033 - mae: 2.1729 - val_loss: 7.9909 - val_mae: 2.2852\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 0s 793us/step - loss: 8.2871 - mae: 2.1576 - val_loss: 8.1641 - val_mae: 1.9238\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 0s 778us/step - loss: 8.2134 - mae: 2.1540 - val_loss: 8.0032 - val_mae: 1.9764\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 0s 791us/step - loss: 8.2774 - mae: 2.1575 - val_loss: 7.7523 - val_mae: 2.0878\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 0s 820us/step - loss: 8.2742 - mae: 2.1507 - val_loss: 7.7440 - val_mae: 2.1326\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 0s 793us/step - loss: 8.1896 - mae: 2.1399 - val_loss: 7.9040 - val_mae: 2.2719\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 0s 792us/step - loss: 8.2036 - mae: 2.1704 - val_loss: 7.8779 - val_mae: 1.9903\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 0s 772us/step - loss: 8.2035 - mae: 2.1431 - val_loss: 7.7873 - val_mae: 2.0456\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 0s 755us/step - loss: 8.2940 - mae: 2.1512 - val_loss: 7.7631 - val_mae: 2.1129\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 0s 861us/step - loss: 8.1256 - mae: 2.1533 - val_loss: 7.7469 - val_mae: 2.1563\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 0s 813us/step - loss: 8.1599 - mae: 2.1523 - val_loss: 7.8414 - val_mae: 2.2548\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 0s 782us/step - loss: 8.1517 - mae: 2.1722 - val_loss: 7.7461 - val_mae: 2.1118\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 0s 784us/step - loss: 8.1157 - mae: 2.1576 - val_loss: 7.8209 - val_mae: 2.2434\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 0s 793us/step - loss: 8.1488 - mae: 2.1619 - val_loss: 7.7229 - val_mae: 2.1526\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 0s 842us/step - loss: 8.1460 - mae: 2.1548 - val_loss: 8.0749 - val_mae: 2.3817\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 0s 787us/step - loss: 8.1532 - mae: 2.1657 - val_loss: 7.7552 - val_mae: 2.2061\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 0s 746us/step - loss: 8.1278 - mae: 2.1548 - val_loss: 7.7647 - val_mae: 2.0850\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 0s 774us/step - loss: 8.1425 - mae: 2.1671 - val_loss: 7.7393 - val_mae: 2.1380\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 0s 781us/step - loss: 8.1645 - mae: 2.1597 - val_loss: 7.7534 - val_mae: 2.1665\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 0s 871us/step - loss: 8.1198 - mae: 2.1437 - val_loss: 7.7123 - val_mae: 2.1146\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 0s 788us/step - loss: 8.1182 - mae: 2.1525 - val_loss: 7.7538 - val_mae: 2.1385\n",
      "Epoch 27/100\n",
      "69/69 [==============================] - 0s 797us/step - loss: 8.1235 - mae: 2.1724 - val_loss: 7.7550 - val_mae: 2.2003\n",
      "Epoch 28/100\n",
      "69/69 [==============================] - 0s 753us/step - loss: 8.1067 - mae: 2.1627 - val_loss: 7.7061 - val_mae: 2.1396\n",
      "Epoch 29/100\n",
      "69/69 [==============================] - 0s 762us/step - loss: 8.1049 - mae: 2.1468 - val_loss: 7.7884 - val_mae: 2.2126\n",
      "Epoch 30/100\n",
      "69/69 [==============================] - 0s 852us/step - loss: 8.0988 - mae: 2.1447 - val_loss: 7.7270 - val_mae: 2.1109\n",
      "Epoch 31/100\n",
      "69/69 [==============================] - 0s 755us/step - loss: 8.1414 - mae: 2.1785 - val_loss: 7.7452 - val_mae: 2.0558\n",
      "Epoch 32/100\n",
      "69/69 [==============================] - 0s 784us/step - loss: 8.1168 - mae: 2.1582 - val_loss: 7.6791 - val_mae: 2.1089\n",
      "Epoch 33/100\n",
      "69/69 [==============================] - 0s 798us/step - loss: 8.1126 - mae: 2.1485 - val_loss: 7.7299 - val_mae: 2.1317\n",
      "Epoch 34/100\n",
      "69/69 [==============================] - 0s 801us/step - loss: 8.0929 - mae: 2.1475 - val_loss: 7.7090 - val_mae: 2.1428\n",
      "Epoch 35/100\n",
      "69/69 [==============================] - 0s 909us/step - loss: 8.1077 - mae: 2.1408 - val_loss: 7.7546 - val_mae: 2.1963\n",
      "Epoch 36/100\n",
      "69/69 [==============================] - 0s 807us/step - loss: 8.1019 - mae: 2.1730 - val_loss: 7.7541 - val_mae: 2.0836\n",
      "Epoch 37/100\n",
      "69/69 [==============================] - 0s 784us/step - loss: 8.1295 - mae: 2.1527 - val_loss: 7.7310 - val_mae: 2.1724\n",
      "Epoch 38/100\n",
      "69/69 [==============================] - 0s 793us/step - loss: 8.0709 - mae: 2.1601 - val_loss: 7.9345 - val_mae: 1.9844\n",
      "Epoch 39/100\n",
      "69/69 [==============================] - 0s 801us/step - loss: 8.1375 - mae: 2.1294 - val_loss: 7.7508 - val_mae: 2.1903\n",
      "Epoch 40/100\n",
      "69/69 [==============================] - 0s 927us/step - loss: 8.0652 - mae: 2.1571 - val_loss: 7.7428 - val_mae: 2.1955\n",
      "Epoch 41/100\n",
      "69/69 [==============================] - 0s 797us/step - loss: 8.0870 - mae: 2.1549 - val_loss: 7.7251 - val_mae: 2.1878\n",
      "Epoch 42/100\n",
      "69/69 [==============================] - 0s 788us/step - loss: 8.0781 - mae: 2.1581 - val_loss: 7.7315 - val_mae: 2.1571\n",
      "Epoch 43/100\n",
      "69/69 [==============================] - 0s 850us/step - loss: 8.0819 - mae: 2.1565 - val_loss: 7.7392 - val_mae: 2.0623\n",
      "Epoch 44/100\n",
      "69/69 [==============================] - 0s 804us/step - loss: 8.0520 - mae: 2.1486 - val_loss: 7.9255 - val_mae: 1.9936\n",
      "Epoch 45/100\n",
      "69/69 [==============================] - 0s 995us/step - loss: 8.1198 - mae: 2.1365 - val_loss: 7.8131 - val_mae: 2.2355\n",
      "Epoch 46/100\n",
      "69/69 [==============================] - 0s 820us/step - loss: 8.0787 - mae: 2.1590 - val_loss: 7.7016 - val_mae: 2.1377\n",
      "Epoch 47/100\n",
      "69/69 [==============================] - 0s 828us/step - loss: 8.0817 - mae: 2.1451 - val_loss: 7.7289 - val_mae: 2.1531\n",
      "Epoch 48/100\n",
      "69/69 [==============================] - 0s 806us/step - loss: 8.0565 - mae: 2.1635 - val_loss: 7.7777 - val_mae: 2.1801\n",
      "Epoch 49/100\n",
      "69/69 [==============================] - 0s 956us/step - loss: 8.0719 - mae: 2.1453 - val_loss: 7.7216 - val_mae: 2.1071\n",
      "Epoch 50/100\n",
      "69/69 [==============================] - 0s 874us/step - loss: 8.1029 - mae: 2.1689 - val_loss: 7.7001 - val_mae: 2.1115\n",
      "Epoch 51/100\n",
      "69/69 [==============================] - 0s 878us/step - loss: 8.0645 - mae: 2.1541 - val_loss: 7.7632 - val_mae: 2.2010\n",
      "Epoch 52/100\n",
      "69/69 [==============================] - 0s 822us/step - loss: 8.0880 - mae: 2.1321 - val_loss: 7.7408 - val_mae: 2.1720\n",
      "Epoch 52: early stopping\n",
      "Test Loss (MSE): 7.763949394226074, Test Mean Absolute Error (MAE): 2.1287760734558105\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 9.1762 - mae: 2.0944 - val_loss: 8.5848 - val_mae: 2.0778\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 0s 898us/step - loss: 8.4491 - mae: 2.0747 - val_loss: 8.3565 - val_mae: 2.0541\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 0s 855us/step - loss: 7.9996 - mae: 2.0406 - val_loss: 8.1475 - val_mae: 2.0752\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 0s 877us/step - loss: 7.7539 - mae: 2.0533 - val_loss: 8.1543 - val_mae: 2.0575\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 0s 876us/step - loss: 7.7662 - mae: 2.0592 - val_loss: 8.2480 - val_mae: 2.1438\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 0s 864us/step - loss: 7.6926 - mae: 2.0400 - val_loss: 8.3127 - val_mae: 2.2337\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 0s 829us/step - loss: 7.6484 - mae: 2.0367 - val_loss: 8.0556 - val_mae: 2.1272\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 0s 837us/step - loss: 7.6026 - mae: 2.0352 - val_loss: 8.4336 - val_mae: 2.1987\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 0s 895us/step - loss: 7.5460 - mae: 2.0282 - val_loss: 8.2208 - val_mae: 2.1309\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 0s 818us/step - loss: 7.5202 - mae: 2.0138 - val_loss: 8.2355 - val_mae: 2.1134\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 0s 823us/step - loss: 7.5330 - mae: 2.0188 - val_loss: 8.2077 - val_mae: 1.9986\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 0s 816us/step - loss: 7.4250 - mae: 1.9959 - val_loss: 8.9136 - val_mae: 2.3663\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 0s 842us/step - loss: 7.4387 - mae: 2.0150 - val_loss: 8.2072 - val_mae: 2.1248\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 0s 908us/step - loss: 7.3467 - mae: 2.0018 - val_loss: 8.1300 - val_mae: 2.0929\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 0s 856us/step - loss: 7.4716 - mae: 2.0121 - val_loss: 8.4752 - val_mae: 2.1637\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 0s 820us/step - loss: 7.4552 - mae: 2.0130 - val_loss: 8.1812 - val_mae: 2.0377\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 0s 853us/step - loss: 7.3049 - mae: 1.9876 - val_loss: 8.2510 - val_mae: 2.0815\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 0s 799us/step - loss: 7.2933 - mae: 1.9711 - val_loss: 8.0787 - val_mae: 2.1043\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 0s 915us/step - loss: 7.2637 - mae: 1.9657 - val_loss: 8.7274 - val_mae: 2.2847\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 0s 812us/step - loss: 7.3526 - mae: 1.9783 - val_loss: 8.2403 - val_mae: 2.1139\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 0s 785us/step - loss: 7.2263 - mae: 1.9763 - val_loss: 8.5596 - val_mae: 2.1402\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 0s 794us/step - loss: 7.1715 - mae: 1.9547 - val_loss: 8.4143 - val_mae: 2.0661\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 0s 835us/step - loss: 7.0481 - mae: 1.9475 - val_loss: 8.5294 - val_mae: 2.1938\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 0s 896us/step - loss: 7.1146 - mae: 1.9450 - val_loss: 8.4255 - val_mae: 2.1497\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 0s 824us/step - loss: 7.1068 - mae: 1.9575 - val_loss: 8.5837 - val_mae: 1.9921\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 0s 841us/step - loss: 7.1745 - mae: 1.9246 - val_loss: 8.5095 - val_mae: 2.0496\n",
      "Epoch 27/100\n",
      "69/69 [==============================] - 0s 804us/step - loss: 7.0921 - mae: 1.9428 - val_loss: 8.8074 - val_mae: 2.1729\n",
      "Epoch 27: early stopping\n",
      "Test Loss (MSE): 10.650571823120117, Test Mean Absolute Error (MAE): 2.403500556945801\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 9.1480 - mae: 2.1259 - val_loss: 9.9949 - val_mae: 2.0824\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 0s 885us/step - loss: 8.0039 - mae: 2.0527 - val_loss: 9.5395 - val_mae: 2.1760\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 0s 833us/step - loss: 7.8602 - mae: 2.0605 - val_loss: 9.5750 - val_mae: 2.0139\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 0s 887us/step - loss: 7.6530 - mae: 2.0307 - val_loss: 9.2312 - val_mae: 2.1926\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 0s 926us/step - loss: 7.5879 - mae: 2.0278 - val_loss: 9.4586 - val_mae: 2.3125\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 0s 895us/step - loss: 7.5287 - mae: 2.0560 - val_loss: 9.4937 - val_mae: 2.3877\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 0s 879us/step - loss: 7.4828 - mae: 2.0562 - val_loss: 9.1597 - val_mae: 2.1883\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 0s 859us/step - loss: 7.4692 - mae: 2.0319 - val_loss: 9.3427 - val_mae: 2.3077\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 0s 875us/step - loss: 7.4406 - mae: 2.0346 - val_loss: 9.2024 - val_mae: 2.2529\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 0s 889us/step - loss: 7.3483 - mae: 2.0209 - val_loss: 9.1553 - val_mae: 2.1950\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 0s 869us/step - loss: 7.2974 - mae: 2.0192 - val_loss: 9.2843 - val_mae: 2.0932\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 0s 862us/step - loss: 7.3391 - mae: 2.0156 - val_loss: 9.3031 - val_mae: 2.2172\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 0s 853us/step - loss: 7.3267 - mae: 2.0311 - val_loss: 9.2660 - val_mae: 2.1850\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 0s 904us/step - loss: 7.2846 - mae: 2.0164 - val_loss: 9.4302 - val_mae: 2.3531\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 0s 835us/step - loss: 7.3134 - mae: 2.0155 - val_loss: 9.2569 - val_mae: 2.2243\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 0s 878us/step - loss: 7.2502 - mae: 2.0279 - val_loss: 9.4829 - val_mae: 2.2443\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 0s 875us/step - loss: 7.1847 - mae: 2.0051 - val_loss: 9.4023 - val_mae: 2.2234\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 0s 948us/step - loss: 7.1467 - mae: 2.0070 - val_loss: 9.5669 - val_mae: 2.1601\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 0s 900us/step - loss: 7.1822 - mae: 1.9920 - val_loss: 9.7054 - val_mae: 2.2627\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 0s 889us/step - loss: 7.0479 - mae: 1.9709 - val_loss: 9.3303 - val_mae: 2.1978\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 0s 896us/step - loss: 7.1676 - mae: 2.0034 - val_loss: 9.4748 - val_mae: 2.2026\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 0s 954us/step - loss: 7.0778 - mae: 1.9741 - val_loss: 9.5630 - val_mae: 2.1923\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 6.9793 - mae: 1.9782 - val_loss: 9.4525 - val_mae: 2.1154\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 0s 900us/step - loss: 7.1905 - mae: 2.0047 - val_loss: 9.8330 - val_mae: 2.1950\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 0s 826us/step - loss: 7.0409 - mae: 1.9746 - val_loss: 9.8835 - val_mae: 2.2942\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 6.9368 - mae: 1.9517 - val_loss: 9.5788 - val_mae: 2.1395\n",
      "Epoch 27/100\n",
      "69/69 [==============================] - 0s 976us/step - loss: 6.9492 - mae: 1.9404 - val_loss: 9.5435 - val_mae: 2.1996\n",
      "Epoch 28/100\n",
      "69/69 [==============================] - 0s 965us/step - loss: 6.9233 - mae: 1.9576 - val_loss: 10.0279 - val_mae: 2.3498\n",
      "Epoch 29/100\n",
      "69/69 [==============================] - 0s 938us/step - loss: 6.8968 - mae: 1.9560 - val_loss: 9.6653 - val_mae: 2.2568\n",
      "Epoch 30/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 6.8135 - mae: 1.9381 - val_loss: 10.3171 - val_mae: 2.3394\n",
      "Epoch 30: early stopping\n",
      "Test Loss (MSE): 8.749476432800293, Test Mean Absolute Error (MAE): 2.177833080291748\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 9.5764 - mae: 2.1269 - val_loss: 9.0514 - val_mae: 2.1704\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 0s 862us/step - loss: 8.4147 - mae: 2.0563 - val_loss: 8.8582 - val_mae: 2.0596\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 0s 899us/step - loss: 8.0503 - mae: 2.0710 - val_loss: 8.6146 - val_mae: 2.1699\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 0s 867us/step - loss: 7.8733 - mae: 2.0618 - val_loss: 8.8336 - val_mae: 2.2636\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 0s 949us/step - loss: 7.7943 - mae: 2.0552 - val_loss: 8.4937 - val_mae: 2.0857\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 0s 878us/step - loss: 7.7865 - mae: 2.0342 - val_loss: 8.7169 - val_mae: 2.2574\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 0s 856us/step - loss: 7.5874 - mae: 2.0202 - val_loss: 8.7426 - val_mae: 2.1816\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 0s 871us/step - loss: 7.6471 - mae: 2.0209 - val_loss: 8.6484 - val_mae: 2.1153\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 0s 935us/step - loss: 7.5273 - mae: 2.0146 - val_loss: 8.7167 - val_mae: 2.0670\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 0s 879us/step - loss: 7.5779 - mae: 1.9824 - val_loss: 8.6887 - val_mae: 2.1594\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 0s 900us/step - loss: 7.3876 - mae: 1.9920 - val_loss: 8.5823 - val_mae: 2.2083\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 0s 869us/step - loss: 7.4184 - mae: 2.0258 - val_loss: 8.9396 - val_mae: 2.2678\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 0s 850us/step - loss: 7.3830 - mae: 1.9776 - val_loss: 8.7669 - val_mae: 2.1554\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 0s 995us/step - loss: 7.3797 - mae: 1.9617 - val_loss: 8.9382 - val_mae: 2.2775\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 0s 902us/step - loss: 7.3810 - mae: 1.9754 - val_loss: 9.1578 - val_mae: 2.0951\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 0s 841us/step - loss: 7.2239 - mae: 1.9290 - val_loss: 9.1935 - val_mae: 2.1846\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 0s 867us/step - loss: 7.2944 - mae: 1.9389 - val_loss: 9.1301 - val_mae: 2.0698\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 0s 864us/step - loss: 7.0040 - mae: 1.9033 - val_loss: 9.2944 - val_mae: 2.2189\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 0s 977us/step - loss: 7.2492 - mae: 1.8979 - val_loss: 9.2681 - val_mae: 2.1697\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 0s 885us/step - loss: 7.0913 - mae: 1.8923 - val_loss: 9.6346 - val_mae: 2.3080\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 0s 853us/step - loss: 7.0068 - mae: 1.8819 - val_loss: 10.1114 - val_mae: 2.3139\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 0s 863us/step - loss: 7.0555 - mae: 1.8730 - val_loss: 9.6962 - val_mae: 2.1537\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 0s 929us/step - loss: 6.6956 - mae: 1.8066 - val_loss: 10.1084 - val_mae: 2.3100\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 0s 907us/step - loss: 6.8891 - mae: 1.8392 - val_loss: 9.9319 - val_mae: 2.2233\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 0s 841us/step - loss: 6.8114 - mae: 1.8116 - val_loss: 9.6261 - val_mae: 2.1030\n",
      "Epoch 25: early stopping\n",
      "Test Loss (MSE): 9.734539985656738, Test Mean Absolute Error (MAE): 2.04262638092041\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 5.8438 - mae: 1.3548 - val_loss: 4.6555 - val_mae: 1.2415\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 739us/step - loss: 5.1627 - mae: 1.3356 - val_loss: 4.6035 - val_mae: 1.3214\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 725us/step - loss: 4.9800 - mae: 1.3126 - val_loss: 4.4274 - val_mae: 1.3353\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 701us/step - loss: 4.9843 - mae: 1.3312 - val_loss: 4.4228 - val_mae: 1.1706\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 788us/step - loss: 4.9581 - mae: 1.3103 - val_loss: 4.6530 - val_mae: 1.5186\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 738us/step - loss: 4.9488 - mae: 1.3233 - val_loss: 4.3563 - val_mae: 1.2461\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 690us/step - loss: 4.9002 - mae: 1.3024 - val_loss: 4.3864 - val_mae: 1.3248\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 771us/step - loss: 4.8952 - mae: 1.3223 - val_loss: 4.3774 - val_mae: 1.1354\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 751us/step - loss: 4.8683 - mae: 1.3208 - val_loss: 4.3620 - val_mae: 1.1702\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 759us/step - loss: 4.8844 - mae: 1.3130 - val_loss: 4.3647 - val_mae: 1.1816\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 884us/step - loss: 4.9083 - mae: 1.3115 - val_loss: 4.5127 - val_mae: 1.2626\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 791us/step - loss: 4.8730 - mae: 1.3151 - val_loss: 4.3812 - val_mae: 1.2565\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 820us/step - loss: 4.8688 - mae: 1.3080 - val_loss: 4.3586 - val_mae: 1.2654\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 739us/step - loss: 4.8338 - mae: 1.3131 - val_loss: 4.4241 - val_mae: 1.2825\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 699us/step - loss: 4.8572 - mae: 1.3122 - val_loss: 4.3775 - val_mae: 1.2826\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 723us/step - loss: 4.8419 - mae: 1.3111 - val_loss: 4.4249 - val_mae: 1.1179\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 698us/step - loss: 4.8387 - mae: 1.3098 - val_loss: 4.3523 - val_mae: 1.2288\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 704us/step - loss: 4.8530 - mae: 1.3087 - val_loss: 4.4640 - val_mae: 1.3202\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 733us/step - loss: 4.8528 - mae: 1.3063 - val_loss: 4.3866 - val_mae: 1.2732\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 714us/step - loss: 4.8240 - mae: 1.3029 - val_loss: 4.5185 - val_mae: 1.3000\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 718us/step - loss: 4.8208 - mae: 1.3062 - val_loss: 4.4354 - val_mae: 1.2029\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 762us/step - loss: 4.8124 - mae: 1.3027 - val_loss: 4.4399 - val_mae: 1.2291\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 708us/step - loss: 4.8053 - mae: 1.3011 - val_loss: 4.3648 - val_mae: 1.2223\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 705us/step - loss: 4.8149 - mae: 1.3029 - val_loss: 4.4186 - val_mae: 1.1944\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 734us/step - loss: 4.8184 - mae: 1.3009 - val_loss: 4.3883 - val_mae: 1.2093\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 693us/step - loss: 4.8075 - mae: 1.3018 - val_loss: 4.4793 - val_mae: 1.3285\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 724us/step - loss: 4.8265 - mae: 1.2931 - val_loss: 4.3715 - val_mae: 1.2145\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 735us/step - loss: 4.8324 - mae: 1.2961 - val_loss: 4.3571 - val_mae: 1.2631\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 707us/step - loss: 4.7882 - mae: 1.3012 - val_loss: 4.4003 - val_mae: 1.2478\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 709us/step - loss: 4.8126 - mae: 1.2948 - val_loss: 4.3929 - val_mae: 1.1253\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 703us/step - loss: 4.7929 - mae: 1.2930 - val_loss: 4.3793 - val_mae: 1.1489\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 711us/step - loss: 4.7938 - mae: 1.2919 - val_loss: 4.4061 - val_mae: 1.1205\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 693us/step - loss: 4.7968 - mae: 1.2896 - val_loss: 4.3749 - val_mae: 1.1760\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 741us/step - loss: 4.7747 - mae: 1.2905 - val_loss: 4.3856 - val_mae: 1.1713\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 703us/step - loss: 4.7928 - mae: 1.2932 - val_loss: 4.4107 - val_mae: 1.1480\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 715us/step - loss: 4.7822 - mae: 1.2978 - val_loss: 4.3977 - val_mae: 1.2372\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 743us/step - loss: 4.7650 - mae: 1.2909 - val_loss: 4.3558 - val_mae: 1.1637\n",
      "Epoch 37: early stopping\n",
      "Test Loss (MSE): 4.249427795410156, Test Mean Absolute Error (MAE): 1.2333487272262573\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 5.4722 - mae: 1.3025 - val_loss: 5.0576 - val_mae: 1.1741\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 0s 776us/step - loss: 4.9170 - mae: 1.2610 - val_loss: 5.0546 - val_mae: 1.3505\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 0s 703us/step - loss: 4.8137 - mae: 1.2782 - val_loss: 4.9024 - val_mae: 1.2779\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 0s 762us/step - loss: 4.7919 - mae: 1.2743 - val_loss: 4.8064 - val_mae: 1.2403\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 0s 765us/step - loss: 4.7344 - mae: 1.2640 - val_loss: 4.7695 - val_mae: 1.2555\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 0s 756us/step - loss: 4.7773 - mae: 1.2734 - val_loss: 4.7924 - val_mae: 1.2506\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 0s 882us/step - loss: 4.7128 - mae: 1.2827 - val_loss: 4.7681 - val_mae: 1.3127\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 0s 737us/step - loss: 4.6781 - mae: 1.2775 - val_loss: 4.7301 - val_mae: 1.2411\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 0s 781us/step - loss: 4.6924 - mae: 1.2498 - val_loss: 4.7574 - val_mae: 1.3086\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 0s 891us/step - loss: 4.6830 - mae: 1.2636 - val_loss: 4.7556 - val_mae: 1.3055\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 0s 821us/step - loss: 4.6483 - mae: 1.2685 - val_loss: 4.7875 - val_mae: 1.2530\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 0s 865us/step - loss: 4.6519 - mae: 1.2561 - val_loss: 4.7884 - val_mae: 1.2757\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 0s 987us/step - loss: 4.6118 - mae: 1.2485 - val_loss: 4.8365 - val_mae: 1.3499\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 0s 817us/step - loss: 4.6168 - mae: 1.2563 - val_loss: 4.8119 - val_mae: 1.2804\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 0s 771us/step - loss: 4.6346 - mae: 1.2698 - val_loss: 4.8536 - val_mae: 1.1536\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 0s 813us/step - loss: 4.5954 - mae: 1.2531 - val_loss: 4.7751 - val_mae: 1.2982\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 0s 775us/step - loss: 4.5925 - mae: 1.2470 - val_loss: 4.7973 - val_mae: 1.2171\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 0s 768us/step - loss: 4.5736 - mae: 1.2454 - val_loss: 4.8017 - val_mae: 1.2559\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 0s 801us/step - loss: 4.5823 - mae: 1.2494 - val_loss: 4.8574 - val_mae: 1.2409\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 0s 781us/step - loss: 4.5829 - mae: 1.2469 - val_loss: 4.8551 - val_mae: 1.3118\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 0s 747us/step - loss: 4.6039 - mae: 1.2393 - val_loss: 4.8697 - val_mae: 1.2507\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 0s 778us/step - loss: 4.5661 - mae: 1.2532 - val_loss: 4.8381 - val_mae: 1.2514\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 0s 779us/step - loss: 4.5843 - mae: 1.2410 - val_loss: 4.8509 - val_mae: 1.3601\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 0s 780us/step - loss: 4.6200 - mae: 1.2638 - val_loss: 4.8279 - val_mae: 1.2507\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 0s 787us/step - loss: 4.5480 - mae: 1.2436 - val_loss: 4.8666 - val_mae: 1.2954\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 0s 756us/step - loss: 4.5488 - mae: 1.2356 - val_loss: 4.8193 - val_mae: 1.2814\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 0s 758us/step - loss: 4.5603 - mae: 1.2469 - val_loss: 5.0888 - val_mae: 1.4739\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 0s 835us/step - loss: 4.5073 - mae: 1.2289 - val_loss: 4.9058 - val_mae: 1.2877\n",
      "Epoch 28: early stopping\n",
      "Test Loss (MSE): 4.25016975402832, Test Mean Absolute Error (MAE): 1.226455807685852\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 5.8920 - mae: 1.3841 - val_loss: 4.5264 - val_mae: 1.1763\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 791us/step - loss: 5.1116 - mae: 1.3580 - val_loss: 4.2909 - val_mae: 1.1276\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 894us/step - loss: 4.9947 - mae: 1.3595 - val_loss: 4.1479 - val_mae: 1.1255\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 790us/step - loss: 4.8914 - mae: 1.3487 - val_loss: 4.3141 - val_mae: 1.0859\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 832us/step - loss: 4.8822 - mae: 1.3555 - val_loss: 4.2075 - val_mae: 1.1122\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 787us/step - loss: 4.9286 - mae: 1.3461 - val_loss: 4.4941 - val_mae: 1.0395\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 839us/step - loss: 4.8554 - mae: 1.3572 - val_loss: 4.3439 - val_mae: 1.1874\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 972us/step - loss: 4.8490 - mae: 1.3479 - val_loss: 4.2271 - val_mae: 0.9664\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 862us/step - loss: 4.8037 - mae: 1.3388 - val_loss: 4.2516 - val_mae: 1.1540\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 890us/step - loss: 4.8087 - mae: 1.3264 - val_loss: 4.1453 - val_mae: 1.1666\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 796us/step - loss: 4.7320 - mae: 1.3308 - val_loss: 4.2653 - val_mae: 1.0823\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 765us/step - loss: 4.7337 - mae: 1.3127 - val_loss: 4.2227 - val_mae: 1.1576\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 824us/step - loss: 4.7185 - mae: 1.3268 - val_loss: 4.3234 - val_mae: 1.0320\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 779us/step - loss: 4.6814 - mae: 1.3119 - val_loss: 4.4236 - val_mae: 1.1519\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 776us/step - loss: 4.7593 - mae: 1.3254 - val_loss: 4.3269 - val_mae: 1.0866\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 802us/step - loss: 4.7508 - mae: 1.3175 - val_loss: 4.2967 - val_mae: 1.1284\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 783us/step - loss: 4.6423 - mae: 1.3093 - val_loss: 4.3065 - val_mae: 1.1169\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 761us/step - loss: 4.6567 - mae: 1.2997 - val_loss: 4.2830 - val_mae: 1.0888\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 836us/step - loss: 4.7355 - mae: 1.3187 - val_loss: 4.4113 - val_mae: 1.1993\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 763us/step - loss: 4.6559 - mae: 1.3045 - val_loss: 4.4200 - val_mae: 0.9655\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 755us/step - loss: 4.6645 - mae: 1.2903 - val_loss: 4.4687 - val_mae: 1.0841\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 789us/step - loss: 4.6767 - mae: 1.2987 - val_loss: 4.4364 - val_mae: 1.0878\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 758us/step - loss: 4.6329 - mae: 1.2855 - val_loss: 4.4736 - val_mae: 1.1514\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 772us/step - loss: 4.6294 - mae: 1.2932 - val_loss: 4.5462 - val_mae: 1.1266\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 834us/step - loss: 4.6642 - mae: 1.2926 - val_loss: 4.6517 - val_mae: 1.1782\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 772us/step - loss: 4.6053 - mae: 1.2896 - val_loss: 4.5944 - val_mae: 1.1618\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 770us/step - loss: 4.6355 - mae: 1.2887 - val_loss: 4.6515 - val_mae: 1.1812\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 799us/step - loss: 4.5939 - mae: 1.2879 - val_loss: 4.5270 - val_mae: 1.1192\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 765us/step - loss: 4.6378 - mae: 1.2838 - val_loss: 4.5763 - val_mae: 1.1636\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 757us/step - loss: 4.5695 - mae: 1.2869 - val_loss: 4.7014 - val_mae: 1.1510\n",
      "Epoch 30: early stopping\n",
      "Test Loss (MSE): 5.0577216148376465, Test Mean Absolute Error (MAE): 1.2918976545333862\n",
      "Epoch 1/100\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 5.9779 - mae: 1.3266 - val_loss: 4.9967 - val_mae: 1.2761\n",
      "Epoch 2/100\n",
      "131/131 [==============================] - 0s 805us/step - loss: 5.1597 - mae: 1.2979 - val_loss: 4.7679 - val_mae: 1.2549\n",
      "Epoch 3/100\n",
      "131/131 [==============================] - 0s 831us/step - loss: 5.0563 - mae: 1.2802 - val_loss: 4.6679 - val_mae: 1.2109\n",
      "Epoch 4/100\n",
      "131/131 [==============================] - 0s 784us/step - loss: 4.9842 - mae: 1.2933 - val_loss: 4.6280 - val_mae: 1.2641\n",
      "Epoch 5/100\n",
      "131/131 [==============================] - 0s 781us/step - loss: 4.8880 - mae: 1.2875 - val_loss: 4.6263 - val_mae: 1.2084\n",
      "Epoch 6/100\n",
      "131/131 [==============================] - 0s 862us/step - loss: 4.8053 - mae: 1.2568 - val_loss: 4.6077 - val_mae: 1.3251\n",
      "Epoch 7/100\n",
      "131/131 [==============================] - 0s 830us/step - loss: 4.8889 - mae: 1.2801 - val_loss: 4.6541 - val_mae: 1.1870\n",
      "Epoch 8/100\n",
      "131/131 [==============================] - 0s 791us/step - loss: 4.7935 - mae: 1.2539 - val_loss: 4.6191 - val_mae: 1.3587\n",
      "Epoch 9/100\n",
      "131/131 [==============================] - 0s 873us/step - loss: 4.8042 - mae: 1.2625 - val_loss: 4.6233 - val_mae: 1.1791\n",
      "Epoch 10/100\n",
      "131/131 [==============================] - 0s 850us/step - loss: 4.7450 - mae: 1.2555 - val_loss: 4.6455 - val_mae: 1.1848\n",
      "Epoch 11/100\n",
      "131/131 [==============================] - 0s 874us/step - loss: 4.7734 - mae: 1.2460 - val_loss: 4.6352 - val_mae: 1.2742\n",
      "Epoch 12/100\n",
      "131/131 [==============================] - 0s 992us/step - loss: 4.6832 - mae: 1.2453 - val_loss: 4.8091 - val_mae: 1.2567\n",
      "Epoch 13/100\n",
      "131/131 [==============================] - 0s 884us/step - loss: 4.6797 - mae: 1.2222 - val_loss: 4.7212 - val_mae: 1.2001\n",
      "Epoch 14/100\n",
      "131/131 [==============================] - 0s 823us/step - loss: 4.6415 - mae: 1.2342 - val_loss: 4.8996 - val_mae: 1.3467\n",
      "Epoch 15/100\n",
      "131/131 [==============================] - 0s 827us/step - loss: 4.6811 - mae: 1.2366 - val_loss: 4.9421 - val_mae: 1.2314\n",
      "Epoch 16/100\n",
      "131/131 [==============================] - 0s 802us/step - loss: 4.6854 - mae: 1.2350 - val_loss: 4.7572 - val_mae: 1.2279\n",
      "Epoch 17/100\n",
      "131/131 [==============================] - 0s 813us/step - loss: 4.6973 - mae: 1.2389 - val_loss: 4.7819 - val_mae: 1.2031\n",
      "Epoch 18/100\n",
      "131/131 [==============================] - 0s 847us/step - loss: 4.6174 - mae: 1.2284 - val_loss: 4.7426 - val_mae: 1.1929\n",
      "Epoch 19/100\n",
      "131/131 [==============================] - 0s 791us/step - loss: 4.6134 - mae: 1.2304 - val_loss: 4.8106 - val_mae: 1.1760\n",
      "Epoch 20/100\n",
      "131/131 [==============================] - 0s 791us/step - loss: 4.5568 - mae: 1.1988 - val_loss: 4.7740 - val_mae: 1.3035\n",
      "Epoch 21/100\n",
      "131/131 [==============================] - 0s 827us/step - loss: 4.5832 - mae: 1.2304 - val_loss: 4.8127 - val_mae: 1.2685\n",
      "Epoch 22/100\n",
      "131/131 [==============================] - 0s 780us/step - loss: 4.5685 - mae: 1.2175 - val_loss: 4.8384 - val_mae: 1.1596\n",
      "Epoch 23/100\n",
      "131/131 [==============================] - 0s 769us/step - loss: 4.5889 - mae: 1.2164 - val_loss: 4.7616 - val_mae: 1.1907\n",
      "Epoch 24/100\n",
      "131/131 [==============================] - 0s 840us/step - loss: 4.4768 - mae: 1.1968 - val_loss: 4.9766 - val_mae: 1.2014\n",
      "Epoch 25/100\n",
      "131/131 [==============================] - 0s 789us/step - loss: 4.5049 - mae: 1.1991 - val_loss: 4.9856 - val_mae: 1.2922\n",
      "Epoch 26/100\n",
      "131/131 [==============================] - 0s 804us/step - loss: 4.4461 - mae: 1.1981 - val_loss: 4.7980 - val_mae: 1.1760\n",
      "Epoch 26: early stopping\n",
      "Test Loss (MSE): 4.39275598526001, Test Mean Absolute Error (MAE): 1.1185864210128784\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 9.2768 - mae: 2.1532 - val_loss: 9.4422 - val_mae: 2.2830\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 0s 830us/step - loss: 8.3189 - mae: 2.1443 - val_loss: 9.1175 - val_mae: 2.1005\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 0s 800us/step - loss: 8.1689 - mae: 2.1248 - val_loss: 9.0101 - val_mae: 2.2829\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 0s 831us/step - loss: 8.0029 - mae: 2.1385 - val_loss: 8.8732 - val_mae: 2.1398\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 0s 768us/step - loss: 8.1024 - mae: 2.1198 - val_loss: 8.9438 - val_mae: 2.1247\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 0s 793us/step - loss: 7.9443 - mae: 2.1118 - val_loss: 9.2601 - val_mae: 2.0573\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 0s 776us/step - loss: 7.9521 - mae: 2.1269 - val_loss: 8.9134 - val_mae: 2.2581\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 0s 790us/step - loss: 7.9355 - mae: 2.1197 - val_loss: 9.1750 - val_mae: 2.0484\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 0s 818us/step - loss: 7.8285 - mae: 2.1098 - val_loss: 8.8220 - val_mae: 2.1812\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 0s 800us/step - loss: 7.8358 - mae: 2.1034 - val_loss: 8.8406 - val_mae: 2.1693\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 0s 807us/step - loss: 7.8269 - mae: 2.1092 - val_loss: 9.0936 - val_mae: 2.0590\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 0s 750us/step - loss: 7.7744 - mae: 2.0766 - val_loss: 8.8415 - val_mae: 2.2516\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 0s 805us/step - loss: 7.7494 - mae: 2.0996 - val_loss: 8.9310 - val_mae: 2.2605\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 7.8173 - mae: 2.1123 - val_loss: 8.8068 - val_mae: 2.2514\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 0s 845us/step - loss: 7.7641 - mae: 2.1065 - val_loss: 8.8938 - val_mae: 2.2975\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 0s 728us/step - loss: 7.8275 - mae: 2.0967 - val_loss: 9.0071 - val_mae: 2.1504\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 0s 725us/step - loss: 7.8281 - mae: 2.1045 - val_loss: 8.8638 - val_mae: 2.1873\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 0s 961us/step - loss: 7.7644 - mae: 2.1126 - val_loss: 8.8975 - val_mae: 2.1548\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 0s 816us/step - loss: 7.7451 - mae: 2.0823 - val_loss: 8.8415 - val_mae: 2.2000\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 0s 812us/step - loss: 7.7216 - mae: 2.1188 - val_loss: 8.8695 - val_mae: 2.2025\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 0s 842us/step - loss: 7.7884 - mae: 2.1074 - val_loss: 8.8709 - val_mae: 2.1636\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 0s 827us/step - loss: 7.7191 - mae: 2.1032 - val_loss: 8.8940 - val_mae: 2.1743\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 0s 822us/step - loss: 7.7417 - mae: 2.0921 - val_loss: 8.9155 - val_mae: 2.1477\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 0s 758us/step - loss: 7.7007 - mae: 2.1130 - val_loss: 8.8592 - val_mae: 2.2132\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 0s 762us/step - loss: 7.7063 - mae: 2.1012 - val_loss: 8.8837 - val_mae: 2.1937\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 0s 781us/step - loss: 7.7175 - mae: 2.0931 - val_loss: 8.9146 - val_mae: 2.1809\n",
      "Epoch 27/100\n",
      "69/69 [==============================] - 0s 752us/step - loss: 7.7606 - mae: 2.1018 - val_loss: 8.9585 - val_mae: 2.1365\n",
      "Epoch 28/100\n",
      "69/69 [==============================] - 0s 800us/step - loss: 7.7266 - mae: 2.1023 - val_loss: 8.9088 - val_mae: 2.2086\n",
      "Epoch 29/100\n",
      "69/69 [==============================] - 0s 774us/step - loss: 7.6852 - mae: 2.0852 - val_loss: 8.9795 - val_mae: 2.1296\n",
      "Epoch 30/100\n",
      "69/69 [==============================] - 0s 770us/step - loss: 7.7059 - mae: 2.0854 - val_loss: 8.9227 - val_mae: 2.2241\n",
      "Epoch 31/100\n",
      "69/69 [==============================] - 0s 831us/step - loss: 7.6909 - mae: 2.1050 - val_loss: 8.8993 - val_mae: 2.1810\n",
      "Epoch 32/100\n",
      "69/69 [==============================] - 0s 862us/step - loss: 7.6949 - mae: 2.0863 - val_loss: 8.9448 - val_mae: 2.1768\n",
      "Epoch 33/100\n",
      "69/69 [==============================] - 0s 800us/step - loss: 7.6710 - mae: 2.0933 - val_loss: 8.9417 - val_mae: 2.2600\n",
      "Epoch 34/100\n",
      "69/69 [==============================] - 0s 788us/step - loss: 7.6318 - mae: 2.0765 - val_loss: 8.9768 - val_mae: 2.2574\n",
      "Epoch 34: early stopping\n",
      "Test Loss (MSE): 7.278068542480469, Test Mean Absolute Error (MAE): 2.1161575317382812\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 9.6616 - mae: 2.1716 - val_loss: 8.3824 - val_mae: 1.8262\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 0s 859us/step - loss: 8.6634 - mae: 2.1286 - val_loss: 8.1283 - val_mae: 2.0582\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 0s 859us/step - loss: 8.5307 - mae: 2.1294 - val_loss: 8.2132 - val_mae: 1.8215\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 0s 825us/step - loss: 8.3260 - mae: 2.1066 - val_loss: 7.7987 - val_mae: 1.9765\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 0s 912us/step - loss: 8.2475 - mae: 2.0902 - val_loss: 7.9990 - val_mae: 2.1527\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 0s 848us/step - loss: 8.0770 - mae: 2.1035 - val_loss: 8.4128 - val_mae: 2.1667\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 0s 846us/step - loss: 8.1265 - mae: 2.1068 - val_loss: 7.8625 - val_mae: 2.0918\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 0s 850us/step - loss: 8.0087 - mae: 2.0853 - val_loss: 8.3326 - val_mae: 2.2501\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 0s 925us/step - loss: 7.9461 - mae: 2.1034 - val_loss: 8.1776 - val_mae: 2.1400\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 0s 863us/step - loss: 7.9732 - mae: 2.0849 - val_loss: 7.9551 - val_mae: 2.1281\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 0s 850us/step - loss: 7.9646 - mae: 2.0847 - val_loss: 7.9961 - val_mae: 2.1100\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 0s 838us/step - loss: 7.9337 - mae: 2.0781 - val_loss: 8.2239 - val_mae: 2.1928\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 0s 836us/step - loss: 7.8339 - mae: 2.0662 - val_loss: 8.3438 - val_mae: 2.2104\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 0s 917us/step - loss: 7.9610 - mae: 2.0779 - val_loss: 8.1760 - val_mae: 2.2051\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 0s 833us/step - loss: 7.8387 - mae: 2.0810 - val_loss: 8.0212 - val_mae: 2.1358\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 0s 817us/step - loss: 7.7550 - mae: 2.0463 - val_loss: 8.3138 - val_mae: 2.2567\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 0s 848us/step - loss: 7.7861 - mae: 2.0728 - val_loss: 7.8222 - val_mae: 1.9899\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 0s 843us/step - loss: 7.7864 - mae: 2.0627 - val_loss: 7.9205 - val_mae: 2.0238\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 0s 917us/step - loss: 7.7193 - mae: 2.0521 - val_loss: 7.9699 - val_mae: 2.0111\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 0s 845us/step - loss: 7.7803 - mae: 2.0407 - val_loss: 8.0003 - val_mae: 2.0996\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 0s 829us/step - loss: 7.7077 - mae: 2.0532 - val_loss: 8.5468 - val_mae: 2.2018\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 0s 937us/step - loss: 7.5074 - mae: 2.0183 - val_loss: 8.3067 - val_mae: 2.1221\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 0s 845us/step - loss: 7.6577 - mae: 2.0050 - val_loss: 8.5846 - val_mae: 2.2830\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 0s 804us/step - loss: 7.6355 - mae: 2.0301 - val_loss: 8.2020 - val_mae: 2.0838\n",
      "Epoch 24: early stopping\n",
      "Test Loss (MSE): 8.929866790771484, Test Mean Absolute Error (MAE): 2.2245891094207764\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 0s 2ms/step - loss: 9.3614 - mae: 2.1520 - val_loss: 8.5096 - val_mae: 1.9485\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 0s 871us/step - loss: 8.4653 - mae: 2.1181 - val_loss: 8.2790 - val_mae: 1.9042\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 0s 942us/step - loss: 8.0927 - mae: 2.0916 - val_loss: 8.1583 - val_mae: 2.0823\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 0s 852us/step - loss: 7.9055 - mae: 2.0808 - val_loss: 8.3002 - val_mae: 2.3068\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 0s 922us/step - loss: 7.8944 - mae: 2.1053 - val_loss: 7.9090 - val_mae: 2.0613\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 0s 851us/step - loss: 7.8839 - mae: 2.0802 - val_loss: 7.9455 - val_mae: 2.0852\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 0s 883us/step - loss: 7.8642 - mae: 2.0790 - val_loss: 8.1249 - val_mae: 1.9923\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 0s 892us/step - loss: 7.6108 - mae: 2.0687 - val_loss: 8.1805 - val_mae: 2.1185\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 0s 845us/step - loss: 7.6511 - mae: 2.0668 - val_loss: 8.2323 - val_mae: 2.1286\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 0s 838us/step - loss: 7.7104 - mae: 2.0645 - val_loss: 8.2723 - val_mae: 2.1206\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 0s 867us/step - loss: 7.6765 - mae: 2.0775 - val_loss: 8.0950 - val_mae: 1.9892\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 0s 837us/step - loss: 7.5122 - mae: 2.0360 - val_loss: 8.1206 - val_mae: 2.0772\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 0s 894us/step - loss: 7.4692 - mae: 2.0449 - val_loss: 8.1601 - val_mae: 2.0858\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 0s 874us/step - loss: 7.4989 - mae: 2.0180 - val_loss: 8.0734 - val_mae: 2.0355\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 0s 827us/step - loss: 7.3979 - mae: 2.0392 - val_loss: 8.2848 - val_mae: 2.0937\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 0s 828us/step - loss: 7.5358 - mae: 2.0385 - val_loss: 8.0918 - val_mae: 2.0038\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 0s 856us/step - loss: 7.4546 - mae: 2.0299 - val_loss: 8.2128 - val_mae: 2.0212\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 0s 919us/step - loss: 7.3966 - mae: 2.0249 - val_loss: 8.0755 - val_mae: 1.9888\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 0s 839us/step - loss: 7.5514 - mae: 2.0139 - val_loss: 8.0861 - val_mae: 2.0662\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 0s 839us/step - loss: 7.3677 - mae: 2.0415 - val_loss: 8.2576 - val_mae: 1.9831\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 0s 817us/step - loss: 7.2976 - mae: 1.9938 - val_loss: 8.3960 - val_mae: 2.1050\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 0s 844us/step - loss: 7.2869 - mae: 1.9778 - val_loss: 8.6141 - val_mae: 2.1790\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 0s 921us/step - loss: 7.3135 - mae: 2.0171 - val_loss: 8.2941 - val_mae: 2.0405\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 0s 827us/step - loss: 7.2274 - mae: 1.9870 - val_loss: 8.6183 - val_mae: 2.1473\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 0s 852us/step - loss: 7.3225 - mae: 1.9774 - val_loss: 8.3540 - val_mae: 2.1020\n",
      "Epoch 25: early stopping\n",
      "Test Loss (MSE): 9.265727996826172, Test Mean Absolute Error (MAE): 2.1859755516052246\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 9.8293 - mae: 2.1495 - val_loss: 8.6758 - val_mae: 2.1352\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 0s 871us/step - loss: 8.7792 - mae: 2.0823 - val_loss: 8.6639 - val_mae: 2.2285\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 0s 887us/step - loss: 8.5214 - mae: 2.0883 - val_loss: 8.6972 - val_mae: 1.9659\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 0s 853us/step - loss: 8.3610 - mae: 2.0594 - val_loss: 8.0900 - val_mae: 2.1152\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 0s 922us/step - loss: 8.1264 - mae: 2.0288 - val_loss: 8.2230 - val_mae: 2.2033\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 0s 837us/step - loss: 8.1185 - mae: 2.0674 - val_loss: 8.1207 - val_mae: 2.1645\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 0s 852us/step - loss: 8.0363 - mae: 2.0280 - val_loss: 8.1530 - val_mae: 2.1758\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 0s 869us/step - loss: 8.1196 - mae: 2.0486 - val_loss: 8.5041 - val_mae: 2.3036\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 0s 887us/step - loss: 7.9379 - mae: 2.0378 - val_loss: 8.4257 - val_mae: 2.0777\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 0s 891us/step - loss: 7.7953 - mae: 2.0098 - val_loss: 8.3257 - val_mae: 2.0698\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 0s 891us/step - loss: 7.7032 - mae: 1.9922 - val_loss: 8.2784 - val_mae: 2.1797\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 0s 880us/step - loss: 7.7153 - mae: 1.9936 - val_loss: 8.3633 - val_mae: 2.1599\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 0s 856us/step - loss: 7.7201 - mae: 1.9816 - val_loss: 8.4094 - val_mae: 2.1741\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 0s 876us/step - loss: 7.6078 - mae: 1.9438 - val_loss: 9.1522 - val_mae: 2.3698\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 0s 848us/step - loss: 7.5974 - mae: 1.9721 - val_loss: 8.7260 - val_mae: 2.0326\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 0s 847us/step - loss: 7.5152 - mae: 1.9241 - val_loss: 8.5746 - val_mae: 2.1468\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 0s 867us/step - loss: 7.3930 - mae: 1.9418 - val_loss: 8.8100 - val_mae: 2.1083\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 0s 946us/step - loss: 7.3701 - mae: 1.8920 - val_loss: 8.7597 - val_mae: 2.0817\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 0s 862us/step - loss: 7.1808 - mae: 1.8703 - val_loss: 8.7121 - val_mae: 2.2079\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 0s 851us/step - loss: 7.2055 - mae: 1.9106 - val_loss: 9.0177 - val_mae: 2.0675\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 0s 846us/step - loss: 7.0813 - mae: 1.8578 - val_loss: 9.0172 - val_mae: 2.2097\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 0s 826us/step - loss: 7.2330 - mae: 1.8739 - val_loss: 8.9893 - val_mae: 2.1018\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 0s 943us/step - loss: 6.9231 - mae: 1.8473 - val_loss: 9.6057 - val_mae: 2.3786\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 0s 810us/step - loss: 6.9402 - mae: 1.8395 - val_loss: 9.1024 - val_mae: 2.0739\n",
      "Epoch 24: early stopping\n",
      "Test Loss (MSE): 9.19021224975586, Test Mean Absolute Error (MAE): 2.0518100261688232\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.4735 - mae: 1.2819 - val_loss: 5.0392 - val_mae: 1.3636\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 851us/step - loss: 4.7893 - mae: 1.2779 - val_loss: 4.8818 - val_mae: 1.2728\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 908us/step - loss: 4.7133 - mae: 1.2600 - val_loss: 4.9837 - val_mae: 1.5521\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 865us/step - loss: 4.6966 - mae: 1.2709 - val_loss: 5.0333 - val_mae: 1.2492\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 876us/step - loss: 4.6348 - mae: 1.2615 - val_loss: 4.9211 - val_mae: 1.2773\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.6596 - mae: 1.2745 - val_loss: 4.8325 - val_mae: 1.2674\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 805us/step - loss: 4.6535 - mae: 1.2489 - val_loss: 4.7236 - val_mae: 1.3434\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 913us/step - loss: 4.6108 - mae: 1.2667 - val_loss: 4.7601 - val_mae: 1.4956\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.5877 - mae: 1.2529 - val_loss: 4.7017 - val_mae: 1.3345\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 987us/step - loss: 4.5800 - mae: 1.2473 - val_loss: 4.7697 - val_mae: 1.2889\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 956us/step - loss: 4.5671 - mae: 1.2562 - val_loss: 4.8918 - val_mae: 1.2395\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.6158 - mae: 1.2401 - val_loss: 4.7320 - val_mae: 1.3141\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 878us/step - loss: 4.5896 - mae: 1.2551 - val_loss: 4.6949 - val_mae: 1.3460\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 884us/step - loss: 4.5576 - mae: 1.2398 - val_loss: 4.6955 - val_mae: 1.3336\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 911us/step - loss: 4.5727 - mae: 1.2507 - val_loss: 4.7402 - val_mae: 1.2940\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 859us/step - loss: 4.5671 - mae: 1.2381 - val_loss: 4.7455 - val_mae: 1.3018\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 872us/step - loss: 4.5533 - mae: 1.2257 - val_loss: 4.7511 - val_mae: 1.3400\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 903us/step - loss: 4.5829 - mae: 1.2411 - val_loss: 4.7293 - val_mae: 1.3291\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 848us/step - loss: 4.5368 - mae: 1.2397 - val_loss: 4.7824 - val_mae: 1.2900\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 889us/step - loss: 4.5762 - mae: 1.2276 - val_loss: 4.7385 - val_mae: 1.4102\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 878us/step - loss: 4.5244 - mae: 1.2407 - val_loss: 4.7078 - val_mae: 1.3295\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 863us/step - loss: 4.5400 - mae: 1.2393 - val_loss: 4.7073 - val_mae: 1.3036\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 917us/step - loss: 4.5168 - mae: 1.2197 - val_loss: 4.7417 - val_mae: 1.2783\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 856us/step - loss: 4.5167 - mae: 1.2120 - val_loss: 4.7237 - val_mae: 1.3198\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 863us/step - loss: 4.4953 - mae: 1.2234 - val_loss: 4.7412 - val_mae: 1.3448\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 914us/step - loss: 4.5212 - mae: 1.2297 - val_loss: 4.7299 - val_mae: 1.3230\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 877us/step - loss: 4.5010 - mae: 1.2098 - val_loss: 4.7624 - val_mae: 1.3580\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 880us/step - loss: 4.5011 - mae: 1.2269 - val_loss: 4.7203 - val_mae: 1.3455\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 879us/step - loss: 4.4991 - mae: 1.2202 - val_loss: 4.7500 - val_mae: 1.3103\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 859us/step - loss: 4.4926 - mae: 1.2136 - val_loss: 4.7312 - val_mae: 1.3366\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 915us/step - loss: 4.4966 - mae: 1.2323 - val_loss: 4.7229 - val_mae: 1.3358\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 881us/step - loss: 4.5088 - mae: 1.2084 - val_loss: 4.7440 - val_mae: 1.3065\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 873us/step - loss: 4.4699 - mae: 1.2186 - val_loss: 4.7367 - val_mae: 1.3190\n",
      "Epoch 33: early stopping\n",
      "Test Loss (MSE): 5.467464447021484, Test Mean Absolute Error (MAE): 1.345790147781372\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.1683 - mae: 1.1708 - val_loss: 5.8562 - val_mae: 1.5432\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 866us/step - loss: 4.4108 - mae: 1.1334 - val_loss: 5.7049 - val_mae: 1.5295\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 938us/step - loss: 4.2939 - mae: 1.1442 - val_loss: 5.8557 - val_mae: 1.3236\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 858us/step - loss: 4.2922 - mae: 1.1392 - val_loss: 5.5972 - val_mae: 1.5234\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 874us/step - loss: 4.2452 - mae: 1.1289 - val_loss: 5.5687 - val_mae: 1.4679\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 926us/step - loss: 4.2042 - mae: 1.1378 - val_loss: 5.5525 - val_mae: 1.4521\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 900us/step - loss: 4.1614 - mae: 1.1305 - val_loss: 5.6473 - val_mae: 1.4275\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 900us/step - loss: 4.1346 - mae: 1.1128 - val_loss: 5.5586 - val_mae: 1.4870\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 955us/step - loss: 4.1462 - mae: 1.1237 - val_loss: 5.6056 - val_mae: 1.4184\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 871us/step - loss: 4.1315 - mae: 1.1278 - val_loss: 5.7477 - val_mae: 1.3486\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.1960 - mae: 1.1207 - val_loss: 5.5809 - val_mae: 1.4793\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 977us/step - loss: 4.1279 - mae: 1.1182 - val_loss: 5.6796 - val_mae: 1.5084\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 971us/step - loss: 4.1396 - mae: 1.1515 - val_loss: 5.7056 - val_mae: 1.4450\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.1019 - mae: 1.1178 - val_loss: 5.6192 - val_mae: 1.4805\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 891us/step - loss: 4.0859 - mae: 1.1261 - val_loss: 5.6153 - val_mae: 1.4709\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 864us/step - loss: 4.0581 - mae: 1.1226 - val_loss: 5.8344 - val_mae: 1.3833\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 920us/step - loss: 4.1093 - mae: 1.1081 - val_loss: 5.6057 - val_mae: 1.4451\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 873us/step - loss: 4.0683 - mae: 1.1255 - val_loss: 5.6899 - val_mae: 1.3847\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 870us/step - loss: 4.0813 - mae: 1.1156 - val_loss: 5.6091 - val_mae: 1.4559\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 908us/step - loss: 4.0723 - mae: 1.1258 - val_loss: 5.6807 - val_mae: 1.3760\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 882us/step - loss: 4.0584 - mae: 1.1028 - val_loss: 5.6319 - val_mae: 1.5131\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 870us/step - loss: 4.0708 - mae: 1.1253 - val_loss: 5.6395 - val_mae: 1.4282\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 917us/step - loss: 4.0720 - mae: 1.1352 - val_loss: 5.7548 - val_mae: 1.3917\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 862us/step - loss: 4.0608 - mae: 1.1053 - val_loss: 5.6786 - val_mae: 1.4534\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 843us/step - loss: 4.1085 - mae: 1.1262 - val_loss: 5.6573 - val_mae: 1.4466\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 915us/step - loss: 4.0499 - mae: 1.1209 - val_loss: 5.6727 - val_mae: 1.4172\n",
      "Epoch 26: early stopping\n",
      "Test Loss (MSE): 5.356666088104248, Test Mean Absolute Error (MAE): 1.330704689025879\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.5495 - mae: 1.2116 - val_loss: 5.0995 - val_mae: 1.4075\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 946us/step - loss: 4.6410 - mae: 1.1928 - val_loss: 4.9303 - val_mae: 1.2915\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.4932 - mae: 1.1958 - val_loss: 4.8136 - val_mae: 1.3658\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 918us/step - loss: 4.6105 - mae: 1.1992 - val_loss: 4.8276 - val_mae: 1.4066\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 916us/step - loss: 4.4608 - mae: 1.2045 - val_loss: 4.9877 - val_mae: 1.1713\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.4245 - mae: 1.1950 - val_loss: 4.8686 - val_mae: 1.2646\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 955us/step - loss: 4.4001 - mae: 1.1708 - val_loss: 4.9634 - val_mae: 1.5156\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 935us/step - loss: 4.4211 - mae: 1.1897 - val_loss: 4.8267 - val_mae: 1.3956\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.3292 - mae: 1.1818 - val_loss: 4.8459 - val_mae: 1.3390\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.3586 - mae: 1.2114 - val_loss: 4.9706 - val_mae: 1.2687\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.3599 - mae: 1.1819 - val_loss: 4.8370 - val_mae: 1.3695\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.3334 - mae: 1.1747 - val_loss: 4.8462 - val_mae: 1.3439\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.2756 - mae: 1.1642 - val_loss: 4.8724 - val_mae: 1.3124\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 970us/step - loss: 4.2973 - mae: 1.1657 - val_loss: 4.8879 - val_mae: 1.3783\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 927us/step - loss: 4.2183 - mae: 1.1583 - val_loss: 5.0320 - val_mae: 1.2868\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 916us/step - loss: 4.2340 - mae: 1.1532 - val_loss: 4.8429 - val_mae: 1.3389\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 972us/step - loss: 4.2059 - mae: 1.1393 - val_loss: 5.4001 - val_mae: 1.5686\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 925us/step - loss: 4.3311 - mae: 1.1772 - val_loss: 4.9379 - val_mae: 1.2708\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 917us/step - loss: 4.1998 - mae: 1.1671 - val_loss: 4.9278 - val_mae: 1.3216\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 969us/step - loss: 4.2186 - mae: 1.1443 - val_loss: 4.9238 - val_mae: 1.3569\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 932us/step - loss: 4.2005 - mae: 1.1469 - val_loss: 5.0297 - val_mae: 1.2719\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 940us/step - loss: 4.2174 - mae: 1.1519 - val_loss: 5.0842 - val_mae: 1.4354\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 992us/step - loss: 4.1891 - mae: 1.1461 - val_loss: 5.0164 - val_mae: 1.2494\n",
      "Epoch 23: early stopping\n",
      "Test Loss (MSE): 6.076637268066406, Test Mean Absolute Error (MAE): 1.3399046659469604\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 6.1970 - mae: 1.2666 - val_loss: 5.3552 - val_mae: 1.2956\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 982us/step - loss: 5.0229 - mae: 1.2156 - val_loss: 4.9675 - val_mae: 1.3486\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 899us/step - loss: 4.8017 - mae: 1.2187 - val_loss: 4.9321 - val_mae: 1.2851\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 942us/step - loss: 4.7089 - mae: 1.2221 - val_loss: 5.0071 - val_mae: 1.3110\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.7018 - mae: 1.2214 - val_loss: 4.9338 - val_mae: 1.4436\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 908us/step - loss: 4.6647 - mae: 1.2237 - val_loss: 4.9133 - val_mae: 1.3774\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.6156 - mae: 1.2038 - val_loss: 4.8478 - val_mae: 1.3693\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.6171 - mae: 1.2009 - val_loss: 5.0103 - val_mae: 1.4531\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.5786 - mae: 1.2089 - val_loss: 4.9759 - val_mae: 1.4375\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.5515 - mae: 1.1902 - val_loss: 5.1285 - val_mae: 1.5112\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.5368 - mae: 1.2092 - val_loss: 4.8533 - val_mae: 1.2892\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 949us/step - loss: 4.5535 - mae: 1.1884 - val_loss: 4.8081 - val_mae: 1.3496\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 967us/step - loss: 4.5665 - mae: 1.1982 - val_loss: 4.8908 - val_mae: 1.2800\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 919us/step - loss: 4.5551 - mae: 1.1967 - val_loss: 4.8664 - val_mae: 1.3572\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 962us/step - loss: 4.5524 - mae: 1.1970 - val_loss: 4.8895 - val_mae: 1.3183\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 935us/step - loss: 4.5634 - mae: 1.1775 - val_loss: 4.8915 - val_mae: 1.3343\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 953us/step - loss: 4.4989 - mae: 1.1764 - val_loss: 4.9200 - val_mae: 1.3918\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 969us/step - loss: 4.4969 - mae: 1.1842 - val_loss: 5.0585 - val_mae: 1.4839\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 941us/step - loss: 4.5082 - mae: 1.1874 - val_loss: 5.0054 - val_mae: 1.4095\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 932us/step - loss: 4.4935 - mae: 1.1669 - val_loss: 5.0989 - val_mae: 1.4896\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 988us/step - loss: 4.5305 - mae: 1.1904 - val_loss: 4.9468 - val_mae: 1.3501\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 926us/step - loss: 4.4760 - mae: 1.1700 - val_loss: 4.9744 - val_mae: 1.3909\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 972us/step - loss: 4.4777 - mae: 1.1620 - val_loss: 5.1022 - val_mae: 1.4540\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 953us/step - loss: 4.4869 - mae: 1.1692 - val_loss: 4.9818 - val_mae: 1.3719\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 957us/step - loss: 4.4722 - mae: 1.1660 - val_loss: 5.0828 - val_mae: 1.3758\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 979us/step - loss: 4.4842 - mae: 1.1585 - val_loss: 5.1197 - val_mae: 1.4670\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 949us/step - loss: 4.5219 - mae: 1.1630 - val_loss: 5.0755 - val_mae: 1.4014\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 949us/step - loss: 4.4646 - mae: 1.1709 - val_loss: 5.0176 - val_mae: 1.3783\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 945us/step - loss: 4.4263 - mae: 1.1525 - val_loss: 5.0591 - val_mae: 1.3449\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 910us/step - loss: 4.4513 - mae: 1.1448 - val_loss: 5.5899 - val_mae: 1.5834\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 938us/step - loss: 4.4177 - mae: 1.1378 - val_loss: 5.1285 - val_mae: 1.4034\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 972us/step - loss: 4.5082 - mae: 1.1635 - val_loss: 5.1956 - val_mae: 1.3514\n",
      "Epoch 32: early stopping\n",
      "Test Loss (MSE): 5.115363121032715, Test Mean Absolute Error (MAE): 1.2973277568817139\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.0622 - mae: 2.1626 - val_loss: 7.9818 - val_mae: 1.9490\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 949us/step - loss: 8.7899 - mae: 2.1634 - val_loss: 8.0742 - val_mae: 1.8482\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 912us/step - loss: 8.5558 - mae: 2.1291 - val_loss: 7.6028 - val_mae: 1.9935\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 930us/step - loss: 8.4967 - mae: 2.1363 - val_loss: 7.4416 - val_mae: 1.9457\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 991us/step - loss: 8.3892 - mae: 2.1326 - val_loss: 7.6014 - val_mae: 1.9954\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 958us/step - loss: 8.3979 - mae: 2.1546 - val_loss: 7.6027 - val_mae: 2.2189\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 915us/step - loss: 8.5840 - mae: 2.1416 - val_loss: 7.5215 - val_mae: 2.1741\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 899us/step - loss: 8.2934 - mae: 2.1238 - val_loss: 7.5465 - val_mae: 1.9108\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.2821 - mae: 2.1392 - val_loss: 7.3533 - val_mae: 2.0424\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 982us/step - loss: 8.2654 - mae: 2.1449 - val_loss: 7.4053 - val_mae: 1.9730\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 895us/step - loss: 8.3182 - mae: 2.1145 - val_loss: 7.3787 - val_mae: 2.0712\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 916us/step - loss: 8.2262 - mae: 2.1358 - val_loss: 7.6701 - val_mae: 1.9004\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 890us/step - loss: 8.2416 - mae: 2.1301 - val_loss: 7.3739 - val_mae: 1.9701\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.2135 - mae: 2.1211 - val_loss: 7.3720 - val_mae: 2.1334\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 937us/step - loss: 8.2165 - mae: 2.1329 - val_loss: 7.4237 - val_mae: 2.1377\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 935us/step - loss: 8.2279 - mae: 2.1386 - val_loss: 7.4904 - val_mae: 1.9160\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 933us/step - loss: 8.2204 - mae: 2.1257 - val_loss: 7.4106 - val_mae: 1.9952\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.2358 - mae: 2.1419 - val_loss: 7.3322 - val_mae: 2.0159\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 963us/step - loss: 8.1981 - mae: 2.1376 - val_loss: 7.3938 - val_mae: 2.1299\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 926us/step - loss: 8.1989 - mae: 2.1233 - val_loss: 7.4262 - val_mae: 2.1749\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 923us/step - loss: 8.1600 - mae: 2.1247 - val_loss: 7.3191 - val_mae: 2.0233\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 947us/step - loss: 8.1605 - mae: 2.1240 - val_loss: 7.3139 - val_mae: 2.0319\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.1824 - mae: 2.1472 - val_loss: 7.3414 - val_mae: 2.0244\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 900us/step - loss: 8.1771 - mae: 2.1112 - val_loss: 7.3439 - val_mae: 2.1134\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 912us/step - loss: 8.2012 - mae: 2.1404 - val_loss: 7.3326 - val_mae: 1.9974\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 923us/step - loss: 8.1269 - mae: 2.1360 - val_loss: 7.3638 - val_mae: 2.0120\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 930us/step - loss: 8.1687 - mae: 2.1313 - val_loss: 7.3399 - val_mae: 1.9886\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.1108 - mae: 2.1173 - val_loss: 7.3819 - val_mae: 1.9723\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 976us/step - loss: 8.1238 - mae: 2.1235 - val_loss: 7.3252 - val_mae: 2.0647\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 931us/step - loss: 8.1116 - mae: 2.1143 - val_loss: 7.3492 - val_mae: 2.1097\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 943us/step - loss: 8.1206 - mae: 2.1380 - val_loss: 7.3642 - val_mae: 1.9757\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 903us/step - loss: 8.1294 - mae: 2.1300 - val_loss: 7.3161 - val_mae: 2.0528\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.1442 - mae: 2.1214 - val_loss: 7.3534 - val_mae: 1.9820\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 945us/step - loss: 8.1470 - mae: 2.1485 - val_loss: 7.3956 - val_mae: 1.9741\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 923us/step - loss: 8.1189 - mae: 2.1149 - val_loss: 7.3287 - val_mae: 2.0415\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 968us/step - loss: 8.1280 - mae: 2.1213 - val_loss: 7.3653 - val_mae: 2.0394\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 979us/step - loss: 8.1384 - mae: 2.1233 - val_loss: 7.3447 - val_mae: 2.1031\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.1360 - mae: 2.1320 - val_loss: 7.3581 - val_mae: 2.0125\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 954us/step - loss: 8.1122 - mae: 2.1321 - val_loss: 7.3605 - val_mae: 2.0077\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 927us/step - loss: 8.1375 - mae: 2.1341 - val_loss: 7.3779 - val_mae: 2.0452\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 918us/step - loss: 8.1633 - mae: 2.1275 - val_loss: 7.3828 - val_mae: 2.0977\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.1146 - mae: 2.1292 - val_loss: 7.3816 - val_mae: 2.0841\n",
      "Epoch 42: early stopping\n",
      "Test Loss (MSE): 8.7413969039917, Test Mean Absolute Error (MAE): 2.2756311893463135\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 10.2917 - mae: 2.1634 - val_loss: 7.6495 - val_mae: 1.9453\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 923us/step - loss: 8.8150 - mae: 2.1427 - val_loss: 7.4295 - val_mae: 2.1495\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 958us/step - loss: 8.5808 - mae: 2.1297 - val_loss: 7.1016 - val_mae: 1.9230\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 937us/step - loss: 8.5122 - mae: 2.1439 - val_loss: 7.0150 - val_mae: 2.0571\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 993us/step - loss: 8.4245 - mae: 2.1207 - val_loss: 6.9537 - val_mae: 1.9836\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 937us/step - loss: 8.4010 - mae: 2.1488 - val_loss: 6.9586 - val_mae: 1.9127\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 920us/step - loss: 8.3728 - mae: 2.1063 - val_loss: 6.9242 - val_mae: 1.9788\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 904us/step - loss: 8.4411 - mae: 2.1473 - val_loss: 6.9409 - val_mae: 2.0287\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 928us/step - loss: 8.2824 - mae: 2.1365 - val_loss: 6.9521 - val_mae: 1.9087\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 8.3638 - mae: 2.1121 - val_loss: 6.9023 - val_mae: 1.9798\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 911us/step - loss: 8.3450 - mae: 2.1263 - val_loss: 7.0643 - val_mae: 2.0724\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 920us/step - loss: 8.2373 - mae: 2.0992 - val_loss: 7.4191 - val_mae: 2.2308\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 903us/step - loss: 8.2381 - mae: 2.1355 - val_loss: 7.0201 - val_mae: 2.0666\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 902us/step - loss: 8.1971 - mae: 2.1207 - val_loss: 6.8937 - val_mae: 1.9862\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 8.1774 - mae: 2.1140 - val_loss: 7.0596 - val_mae: 2.0747\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 900us/step - loss: 8.2418 - mae: 2.1176 - val_loss: 6.8876 - val_mae: 1.9701\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 935us/step - loss: 8.1886 - mae: 2.1359 - val_loss: 6.8988 - val_mae: 1.9763\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 925us/step - loss: 8.1439 - mae: 2.1245 - val_loss: 6.9254 - val_mae: 1.9118\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 8.2118 - mae: 2.1087 - val_loss: 6.9395 - val_mae: 1.9902\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 937us/step - loss: 8.1539 - mae: 2.1257 - val_loss: 6.9755 - val_mae: 2.0290\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 899us/step - loss: 8.1822 - mae: 2.1349 - val_loss: 6.9168 - val_mae: 1.9741\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 913us/step - loss: 8.2455 - mae: 2.1168 - val_loss: 6.9944 - val_mae: 2.0697\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 910us/step - loss: 8.1402 - mae: 2.1082 - val_loss: 6.9286 - val_mae: 1.9312\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 8.1472 - mae: 2.1026 - val_loss: 7.0034 - val_mae: 2.0730\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 944us/step - loss: 8.1804 - mae: 2.1407 - val_loss: 6.9680 - val_mae: 2.0472\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 871us/step - loss: 8.1360 - mae: 2.1218 - val_loss: 6.9647 - val_mae: 2.0430\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 894us/step - loss: 8.1072 - mae: 2.1264 - val_loss: 6.9149 - val_mae: 1.9672\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 964us/step - loss: 8.1036 - mae: 2.1290 - val_loss: 6.9530 - val_mae: 2.0158\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 8.1602 - mae: 2.1179 - val_loss: 6.8871 - val_mae: 1.9681\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 934us/step - loss: 8.1361 - mae: 2.1097 - val_loss: 6.9284 - val_mae: 1.9950\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 987us/step - loss: 8.1607 - mae: 2.1220 - val_loss: 6.9513 - val_mae: 1.9754\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 925us/step - loss: 8.1269 - mae: 2.1221 - val_loss: 7.0119 - val_mae: 2.0824\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 8.1195 - mae: 2.1237 - val_loss: 6.9799 - val_mae: 1.9976\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 902us/step - loss: 8.1089 - mae: 2.1269 - val_loss: 6.9942 - val_mae: 1.8893\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 947us/step - loss: 8.1185 - mae: 2.1040 - val_loss: 7.0303 - val_mae: 2.0570\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 8.1184 - mae: 2.1137 - val_loss: 6.9453 - val_mae: 1.9771\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 8.1185 - mae: 2.1235 - val_loss: 6.9881 - val_mae: 1.9071\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 8.1265 - mae: 2.1361 - val_loss: 6.9527 - val_mae: 1.9890\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 8.1224 - mae: 2.1045 - val_loss: 7.0168 - val_mae: 2.0547\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 8.0915 - mae: 2.1211 - val_loss: 6.9563 - val_mae: 2.0017\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 8.1244 - mae: 2.1214 - val_loss: 6.9464 - val_mae: 1.9157\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 8.0891 - mae: 2.1212 - val_loss: 6.9380 - val_mae: 1.9800\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 943us/step - loss: 8.0658 - mae: 2.1074 - val_loss: 6.9943 - val_mae: 2.0083\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 904us/step - loss: 8.0729 - mae: 2.1099 - val_loss: 6.9690 - val_mae: 1.9984\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 949us/step - loss: 8.0877 - mae: 2.1032 - val_loss: 7.0375 - val_mae: 2.0646\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 981us/step - loss: 8.0867 - mae: 2.1104 - val_loss: 7.0749 - val_mae: 2.0879\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 964us/step - loss: 8.1718 - mae: 2.1277 - val_loss: 6.9670 - val_mae: 2.0037\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 912us/step - loss: 8.1118 - mae: 2.1294 - val_loss: 6.9700 - val_mae: 1.9564\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 895us/step - loss: 8.0629 - mae: 2.0960 - val_loss: 6.9661 - val_mae: 1.9806\n",
      "Epoch 49: early stopping\n",
      "Test Loss (MSE): 8.833550453186035, Test Mean Absolute Error (MAE): 2.2481565475463867\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.5869 - mae: 2.1293 - val_loss: 8.6786 - val_mae: 2.0886\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 964us/step - loss: 8.3801 - mae: 2.0715 - val_loss: 8.6385 - val_mae: 1.8778\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 987us/step - loss: 8.2601 - mae: 2.0869 - val_loss: 8.1252 - val_mae: 2.0598\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 8.1154 - mae: 2.0679 - val_loss: 8.1291 - val_mae: 2.1767\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.9541 - mae: 2.0879 - val_loss: 7.9844 - val_mae: 2.0461\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.8974 - mae: 2.0757 - val_loss: 8.0793 - val_mae: 2.0290\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 995us/step - loss: 7.8739 - mae: 2.0661 - val_loss: 8.6594 - val_mae: 2.3761\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 969us/step - loss: 7.8184 - mae: 2.0621 - val_loss: 8.1027 - val_mae: 2.0194\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.9018 - mae: 2.0696 - val_loss: 8.0379 - val_mae: 2.1045\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.8078 - mae: 2.0584 - val_loss: 8.1419 - val_mae: 2.1133\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.8074 - mae: 2.0635 - val_loss: 8.0871 - val_mae: 2.1924\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.7805 - mae: 2.0728 - val_loss: 8.0758 - val_mae: 2.0810\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.8087 - mae: 2.0878 - val_loss: 8.1500 - val_mae: 2.1798\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.8126 - mae: 2.0620 - val_loss: 8.5204 - val_mae: 2.3524\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 989us/step - loss: 7.8491 - mae: 2.0697 - val_loss: 8.0030 - val_mae: 2.1028\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 978us/step - loss: 7.7656 - mae: 2.0603 - val_loss: 8.0145 - val_mae: 2.0912\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.7064 - mae: 2.0494 - val_loss: 8.0464 - val_mae: 2.0403\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 986us/step - loss: 7.7345 - mae: 2.0687 - val_loss: 8.0441 - val_mae: 2.0572\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.7240 - mae: 2.0823 - val_loss: 8.1435 - val_mae: 2.1114\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.7336 - mae: 2.0456 - val_loss: 8.2238 - val_mae: 2.0594\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 971us/step - loss: 7.7577 - mae: 2.0427 - val_loss: 8.3474 - val_mae: 1.9950\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 969us/step - loss: 7.5603 - mae: 2.0204 - val_loss: 8.5348 - val_mae: 2.1751\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 989us/step - loss: 7.6655 - mae: 2.0573 - val_loss: 8.6502 - val_mae: 1.9616\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.6518 - mae: 2.0086 - val_loss: 8.6819 - val_mae: 2.1498\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 971us/step - loss: 7.6423 - mae: 2.0095 - val_loss: 8.5227 - val_mae: 2.2540\n",
      "Epoch 25: early stopping\n",
      "Test Loss (MSE): 8.636913299560547, Test Mean Absolute Error (MAE): 2.329127073287964\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.4513 - mae: 2.2274 - val_loss: 9.2590 - val_mae: 2.0123\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 9.0247 - mae: 2.1384 - val_loss: 9.1331 - val_mae: 2.3603\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.3747 - mae: 2.1377 - val_loss: 8.5202 - val_mae: 2.1827\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.3045 - mae: 2.1230 - val_loss: 8.5980 - val_mae: 2.2352\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.2016 - mae: 2.1208 - val_loss: 8.3324 - val_mae: 2.0805\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.0870 - mae: 2.0981 - val_loss: 8.7928 - val_mae: 2.3075\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 991us/step - loss: 8.0788 - mae: 2.0958 - val_loss: 8.9373 - val_mae: 1.8871\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.0982 - mae: 2.0820 - val_loss: 8.8206 - val_mae: 2.3130\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.9742 - mae: 2.0900 - val_loss: 8.4660 - val_mae: 2.0484\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.9120 - mae: 2.0637 - val_loss: 8.7313 - val_mae: 2.0538\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 959us/step - loss: 7.7016 - mae: 2.0095 - val_loss: 9.0307 - val_mae: 2.0595\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.6538 - mae: 1.9782 - val_loss: 9.1180 - val_mae: 2.0850\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.4709 - mae: 1.9837 - val_loss: 9.1450 - val_mae: 2.0352\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.3999 - mae: 1.9477 - val_loss: 9.3483 - val_mae: 2.1705\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.3848 - mae: 1.9419 - val_loss: 9.4355 - val_mae: 2.1150\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.2050 - mae: 1.8816 - val_loss: 9.7354 - val_mae: 2.2127\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 994us/step - loss: 7.1455 - mae: 1.8787 - val_loss: 10.4612 - val_mae: 2.3547\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 6.8542 - mae: 1.8543 - val_loss: 9.9160 - val_mae: 2.1785\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 6.7186 - mae: 1.8068 - val_loss: 10.1603 - val_mae: 2.0995\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 6.5526 - mae: 1.7863 - val_loss: 10.6083 - val_mae: 2.3325\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 6.4520 - mae: 1.7538 - val_loss: 10.6682 - val_mae: 2.2058\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 6.4305 - mae: 1.7649 - val_loss: 10.6041 - val_mae: 2.2380\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 998us/step - loss: 6.0905 - mae: 1.7062 - val_loss: 10.1862 - val_mae: 2.1667\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 6.0591 - mae: 1.6852 - val_loss: 10.9259 - val_mae: 2.3156\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 992us/step - loss: 6.1124 - mae: 1.6880 - val_loss: 10.9706 - val_mae: 2.2056\n",
      "Epoch 25: early stopping\n",
      "Test Loss (MSE): 9.809098243713379, Test Mean Absolute Error (MAE): 2.07414174079895\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.3940 - mae: 1.2532 - val_loss: 5.8281 - val_mae: 1.5912\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 818us/step - loss: 4.6682 - mae: 1.2626 - val_loss: 5.5911 - val_mae: 1.4989\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 841us/step - loss: 4.6002 - mae: 1.2552 - val_loss: 5.5706 - val_mae: 1.5458\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 827us/step - loss: 4.5622 - mae: 1.2590 - val_loss: 5.5709 - val_mae: 1.3652\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 833us/step - loss: 4.5643 - mae: 1.2599 - val_loss: 5.5208 - val_mae: 1.3862\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 872us/step - loss: 4.5306 - mae: 1.2561 - val_loss: 5.5660 - val_mae: 1.3682\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 821us/step - loss: 4.5581 - mae: 1.2447 - val_loss: 5.6116 - val_mae: 1.3542\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 813us/step - loss: 4.5010 - mae: 1.2518 - val_loss: 5.4994 - val_mae: 1.4120\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 905us/step - loss: 4.5182 - mae: 1.2446 - val_loss: 5.5148 - val_mae: 1.3901\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 902us/step - loss: 4.5339 - mae: 1.2513 - val_loss: 5.4848 - val_mae: 1.4378\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 902us/step - loss: 4.4711 - mae: 1.2419 - val_loss: 5.4751 - val_mae: 1.4696\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 882us/step - loss: 4.5252 - mae: 1.2454 - val_loss: 5.5277 - val_mae: 1.4091\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 869us/step - loss: 4.4633 - mae: 1.2398 - val_loss: 5.4602 - val_mae: 1.4181\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.4497 - mae: 1.2311 - val_loss: 5.4660 - val_mae: 1.4105\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 893us/step - loss: 4.5123 - mae: 1.2443 - val_loss: 5.5297 - val_mae: 1.5207\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 950us/step - loss: 4.4596 - mae: 1.2408 - val_loss: 5.4701 - val_mae: 1.4167\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 976us/step - loss: 4.4533 - mae: 1.2293 - val_loss: 5.6524 - val_mae: 1.5671\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 879us/step - loss: 4.4724 - mae: 1.2462 - val_loss: 5.5200 - val_mae: 1.5387\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 828us/step - loss: 4.4704 - mae: 1.2484 - val_loss: 5.6305 - val_mae: 1.5214\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 810us/step - loss: 4.5342 - mae: 1.2540 - val_loss: 5.5521 - val_mae: 1.3634\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 829us/step - loss: 4.4701 - mae: 1.2366 - val_loss: 5.4839 - val_mae: 1.4516\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 819us/step - loss: 4.4548 - mae: 1.2312 - val_loss: 5.5308 - val_mae: 1.5107\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 829us/step - loss: 4.4634 - mae: 1.2520 - val_loss: 5.4828 - val_mae: 1.4411\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 867us/step - loss: 4.4243 - mae: 1.2316 - val_loss: 5.4849 - val_mae: 1.4225\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 801us/step - loss: 4.4684 - mae: 1.2303 - val_loss: 5.5106 - val_mae: 1.3848\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 820us/step - loss: 4.4337 - mae: 1.2319 - val_loss: 5.4712 - val_mae: 1.4791\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 854us/step - loss: 4.4575 - mae: 1.2233 - val_loss: 5.4743 - val_mae: 1.4368\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 804us/step - loss: 4.4387 - mae: 1.2401 - val_loss: 5.5801 - val_mae: 1.3414\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 856us/step - loss: 4.4404 - mae: 1.2262 - val_loss: 5.4569 - val_mae: 1.4303\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 802us/step - loss: 4.4435 - mae: 1.2364 - val_loss: 5.5139 - val_mae: 1.3448\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 804us/step - loss: 4.4670 - mae: 1.2216 - val_loss: 5.5000 - val_mae: 1.3754\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 851us/step - loss: 4.4193 - mae: 1.2327 - val_loss: 5.4900 - val_mae: 1.3718\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 820us/step - loss: 4.4203 - mae: 1.2122 - val_loss: 5.5616 - val_mae: 1.6184\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 853us/step - loss: 4.4371 - mae: 1.2352 - val_loss: 5.4792 - val_mae: 1.4288\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 828us/step - loss: 4.4404 - mae: 1.2356 - val_loss: 5.5275 - val_mae: 1.3703\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 780us/step - loss: 4.4285 - mae: 1.2243 - val_loss: 5.4645 - val_mae: 1.4525\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 845us/step - loss: 4.4365 - mae: 1.2308 - val_loss: 5.4857 - val_mae: 1.4276\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 782us/step - loss: 4.4578 - mae: 1.2266 - val_loss: 5.4606 - val_mae: 1.4629\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 844us/step - loss: 4.4223 - mae: 1.2366 - val_loss: 5.5298 - val_mae: 1.3387\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 802us/step - loss: 4.4346 - mae: 1.2280 - val_loss: 5.4549 - val_mae: 1.4398\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 851us/step - loss: 4.4604 - mae: 1.2321 - val_loss: 5.5189 - val_mae: 1.5496\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 814us/step - loss: 4.4686 - mae: 1.2496 - val_loss: 5.4680 - val_mae: 1.4585\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 831us/step - loss: 4.4193 - mae: 1.2277 - val_loss: 5.4866 - val_mae: 1.3939\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 849us/step - loss: 4.4398 - mae: 1.2406 - val_loss: 5.5615 - val_mae: 1.3221\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 794us/step - loss: 4.4363 - mae: 1.2201 - val_loss: 5.4576 - val_mae: 1.4532\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 818us/step - loss: 4.4300 - mae: 1.2335 - val_loss: 5.5073 - val_mae: 1.5108\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 822us/step - loss: 4.4229 - mae: 1.2371 - val_loss: 5.5056 - val_mae: 1.5131\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 803us/step - loss: 4.4337 - mae: 1.2335 - val_loss: 5.5020 - val_mae: 1.4799\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 836us/step - loss: 4.4144 - mae: 1.2278 - val_loss: 5.4699 - val_mae: 1.4345\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 823us/step - loss: 4.4239 - mae: 1.2312 - val_loss: 5.4756 - val_mae: 1.3801\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 867us/step - loss: 4.4251 - mae: 1.2323 - val_loss: 5.5152 - val_mae: 1.3599\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 832us/step - loss: 4.4344 - mae: 1.2144 - val_loss: 5.4759 - val_mae: 1.4197\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 832us/step - loss: 4.4080 - mae: 1.2241 - val_loss: 5.5270 - val_mae: 1.5207\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 852us/step - loss: 4.4281 - mae: 1.2337 - val_loss: 5.4880 - val_mae: 1.3854\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 800us/step - loss: 4.4090 - mae: 1.2154 - val_loss: 5.4926 - val_mae: 1.4231\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 809us/step - loss: 4.3980 - mae: 1.2276 - val_loss: 5.5202 - val_mae: 1.3774\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 810us/step - loss: 4.4210 - mae: 1.2272 - val_loss: 5.4958 - val_mae: 1.3989\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 824us/step - loss: 4.4209 - mae: 1.2157 - val_loss: 5.5202 - val_mae: 1.3535\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 857us/step - loss: 4.4305 - mae: 1.2150 - val_loss: 5.4939 - val_mae: 1.4198\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 810us/step - loss: 4.4128 - mae: 1.2202 - val_loss: 5.5131 - val_mae: 1.3895\n",
      "Epoch 60: early stopping\n",
      "Test Loss (MSE): 4.087080955505371, Test Mean Absolute Error (MAE): 1.1860369443893433\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.4600 - mae: 1.2533 - val_loss: 5.4414 - val_mae: 1.3719\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 863us/step - loss: 4.5782 - mae: 1.2286 - val_loss: 5.1155 - val_mae: 1.2656\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 888us/step - loss: 4.3924 - mae: 1.2419 - val_loss: 5.1186 - val_mae: 1.3605\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 878us/step - loss: 4.4327 - mae: 1.2451 - val_loss: 5.0160 - val_mae: 1.3089\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 934us/step - loss: 4.2709 - mae: 1.2312 - val_loss: 5.0585 - val_mae: 1.3572\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 878us/step - loss: 4.2732 - mae: 1.2262 - val_loss: 5.1440 - val_mae: 1.4008\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 944us/step - loss: 4.2882 - mae: 1.2241 - val_loss: 5.0698 - val_mae: 1.2304\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 944us/step - loss: 4.3300 - mae: 1.2220 - val_loss: 4.9942 - val_mae: 1.3743\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.2737 - mae: 1.2379 - val_loss: 4.9773 - val_mae: 1.3098\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 897us/step - loss: 4.2359 - mae: 1.2213 - val_loss: 5.1290 - val_mae: 1.1759\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 940us/step - loss: 4.2695 - mae: 1.2245 - val_loss: 5.0147 - val_mae: 1.2365\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 949us/step - loss: 4.1984 - mae: 1.2162 - val_loss: 5.0420 - val_mae: 1.2186\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.2399 - mae: 1.2117 - val_loss: 5.0484 - val_mae: 1.3623\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 986us/step - loss: 4.2561 - mae: 1.2275 - val_loss: 5.2053 - val_mae: 1.1847\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.1953 - mae: 1.2139 - val_loss: 5.0363 - val_mae: 1.2894\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 932us/step - loss: 4.2322 - mae: 1.2126 - val_loss: 5.1252 - val_mae: 1.1944\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 857us/step - loss: 4.2465 - mae: 1.2085 - val_loss: 5.0417 - val_mae: 1.2517\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 869us/step - loss: 4.2409 - mae: 1.2213 - val_loss: 5.0386 - val_mae: 1.2759\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 878us/step - loss: 4.2157 - mae: 1.2116 - val_loss: 5.0660 - val_mae: 1.2757\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 890us/step - loss: 4.1759 - mae: 1.2111 - val_loss: 5.1272 - val_mae: 1.2330\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 914us/step - loss: 4.2039 - mae: 1.2000 - val_loss: 5.1002 - val_mae: 1.2773\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 890us/step - loss: 4.1779 - mae: 1.1934 - val_loss: 5.0687 - val_mae: 1.3122\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 897us/step - loss: 4.2018 - mae: 1.2062 - val_loss: 5.1329 - val_mae: 1.3599\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 872us/step - loss: 4.2090 - mae: 1.2023 - val_loss: 5.0949 - val_mae: 1.2149\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 863us/step - loss: 4.1938 - mae: 1.2028 - val_loss: 5.1296 - val_mae: 1.3583\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 917us/step - loss: 4.1797 - mae: 1.2067 - val_loss: 5.0582 - val_mae: 1.2662\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 862us/step - loss: 4.1637 - mae: 1.1931 - val_loss: 5.1100 - val_mae: 1.2217\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 920us/step - loss: 4.1876 - mae: 1.1824 - val_loss: 5.1986 - val_mae: 1.3770\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 877us/step - loss: 4.1580 - mae: 1.2112 - val_loss: 5.0879 - val_mae: 1.3263\n",
      "Epoch 29: early stopping\n",
      "Test Loss (MSE): 5.714271068572998, Test Mean Absolute Error (MAE): 1.422980785369873\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 6.4170 - mae: 1.4071 - val_loss: 4.2156 - val_mae: 1.4165\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 916us/step - loss: 5.6400 - mae: 1.4249 - val_loss: 3.7492 - val_mae: 1.0829\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 945us/step - loss: 5.4317 - mae: 1.3901 - val_loss: 3.6587 - val_mae: 1.1278\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 897us/step - loss: 5.2935 - mae: 1.3685 - val_loss: 3.9131 - val_mae: 1.2068\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 915us/step - loss: 5.3219 - mae: 1.3795 - val_loss: 3.7087 - val_mae: 1.2538\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 887us/step - loss: 5.1858 - mae: 1.3581 - val_loss: 3.7691 - val_mae: 1.2363\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 919us/step - loss: 5.2867 - mae: 1.3686 - val_loss: 3.6390 - val_mae: 1.1326\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 910us/step - loss: 5.1554 - mae: 1.3545 - val_loss: 3.6953 - val_mae: 1.2528\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 975us/step - loss: 5.1979 - mae: 1.3627 - val_loss: 3.6711 - val_mae: 1.2398\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 940us/step - loss: 5.1626 - mae: 1.3618 - val_loss: 3.6530 - val_mae: 1.0299\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.1503 - mae: 1.3536 - val_loss: 3.6362 - val_mae: 1.1121\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 904us/step - loss: 5.1738 - mae: 1.3840 - val_loss: 3.6580 - val_mae: 1.1495\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.1669 - mae: 1.3597 - val_loss: 3.6345 - val_mae: 1.1606\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 978us/step - loss: 5.1747 - mae: 1.3646 - val_loss: 3.6684 - val_mae: 1.0799\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.1342 - mae: 1.3619 - val_loss: 3.6617 - val_mae: 1.1069\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.0934 - mae: 1.3444 - val_loss: 3.6444 - val_mae: 1.0310\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 999us/step - loss: 5.1705 - mae: 1.3556 - val_loss: 3.6678 - val_mae: 1.0212\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 896us/step - loss: 5.1649 - mae: 1.3751 - val_loss: 3.7598 - val_mae: 1.1331\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 930us/step - loss: 5.1742 - mae: 1.3804 - val_loss: 3.6929 - val_mae: 1.0764\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 909us/step - loss: 5.1301 - mae: 1.3491 - val_loss: 3.7393 - val_mae: 1.0601\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 918us/step - loss: 5.1135 - mae: 1.3605 - val_loss: 3.7174 - val_mae: 1.0682\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 890us/step - loss: 5.1008 - mae: 1.3533 - val_loss: 3.7187 - val_mae: 1.1335\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 911us/step - loss: 5.0871 - mae: 1.3429 - val_loss: 3.6868 - val_mae: 1.0949\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 923us/step - loss: 5.0594 - mae: 1.3498 - val_loss: 3.7468 - val_mae: 1.1388\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 935us/step - loss: 5.1019 - mae: 1.3483 - val_loss: 3.7090 - val_mae: 1.0114\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 915us/step - loss: 5.1100 - mae: 1.3355 - val_loss: 3.8324 - val_mae: 1.1975\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 920us/step - loss: 5.1309 - mae: 1.3554 - val_loss: 3.8329 - val_mae: 1.1284\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 908us/step - loss: 5.0564 - mae: 1.3662 - val_loss: 3.7472 - val_mae: 1.0794\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 899us/step - loss: 5.0504 - mae: 1.3508 - val_loss: 3.7700 - val_mae: 1.2352\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 909us/step - loss: 5.0365 - mae: 1.3441 - val_loss: 3.7957 - val_mae: 1.0689\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 915us/step - loss: 5.0522 - mae: 1.3329 - val_loss: 3.7746 - val_mae: 1.0739\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 927us/step - loss: 5.0335 - mae: 1.3378 - val_loss: 3.8204 - val_mae: 1.1302\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 930us/step - loss: 5.0677 - mae: 1.3454 - val_loss: 3.8580 - val_mae: 1.1794\n",
      "Epoch 33: early stopping\n",
      "Test Loss (MSE): 4.501652240753174, Test Mean Absolute Error (MAE): 1.2533246278762817\n",
      "Epoch 1/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 5.8104 - mae: 1.2569 - val_loss: 5.7040 - val_mae: 1.3670\n",
      "Epoch 2/100\n",
      "121/121 [==============================] - 0s 950us/step - loss: 4.6548 - mae: 1.1815 - val_loss: 5.3422 - val_mae: 1.3462\n",
      "Epoch 3/100\n",
      "121/121 [==============================] - 0s 900us/step - loss: 4.4807 - mae: 1.1987 - val_loss: 5.3638 - val_mae: 1.3963\n",
      "Epoch 4/100\n",
      "121/121 [==============================] - 0s 903us/step - loss: 4.4100 - mae: 1.1802 - val_loss: 5.3561 - val_mae: 1.2582\n",
      "Epoch 5/100\n",
      "121/121 [==============================] - 0s 883us/step - loss: 4.3654 - mae: 1.1946 - val_loss: 5.4141 - val_mae: 1.2551\n",
      "Epoch 6/100\n",
      "121/121 [==============================] - 0s 809us/step - loss: 4.4168 - mae: 1.1800 - val_loss: 5.3795 - val_mae: 1.3057\n",
      "Epoch 7/100\n",
      "121/121 [==============================] - 0s 955us/step - loss: 4.3579 - mae: 1.1907 - val_loss: 5.3151 - val_mae: 1.3433\n",
      "Epoch 8/100\n",
      "121/121 [==============================] - 0s 854us/step - loss: 4.3550 - mae: 1.1775 - val_loss: 5.3249 - val_mae: 1.3268\n",
      "Epoch 9/100\n",
      "121/121 [==============================] - 0s 992us/step - loss: 4.3540 - mae: 1.1878 - val_loss: 5.4265 - val_mae: 1.4515\n",
      "Epoch 10/100\n",
      "121/121 [==============================] - 0s 852us/step - loss: 4.2574 - mae: 1.1576 - val_loss: 5.4282 - val_mae: 1.4125\n",
      "Epoch 11/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.3657 - mae: 1.1673 - val_loss: 5.3909 - val_mae: 1.4410\n",
      "Epoch 12/100\n",
      "121/121 [==============================] - 0s 982us/step - loss: 4.2622 - mae: 1.1753 - val_loss: 5.6777 - val_mae: 1.5156\n",
      "Epoch 13/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.2862 - mae: 1.1742 - val_loss: 5.3200 - val_mae: 1.3511\n",
      "Epoch 14/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.2340 - mae: 1.1641 - val_loss: 5.3848 - val_mae: 1.4053\n",
      "Epoch 15/100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 4.2556 - mae: 1.1934 - val_loss: 5.4067 - val_mae: 1.2683\n",
      "Epoch 16/100\n",
      "121/121 [==============================] - 0s 895us/step - loss: 4.2485 - mae: 1.1567 - val_loss: 5.5319 - val_mae: 1.3869\n",
      "Epoch 17/100\n",
      "121/121 [==============================] - 0s 934us/step - loss: 4.2959 - mae: 1.1752 - val_loss: 5.3711 - val_mae: 1.3804\n",
      "Epoch 18/100\n",
      "121/121 [==============================] - 0s 901us/step - loss: 4.2944 - mae: 1.1995 - val_loss: 5.5634 - val_mae: 1.2644\n",
      "Epoch 19/100\n",
      "121/121 [==============================] - 0s 961us/step - loss: 4.2897 - mae: 1.1586 - val_loss: 5.5028 - val_mae: 1.4121\n",
      "Epoch 20/100\n",
      "121/121 [==============================] - 0s 918us/step - loss: 4.1950 - mae: 1.1665 - val_loss: 5.7116 - val_mae: 1.4756\n",
      "Epoch 21/100\n",
      "121/121 [==============================] - 0s 906us/step - loss: 4.2428 - mae: 1.1688 - val_loss: 5.7313 - val_mae: 1.4723\n",
      "Epoch 22/100\n",
      "121/121 [==============================] - 0s 900us/step - loss: 4.1667 - mae: 1.1632 - val_loss: 5.5273 - val_mae: 1.3974\n",
      "Epoch 23/100\n",
      "121/121 [==============================] - 0s 929us/step - loss: 4.2166 - mae: 1.1596 - val_loss: 5.5001 - val_mae: 1.3681\n",
      "Epoch 24/100\n",
      "121/121 [==============================] - 0s 876us/step - loss: 4.1591 - mae: 1.1510 - val_loss: 5.7258 - val_mae: 1.4432\n",
      "Epoch 25/100\n",
      "121/121 [==============================] - 0s 939us/step - loss: 4.1418 - mae: 1.1481 - val_loss: 5.5632 - val_mae: 1.3522\n",
      "Epoch 26/100\n",
      "121/121 [==============================] - 0s 899us/step - loss: 4.2022 - mae: 1.1697 - val_loss: 5.5191 - val_mae: 1.4333\n",
      "Epoch 27/100\n",
      "121/121 [==============================] - 0s 888us/step - loss: 4.1290 - mae: 1.1542 - val_loss: 5.9239 - val_mae: 1.5167\n",
      "Epoch 27: early stopping\n",
      "Test Loss (MSE): 5.703742980957031, Test Mean Absolute Error (MAE): 1.4427260160446167\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.5507 - mae: 2.1015 - val_loss: 9.1063 - val_mae: 2.1716\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 884us/step - loss: 8.1760 - mae: 2.0693 - val_loss: 8.5853 - val_mae: 2.1331\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 882us/step - loss: 8.0404 - mae: 2.0650 - val_loss: 9.0220 - val_mae: 2.0015\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 902us/step - loss: 7.8475 - mae: 2.0476 - val_loss: 8.7015 - val_mae: 2.0115\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 955us/step - loss: 7.8012 - mae: 2.0641 - val_loss: 8.4391 - val_mae: 2.0705\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 895us/step - loss: 7.8105 - mae: 2.0512 - val_loss: 8.4630 - val_mae: 2.2494\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 889us/step - loss: 7.7255 - mae: 2.0493 - val_loss: 8.3428 - val_mae: 2.1387\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 901us/step - loss: 7.7084 - mae: 2.0421 - val_loss: 8.3159 - val_mae: 2.0808\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 885us/step - loss: 7.7171 - mae: 2.0536 - val_loss: 8.4148 - val_mae: 2.2889\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 943us/step - loss: 7.7207 - mae: 2.0352 - val_loss: 8.4477 - val_mae: 2.3289\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 885us/step - loss: 7.7870 - mae: 2.0498 - val_loss: 8.3479 - val_mae: 2.2687\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 858us/step - loss: 7.6823 - mae: 2.0590 - val_loss: 8.4085 - val_mae: 2.0452\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 900us/step - loss: 7.6587 - mae: 2.0386 - val_loss: 8.3112 - val_mae: 2.1664\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 884us/step - loss: 7.6446 - mae: 2.0511 - val_loss: 8.2928 - val_mae: 2.2359\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 890us/step - loss: 7.6191 - mae: 2.0530 - val_loss: 8.4155 - val_mae: 2.3322\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 947us/step - loss: 7.6229 - mae: 2.0553 - val_loss: 8.2628 - val_mae: 2.1311\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 851us/step - loss: 7.5908 - mae: 2.0409 - val_loss: 8.3072 - val_mae: 2.1071\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 874us/step - loss: 7.6507 - mae: 2.0535 - val_loss: 8.2797 - val_mae: 2.1813\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 906us/step - loss: 7.6069 - mae: 2.0477 - val_loss: 8.3624 - val_mae: 2.1948\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 911us/step - loss: 7.6355 - mae: 2.0476 - val_loss: 8.2926 - val_mae: 2.1897\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 892us/step - loss: 7.6022 - mae: 2.0544 - val_loss: 8.4087 - val_mae: 2.2862\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 880us/step - loss: 7.6268 - mae: 2.0765 - val_loss: 8.4025 - val_mae: 2.0814\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 965us/step - loss: 7.6478 - mae: 2.0400 - val_loss: 8.4110 - val_mae: 2.0977\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 879us/step - loss: 7.6145 - mae: 2.0563 - val_loss: 8.4535 - val_mae: 2.0730\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 914us/step - loss: 7.5866 - mae: 2.0602 - val_loss: 8.4508 - val_mae: 2.0524\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 879us/step - loss: 7.5835 - mae: 2.0464 - val_loss: 8.4449 - val_mae: 2.2608\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 888us/step - loss: 7.6336 - mae: 2.0425 - val_loss: 8.4807 - val_mae: 2.0987\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 970us/step - loss: 7.6535 - mae: 2.0492 - val_loss: 8.3193 - val_mae: 2.1057\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 911us/step - loss: 7.6452 - mae: 2.0549 - val_loss: 8.3098 - val_mae: 2.2059\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 913us/step - loss: 7.6176 - mae: 2.0574 - val_loss: 8.3915 - val_mae: 2.0753\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 952us/step - loss: 7.5853 - mae: 2.0550 - val_loss: 8.2996 - val_mae: 2.1604\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 919us/step - loss: 7.5733 - mae: 2.0499 - val_loss: 8.3834 - val_mae: 2.0690\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 890us/step - loss: 7.5922 - mae: 2.0394 - val_loss: 8.3464 - val_mae: 2.1146\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 976us/step - loss: 7.5596 - mae: 2.0452 - val_loss: 8.3346 - val_mae: 2.1138\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 916us/step - loss: 7.5597 - mae: 2.0243 - val_loss: 8.3086 - val_mae: 2.2290\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 945us/step - loss: 7.5791 - mae: 2.0629 - val_loss: 8.3441 - val_mae: 2.0806\n",
      "Epoch 36: early stopping\n",
      "Test Loss (MSE): 9.083664894104004, Test Mean Absolute Error (MAE): 2.1807942390441895\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.7627 - mae: 2.1242 - val_loss: 8.6188 - val_mae: 2.1526\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 943us/step - loss: 8.4252 - mae: 2.0720 - val_loss: 8.0903 - val_mae: 1.9713\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 992us/step - loss: 8.1024 - mae: 2.0668 - val_loss: 7.8961 - val_mae: 2.1610\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.8313 - mae: 2.0683 - val_loss: 7.9978 - val_mae: 2.2065\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 939us/step - loss: 7.8707 - mae: 2.0538 - val_loss: 7.8427 - val_mae: 2.0862\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 922us/step - loss: 7.6822 - mae: 2.0532 - val_loss: 7.9245 - val_mae: 2.0215\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 913us/step - loss: 7.7505 - mae: 2.0364 - val_loss: 7.7802 - val_mae: 2.1348\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 941us/step - loss: 7.6930 - mae: 2.0506 - val_loss: 7.7120 - val_mae: 2.0371\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 986us/step - loss: 7.6565 - mae: 2.0368 - val_loss: 7.8660 - val_mae: 2.0936\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 965us/step - loss: 7.7579 - mae: 2.0339 - val_loss: 8.4005 - val_mae: 2.3507\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 948us/step - loss: 7.6412 - mae: 2.0526 - val_loss: 7.7277 - val_mae: 2.0329\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 942us/step - loss: 7.6457 - mae: 2.0450 - val_loss: 7.7621 - val_mae: 2.0053\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 956us/step - loss: 7.6276 - mae: 2.0356 - val_loss: 7.8450 - val_mae: 2.0425\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.6201 - mae: 2.0422 - val_loss: 7.8675 - val_mae: 2.0311\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 957us/step - loss: 7.5752 - mae: 2.0343 - val_loss: 7.8246 - val_mae: 2.1320\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 907us/step - loss: 7.6249 - mae: 2.0370 - val_loss: 7.8614 - val_mae: 2.1089\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 929us/step - loss: 7.5221 - mae: 2.0253 - val_loss: 7.8964 - val_mae: 2.1342\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.4997 - mae: 2.0191 - val_loss: 7.7975 - val_mae: 2.0211\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 950us/step - loss: 7.5023 - mae: 2.0125 - val_loss: 7.8391 - val_mae: 2.0371\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 929us/step - loss: 7.4713 - mae: 2.0119 - val_loss: 8.0664 - val_mae: 2.1352\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 934us/step - loss: 7.4769 - mae: 2.0095 - val_loss: 7.8860 - val_mae: 2.0676\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 922us/step - loss: 7.4894 - mae: 2.0064 - val_loss: 7.8633 - val_mae: 2.0876\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 918us/step - loss: 7.4247 - mae: 1.9673 - val_loss: 8.0303 - val_mae: 2.1350\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.5429 - mae: 1.9982 - val_loss: 7.9988 - val_mae: 2.0512\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 955us/step - loss: 7.3461 - mae: 1.9898 - val_loss: 7.9433 - val_mae: 1.9791\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 967us/step - loss: 7.3968 - mae: 1.9732 - val_loss: 8.0692 - val_mae: 2.0504\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 938us/step - loss: 7.3781 - mae: 1.9734 - val_loss: 8.0202 - val_mae: 2.0799\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 938us/step - loss: 7.2483 - mae: 1.9560 - val_loss: 8.2703 - val_mae: 1.9688\n",
      "Epoch 28: early stopping\n",
      "Test Loss (MSE): 11.104852676391602, Test Mean Absolute Error (MAE): 2.2752158641815186\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.9938 - mae: 2.1273 - val_loss: 9.8990 - val_mae: 2.3298\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.4823 - mae: 2.0601 - val_loss: 9.5234 - val_mae: 2.3740\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 964us/step - loss: 8.1394 - mae: 2.0584 - val_loss: 9.3178 - val_mae: 2.1834\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 979us/step - loss: 7.9277 - mae: 2.0253 - val_loss: 9.6608 - val_mae: 2.5013\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 958us/step - loss: 7.9042 - mae: 2.0492 - val_loss: 9.2386 - val_mae: 2.1474\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.8736 - mae: 2.0087 - val_loss: 9.2101 - val_mae: 2.1680\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 955us/step - loss: 7.8615 - mae: 2.0262 - val_loss: 9.1496 - val_mae: 2.3597\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 949us/step - loss: 7.7956 - mae: 2.0376 - val_loss: 9.1703 - val_mae: 2.2026\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 970us/step - loss: 7.7163 - mae: 2.0224 - val_loss: 9.6869 - val_mae: 2.4924\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 934us/step - loss: 7.7867 - mae: 2.0434 - val_loss: 9.2392 - val_mae: 2.1444\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.7252 - mae: 2.0090 - val_loss: 9.2523 - val_mae: 2.1399\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 959us/step - loss: 7.6280 - mae: 1.9909 - val_loss: 9.1189 - val_mae: 2.2059\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 947us/step - loss: 7.6813 - mae: 2.0437 - val_loss: 9.2328 - val_mae: 2.3868\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 875us/step - loss: 7.6225 - mae: 1.9832 - val_loss: 9.2674 - val_mae: 2.2028\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 971us/step - loss: 7.5730 - mae: 2.0068 - val_loss: 9.2290 - val_mae: 2.3639\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 962us/step - loss: 7.5345 - mae: 2.0089 - val_loss: 9.2457 - val_mae: 2.1628\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 918us/step - loss: 7.4781 - mae: 1.9996 - val_loss: 9.2984 - val_mae: 2.3469\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 975us/step - loss: 7.5130 - mae: 1.9920 - val_loss: 9.2962 - val_mae: 2.1959\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.5490 - mae: 2.0113 - val_loss: 9.3189 - val_mae: 2.2574\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 929us/step - loss: 7.4928 - mae: 1.9740 - val_loss: 9.4467 - val_mae: 2.1749\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 907us/step - loss: 7.3966 - mae: 1.9660 - val_loss: 9.3571 - val_mae: 2.2028\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 922us/step - loss: 7.3972 - mae: 1.9977 - val_loss: 9.6230 - val_mae: 2.2270\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 925us/step - loss: 7.4156 - mae: 1.9404 - val_loss: 9.3623 - val_mae: 2.2574\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.2969 - mae: 1.9605 - val_loss: 9.9889 - val_mae: 2.3298\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 991us/step - loss: 7.2218 - mae: 1.9401 - val_loss: 9.7884 - val_mae: 2.1276\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 942us/step - loss: 7.1658 - mae: 1.9394 - val_loss: 10.5104 - val_mae: 2.2950\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 947us/step - loss: 7.1868 - mae: 1.9128 - val_loss: 9.8650 - val_mae: 2.1788\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.0621 - mae: 1.9108 - val_loss: 9.9543 - val_mae: 2.2820\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 961us/step - loss: 6.8652 - mae: 1.8777 - val_loss: 10.4710 - val_mae: 2.3867\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 921us/step - loss: 6.8878 - mae: 1.8630 - val_loss: 9.6997 - val_mae: 2.2358\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 912us/step - loss: 6.9045 - mae: 1.8692 - val_loss: 9.9196 - val_mae: 2.2706\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 922us/step - loss: 6.7012 - mae: 1.8222 - val_loss: 10.2845 - val_mae: 2.2817\n",
      "Epoch 32: early stopping\n",
      "Test Loss (MSE): 8.341787338256836, Test Mean Absolute Error (MAE): 1.9978089332580566\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.2766 - mae: 2.1891 - val_loss: 8.9762 - val_mae: 2.2186\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.8405 - mae: 2.0860 - val_loss: 8.4101 - val_mae: 2.0647\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 989us/step - loss: 8.4369 - mae: 2.0578 - val_loss: 8.5081 - val_mae: 2.2519\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 966us/step - loss: 8.2485 - mae: 2.0470 - val_loss: 9.6957 - val_mae: 2.5935\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.1714 - mae: 2.0487 - val_loss: 8.3076 - val_mae: 2.1520\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 975us/step - loss: 8.1910 - mae: 2.0806 - val_loss: 8.2377 - val_mae: 2.2052\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 991us/step - loss: 8.0647 - mae: 2.0373 - val_loss: 8.3465 - val_mae: 2.2056\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 987us/step - loss: 7.9736 - mae: 2.0201 - val_loss: 8.5387 - val_mae: 2.3057\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.8744 - mae: 2.0313 - val_loss: 8.2682 - val_mae: 2.1325\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 991us/step - loss: 7.9843 - mae: 2.0242 - val_loss: 8.3248 - val_mae: 2.1352\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 956us/step - loss: 7.8700 - mae: 2.0238 - val_loss: 8.4661 - val_mae: 2.2492\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 989us/step - loss: 7.8276 - mae: 2.0228 - val_loss: 8.5077 - val_mae: 2.0707\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 981us/step - loss: 7.7592 - mae: 1.9863 - val_loss: 8.4054 - val_mae: 2.0971\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.5979 - mae: 1.9767 - val_loss: 8.4904 - val_mae: 2.1217\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.6683 - mae: 1.9678 - val_loss: 8.6113 - val_mae: 2.1842\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.5222 - mae: 1.9702 - val_loss: 8.8704 - val_mae: 2.2179\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 976us/step - loss: 7.4576 - mae: 1.9326 - val_loss: 9.1128 - val_mae: 2.0990\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 987us/step - loss: 7.5077 - mae: 1.9242 - val_loss: 9.0957 - val_mae: 2.0904\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.3554 - mae: 1.8563 - val_loss: 9.6546 - val_mae: 2.4376\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.1433 - mae: 1.8756 - val_loss: 9.3358 - val_mae: 2.2396\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 956us/step - loss: 7.0016 - mae: 1.8491 - val_loss: 9.7488 - val_mae: 2.2382\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 923us/step - loss: 6.8258 - mae: 1.8091 - val_loss: 10.2193 - val_mae: 2.3319\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 945us/step - loss: 6.9136 - mae: 1.8293 - val_loss: 9.5863 - val_mae: 2.0609\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 6.6145 - mae: 1.7714 - val_loss: 10.3700 - val_mae: 2.2982\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 6.7049 - mae: 1.7840 - val_loss: 10.1772 - val_mae: 2.3047\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 985us/step - loss: 6.5140 - mae: 1.7527 - val_loss: 9.7833 - val_mae: 2.1296\n",
      "Epoch 26: early stopping\n",
      "Test Loss (MSE): 9.48944091796875, Test Mean Absolute Error (MAE): 2.0621097087860107\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 5.6710 - mae: 1.3544 - val_loss: 4.5875 - val_mae: 1.1650\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 902us/step - loss: 5.0341 - mae: 1.3212 - val_loss: 4.5634 - val_mae: 1.2003\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 791us/step - loss: 4.9181 - mae: 1.3308 - val_loss: 4.3549 - val_mae: 1.2384\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 776us/step - loss: 4.9214 - mae: 1.3198 - val_loss: 4.3371 - val_mae: 1.3017\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 829us/step - loss: 4.8704 - mae: 1.3166 - val_loss: 4.3690 - val_mae: 1.2184\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 805us/step - loss: 4.8930 - mae: 1.3146 - val_loss: 4.4114 - val_mae: 1.3598\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 798us/step - loss: 4.8486 - mae: 1.3104 - val_loss: 4.8286 - val_mae: 1.4733\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 874us/step - loss: 4.8525 - mae: 1.3077 - val_loss: 4.3033 - val_mae: 1.1908\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 820us/step - loss: 4.8327 - mae: 1.3194 - val_loss: 4.2987 - val_mae: 1.2225\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 848us/step - loss: 4.8293 - mae: 1.3154 - val_loss: 4.2917 - val_mae: 1.2337\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 864us/step - loss: 4.8174 - mae: 1.2967 - val_loss: 4.2993 - val_mae: 1.2161\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 830us/step - loss: 4.8028 - mae: 1.3001 - val_loss: 4.4184 - val_mae: 1.3076\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 860us/step - loss: 4.7959 - mae: 1.3056 - val_loss: 4.3839 - val_mae: 1.1437\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 790us/step - loss: 4.8101 - mae: 1.2991 - val_loss: 4.2953 - val_mae: 1.2674\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 869us/step - loss: 4.7778 - mae: 1.2985 - val_loss: 4.2841 - val_mae: 1.2095\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 857us/step - loss: 4.7881 - mae: 1.2976 - val_loss: 4.3333 - val_mae: 1.1438\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.7940 - mae: 1.3028 - val_loss: 4.2861 - val_mae: 1.1848\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 952us/step - loss: 4.7483 - mae: 1.2891 - val_loss: 4.3040 - val_mae: 1.2386\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 882us/step - loss: 4.7785 - mae: 1.2954 - val_loss: 4.3150 - val_mae: 1.2032\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 829us/step - loss: 4.7897 - mae: 1.2903 - val_loss: 4.2917 - val_mae: 1.2705\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 764us/step - loss: 4.7892 - mae: 1.3031 - val_loss: 4.3276 - val_mae: 1.1865\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 778us/step - loss: 4.7899 - mae: 1.3018 - val_loss: 4.2885 - val_mae: 1.2276\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 837us/step - loss: 4.7704 - mae: 1.2934 - val_loss: 4.3110 - val_mae: 1.2345\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 796us/step - loss: 4.7542 - mae: 1.2923 - val_loss: 4.3986 - val_mae: 1.3213\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 820us/step - loss: 4.7708 - mae: 1.2892 - val_loss: 4.3249 - val_mae: 1.3459\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 817us/step - loss: 4.7632 - mae: 1.3005 - val_loss: 4.3534 - val_mae: 1.2556\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 783us/step - loss: 4.7733 - mae: 1.2946 - val_loss: 4.3103 - val_mae: 1.1353\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 811us/step - loss: 4.7643 - mae: 1.2841 - val_loss: 4.3409 - val_mae: 1.2990\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 798us/step - loss: 4.7430 - mae: 1.2835 - val_loss: 4.2935 - val_mae: 1.3135\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 794us/step - loss: 4.7634 - mae: 1.2998 - val_loss: 4.3038 - val_mae: 1.1820\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 776us/step - loss: 4.7629 - mae: 1.2946 - val_loss: 4.2927 - val_mae: 1.2160\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 840us/step - loss: 4.7541 - mae: 1.2969 - val_loss: 4.3909 - val_mae: 1.2552\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 833us/step - loss: 4.7545 - mae: 1.2958 - val_loss: 4.2945 - val_mae: 1.1655\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 802us/step - loss: 4.7445 - mae: 1.2855 - val_loss: 4.3755 - val_mae: 1.2958\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 814us/step - loss: 4.7435 - mae: 1.2845 - val_loss: 4.3541 - val_mae: 1.3443\n",
      "Epoch 35: early stopping\n",
      "Test Loss (MSE): 4.939550876617432, Test Mean Absolute Error (MAE): 1.4237923622131348\n",
      "Epoch 1/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 5.8907 - mae: 1.3077 - val_loss: 5.2736 - val_mae: 1.2376\n",
      "Epoch 2/100\n",
      "117/117 [==============================] - 0s 923us/step - loss: 5.0794 - mae: 1.3016 - val_loss: 5.0180 - val_mae: 1.3354\n",
      "Epoch 3/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 5.0220 - mae: 1.2998 - val_loss: 5.3690 - val_mae: 1.2094\n",
      "Epoch 4/100\n",
      "117/117 [==============================] - 0s 865us/step - loss: 4.9633 - mae: 1.2904 - val_loss: 5.1586 - val_mae: 1.4714\n",
      "Epoch 5/100\n",
      "117/117 [==============================] - 0s 952us/step - loss: 4.8437 - mae: 1.2963 - val_loss: 4.8441 - val_mae: 1.3186\n",
      "Epoch 6/100\n",
      "117/117 [==============================] - 0s 914us/step - loss: 4.7883 - mae: 1.2828 - val_loss: 5.0075 - val_mae: 1.2244\n",
      "Epoch 7/100\n",
      "117/117 [==============================] - 0s 924us/step - loss: 4.8409 - mae: 1.2787 - val_loss: 4.9162 - val_mae: 1.3016\n",
      "Epoch 8/100\n",
      "117/117 [==============================] - 0s 917us/step - loss: 4.7367 - mae: 1.2891 - val_loss: 5.1279 - val_mae: 1.4464\n",
      "Epoch 9/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 4.7505 - mae: 1.2841 - val_loss: 4.8933 - val_mae: 1.3090\n",
      "Epoch 10/100\n",
      "117/117 [==============================] - 0s 923us/step - loss: 4.7116 - mae: 1.2718 - val_loss: 5.0044 - val_mae: 1.2329\n",
      "Epoch 11/100\n",
      "117/117 [==============================] - 0s 956us/step - loss: 4.7302 - mae: 1.2565 - val_loss: 4.9239 - val_mae: 1.3365\n",
      "Epoch 12/100\n",
      "117/117 [==============================] - 0s 864us/step - loss: 4.6872 - mae: 1.2660 - val_loss: 5.2185 - val_mae: 1.4352\n",
      "Epoch 13/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 4.6495 - mae: 1.2528 - val_loss: 5.9293 - val_mae: 1.5923\n",
      "Epoch 14/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 4.7992 - mae: 1.2753 - val_loss: 4.9765 - val_mae: 1.2742\n",
      "Epoch 15/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 4.7211 - mae: 1.2700 - val_loss: 4.9682 - val_mae: 1.3418\n",
      "Epoch 16/100\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 4.7131 - mae: 1.2609 - val_loss: 5.0927 - val_mae: 1.4152\n",
      "Epoch 17/100\n",
      "117/117 [==============================] - 0s 980us/step - loss: 4.6613 - mae: 1.2525 - val_loss: 4.9517 - val_mae: 1.3050\n",
      "Epoch 18/100\n",
      "117/117 [==============================] - 0s 904us/step - loss: 4.6041 - mae: 1.2444 - val_loss: 5.3129 - val_mae: 1.4051\n",
      "Epoch 19/100\n",
      "117/117 [==============================] - 0s 913us/step - loss: 4.6510 - mae: 1.2582 - val_loss: 5.0616 - val_mae: 1.3659\n",
      "Epoch 20/100\n",
      "117/117 [==============================] - 0s 912us/step - loss: 4.6280 - mae: 1.2549 - val_loss: 5.0931 - val_mae: 1.2545\n",
      "Epoch 21/100\n",
      "117/117 [==============================] - 0s 888us/step - loss: 4.6644 - mae: 1.2487 - val_loss: 5.2459 - val_mae: 1.4328\n",
      "Epoch 22/100\n",
      "117/117 [==============================] - 0s 966us/step - loss: 4.6622 - mae: 1.2430 - val_loss: 5.0811 - val_mae: 1.3653\n",
      "Epoch 23/100\n",
      "117/117 [==============================] - 0s 906us/step - loss: 4.6186 - mae: 1.2599 - val_loss: 5.1358 - val_mae: 1.2222\n",
      "Epoch 24/100\n",
      "117/117 [==============================] - 0s 925us/step - loss: 4.6383 - mae: 1.2376 - val_loss: 5.0822 - val_mae: 1.2840\n",
      "Epoch 25/100\n",
      "117/117 [==============================] - 0s 948us/step - loss: 4.6611 - mae: 1.2418 - val_loss: 5.2545 - val_mae: 1.2328\n",
      "Epoch 25: early stopping\n",
      "Test Loss (MSE): 4.258683681488037, Test Mean Absolute Error (MAE): 1.0853867530822754\n",
      "Epoch 1/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 6.0157 - mae: 1.2963 - val_loss: 5.1331 - val_mae: 1.3044\n",
      "Epoch 2/100\n",
      "118/118 [==============================] - 0s 914us/step - loss: 5.1374 - mae: 1.2674 - val_loss: 5.3571 - val_mae: 1.1487\n",
      "Epoch 3/100\n",
      "118/118 [==============================] - 0s 971us/step - loss: 4.9171 - mae: 1.2543 - val_loss: 4.9820 - val_mae: 1.3632\n",
      "Epoch 4/100\n",
      "118/118 [==============================] - 0s 907us/step - loss: 4.9503 - mae: 1.2526 - val_loss: 4.7860 - val_mae: 1.4002\n",
      "Epoch 5/100\n",
      "118/118 [==============================] - 0s 985us/step - loss: 4.7343 - mae: 1.2597 - val_loss: 4.8906 - val_mae: 1.4319\n",
      "Epoch 6/100\n",
      "118/118 [==============================] - 0s 922us/step - loss: 4.8033 - mae: 1.2508 - val_loss: 4.8958 - val_mae: 1.1346\n",
      "Epoch 7/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 4.7939 - mae: 1.2733 - val_loss: 4.7984 - val_mae: 1.2114\n",
      "Epoch 8/100\n",
      "118/118 [==============================] - 0s 966us/step - loss: 4.7370 - mae: 1.2231 - val_loss: 4.9043 - val_mae: 1.4808\n",
      "Epoch 9/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 4.7015 - mae: 1.2546 - val_loss: 4.7726 - val_mae: 1.3010\n",
      "Epoch 10/100\n",
      "118/118 [==============================] - 0s 897us/step - loss: 4.6824 - mae: 1.2198 - val_loss: 4.8901 - val_mae: 1.2944\n",
      "Epoch 11/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 4.6286 - mae: 1.2356 - val_loss: 4.8634 - val_mae: 1.2884\n",
      "Epoch 12/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 4.6318 - mae: 1.2152 - val_loss: 4.9124 - val_mae: 1.2036\n",
      "Epoch 13/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 4.5936 - mae: 1.2156 - val_loss: 4.9711 - val_mae: 1.1880\n",
      "Epoch 14/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 4.6294 - mae: 1.2323 - val_loss: 4.9732 - val_mae: 1.2499\n",
      "Epoch 15/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 4.5609 - mae: 1.2051 - val_loss: 4.9798 - val_mae: 1.2816\n",
      "Epoch 16/100\n",
      "118/118 [==============================] - 0s 933us/step - loss: 4.5392 - mae: 1.1989 - val_loss: 4.9607 - val_mae: 1.2153\n",
      "Epoch 17/100\n",
      "118/118 [==============================] - 0s 931us/step - loss: 4.4920 - mae: 1.2002 - val_loss: 5.1451 - val_mae: 1.2468\n",
      "Epoch 18/100\n",
      "118/118 [==============================] - 0s 921us/step - loss: 4.5125 - mae: 1.2013 - val_loss: 5.2276 - val_mae: 1.1716\n",
      "Epoch 19/100\n",
      "118/118 [==============================] - 0s 933us/step - loss: 4.3888 - mae: 1.1688 - val_loss: 5.9356 - val_mae: 1.5048\n",
      "Epoch 20/100\n",
      "118/118 [==============================] - 0s 944us/step - loss: 4.4389 - mae: 1.1752 - val_loss: 5.1260 - val_mae: 1.2869\n",
      "Epoch 21/100\n",
      "118/118 [==============================] - 0s 891us/step - loss: 4.3838 - mae: 1.1738 - val_loss: 5.2017 - val_mae: 1.2218\n",
      "Epoch 22/100\n",
      "118/118 [==============================] - 0s 927us/step - loss: 4.4371 - mae: 1.1755 - val_loss: 5.1721 - val_mae: 1.2812\n",
      "Epoch 23/100\n",
      "118/118 [==============================] - 0s 928us/step - loss: 4.3508 - mae: 1.1692 - val_loss: 5.2095 - val_mae: 1.3993\n",
      "Epoch 24/100\n",
      "118/118 [==============================] - 0s 929us/step - loss: 4.3855 - mae: 1.1709 - val_loss: 5.3411 - val_mae: 1.3388\n",
      "Epoch 25/100\n",
      "118/118 [==============================] - 0s 959us/step - loss: 4.2968 - mae: 1.1481 - val_loss: 5.5786 - val_mae: 1.4144\n",
      "Epoch 26/100\n",
      "118/118 [==============================] - 0s 882us/step - loss: 4.4041 - mae: 1.1607 - val_loss: 5.4764 - val_mae: 1.3347\n",
      "Epoch 27/100\n",
      "118/118 [==============================] - 0s 948us/step - loss: 4.2660 - mae: 1.1448 - val_loss: 5.6572 - val_mae: 1.3812\n",
      "Epoch 28/100\n",
      "118/118 [==============================] - 0s 929us/step - loss: 4.2653 - mae: 1.1667 - val_loss: 5.5640 - val_mae: 1.3338\n",
      "Epoch 29/100\n",
      "118/118 [==============================] - 0s 943us/step - loss: 4.2691 - mae: 1.1349 - val_loss: 5.5069 - val_mae: 1.3663\n",
      "Epoch 29: early stopping\n",
      "Test Loss (MSE): 5.584456443786621, Test Mean Absolute Error (MAE): 1.3781956434249878\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.7020 - mae: 1.2468 - val_loss: 5.5465 - val_mae: 1.2903\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 923us/step - loss: 4.7733 - mae: 1.1976 - val_loss: 5.6771 - val_mae: 1.5734\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.6680 - mae: 1.2005 - val_loss: 5.1570 - val_mae: 1.3600\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 935us/step - loss: 4.5239 - mae: 1.1902 - val_loss: 5.2888 - val_mae: 1.3092\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.5312 - mae: 1.1960 - val_loss: 5.0855 - val_mae: 1.3356\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 964us/step - loss: 4.5100 - mae: 1.1938 - val_loss: 5.1756 - val_mae: 1.4134\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.4111 - mae: 1.1772 - val_loss: 5.5339 - val_mae: 1.5430\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 965us/step - loss: 4.4346 - mae: 1.1701 - val_loss: 5.2631 - val_mae: 1.4557\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 977us/step - loss: 4.3934 - mae: 1.1641 - val_loss: 5.2679 - val_mae: 1.3931\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 976us/step - loss: 4.3422 - mae: 1.1616 - val_loss: 5.2970 - val_mae: 1.3680\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.2895 - mae: 1.1496 - val_loss: 5.4861 - val_mae: 1.3036\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.2910 - mae: 1.1258 - val_loss: 5.4627 - val_mae: 1.4239\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.2345 - mae: 1.1377 - val_loss: 5.8164 - val_mae: 1.5124\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 985us/step - loss: 4.2729 - mae: 1.1314 - val_loss: 5.4782 - val_mae: 1.3451\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 954us/step - loss: 4.2333 - mae: 1.1253 - val_loss: 5.5936 - val_mae: 1.3835\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 959us/step - loss: 4.2677 - mae: 1.1126 - val_loss: 5.5886 - val_mae: 1.3531\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 958us/step - loss: 4.2256 - mae: 1.1244 - val_loss: 5.6690 - val_mae: 1.4426\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 939us/step - loss: 4.1887 - mae: 1.1066 - val_loss: 5.6865 - val_mae: 1.4294\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 941us/step - loss: 4.2297 - mae: 1.1080 - val_loss: 5.7946 - val_mae: 1.3889\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 950us/step - loss: 4.2299 - mae: 1.1133 - val_loss: 5.7660 - val_mae: 1.4506\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 971us/step - loss: 4.1671 - mae: 1.1059 - val_loss: 5.8067 - val_mae: 1.4372\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 912us/step - loss: 4.1857 - mae: 1.0993 - val_loss: 5.9332 - val_mae: 1.4790\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 966us/step - loss: 4.1605 - mae: 1.0803 - val_loss: 5.9621 - val_mae: 1.4056\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 940us/step - loss: 4.1663 - mae: 1.1108 - val_loss: 6.0512 - val_mae: 1.4022\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 922us/step - loss: 4.1215 - mae: 1.0783 - val_loss: 6.0479 - val_mae: 1.4586\n",
      "Epoch 25: early stopping\n",
      "Test Loss (MSE): 5.77833890914917, Test Mean Absolute Error (MAE): 1.4297714233398438\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 10.2027 - mae: 2.2483 - val_loss: 7.3203 - val_mae: 1.8730\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 876us/step - loss: 9.0888 - mae: 2.2010 - val_loss: 7.6774 - val_mae: 2.3522\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 917us/step - loss: 8.9323 - mae: 2.2017 - val_loss: 6.8746 - val_mae: 1.9503\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 890us/step - loss: 8.6911 - mae: 2.2141 - val_loss: 6.7752 - val_mae: 1.8261\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 941us/step - loss: 8.6767 - mae: 2.1911 - val_loss: 6.7586 - val_mae: 1.9711\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 864us/step - loss: 8.6938 - mae: 2.2176 - val_loss: 6.7855 - val_mae: 1.8249\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 847us/step - loss: 8.5783 - mae: 2.1845 - val_loss: 6.7011 - val_mae: 1.9169\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 887us/step - loss: 8.5926 - mae: 2.1809 - val_loss: 6.9938 - val_mae: 2.0261\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 858us/step - loss: 8.5429 - mae: 2.1648 - val_loss: 6.7666 - val_mae: 1.9317\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 943us/step - loss: 8.4892 - mae: 2.1747 - val_loss: 6.7445 - val_mae: 1.9790\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 873us/step - loss: 8.5589 - mae: 2.1836 - val_loss: 7.0342 - val_mae: 2.1754\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 854us/step - loss: 8.4377 - mae: 2.1999 - val_loss: 6.8782 - val_mae: 2.0874\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 893us/step - loss: 8.3932 - mae: 2.1772 - val_loss: 6.7635 - val_mae: 2.0028\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 855us/step - loss: 8.4055 - mae: 2.1917 - val_loss: 6.7082 - val_mae: 1.9366\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 874us/step - loss: 8.4244 - mae: 2.1525 - val_loss: 6.7414 - val_mae: 2.0065\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 842us/step - loss: 8.4625 - mae: 2.1617 - val_loss: 6.9228 - val_mae: 1.9436\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 930us/step - loss: 8.4128 - mae: 2.1780 - val_loss: 6.6141 - val_mae: 1.8734\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 864us/step - loss: 8.4517 - mae: 2.1721 - val_loss: 6.8129 - val_mae: 1.9430\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 873us/step - loss: 8.3618 - mae: 2.1868 - val_loss: 6.8759 - val_mae: 2.1269\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 890us/step - loss: 8.4438 - mae: 2.2052 - val_loss: 6.7821 - val_mae: 2.0212\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 851us/step - loss: 8.3238 - mae: 2.1571 - val_loss: 6.6852 - val_mae: 1.9687\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 873us/step - loss: 8.3274 - mae: 2.1535 - val_loss: 6.7290 - val_mae: 1.9500\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 909us/step - loss: 8.3607 - mae: 2.1832 - val_loss: 7.2301 - val_mae: 2.1767\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 881us/step - loss: 8.3123 - mae: 2.1788 - val_loss: 6.6803 - val_mae: 1.9453\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 872us/step - loss: 8.2531 - mae: 2.1707 - val_loss: 6.7133 - val_mae: 1.8827\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 842us/step - loss: 8.3301 - mae: 2.1603 - val_loss: 6.7886 - val_mae: 2.0283\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 844us/step - loss: 8.3119 - mae: 2.1793 - val_loss: 6.8619 - val_mae: 2.1120\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 851us/step - loss: 8.2525 - mae: 2.1599 - val_loss: 6.7002 - val_mae: 1.9190\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 866us/step - loss: 8.2411 - mae: 2.1611 - val_loss: 6.6559 - val_mae: 1.9563\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 846us/step - loss: 8.2836 - mae: 2.1612 - val_loss: 6.6629 - val_mae: 1.9234\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 955us/step - loss: 8.2704 - mae: 2.1871 - val_loss: 6.8172 - val_mae: 2.0478\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 907us/step - loss: 8.2333 - mae: 2.1576 - val_loss: 6.7194 - val_mae: 1.9520\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 889us/step - loss: 8.3012 - mae: 2.1582 - val_loss: 6.8577 - val_mae: 2.0214\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 895us/step - loss: 8.3633 - mae: 2.1786 - val_loss: 6.7518 - val_mae: 1.9262\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 826us/step - loss: 8.2215 - mae: 2.1532 - val_loss: 6.7061 - val_mae: 1.9291\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 866us/step - loss: 8.2450 - mae: 2.1305 - val_loss: 6.9013 - val_mae: 2.0507\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 883us/step - loss: 8.2773 - mae: 2.1520 - val_loss: 6.9424 - val_mae: 2.0739\n",
      "Epoch 37: early stopping\n",
      "Test Loss (MSE): 8.63628101348877, Test Mean Absolute Error (MAE): 2.2808682918548584\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9.5246 - mae: 2.1019 - val_loss: 9.1872 - val_mae: 2.0615\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 935us/step - loss: 8.2873 - mae: 2.0444 - val_loss: 9.4825 - val_mae: 1.9804\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 951us/step - loss: 7.9738 - mae: 2.0108 - val_loss: 8.9593 - val_mae: 2.3392\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 976us/step - loss: 8.0969 - mae: 2.0464 - val_loss: 8.5840 - val_mae: 2.0780\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 945us/step - loss: 7.7118 - mae: 2.0137 - val_loss: 9.1381 - val_mae: 2.0017\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 905us/step - loss: 7.7196 - mae: 2.0235 - val_loss: 8.4847 - val_mae: 2.2070\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 950us/step - loss: 7.6505 - mae: 2.0193 - val_loss: 8.5700 - val_mae: 2.1873\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 906us/step - loss: 7.5950 - mae: 2.0274 - val_loss: 8.6439 - val_mae: 2.1556\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 917us/step - loss: 7.5275 - mae: 1.9889 - val_loss: 8.5291 - val_mae: 2.1271\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 987us/step - loss: 7.4966 - mae: 2.0072 - val_loss: 8.7377 - val_mae: 2.2908\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 918us/step - loss: 7.4856 - mae: 1.9957 - val_loss: 8.5580 - val_mae: 2.1932\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 979us/step - loss: 7.4149 - mae: 1.9816 - val_loss: 9.1716 - val_mae: 2.3850\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 942us/step - loss: 7.4753 - mae: 1.9732 - val_loss: 8.7040 - val_mae: 2.2070\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 939us/step - loss: 7.3949 - mae: 1.9936 - val_loss: 8.6806 - val_mae: 2.1032\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 923us/step - loss: 7.2756 - mae: 1.9538 - val_loss: 9.0225 - val_mae: 2.3474\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.2668 - mae: 1.9719 - val_loss: 8.8712 - val_mae: 2.2306\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 947us/step - loss: 7.2519 - mae: 1.9332 - val_loss: 9.1213 - val_mae: 2.2043\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 933us/step - loss: 7.3638 - mae: 1.9542 - val_loss: 9.1161 - val_mae: 2.2987\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 930us/step - loss: 7.2599 - mae: 1.9468 - val_loss: 8.9681 - val_mae: 2.1326\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 928us/step - loss: 7.2392 - mae: 1.9131 - val_loss: 9.4608 - val_mae: 2.3587\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 997us/step - loss: 7.0192 - mae: 1.9097 - val_loss: 9.2407 - val_mae: 2.2379\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 929us/step - loss: 6.9412 - mae: 1.8857 - val_loss: 9.4364 - val_mae: 2.1561\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 939us/step - loss: 7.0053 - mae: 1.8826 - val_loss: 9.8380 - val_mae: 2.3042\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 902us/step - loss: 6.9516 - mae: 1.8657 - val_loss: 9.6432 - val_mae: 2.2501\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 941us/step - loss: 6.9360 - mae: 1.8812 - val_loss: 9.9053 - val_mae: 2.3072\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 932us/step - loss: 6.7516 - mae: 1.8395 - val_loss: 9.8457 - val_mae: 2.1426\n",
      "Epoch 26: early stopping\n",
      "Test Loss (MSE): 10.204292297363281, Test Mean Absolute Error (MAE): 2.0941922664642334\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 10.1063 - mae: 2.1605 - val_loss: 8.5682 - val_mae: 1.9302\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 986us/step - loss: 8.9622 - mae: 2.0892 - val_loss: 8.0286 - val_mae: 2.0982\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 956us/step - loss: 8.6346 - mae: 2.0906 - val_loss: 8.2084 - val_mae: 2.2109\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 8.4015 - mae: 2.0808 - val_loss: 7.9449 - val_mae: 1.9954\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 939us/step - loss: 8.4214 - mae: 2.0547 - val_loss: 8.2987 - val_mae: 2.2242\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 963us/step - loss: 8.3973 - mae: 2.0992 - val_loss: 7.9875 - val_mae: 2.0720\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 938us/step - loss: 8.3631 - mae: 2.0486 - val_loss: 7.9942 - val_mae: 2.1347\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 922us/step - loss: 8.2283 - mae: 2.0461 - val_loss: 8.4698 - val_mae: 2.1886\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 904us/step - loss: 8.1670 - mae: 2.0370 - val_loss: 8.1490 - val_mae: 2.0203\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 8.1089 - mae: 2.0290 - val_loss: 8.2158 - val_mae: 2.1703\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 931us/step - loss: 8.0700 - mae: 2.0172 - val_loss: 8.1968 - val_mae: 2.0329\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 950us/step - loss: 7.9847 - mae: 1.9922 - val_loss: 8.1913 - val_mae: 2.1176\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 956us/step - loss: 7.9129 - mae: 1.9813 - val_loss: 8.3060 - val_mae: 2.0648\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 905us/step - loss: 7.7045 - mae: 1.9667 - val_loss: 8.5135 - val_mae: 2.0980\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.6005 - mae: 1.9418 - val_loss: 8.4885 - val_mae: 2.0897\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 929us/step - loss: 7.5127 - mae: 1.9321 - val_loss: 9.2051 - val_mae: 2.2517\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 969us/step - loss: 7.3815 - mae: 1.8855 - val_loss: 8.7438 - val_mae: 2.1826\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 940us/step - loss: 7.4164 - mae: 1.9057 - val_loss: 9.0313 - val_mae: 2.0911\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 946us/step - loss: 7.4233 - mae: 1.8793 - val_loss: 8.9839 - val_mae: 2.1216\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 961us/step - loss: 7.1584 - mae: 1.8292 - val_loss: 9.2669 - val_mae: 2.1647\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7.2456 - mae: 1.8506 - val_loss: 9.0300 - val_mae: 2.1020\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 955us/step - loss: 7.0346 - mae: 1.8289 - val_loss: 9.6449 - val_mae: 2.1588\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 976us/step - loss: 6.8059 - mae: 1.7751 - val_loss: 9.7719 - val_mae: 2.0994\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 901us/step - loss: 6.7234 - mae: 1.7598 - val_loss: 10.0768 - val_mae: 2.1784\n",
      "Epoch 24: early stopping\n",
      "Test Loss (MSE): 10.099853515625, Test Mean Absolute Error (MAE): 2.2054975032806396\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.3076 - mae: 2.1684 - val_loss: 9.5026 - val_mae: 1.9664\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 986us/step - loss: 9.0006 - mae: 2.0906 - val_loss: 8.8876 - val_mae: 2.0858\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.3749 - mae: 2.0654 - val_loss: 8.5040 - val_mae: 2.0258\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.2415 - mae: 2.0534 - val_loss: 8.5813 - val_mae: 2.0828\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 977us/step - loss: 8.1460 - mae: 2.0069 - val_loss: 9.6194 - val_mae: 2.4766\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.1349 - mae: 2.0272 - val_loss: 10.1456 - val_mae: 2.4378\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.9173 - mae: 1.9755 - val_loss: 9.0591 - val_mae: 2.0244\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.7230 - mae: 1.9676 - val_loss: 9.8723 - val_mae: 2.3768\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 978us/step - loss: 7.7355 - mae: 1.9340 - val_loss: 9.0537 - val_mae: 2.1837\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 970us/step - loss: 7.4553 - mae: 1.9230 - val_loss: 9.4089 - val_mae: 2.0934\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.4506 - mae: 1.8745 - val_loss: 9.7481 - val_mae: 2.2448\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.3801 - mae: 1.8655 - val_loss: 10.6188 - val_mae: 2.3358\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.0990 - mae: 1.8069 - val_loss: 9.6854 - val_mae: 2.1198\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 973us/step - loss: 6.8941 - mae: 1.7876 - val_loss: 9.9356 - val_mae: 2.1665\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 6.8116 - mae: 1.7607 - val_loss: 9.8371 - val_mae: 2.1024\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 956us/step - loss: 6.7456 - mae: 1.7361 - val_loss: 10.1084 - val_mae: 2.2446\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 947us/step - loss: 6.4855 - mae: 1.7000 - val_loss: 10.7110 - val_mae: 2.3270\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 933us/step - loss: 6.3415 - mae: 1.6808 - val_loss: 11.0553 - val_mae: 2.2696\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 6.2254 - mae: 1.6345 - val_loss: 10.5796 - val_mae: 2.2125\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 991us/step - loss: 5.9276 - mae: 1.5954 - val_loss: 10.9452 - val_mae: 2.2838\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 5.8650 - mae: 1.5727 - val_loss: 10.6981 - val_mae: 2.1994\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 983us/step - loss: 5.7078 - mae: 1.5333 - val_loss: 11.7539 - val_mae: 2.3597\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 969us/step - loss: 5.5579 - mae: 1.5065 - val_loss: 11.4726 - val_mae: 2.2783\n",
      "Epoch 23: early stopping\n",
      "Test Loss (MSE): 11.54800796508789, Test Mean Absolute Error (MAE): 2.181079864501953\n",
      "Epoch 1/100\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 5.1399 - mae: 1.1835 - val_loss: 4.4104 - val_mae: 1.0680\n",
      "Epoch 2/100\n",
      "165/165 [==============================] - 0s 679us/step - loss: 4.7578 - mae: 1.1551 - val_loss: 4.3435 - val_mae: 1.2272\n",
      "Epoch 3/100\n",
      "165/165 [==============================] - 0s 695us/step - loss: 4.7781 - mae: 1.1706 - val_loss: 4.6413 - val_mae: 1.0897\n",
      "Epoch 4/100\n",
      "165/165 [==============================] - 0s 696us/step - loss: 4.7296 - mae: 1.1636 - val_loss: 4.2734 - val_mae: 1.1074\n",
      "Epoch 5/100\n",
      "165/165 [==============================] - 0s 718us/step - loss: 4.6626 - mae: 1.1554 - val_loss: 4.4091 - val_mae: 1.2052\n",
      "Epoch 6/100\n",
      "165/165 [==============================] - 0s 676us/step - loss: 4.6215 - mae: 1.1478 - val_loss: 4.2102 - val_mae: 1.0987\n",
      "Epoch 7/100\n",
      "165/165 [==============================] - 0s 685us/step - loss: 4.6301 - mae: 1.1303 - val_loss: 4.2164 - val_mae: 1.2257\n",
      "Epoch 8/100\n",
      "165/165 [==============================] - 0s 683us/step - loss: 4.6506 - mae: 1.1537 - val_loss: 4.3109 - val_mae: 1.2990\n",
      "Epoch 9/100\n",
      "165/165 [==============================] - 0s 703us/step - loss: 4.5836 - mae: 1.1301 - val_loss: 4.1983 - val_mae: 1.1413\n",
      "Epoch 10/100\n",
      "165/165 [==============================] - 0s 683us/step - loss: 4.6274 - mae: 1.1330 - val_loss: 4.1861 - val_mae: 1.1541\n",
      "Epoch 11/100\n",
      "165/165 [==============================] - 0s 708us/step - loss: 4.5642 - mae: 1.1321 - val_loss: 4.2344 - val_mae: 1.2139\n",
      "Epoch 12/100\n",
      "165/165 [==============================] - 0s 677us/step - loss: 4.5873 - mae: 1.1319 - val_loss: 4.1806 - val_mae: 1.1375\n",
      "Epoch 13/100\n",
      "165/165 [==============================] - 0s 685us/step - loss: 4.5849 - mae: 1.1347 - val_loss: 4.1912 - val_mae: 1.1113\n",
      "Epoch 14/100\n",
      "165/165 [==============================] - 0s 675us/step - loss: 4.5732 - mae: 1.1268 - val_loss: 4.2386 - val_mae: 1.2047\n",
      "Epoch 15/100\n",
      "165/165 [==============================] - 0s 697us/step - loss: 4.5847 - mae: 1.1367 - val_loss: 4.1895 - val_mae: 1.1243\n",
      "Epoch 16/100\n",
      "165/165 [==============================] - 0s 681us/step - loss: 4.5925 - mae: 1.1358 - val_loss: 4.2328 - val_mae: 1.0765\n",
      "Epoch 17/100\n",
      "165/165 [==============================] - 0s 719us/step - loss: 4.5597 - mae: 1.1254 - val_loss: 4.2014 - val_mae: 1.1711\n",
      "Epoch 18/100\n",
      "165/165 [==============================] - 0s 670us/step - loss: 4.5644 - mae: 1.1254 - val_loss: 4.1814 - val_mae: 1.1154\n",
      "Epoch 19/100\n",
      "165/165 [==============================] - 0s 707us/step - loss: 4.5564 - mae: 1.1289 - val_loss: 4.1694 - val_mae: 1.1437\n",
      "Epoch 20/100\n",
      "165/165 [==============================] - 0s 677us/step - loss: 4.5567 - mae: 1.1262 - val_loss: 4.1872 - val_mae: 1.1348\n",
      "Epoch 21/100\n",
      "165/165 [==============================] - 0s 713us/step - loss: 4.5652 - mae: 1.1278 - val_loss: 4.1824 - val_mae: 1.2006\n",
      "Epoch 22/100\n",
      "165/165 [==============================] - 0s 671us/step - loss: 4.5526 - mae: 1.1305 - val_loss: 4.1672 - val_mae: 1.1593\n",
      "Epoch 23/100\n",
      "165/165 [==============================] - 0s 737us/step - loss: 4.5547 - mae: 1.1308 - val_loss: 4.1684 - val_mae: 1.1220\n",
      "Epoch 24/100\n",
      "165/165 [==============================] - 0s 683us/step - loss: 4.5439 - mae: 1.1218 - val_loss: 4.1781 - val_mae: 1.1229\n",
      "Epoch 25/100\n",
      "165/165 [==============================] - 0s 695us/step - loss: 4.5648 - mae: 1.1322 - val_loss: 4.1893 - val_mae: 1.0749\n",
      "Epoch 26/100\n",
      "165/165 [==============================] - 0s 685us/step - loss: 4.5469 - mae: 1.1296 - val_loss: 4.1680 - val_mae: 1.1389\n",
      "Epoch 27/100\n",
      "165/165 [==============================] - 0s 683us/step - loss: 4.5505 - mae: 1.1302 - val_loss: 4.1905 - val_mae: 1.1133\n",
      "Epoch 28/100\n",
      "165/165 [==============================] - 0s 664us/step - loss: 4.5592 - mae: 1.1408 - val_loss: 4.1714 - val_mae: 1.1195\n",
      "Epoch 29/100\n",
      "165/165 [==============================] - 0s 695us/step - loss: 4.5555 - mae: 1.1300 - val_loss: 4.1818 - val_mae: 1.1111\n",
      "Epoch 30/100\n",
      "165/165 [==============================] - 0s 672us/step - loss: 4.5442 - mae: 1.1285 - val_loss: 4.2059 - val_mae: 1.2442\n",
      "Epoch 31/100\n",
      "165/165 [==============================] - 0s 708us/step - loss: 4.5436 - mae: 1.1313 - val_loss: 4.1989 - val_mae: 1.0790\n",
      "Epoch 32/100\n",
      "165/165 [==============================] - 0s 699us/step - loss: 4.5453 - mae: 1.1294 - val_loss: 4.1652 - val_mae: 1.1294\n",
      "Epoch 33/100\n",
      "165/165 [==============================] - 0s 721us/step - loss: 4.5575 - mae: 1.1288 - val_loss: 4.1708 - val_mae: 1.1447\n",
      "Epoch 34/100\n",
      "165/165 [==============================] - 0s 686us/step - loss: 4.5364 - mae: 1.1257 - val_loss: 4.1916 - val_mae: 1.1844\n",
      "Epoch 35/100\n",
      "165/165 [==============================] - 0s 691us/step - loss: 4.5567 - mae: 1.1295 - val_loss: 4.1757 - val_mae: 1.1789\n",
      "Epoch 36/100\n",
      "165/165 [==============================] - 0s 675us/step - loss: 4.5625 - mae: 1.1315 - val_loss: 4.1737 - val_mae: 1.1662\n",
      "Epoch 37/100\n",
      "165/165 [==============================] - 0s 702us/step - loss: 4.5543 - mae: 1.1260 - val_loss: 4.1708 - val_mae: 1.1577\n",
      "Epoch 38/100\n",
      "165/165 [==============================] - 0s 676us/step - loss: 4.5570 - mae: 1.1264 - val_loss: 4.1743 - val_mae: 1.1450\n",
      "Epoch 39/100\n",
      "165/165 [==============================] - 0s 680us/step - loss: 4.5353 - mae: 1.1295 - val_loss: 4.1715 - val_mae: 1.1614\n",
      "Epoch 40/100\n",
      "165/165 [==============================] - 0s 683us/step - loss: 4.5426 - mae: 1.1281 - val_loss: 4.1964 - val_mae: 1.2256\n",
      "Epoch 41/100\n",
      "165/165 [==============================] - 0s 698us/step - loss: 4.5279 - mae: 1.1298 - val_loss: 4.1836 - val_mae: 1.1511\n",
      "Epoch 42/100\n",
      "165/165 [==============================] - 0s 671us/step - loss: 4.5565 - mae: 1.1343 - val_loss: 4.1941 - val_mae: 1.1163\n",
      "Epoch 43/100\n",
      "165/165 [==============================] - 0s 693us/step - loss: 4.5384 - mae: 1.1326 - val_loss: 4.1984 - val_mae: 1.1140\n",
      "Epoch 44/100\n",
      "165/165 [==============================] - 0s 684us/step - loss: 4.5315 - mae: 1.1196 - val_loss: 4.1928 - val_mae: 1.0876\n",
      "Epoch 45/100\n",
      "165/165 [==============================] - 0s 691us/step - loss: 4.5275 - mae: 1.1184 - val_loss: 4.2153 - val_mae: 1.1701\n",
      "Epoch 46/100\n",
      "165/165 [==============================] - 0s 669us/step - loss: 4.5415 - mae: 1.1321 - val_loss: 4.1669 - val_mae: 1.1224\n",
      "Epoch 47/100\n",
      "165/165 [==============================] - 0s 684us/step - loss: 4.5489 - mae: 1.1262 - val_loss: 4.1687 - val_mae: 1.1033\n",
      "Epoch 48/100\n",
      "165/165 [==============================] - 0s 684us/step - loss: 4.5375 - mae: 1.1269 - val_loss: 4.1752 - val_mae: 1.1352\n",
      "Epoch 49/100\n",
      "165/165 [==============================] - 0s 670us/step - loss: 4.5368 - mae: 1.1249 - val_loss: 4.1696 - val_mae: 1.1229\n",
      "Epoch 50/100\n",
      "165/165 [==============================] - 0s 677us/step - loss: 4.5353 - mae: 1.1278 - val_loss: 4.1821 - val_mae: 1.1603\n",
      "Epoch 51/100\n",
      "165/165 [==============================] - 0s 713us/step - loss: 4.5305 - mae: 1.1379 - val_loss: 4.1970 - val_mae: 1.1072\n",
      "Epoch 52/100\n",
      "165/165 [==============================] - 0s 671us/step - loss: 4.5338 - mae: 1.1233 - val_loss: 4.2619 - val_mae: 1.1764\n",
      "Epoch 52: early stopping\n",
      "Test Loss (MSE): 4.699742317199707, Test Mean Absolute Error (MAE): 1.195530652999878\n",
      "Epoch 1/100\n",
      "167/167 [==============================] - 0s 1ms/step - loss: 5.4726 - mae: 1.1978 - val_loss: 4.6476 - val_mae: 1.1517\n",
      "Epoch 2/100\n",
      "167/167 [==============================] - 0s 684us/step - loss: 4.9922 - mae: 1.1728 - val_loss: 4.4722 - val_mae: 1.1656\n",
      "Epoch 3/100\n",
      "167/167 [==============================] - 0s 705us/step - loss: 4.8438 - mae: 1.1534 - val_loss: 4.4273 - val_mae: 1.1753\n",
      "Epoch 4/100\n",
      "167/167 [==============================] - 0s 668us/step - loss: 4.8579 - mae: 1.1587 - val_loss: 4.4703 - val_mae: 1.2011\n",
      "Epoch 5/100\n",
      "167/167 [==============================] - 0s 766us/step - loss: 4.8248 - mae: 1.1645 - val_loss: 4.3886 - val_mae: 1.1372\n",
      "Epoch 6/100\n",
      "167/167 [==============================] - 0s 694us/step - loss: 4.8342 - mae: 1.1621 - val_loss: 4.4427 - val_mae: 1.1171\n",
      "Epoch 7/100\n",
      "167/167 [==============================] - 0s 690us/step - loss: 4.7749 - mae: 1.1570 - val_loss: 4.4174 - val_mae: 1.1415\n",
      "Epoch 8/100\n",
      "167/167 [==============================] - 0s 699us/step - loss: 4.7557 - mae: 1.1561 - val_loss: 4.4722 - val_mae: 1.1142\n",
      "Epoch 9/100\n",
      "167/167 [==============================] - 0s 687us/step - loss: 4.7505 - mae: 1.1438 - val_loss: 4.4240 - val_mae: 1.1072\n",
      "Epoch 10/100\n",
      "167/167 [==============================] - 0s 695us/step - loss: 4.7607 - mae: 1.1522 - val_loss: 4.5342 - val_mae: 1.1112\n",
      "Epoch 11/100\n",
      "167/167 [==============================] - 0s 714us/step - loss: 4.7377 - mae: 1.1476 - val_loss: 4.4928 - val_mae: 1.1398\n",
      "Epoch 12/100\n",
      "167/167 [==============================] - 0s 655us/step - loss: 4.7036 - mae: 1.1402 - val_loss: 4.5019 - val_mae: 1.1810\n",
      "Epoch 13/100\n",
      "167/167 [==============================] - 0s 679us/step - loss: 4.7159 - mae: 1.1556 - val_loss: 4.4231 - val_mae: 1.1059\n",
      "Epoch 14/100\n",
      "167/167 [==============================] - 0s 714us/step - loss: 4.7207 - mae: 1.1437 - val_loss: 4.3937 - val_mae: 1.1873\n",
      "Epoch 15/100\n",
      "167/167 [==============================] - 0s 747us/step - loss: 4.7077 - mae: 1.1502 - val_loss: 4.4197 - val_mae: 1.0811\n",
      "Epoch 16/100\n",
      "167/167 [==============================] - 0s 695us/step - loss: 4.7189 - mae: 1.1431 - val_loss: 4.4100 - val_mae: 1.1612\n",
      "Epoch 17/100\n",
      "167/167 [==============================] - 0s 702us/step - loss: 4.6934 - mae: 1.1402 - val_loss: 4.3903 - val_mae: 1.1358\n",
      "Epoch 18/100\n",
      "167/167 [==============================] - 0s 711us/step - loss: 4.7076 - mae: 1.1507 - val_loss: 4.4144 - val_mae: 1.1440\n",
      "Epoch 19/100\n",
      "167/167 [==============================] - 0s 702us/step - loss: 4.7074 - mae: 1.1441 - val_loss: 4.4305 - val_mae: 1.1358\n",
      "Epoch 20/100\n",
      "167/167 [==============================] - 0s 687us/step - loss: 4.7007 - mae: 1.1419 - val_loss: 4.3892 - val_mae: 1.1487\n",
      "Epoch 21/100\n",
      "167/167 [==============================] - 0s 695us/step - loss: 4.6925 - mae: 1.1417 - val_loss: 4.4320 - val_mae: 1.1182\n",
      "Epoch 22/100\n",
      "167/167 [==============================] - 0s 702us/step - loss: 4.6784 - mae: 1.1414 - val_loss: 4.4743 - val_mae: 1.2782\n",
      "Epoch 23/100\n",
      "167/167 [==============================] - 0s 696us/step - loss: 4.7061 - mae: 1.1411 - val_loss: 4.4874 - val_mae: 1.1877\n",
      "Epoch 24/100\n",
      "167/167 [==============================] - 0s 679us/step - loss: 4.7201 - mae: 1.1478 - val_loss: 4.4029 - val_mae: 1.1890\n",
      "Epoch 25/100\n",
      "167/167 [==============================] - 0s 690us/step - loss: 4.6881 - mae: 1.1393 - val_loss: 4.4041 - val_mae: 1.1502\n",
      "Epoch 25: early stopping\n",
      "Test Loss (MSE): 3.562009334564209, Test Mean Absolute Error (MAE): 1.0149940252304077\n",
      "Epoch 1/100\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 5.7466 - mae: 1.2500 - val_loss: 4.0664 - val_mae: 1.0786\n",
      "Epoch 2/100\n",
      "166/166 [==============================] - 0s 772us/step - loss: 5.1518 - mae: 1.2310 - val_loss: 3.9052 - val_mae: 1.0923\n",
      "Epoch 3/100\n",
      "166/166 [==============================] - 0s 724us/step - loss: 5.1270 - mae: 1.2256 - val_loss: 3.8776 - val_mae: 1.0015\n",
      "Epoch 4/100\n",
      "166/166 [==============================] - 0s 826us/step - loss: 4.9552 - mae: 1.1891 - val_loss: 3.8805 - val_mae: 1.1388\n",
      "Epoch 5/100\n",
      "166/166 [==============================] - 0s 792us/step - loss: 4.9555 - mae: 1.1919 - val_loss: 3.8394 - val_mae: 1.1557\n",
      "Epoch 6/100\n",
      "166/166 [==============================] - 0s 875us/step - loss: 4.9142 - mae: 1.1785 - val_loss: 3.9183 - val_mae: 1.1779\n",
      "Epoch 7/100\n",
      "166/166 [==============================] - 0s 755us/step - loss: 4.8919 - mae: 1.1766 - val_loss: 3.9297 - val_mae: 1.1464\n",
      "Epoch 8/100\n",
      "166/166 [==============================] - 0s 757us/step - loss: 4.8938 - mae: 1.1765 - val_loss: 3.9201 - val_mae: 1.1720\n",
      "Epoch 9/100\n",
      "166/166 [==============================] - 0s 718us/step - loss: 4.8841 - mae: 1.1781 - val_loss: 3.9395 - val_mae: 1.2091\n",
      "Epoch 10/100\n",
      "166/166 [==============================] - 0s 861us/step - loss: 4.8332 - mae: 1.1782 - val_loss: 3.8460 - val_mae: 1.1757\n",
      "Epoch 11/100\n",
      "166/166 [==============================] - 0s 761us/step - loss: 4.8312 - mae: 1.1776 - val_loss: 3.8962 - val_mae: 1.1590\n",
      "Epoch 12/100\n",
      "166/166 [==============================] - 0s 751us/step - loss: 4.8283 - mae: 1.1702 - val_loss: 3.8968 - val_mae: 1.2046\n",
      "Epoch 13/100\n",
      "166/166 [==============================] - 0s 768us/step - loss: 4.8216 - mae: 1.1724 - val_loss: 3.7910 - val_mae: 1.0846\n",
      "Epoch 14/100\n",
      "166/166 [==============================] - 0s 756us/step - loss: 4.8291 - mae: 1.1850 - val_loss: 3.7974 - val_mae: 1.1021\n",
      "Epoch 15/100\n",
      "166/166 [==============================] - 0s 706us/step - loss: 4.8138 - mae: 1.1656 - val_loss: 3.7711 - val_mae: 0.9982\n",
      "Epoch 16/100\n",
      "166/166 [==============================] - 0s 747us/step - loss: 4.7943 - mae: 1.1807 - val_loss: 3.7696 - val_mae: 1.0913\n",
      "Epoch 17/100\n",
      "166/166 [==============================] - 0s 718us/step - loss: 4.8045 - mae: 1.1687 - val_loss: 3.7676 - val_mae: 1.0010\n",
      "Epoch 18/100\n",
      "166/166 [==============================] - 0s 748us/step - loss: 4.7939 - mae: 1.1683 - val_loss: 3.8166 - val_mae: 1.0633\n",
      "Epoch 19/100\n",
      "166/166 [==============================] - 0s 719us/step - loss: 4.8057 - mae: 1.1656 - val_loss: 3.7823 - val_mae: 1.1110\n",
      "Epoch 20/100\n",
      "166/166 [==============================] - 0s 706us/step - loss: 4.7892 - mae: 1.1777 - val_loss: 3.8432 - val_mae: 1.0780\n",
      "Epoch 21/100\n",
      "166/166 [==============================] - 0s 713us/step - loss: 4.7896 - mae: 1.1636 - val_loss: 3.8729 - val_mae: 1.1438\n",
      "Epoch 22/100\n",
      "166/166 [==============================] - 0s 753us/step - loss: 4.7934 - mae: 1.1694 - val_loss: 3.7879 - val_mae: 1.0777\n",
      "Epoch 23/100\n",
      "166/166 [==============================] - 0s 724us/step - loss: 4.7963 - mae: 1.1701 - val_loss: 3.7940 - val_mae: 1.0215\n",
      "Epoch 24/100\n",
      "166/166 [==============================] - 0s 724us/step - loss: 4.7856 - mae: 1.1613 - val_loss: 3.7936 - val_mae: 1.0955\n",
      "Epoch 25/100\n",
      "166/166 [==============================] - 0s 735us/step - loss: 4.7666 - mae: 1.1642 - val_loss: 3.7814 - val_mae: 1.0474\n",
      "Epoch 26/100\n",
      "166/166 [==============================] - 0s 735us/step - loss: 4.7976 - mae: 1.1741 - val_loss: 3.7958 - val_mae: 1.0060\n",
      "Epoch 27/100\n",
      "166/166 [==============================] - 0s 764us/step - loss: 4.7957 - mae: 1.1603 - val_loss: 3.8069 - val_mae: 1.0874\n",
      "Epoch 28/100\n",
      "166/166 [==============================] - 0s 717us/step - loss: 4.7757 - mae: 1.1656 - val_loss: 3.7783 - val_mae: 1.0509\n",
      "Epoch 29/100\n",
      "166/166 [==============================] - 0s 754us/step - loss: 4.7884 - mae: 1.1747 - val_loss: 3.7818 - val_mae: 1.0060\n",
      "Epoch 30/100\n",
      "166/166 [==============================] - 0s 749us/step - loss: 4.7794 - mae: 1.1513 - val_loss: 3.8651 - val_mae: 1.1302\n",
      "Epoch 31/100\n",
      "166/166 [==============================] - 0s 758us/step - loss: 4.7788 - mae: 1.1651 - val_loss: 3.9111 - val_mae: 1.0786\n",
      "Epoch 32/100\n",
      "166/166 [==============================] - 0s 714us/step - loss: 4.7576 - mae: 1.1632 - val_loss: 3.7948 - val_mae: 0.9914\n",
      "Epoch 33/100\n",
      "166/166 [==============================] - 0s 750us/step - loss: 4.7560 - mae: 1.1669 - val_loss: 3.7797 - val_mae: 1.0214\n",
      "Epoch 34/100\n",
      "166/166 [==============================] - 0s 719us/step - loss: 4.7691 - mae: 1.1576 - val_loss: 3.8385 - val_mae: 1.0406\n",
      "Epoch 35/100\n",
      "166/166 [==============================] - 0s 761us/step - loss: 4.7621 - mae: 1.1669 - val_loss: 3.7928 - val_mae: 1.0615\n",
      "Epoch 36/100\n",
      "166/166 [==============================] - 0s 745us/step - loss: 4.7602 - mae: 1.1572 - val_loss: 3.7828 - val_mae: 1.0724\n",
      "Epoch 37/100\n",
      "166/166 [==============================] - 0s 748us/step - loss: 4.7605 - mae: 1.1655 - val_loss: 3.8107 - val_mae: 1.1110\n",
      "Epoch 37: early stopping\n",
      "Test Loss (MSE): 4.2457685470581055, Test Mean Absolute Error (MAE): 1.136086106300354\n",
      "Epoch 1/100\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 5.4270 - mae: 1.1865 - val_loss: 4.8112 - val_mae: 1.1848\n",
      "Epoch 2/100\n",
      "164/164 [==============================] - 0s 753us/step - loss: 4.8404 - mae: 1.1533 - val_loss: 4.6311 - val_mae: 1.1548\n",
      "Epoch 3/100\n",
      "164/164 [==============================] - 0s 765us/step - loss: 4.7694 - mae: 1.1496 - val_loss: 4.5910 - val_mae: 1.1531\n",
      "Epoch 4/100\n",
      "164/164 [==============================] - 0s 854us/step - loss: 4.6726 - mae: 1.1500 - val_loss: 4.5371 - val_mae: 1.1455\n",
      "Epoch 5/100\n",
      "164/164 [==============================] - 0s 815us/step - loss: 4.6485 - mae: 1.1445 - val_loss: 4.6440 - val_mae: 1.2930\n",
      "Epoch 6/100\n",
      "164/164 [==============================] - 0s 887us/step - loss: 4.6425 - mae: 1.1455 - val_loss: 4.5486 - val_mae: 1.1295\n",
      "Epoch 7/100\n",
      "164/164 [==============================] - 0s 735us/step - loss: 4.6131 - mae: 1.1424 - val_loss: 4.5471 - val_mae: 1.0957\n",
      "Epoch 8/100\n",
      "164/164 [==============================] - 0s 735us/step - loss: 4.6114 - mae: 1.1344 - val_loss: 4.5510 - val_mae: 1.2350\n",
      "Epoch 9/100\n",
      "164/164 [==============================] - 0s 716us/step - loss: 4.5808 - mae: 1.1522 - val_loss: 4.6001 - val_mae: 1.0824\n",
      "Epoch 10/100\n",
      "164/164 [==============================] - 0s 742us/step - loss: 4.5832 - mae: 1.1390 - val_loss: 4.5250 - val_mae: 1.2673\n",
      "Epoch 11/100\n",
      "164/164 [==============================] - 0s 719us/step - loss: 4.5627 - mae: 1.1482 - val_loss: 4.5279 - val_mae: 1.2534\n",
      "Epoch 12/100\n",
      "164/164 [==============================] - 0s 768us/step - loss: 4.5982 - mae: 1.1439 - val_loss: 4.5291 - val_mae: 1.1675\n",
      "Epoch 13/100\n",
      "164/164 [==============================] - 0s 712us/step - loss: 4.5684 - mae: 1.1326 - val_loss: 4.6271 - val_mae: 1.2637\n",
      "Epoch 14/100\n",
      "164/164 [==============================] - 0s 739us/step - loss: 4.5728 - mae: 1.1457 - val_loss: 4.4956 - val_mae: 1.1877\n",
      "Epoch 15/100\n",
      "164/164 [==============================] - 0s 704us/step - loss: 4.5537 - mae: 1.1409 - val_loss: 4.5099 - val_mae: 1.1942\n",
      "Epoch 16/100\n",
      "164/164 [==============================] - 0s 727us/step - loss: 4.5763 - mae: 1.1342 - val_loss: 4.5022 - val_mae: 1.1688\n",
      "Epoch 17/100\n",
      "164/164 [==============================] - 0s 750us/step - loss: 4.5718 - mae: 1.1444 - val_loss: 4.5543 - val_mae: 1.1071\n",
      "Epoch 18/100\n",
      "164/164 [==============================] - 0s 824us/step - loss: 4.5623 - mae: 1.1260 - val_loss: 4.5381 - val_mae: 1.1729\n",
      "Epoch 19/100\n",
      "164/164 [==============================] - 0s 740us/step - loss: 4.5513 - mae: 1.1292 - val_loss: 4.5615 - val_mae: 1.2610\n",
      "Epoch 20/100\n",
      "164/164 [==============================] - 0s 795us/step - loss: 4.5328 - mae: 1.1363 - val_loss: 4.5895 - val_mae: 1.3089\n",
      "Epoch 21/100\n",
      "164/164 [==============================] - 0s 791us/step - loss: 4.5477 - mae: 1.1402 - val_loss: 4.5301 - val_mae: 1.2296\n",
      "Epoch 22/100\n",
      "164/164 [==============================] - 0s 729us/step - loss: 4.5350 - mae: 1.1370 - val_loss: 4.5663 - val_mae: 1.2366\n",
      "Epoch 23/100\n",
      "164/164 [==============================] - 0s 790us/step - loss: 4.5397 - mae: 1.1414 - val_loss: 4.5106 - val_mae: 1.1722\n",
      "Epoch 24/100\n",
      "164/164 [==============================] - 0s 858us/step - loss: 4.5273 - mae: 1.1289 - val_loss: 4.5872 - val_mae: 1.2467\n",
      "Epoch 25/100\n",
      "164/164 [==============================] - 0s 720us/step - loss: 4.5402 - mae: 1.1392 - val_loss: 4.4999 - val_mae: 1.1534\n",
      "Epoch 26/100\n",
      "164/164 [==============================] - 0s 811us/step - loss: 4.5476 - mae: 1.1373 - val_loss: 4.4915 - val_mae: 1.1201\n",
      "Epoch 27/100\n",
      "164/164 [==============================] - 0s 713us/step - loss: 4.5365 - mae: 1.1387 - val_loss: 4.4994 - val_mae: 1.1548\n",
      "Epoch 28/100\n",
      "164/164 [==============================] - 0s 775us/step - loss: 4.5419 - mae: 1.1369 - val_loss: 4.4948 - val_mae: 1.2118\n",
      "Epoch 29/100\n",
      "164/164 [==============================] - 0s 889us/step - loss: 4.5279 - mae: 1.1334 - val_loss: 4.5136 - val_mae: 1.2232\n",
      "Epoch 30/100\n",
      "164/164 [==============================] - 0s 817us/step - loss: 4.5321 - mae: 1.1328 - val_loss: 4.5113 - val_mae: 1.1816\n",
      "Epoch 31/100\n",
      "164/164 [==============================] - 0s 743us/step - loss: 4.5339 - mae: 1.1377 - val_loss: 4.5876 - val_mae: 1.2934\n",
      "Epoch 32/100\n",
      "164/164 [==============================] - 0s 720us/step - loss: 4.5231 - mae: 1.1387 - val_loss: 4.5215 - val_mae: 1.1350\n",
      "Epoch 33/100\n",
      "164/164 [==============================] - 0s 759us/step - loss: 4.5340 - mae: 1.1381 - val_loss: 4.5504 - val_mae: 1.2065\n",
      "Epoch 34/100\n",
      "164/164 [==============================] - 0s 694us/step - loss: 4.5427 - mae: 1.1359 - val_loss: 4.5066 - val_mae: 1.2092\n",
      "Epoch 35/100\n",
      "164/164 [==============================] - 0s 751us/step - loss: 4.5298 - mae: 1.1390 - val_loss: 4.5777 - val_mae: 1.0645\n",
      "Epoch 36/100\n",
      "164/164 [==============================] - 0s 742us/step - loss: 4.5843 - mae: 1.1293 - val_loss: 4.5673 - val_mae: 1.1871\n",
      "Epoch 37/100\n",
      "164/164 [==============================] - 0s 722us/step - loss: 4.5391 - mae: 1.1367 - val_loss: 4.5330 - val_mae: 1.2510\n",
      "Epoch 38/100\n",
      "164/164 [==============================] - 0s 845us/step - loss: 4.5407 - mae: 1.1423 - val_loss: 4.5696 - val_mae: 1.2472\n",
      "Epoch 39/100\n",
      "164/164 [==============================] - 0s 770us/step - loss: 4.5536 - mae: 1.1365 - val_loss: 4.6449 - val_mae: 1.2774\n",
      "Epoch 40/100\n",
      "164/164 [==============================] - 0s 763us/step - loss: 4.5417 - mae: 1.1377 - val_loss: 4.5201 - val_mae: 1.1284\n",
      "Epoch 41/100\n",
      "164/164 [==============================] - 0s 727us/step - loss: 4.5479 - mae: 1.1395 - val_loss: 4.4960 - val_mae: 1.1410\n",
      "Epoch 42/100\n",
      "164/164 [==============================] - 0s 763us/step - loss: 4.5328 - mae: 1.1376 - val_loss: 4.5164 - val_mae: 1.1848\n",
      "Epoch 43/100\n",
      "164/164 [==============================] - 0s 786us/step - loss: 4.5207 - mae: 1.1302 - val_loss: 4.5078 - val_mae: 1.2049\n",
      "Epoch 44/100\n",
      "164/164 [==============================] - 0s 761us/step - loss: 4.5164 - mae: 1.1377 - val_loss: 4.5295 - val_mae: 1.2060\n",
      "Epoch 45/100\n",
      "164/164 [==============================] - 0s 749us/step - loss: 4.5231 - mae: 1.1334 - val_loss: 4.5217 - val_mae: 1.2032\n",
      "Epoch 46/100\n",
      "164/164 [==============================] - 0s 740us/step - loss: 4.5588 - mae: 1.1262 - val_loss: 4.5443 - val_mae: 1.2696\n",
      "Epoch 46: early stopping\n",
      "Test Loss (MSE): 4.00535249710083, Test Mean Absolute Error (MAE): 1.1816680431365967\n",
      "Epoch 1/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 8.3109 - mae: 1.7931 - val_loss: 7.6311 - val_mae: 1.7258\n",
      "Epoch 2/100\n",
      "93/93 [==============================] - 0s 782us/step - loss: 7.6676 - mae: 1.7430 - val_loss: 7.5426 - val_mae: 1.7265\n",
      "Epoch 3/100\n",
      "93/93 [==============================] - 0s 745us/step - loss: 7.6423 - mae: 1.7612 - val_loss: 7.6823 - val_mae: 1.6257\n",
      "Epoch 4/100\n",
      "93/93 [==============================] - 0s 722us/step - loss: 7.4920 - mae: 1.7307 - val_loss: 7.4030 - val_mae: 1.7002\n",
      "Epoch 5/100\n",
      "93/93 [==============================] - 0s 681us/step - loss: 7.4554 - mae: 1.7284 - val_loss: 7.4637 - val_mae: 1.7549\n",
      "Epoch 6/100\n",
      "93/93 [==============================] - 0s 699us/step - loss: 7.4537 - mae: 1.7430 - val_loss: 7.3639 - val_mae: 1.7116\n",
      "Epoch 7/100\n",
      "93/93 [==============================] - 0s 740us/step - loss: 7.4373 - mae: 1.7181 - val_loss: 7.4884 - val_mae: 1.8699\n",
      "Epoch 8/100\n",
      "93/93 [==============================] - 0s 688us/step - loss: 7.4737 - mae: 1.7444 - val_loss: 7.4558 - val_mae: 1.6798\n",
      "Epoch 9/100\n",
      "93/93 [==============================] - 0s 736us/step - loss: 7.4732 - mae: 1.7357 - val_loss: 7.3575 - val_mae: 1.7357\n",
      "Epoch 10/100\n",
      "93/93 [==============================] - 0s 680us/step - loss: 7.4501 - mae: 1.7285 - val_loss: 7.4875 - val_mae: 1.9077\n",
      "Epoch 11/100\n",
      "93/93 [==============================] - 0s 713us/step - loss: 7.4398 - mae: 1.7425 - val_loss: 7.3696 - val_mae: 1.7383\n",
      "Epoch 12/100\n",
      "93/93 [==============================] - 0s 708us/step - loss: 7.4117 - mae: 1.7309 - val_loss: 7.7427 - val_mae: 1.6205\n",
      "Epoch 13/100\n",
      "93/93 [==============================] - 0s 676us/step - loss: 7.4203 - mae: 1.7304 - val_loss: 7.5159 - val_mae: 1.6620\n",
      "Epoch 14/100\n",
      "93/93 [==============================] - 0s 673us/step - loss: 7.4474 - mae: 1.7220 - val_loss: 7.7048 - val_mae: 2.0270\n",
      "Epoch 15/100\n",
      "93/93 [==============================] - 0s 706us/step - loss: 7.4653 - mae: 1.7363 - val_loss: 7.4057 - val_mae: 1.6842\n",
      "Epoch 16/100\n",
      "93/93 [==============================] - 0s 706us/step - loss: 7.4166 - mae: 1.7404 - val_loss: 7.3579 - val_mae: 1.7171\n",
      "Epoch 17/100\n",
      "93/93 [==============================] - 0s 741us/step - loss: 7.4023 - mae: 1.7214 - val_loss: 7.3587 - val_mae: 1.7202\n",
      "Epoch 18/100\n",
      "93/93 [==============================] - 0s 712us/step - loss: 7.3883 - mae: 1.7304 - val_loss: 7.3427 - val_mae: 1.7936\n",
      "Epoch 19/100\n",
      "93/93 [==============================] - 0s 704us/step - loss: 7.4379 - mae: 1.7375 - val_loss: 7.3903 - val_mae: 1.7021\n",
      "Epoch 20/100\n",
      "93/93 [==============================] - 0s 721us/step - loss: 7.3778 - mae: 1.7279 - val_loss: 7.3521 - val_mae: 1.7911\n",
      "Epoch 21/100\n",
      "93/93 [==============================] - 0s 707us/step - loss: 7.3680 - mae: 1.7262 - val_loss: 7.3989 - val_mae: 1.8265\n",
      "Epoch 22/100\n",
      "93/93 [==============================] - 0s 699us/step - loss: 7.3598 - mae: 1.7437 - val_loss: 7.5952 - val_mae: 1.6495\n",
      "Epoch 23/100\n",
      "93/93 [==============================] - 0s 746us/step - loss: 7.3884 - mae: 1.7094 - val_loss: 7.4165 - val_mae: 1.8721\n",
      "Epoch 24/100\n",
      "93/93 [==============================] - 0s 727us/step - loss: 7.3541 - mae: 1.7379 - val_loss: 7.3545 - val_mae: 1.7644\n",
      "Epoch 25/100\n",
      "93/93 [==============================] - 0s 727us/step - loss: 7.3824 - mae: 1.7216 - val_loss: 7.4146 - val_mae: 1.7163\n",
      "Epoch 26/100\n",
      "93/93 [==============================] - 0s 723us/step - loss: 7.3547 - mae: 1.7349 - val_loss: 7.3970 - val_mae: 1.7297\n",
      "Epoch 27/100\n",
      "93/93 [==============================] - 0s 664us/step - loss: 7.3545 - mae: 1.7341 - val_loss: 7.4253 - val_mae: 1.6912\n",
      "Epoch 28/100\n",
      "93/93 [==============================] - 0s 781us/step - loss: 7.4133 - mae: 1.7265 - val_loss: 7.4079 - val_mae: 1.7542\n",
      "Epoch 29/100\n",
      "93/93 [==============================] - 0s 733us/step - loss: 7.3608 - mae: 1.7334 - val_loss: 7.3682 - val_mae: 1.7413\n",
      "Epoch 30/100\n",
      "93/93 [==============================] - 0s 750us/step - loss: 7.3411 - mae: 1.7282 - val_loss: 7.3988 - val_mae: 1.7684\n",
      "Epoch 31/100\n",
      "93/93 [==============================] - 0s 719us/step - loss: 7.3497 - mae: 1.7458 - val_loss: 7.4080 - val_mae: 1.6960\n",
      "Epoch 32/100\n",
      "93/93 [==============================] - 0s 723us/step - loss: 7.3562 - mae: 1.7227 - val_loss: 7.6977 - val_mae: 1.6307\n",
      "Epoch 33/100\n",
      "93/93 [==============================] - 0s 707us/step - loss: 7.3799 - mae: 1.7355 - val_loss: 7.5994 - val_mae: 1.6529\n",
      "Epoch 34/100\n",
      "93/93 [==============================] - 0s 852us/step - loss: 7.3797 - mae: 1.7249 - val_loss: 7.3871 - val_mae: 1.7968\n",
      "Epoch 35/100\n",
      "93/93 [==============================] - 0s 733us/step - loss: 7.3431 - mae: 1.7226 - val_loss: 7.3990 - val_mae: 1.7979\n",
      "Epoch 36/100\n",
      "93/93 [==============================] - 0s 701us/step - loss: 7.3141 - mae: 1.7299 - val_loss: 7.3894 - val_mae: 1.7597\n",
      "Epoch 37/100\n",
      "93/93 [==============================] - 0s 720us/step - loss: 7.3552 - mae: 1.7235 - val_loss: 7.3740 - val_mae: 1.7572\n",
      "Epoch 38/100\n",
      "93/93 [==============================] - 0s 907us/step - loss: 7.3286 - mae: 1.7370 - val_loss: 7.3808 - val_mae: 1.7749\n",
      "Epoch 38: early stopping\n",
      "Test Loss (MSE): 7.595280647277832, Test Mean Absolute Error (MAE): 1.830307960510254\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 8.6452 - mae: 1.8221 - val_loss: 8.0128 - val_mae: 1.8265\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 772us/step - loss: 7.7913 - mae: 1.7813 - val_loss: 7.6686 - val_mae: 1.6712\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 803us/step - loss: 7.6271 - mae: 1.7631 - val_loss: 7.5894 - val_mae: 1.8112\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 761us/step - loss: 7.5890 - mae: 1.7636 - val_loss: 7.7596 - val_mae: 1.6164\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 755us/step - loss: 7.5503 - mae: 1.7901 - val_loss: 7.6716 - val_mae: 1.6686\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 739us/step - loss: 7.4972 - mae: 1.7509 - val_loss: 7.6889 - val_mae: 1.7521\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 802us/step - loss: 7.5360 - mae: 1.7730 - val_loss: 7.6306 - val_mae: 1.8902\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 970us/step - loss: 7.4398 - mae: 1.7632 - val_loss: 7.5616 - val_mae: 1.7043\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 706us/step - loss: 7.4158 - mae: 1.7675 - val_loss: 7.5595 - val_mae: 1.6768\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 741us/step - loss: 7.3817 - mae: 1.7502 - val_loss: 7.4673 - val_mae: 1.7416\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 753us/step - loss: 7.4275 - mae: 1.7808 - val_loss: 7.6672 - val_mae: 1.6301\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 853us/step - loss: 7.3873 - mae: 1.7504 - val_loss: 7.5192 - val_mae: 1.7473\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 721us/step - loss: 7.3493 - mae: 1.7606 - val_loss: 7.5113 - val_mae: 1.8588\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 744us/step - loss: 7.3382 - mae: 1.7523 - val_loss: 7.5180 - val_mae: 1.6414\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 742us/step - loss: 7.3339 - mae: 1.7456 - val_loss: 7.4761 - val_mae: 1.6778\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 808us/step - loss: 7.3149 - mae: 1.7518 - val_loss: 7.4840 - val_mae: 1.7754\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 703us/step - loss: 7.3412 - mae: 1.7651 - val_loss: 7.5153 - val_mae: 1.7659\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 740us/step - loss: 7.2879 - mae: 1.7574 - val_loss: 7.4961 - val_mae: 1.7678\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 765us/step - loss: 7.3372 - mae: 1.7491 - val_loss: 7.5347 - val_mae: 1.6826\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 815us/step - loss: 7.3224 - mae: 1.7624 - val_loss: 7.5234 - val_mae: 1.6844\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 773us/step - loss: 7.2887 - mae: 1.7549 - val_loss: 7.5089 - val_mae: 1.7779\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 793us/step - loss: 7.3214 - mae: 1.7534 - val_loss: 7.4903 - val_mae: 1.7904\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 734us/step - loss: 7.2904 - mae: 1.7582 - val_loss: 7.5770 - val_mae: 1.6974\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 835us/step - loss: 7.2890 - mae: 1.7520 - val_loss: 7.5048 - val_mae: 1.7877\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 752us/step - loss: 7.2911 - mae: 1.7506 - val_loss: 7.5075 - val_mae: 1.7167\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 733us/step - loss: 7.2767 - mae: 1.7596 - val_loss: 7.5229 - val_mae: 1.7248\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 0s 751us/step - loss: 7.2707 - mae: 1.7655 - val_loss: 7.5661 - val_mae: 1.6780\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 773us/step - loss: 7.2932 - mae: 1.7512 - val_loss: 7.4988 - val_mae: 1.7181\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 747us/step - loss: 7.2914 - mae: 1.7588 - val_loss: 7.4645 - val_mae: 1.7324\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 784us/step - loss: 7.2728 - mae: 1.7485 - val_loss: 7.4746 - val_mae: 1.7298\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 736us/step - loss: 7.2326 - mae: 1.7489 - val_loss: 7.5075 - val_mae: 1.6762\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 0s 758us/step - loss: 7.2877 - mae: 1.7434 - val_loss: 7.5291 - val_mae: 1.7558\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 0s 753us/step - loss: 7.2650 - mae: 1.7555 - val_loss: 7.4787 - val_mae: 1.7723\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 0s 788us/step - loss: 7.2568 - mae: 1.7463 - val_loss: 7.5509 - val_mae: 1.7553\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 0s 713us/step - loss: 7.2902 - mae: 1.7659 - val_loss: 7.4932 - val_mae: 1.7671\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 0s 724us/step - loss: 7.2525 - mae: 1.7371 - val_loss: 7.4936 - val_mae: 1.8123\n",
      "Epoch 37/100\n",
      "91/91 [==============================] - 0s 769us/step - loss: 7.2616 - mae: 1.7662 - val_loss: 7.4761 - val_mae: 1.7671\n",
      "Epoch 38/100\n",
      "91/91 [==============================] - 0s 736us/step - loss: 7.2403 - mae: 1.7383 - val_loss: 7.5292 - val_mae: 1.7609\n",
      "Epoch 39/100\n",
      "91/91 [==============================] - 0s 726us/step - loss: 7.2946 - mae: 1.7398 - val_loss: 7.6057 - val_mae: 1.8344\n",
      "Epoch 40/100\n",
      "91/91 [==============================] - 0s 816us/step - loss: 7.2621 - mae: 1.7690 - val_loss: 7.4594 - val_mae: 1.7333\n",
      "Epoch 41/100\n",
      "91/91 [==============================] - 0s 783us/step - loss: 7.2446 - mae: 1.7460 - val_loss: 7.5503 - val_mae: 1.6955\n",
      "Epoch 42/100\n",
      "91/91 [==============================] - 0s 944us/step - loss: 7.2687 - mae: 1.7396 - val_loss: 7.6357 - val_mae: 1.7359\n",
      "Epoch 43/100\n",
      "91/91 [==============================] - 0s 869us/step - loss: 7.2588 - mae: 1.7473 - val_loss: 7.5691 - val_mae: 1.8637\n",
      "Epoch 44/100\n",
      "91/91 [==============================] - 0s 840us/step - loss: 7.2408 - mae: 1.7710 - val_loss: 7.4584 - val_mae: 1.7123\n",
      "Epoch 45/100\n",
      "91/91 [==============================] - 0s 792us/step - loss: 7.2235 - mae: 1.7273 - val_loss: 7.4921 - val_mae: 1.8131\n",
      "Epoch 46/100\n",
      "91/91 [==============================] - 0s 815us/step - loss: 7.2316 - mae: 1.7566 - val_loss: 7.5083 - val_mae: 1.8207\n",
      "Epoch 47/100\n",
      "91/91 [==============================] - 0s 743us/step - loss: 7.2223 - mae: 1.7492 - val_loss: 7.4811 - val_mae: 1.7681\n",
      "Epoch 48/100\n",
      "91/91 [==============================] - 0s 800us/step - loss: 7.2229 - mae: 1.7578 - val_loss: 7.4851 - val_mae: 1.7086\n",
      "Epoch 49/100\n",
      "91/91 [==============================] - 0s 695us/step - loss: 7.2292 - mae: 1.7359 - val_loss: 7.5525 - val_mae: 1.8324\n",
      "Epoch 50/100\n",
      "91/91 [==============================] - 0s 718us/step - loss: 7.2378 - mae: 1.7545 - val_loss: 7.5195 - val_mae: 1.7694\n",
      "Epoch 51/100\n",
      "91/91 [==============================] - 0s 722us/step - loss: 7.2329 - mae: 1.7457 - val_loss: 7.5327 - val_mae: 1.8080\n",
      "Epoch 52/100\n",
      "91/91 [==============================] - 0s 720us/step - loss: 7.2192 - mae: 1.7487 - val_loss: 7.5381 - val_mae: 1.7812\n",
      "Epoch 53/100\n",
      "91/91 [==============================] - 0s 705us/step - loss: 7.1886 - mae: 1.7500 - val_loss: 7.5302 - val_mae: 1.7436\n",
      "Epoch 54/100\n",
      "91/91 [==============================] - 0s 721us/step - loss: 7.2528 - mae: 1.7425 - val_loss: 7.5751 - val_mae: 1.8285\n",
      "Epoch 55/100\n",
      "91/91 [==============================] - 0s 768us/step - loss: 7.2090 - mae: 1.7488 - val_loss: 7.4796 - val_mae: 1.7034\n",
      "Epoch 56/100\n",
      "91/91 [==============================] - 0s 711us/step - loss: 7.2451 - mae: 1.7346 - val_loss: 7.6048 - val_mae: 1.8090\n",
      "Epoch 57/100\n",
      "91/91 [==============================] - 0s 761us/step - loss: 7.2261 - mae: 1.7571 - val_loss: 7.5735 - val_mae: 1.6392\n",
      "Epoch 58/100\n",
      "91/91 [==============================] - 0s 716us/step - loss: 7.2138 - mae: 1.7241 - val_loss: 7.5575 - val_mae: 1.8218\n",
      "Epoch 59/100\n",
      "91/91 [==============================] - 0s 729us/step - loss: 7.1938 - mae: 1.7490 - val_loss: 7.5285 - val_mae: 1.8062\n",
      "Epoch 60/100\n",
      "91/91 [==============================] - 0s 724us/step - loss: 7.1780 - mae: 1.7464 - val_loss: 7.5122 - val_mae: 1.7619\n",
      "Epoch 61/100\n",
      "91/91 [==============================] - 0s 772us/step - loss: 7.2345 - mae: 1.7452 - val_loss: 7.5217 - val_mae: 1.7068\n",
      "Epoch 62/100\n",
      "91/91 [==============================] - 0s 720us/step - loss: 7.1952 - mae: 1.7509 - val_loss: 7.5384 - val_mae: 1.7301\n",
      "Epoch 63/100\n",
      "91/91 [==============================] - 0s 731us/step - loss: 7.1705 - mae: 1.7393 - val_loss: 7.5189 - val_mae: 1.7757\n",
      "Epoch 64/100\n",
      "91/91 [==============================] - 0s 704us/step - loss: 7.2124 - mae: 1.7378 - val_loss: 7.5917 - val_mae: 1.8026\n",
      "Epoch 64: early stopping\n",
      "Test Loss (MSE): 7.860988616943359, Test Mean Absolute Error (MAE): 1.8404498100280762\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 9.4748 - mae: 1.8958 - val_loss: 7.0430 - val_mae: 1.7170\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 786us/step - loss: 8.5360 - mae: 1.8337 - val_loss: 7.1496 - val_mae: 1.9416\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 793us/step - loss: 8.3398 - mae: 1.8624 - val_loss: 6.7038 - val_mae: 1.5379\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 941us/step - loss: 8.4441 - mae: 1.8480 - val_loss: 6.4602 - val_mae: 1.5519\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 807us/step - loss: 8.3035 - mae: 1.8537 - val_loss: 6.4599 - val_mae: 1.5727\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 791us/step - loss: 8.2210 - mae: 1.8412 - val_loss: 6.7605 - val_mae: 1.8110\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 774us/step - loss: 8.2655 - mae: 1.8575 - val_loss: 6.4733 - val_mae: 1.5032\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 752us/step - loss: 8.2396 - mae: 1.8551 - val_loss: 6.5382 - val_mae: 1.4888\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 806us/step - loss: 8.1583 - mae: 1.8424 - val_loss: 6.4222 - val_mae: 1.6084\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 839us/step - loss: 8.1954 - mae: 1.8266 - val_loss: 6.5639 - val_mae: 1.7285\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 783us/step - loss: 8.2621 - mae: 1.8442 - val_loss: 6.4244 - val_mae: 1.6128\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 782us/step - loss: 8.1412 - mae: 1.8527 - val_loss: 6.6492 - val_mae: 1.7256\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 743us/step - loss: 8.1263 - mae: 1.8338 - val_loss: 6.6640 - val_mae: 1.7632\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 840us/step - loss: 8.2025 - mae: 1.8417 - val_loss: 6.4057 - val_mae: 1.5549\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 770us/step - loss: 8.1072 - mae: 1.8129 - val_loss: 6.5743 - val_mae: 1.6642\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 807us/step - loss: 8.0946 - mae: 1.8622 - val_loss: 6.3982 - val_mae: 1.5643\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 776us/step - loss: 8.1054 - mae: 1.8376 - val_loss: 6.4556 - val_mae: 1.5581\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 756us/step - loss: 8.0676 - mae: 1.8160 - val_loss: 6.7323 - val_mae: 1.8070\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 864us/step - loss: 8.1240 - mae: 1.8420 - val_loss: 6.4935 - val_mae: 1.6899\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 828us/step - loss: 8.0974 - mae: 1.8369 - val_loss: 6.6151 - val_mae: 1.7406\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 779us/step - loss: 8.0574 - mae: 1.8405 - val_loss: 6.5277 - val_mae: 1.6809\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 773us/step - loss: 8.0313 - mae: 1.8238 - val_loss: 6.5195 - val_mae: 1.6660\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 793us/step - loss: 8.1255 - mae: 1.8433 - val_loss: 6.4345 - val_mae: 1.5684\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 810us/step - loss: 8.0077 - mae: 1.8235 - val_loss: 6.6108 - val_mae: 1.7430\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 895us/step - loss: 8.0483 - mae: 1.8334 - val_loss: 6.4835 - val_mae: 1.6300\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 785us/step - loss: 8.0308 - mae: 1.8395 - val_loss: 6.4690 - val_mae: 1.5993\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 0s 745us/step - loss: 8.0304 - mae: 1.8311 - val_loss: 6.4569 - val_mae: 1.5584\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 771us/step - loss: 7.9783 - mae: 1.8222 - val_loss: 6.4664 - val_mae: 1.5662\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 841us/step - loss: 8.0710 - mae: 1.8386 - val_loss: 6.5625 - val_mae: 1.7098\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 976us/step - loss: 8.0376 - mae: 1.8228 - val_loss: 6.5693 - val_mae: 1.7022\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 902us/step - loss: 8.0083 - mae: 1.8296 - val_loss: 6.5566 - val_mae: 1.6844\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 0s 879us/step - loss: 8.0231 - mae: 1.8350 - val_loss: 6.5204 - val_mae: 1.6682\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 0s 908us/step - loss: 8.0030 - mae: 1.8334 - val_loss: 6.5273 - val_mae: 1.6327\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 0s 846us/step - loss: 7.9728 - mae: 1.8138 - val_loss: 6.7645 - val_mae: 1.7680\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 0s 852us/step - loss: 7.9668 - mae: 1.8222 - val_loss: 6.5593 - val_mae: 1.6912\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 0s 789us/step - loss: 7.9735 - mae: 1.8267 - val_loss: 6.7175 - val_mae: 1.7628\n",
      "Epoch 36: early stopping\n",
      "Test Loss (MSE): 6.687452793121338, Test Mean Absolute Error (MAE): 1.7921643257141113\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 8.6034 - mae: 1.7806 - val_loss: 8.3097 - val_mae: 1.7457\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 847us/step - loss: 7.7461 - mae: 1.7460 - val_loss: 8.2634 - val_mae: 1.6479\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 794us/step - loss: 7.5941 - mae: 1.7476 - val_loss: 8.3694 - val_mae: 1.6445\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 844us/step - loss: 7.3790 - mae: 1.7033 - val_loss: 7.8790 - val_mae: 1.7007\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 775us/step - loss: 7.3368 - mae: 1.7218 - val_loss: 7.8447 - val_mae: 1.6879\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 775us/step - loss: 7.2807 - mae: 1.7162 - val_loss: 8.0017 - val_mae: 1.6592\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 743us/step - loss: 7.2773 - mae: 1.7139 - val_loss: 7.8334 - val_mae: 1.8494\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 825us/step - loss: 7.2498 - mae: 1.7218 - val_loss: 7.8969 - val_mae: 1.8727\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 784us/step - loss: 7.2536 - mae: 1.7097 - val_loss: 7.7671 - val_mae: 1.7964\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 811us/step - loss: 7.2389 - mae: 1.7221 - val_loss: 7.9600 - val_mae: 1.6695\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 780us/step - loss: 7.2647 - mae: 1.7171 - val_loss: 7.8207 - val_mae: 1.7697\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 768us/step - loss: 7.1814 - mae: 1.7097 - val_loss: 7.8495 - val_mae: 1.8731\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 841us/step - loss: 7.2032 - mae: 1.7177 - val_loss: 7.7778 - val_mae: 1.7594\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 763us/step - loss: 7.1674 - mae: 1.7227 - val_loss: 7.7896 - val_mae: 1.7119\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 810us/step - loss: 7.1573 - mae: 1.7122 - val_loss: 7.8429 - val_mae: 1.6993\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 799us/step - loss: 7.1583 - mae: 1.7078 - val_loss: 7.7755 - val_mae: 1.7242\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 793us/step - loss: 7.2099 - mae: 1.7256 - val_loss: 7.7778 - val_mae: 1.7107\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 764us/step - loss: 7.1471 - mae: 1.7068 - val_loss: 7.7538 - val_mae: 1.7641\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 804us/step - loss: 7.1419 - mae: 1.7232 - val_loss: 7.7585 - val_mae: 1.7467\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 767us/step - loss: 7.1446 - mae: 1.7112 - val_loss: 7.8264 - val_mae: 1.8046\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 744us/step - loss: 7.1112 - mae: 1.7085 - val_loss: 7.8508 - val_mae: 1.7089\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 756us/step - loss: 7.1328 - mae: 1.7014 - val_loss: 7.7877 - val_mae: 1.7355\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 781us/step - loss: 7.1249 - mae: 1.7036 - val_loss: 7.7841 - val_mae: 1.7706\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 766us/step - loss: 7.0911 - mae: 1.7249 - val_loss: 7.7138 - val_mae: 1.7560\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 881us/step - loss: 7.1085 - mae: 1.7152 - val_loss: 7.8379 - val_mae: 1.7444\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 767us/step - loss: 7.0937 - mae: 1.6968 - val_loss: 7.8631 - val_mae: 1.6779\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 0s 783us/step - loss: 7.0846 - mae: 1.7064 - val_loss: 7.7430 - val_mae: 1.8204\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 777us/step - loss: 7.1259 - mae: 1.7071 - val_loss: 7.8327 - val_mae: 1.7389\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 779us/step - loss: 7.0700 - mae: 1.7039 - val_loss: 7.8548 - val_mae: 1.7780\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 790us/step - loss: 7.0704 - mae: 1.7039 - val_loss: 7.8167 - val_mae: 1.7811\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 749us/step - loss: 7.0889 - mae: 1.7002 - val_loss: 7.8091 - val_mae: 1.7608\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 0s 878us/step - loss: 7.0730 - mae: 1.7000 - val_loss: 7.8934 - val_mae: 1.8490\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 0s 901us/step - loss: 7.0033 - mae: 1.7093 - val_loss: 7.7862 - val_mae: 1.7289\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 0s 842us/step - loss: 6.9989 - mae: 1.6911 - val_loss: 7.8467 - val_mae: 1.7694\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 0s 825us/step - loss: 7.0655 - mae: 1.6949 - val_loss: 7.8560 - val_mae: 1.7566\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 0s 805us/step - loss: 7.0232 - mae: 1.6890 - val_loss: 8.0267 - val_mae: 1.9229\n",
      "Epoch 37/100\n",
      "91/91 [==============================] - 0s 807us/step - loss: 7.0613 - mae: 1.7066 - val_loss: 7.8508 - val_mae: 1.7794\n",
      "Epoch 38/100\n",
      "91/91 [==============================] - 0s 819us/step - loss: 7.0329 - mae: 1.7030 - val_loss: 7.8446 - val_mae: 1.8207\n",
      "Epoch 39/100\n",
      "91/91 [==============================] - 0s 833us/step - loss: 7.0027 - mae: 1.6959 - val_loss: 7.8656 - val_mae: 1.7361\n",
      "Epoch 40/100\n",
      "91/91 [==============================] - 0s 776us/step - loss: 7.0029 - mae: 1.6908 - val_loss: 7.8859 - val_mae: 1.8024\n",
      "Epoch 41/100\n",
      "91/91 [==============================] - 0s 762us/step - loss: 7.0112 - mae: 1.6853 - val_loss: 7.7940 - val_mae: 1.8003\n",
      "Epoch 42/100\n",
      "91/91 [==============================] - 0s 771us/step - loss: 7.0101 - mae: 1.7069 - val_loss: 7.8405 - val_mae: 1.7456\n",
      "Epoch 43/100\n",
      "91/91 [==============================] - 0s 767us/step - loss: 6.9788 - mae: 1.6858 - val_loss: 7.8916 - val_mae: 1.7852\n",
      "Epoch 44/100\n",
      "91/91 [==============================] - 0s 779us/step - loss: 6.9938 - mae: 1.7016 - val_loss: 8.1205 - val_mae: 1.6706\n",
      "Epoch 44: early stopping\n",
      "Test Loss (MSE): 8.011773109436035, Test Mean Absolute Error (MAE): 1.7084949016571045\n",
      "Epoch 1/100\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 5.1116 - mae: 1.2014 - val_loss: 4.9659 - val_mae: 1.5366\n",
      "Epoch 2/100\n",
      "166/166 [==============================] - 0s 698us/step - loss: 4.9194 - mae: 1.1998 - val_loss: 4.3287 - val_mae: 1.1067\n",
      "Epoch 3/100\n",
      "166/166 [==============================] - 0s 695us/step - loss: 4.7427 - mae: 1.1848 - val_loss: 4.3220 - val_mae: 1.2559\n",
      "Epoch 4/100\n",
      "166/166 [==============================] - 0s 695us/step - loss: 4.6812 - mae: 1.1867 - val_loss: 4.2056 - val_mae: 1.1256\n",
      "Epoch 5/100\n",
      "166/166 [==============================] - 0s 728us/step - loss: 4.6623 - mae: 1.1759 - val_loss: 4.2440 - val_mae: 1.0364\n",
      "Epoch 6/100\n",
      "166/166 [==============================] - 0s 664us/step - loss: 4.6654 - mae: 1.1886 - val_loss: 4.2568 - val_mae: 1.0892\n",
      "Epoch 7/100\n",
      "166/166 [==============================] - 0s 648us/step - loss: 4.6407 - mae: 1.1747 - val_loss: 4.2393 - val_mae: 1.1851\n",
      "Epoch 8/100\n",
      "166/166 [==============================] - 0s 694us/step - loss: 4.6433 - mae: 1.1800 - val_loss: 4.1877 - val_mae: 1.0757\n",
      "Epoch 9/100\n",
      "166/166 [==============================] - 0s 696us/step - loss: 4.6420 - mae: 1.1783 - val_loss: 4.1767 - val_mae: 1.0551\n",
      "Epoch 10/100\n",
      "166/166 [==============================] - 0s 747us/step - loss: 4.6454 - mae: 1.1718 - val_loss: 4.2160 - val_mae: 1.0402\n",
      "Epoch 11/100\n",
      "166/166 [==============================] - 0s 668us/step - loss: 4.6277 - mae: 1.1738 - val_loss: 4.2046 - val_mae: 1.1110\n",
      "Epoch 12/100\n",
      "166/166 [==============================] - 0s 690us/step - loss: 4.6372 - mae: 1.1732 - val_loss: 4.2031 - val_mae: 1.1428\n",
      "Epoch 13/100\n",
      "166/166 [==============================] - 0s 677us/step - loss: 4.6366 - mae: 1.1776 - val_loss: 4.2095 - val_mae: 1.0834\n",
      "Epoch 14/100\n",
      "166/166 [==============================] - 0s 685us/step - loss: 4.6544 - mae: 1.1707 - val_loss: 4.2687 - val_mae: 1.2422\n",
      "Epoch 15/100\n",
      "166/166 [==============================] - 0s 690us/step - loss: 4.6470 - mae: 1.1824 - val_loss: 4.1987 - val_mae: 1.1223\n",
      "Epoch 16/100\n",
      "166/166 [==============================] - 0s 667us/step - loss: 4.6142 - mae: 1.1709 - val_loss: 4.1632 - val_mae: 1.1017\n",
      "Epoch 17/100\n",
      "166/166 [==============================] - 0s 725us/step - loss: 4.6314 - mae: 1.1721 - val_loss: 4.1570 - val_mae: 1.0662\n",
      "Epoch 18/100\n",
      "166/166 [==============================] - 0s 689us/step - loss: 4.6127 - mae: 1.1689 - val_loss: 4.1793 - val_mae: 1.0224\n",
      "Epoch 19/100\n",
      "166/166 [==============================] - 0s 674us/step - loss: 4.6209 - mae: 1.1734 - val_loss: 4.2033 - val_mae: 1.0606\n",
      "Epoch 20/100\n",
      "166/166 [==============================] - 0s 671us/step - loss: 4.6264 - mae: 1.1654 - val_loss: 4.2135 - val_mae: 1.1286\n",
      "Epoch 21/100\n",
      "166/166 [==============================] - 0s 687us/step - loss: 4.6052 - mae: 1.1737 - val_loss: 4.2045 - val_mae: 1.1153\n",
      "Epoch 22/100\n",
      "166/166 [==============================] - 0s 702us/step - loss: 4.6147 - mae: 1.1715 - val_loss: 4.1989 - val_mae: 1.0111\n",
      "Epoch 23/100\n",
      "166/166 [==============================] - 0s 714us/step - loss: 4.6237 - mae: 1.1707 - val_loss: 4.2252 - val_mae: 1.1616\n",
      "Epoch 24/100\n",
      "166/166 [==============================] - 0s 816us/step - loss: 4.6061 - mae: 1.1706 - val_loss: 4.1790 - val_mae: 1.0909\n",
      "Epoch 25/100\n",
      "166/166 [==============================] - 0s 736us/step - loss: 4.6154 - mae: 1.1695 - val_loss: 4.1909 - val_mae: 1.0159\n",
      "Epoch 26/100\n",
      "166/166 [==============================] - 0s 656us/step - loss: 4.6108 - mae: 1.1684 - val_loss: 4.1835 - val_mae: 1.0456\n",
      "Epoch 27/100\n",
      "166/166 [==============================] - 0s 710us/step - loss: 4.6274 - mae: 1.1756 - val_loss: 4.2543 - val_mae: 0.9650\n",
      "Epoch 28/100\n",
      "166/166 [==============================] - 0s 666us/step - loss: 4.6009 - mae: 1.1687 - val_loss: 4.1576 - val_mae: 1.0964\n",
      "Epoch 29/100\n",
      "166/166 [==============================] - 0s 690us/step - loss: 4.6008 - mae: 1.1660 - val_loss: 4.1661 - val_mae: 1.0572\n",
      "Epoch 30/100\n",
      "166/166 [==============================] - 0s 695us/step - loss: 4.6000 - mae: 1.1609 - val_loss: 4.2068 - val_mae: 1.1327\n",
      "Epoch 31/100\n",
      "166/166 [==============================] - 0s 673us/step - loss: 4.5993 - mae: 1.1766 - val_loss: 4.2440 - val_mae: 1.0355\n",
      "Epoch 32/100\n",
      "166/166 [==============================] - 0s 686us/step - loss: 4.6023 - mae: 1.1633 - val_loss: 4.1908 - val_mae: 1.1535\n",
      "Epoch 33/100\n",
      "166/166 [==============================] - 0s 698us/step - loss: 4.5944 - mae: 1.1659 - val_loss: 4.1776 - val_mae: 1.1453\n",
      "Epoch 34/100\n",
      "166/166 [==============================] - 0s 780us/step - loss: 4.5896 - mae: 1.1676 - val_loss: 4.1873 - val_mae: 1.1197\n",
      "Epoch 35/100\n",
      "166/166 [==============================] - 0s 687us/step - loss: 4.5985 - mae: 1.1712 - val_loss: 4.1596 - val_mae: 1.0233\n",
      "Epoch 36/100\n",
      "166/166 [==============================] - 0s 680us/step - loss: 4.5999 - mae: 1.1693 - val_loss: 4.2055 - val_mae: 0.9883\n",
      "Epoch 37/100\n",
      "166/166 [==============================] - 0s 682us/step - loss: 4.5913 - mae: 1.1688 - val_loss: 4.2108 - val_mae: 1.0178\n",
      "Epoch 37: early stopping\n",
      "Test Loss (MSE): 4.5322980880737305, Test Mean Absolute Error (MAE): 1.0999128818511963\n",
      "Epoch 1/100\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 5.4240 - mae: 1.1999 - val_loss: 4.7537 - val_mae: 1.1653\n",
      "Epoch 2/100\n",
      "166/166 [==============================] - 0s 780us/step - loss: 4.8414 - mae: 1.1707 - val_loss: 4.6578 - val_mae: 1.0392\n",
      "Epoch 3/100\n",
      "166/166 [==============================] - 0s 768us/step - loss: 4.8101 - mae: 1.1672 - val_loss: 4.4227 - val_mae: 1.0960\n",
      "Epoch 4/100\n",
      "166/166 [==============================] - 0s 715us/step - loss: 4.7030 - mae: 1.1612 - val_loss: 4.4924 - val_mae: 1.1212\n",
      "Epoch 5/100\n",
      "166/166 [==============================] - 0s 715us/step - loss: 4.6828 - mae: 1.1532 - val_loss: 4.4545 - val_mae: 1.0807\n",
      "Epoch 6/100\n",
      "166/166 [==============================] - 0s 726us/step - loss: 4.6450 - mae: 1.1576 - val_loss: 4.6061 - val_mae: 1.0362\n",
      "Epoch 7/100\n",
      "166/166 [==============================] - 0s 780us/step - loss: 4.6617 - mae: 1.1495 - val_loss: 4.4639 - val_mae: 1.0908\n",
      "Epoch 8/100\n",
      "166/166 [==============================] - 0s 764us/step - loss: 4.6308 - mae: 1.1509 - val_loss: 4.4155 - val_mae: 1.1413\n",
      "Epoch 9/100\n",
      "166/166 [==============================] - 0s 740us/step - loss: 4.6121 - mae: 1.1555 - val_loss: 4.3657 - val_mae: 1.1292\n",
      "Epoch 10/100\n",
      "166/166 [==============================] - 0s 841us/step - loss: 4.6185 - mae: 1.1503 - val_loss: 4.3928 - val_mae: 1.1542\n",
      "Epoch 11/100\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 4.6012 - mae: 1.1484 - val_loss: 4.3928 - val_mae: 1.0732\n",
      "Epoch 12/100\n",
      "166/166 [==============================] - 0s 854us/step - loss: 4.6038 - mae: 1.1461 - val_loss: 4.3808 - val_mae: 1.1801\n",
      "Epoch 13/100\n",
      "166/166 [==============================] - 0s 893us/step - loss: 4.5953 - mae: 1.1548 - val_loss: 4.4367 - val_mae: 1.1214\n",
      "Epoch 14/100\n",
      "166/166 [==============================] - 0s 771us/step - loss: 4.6054 - mae: 1.1506 - val_loss: 4.4003 - val_mae: 1.0128\n",
      "Epoch 15/100\n",
      "166/166 [==============================] - 0s 704us/step - loss: 4.6110 - mae: 1.1500 - val_loss: 4.3721 - val_mae: 1.0882\n",
      "Epoch 16/100\n",
      "166/166 [==============================] - 0s 711us/step - loss: 4.6062 - mae: 1.1498 - val_loss: 4.3678 - val_mae: 1.0615\n",
      "Epoch 17/100\n",
      "166/166 [==============================] - 0s 707us/step - loss: 4.5770 - mae: 1.1451 - val_loss: 4.3589 - val_mae: 1.1098\n",
      "Epoch 18/100\n",
      "166/166 [==============================] - 0s 737us/step - loss: 4.5851 - mae: 1.1476 - val_loss: 4.3631 - val_mae: 1.1275\n",
      "Epoch 19/100\n",
      "166/166 [==============================] - 0s 727us/step - loss: 4.5864 - mae: 1.1508 - val_loss: 4.3594 - val_mae: 1.0743\n",
      "Epoch 20/100\n",
      "166/166 [==============================] - 0s 717us/step - loss: 4.5746 - mae: 1.1495 - val_loss: 4.4046 - val_mae: 1.0258\n",
      "Epoch 21/100\n",
      "166/166 [==============================] - 0s 715us/step - loss: 4.5835 - mae: 1.1502 - val_loss: 4.3524 - val_mae: 1.1295\n",
      "Epoch 22/100\n",
      "166/166 [==============================] - 0s 712us/step - loss: 4.5970 - mae: 1.1586 - val_loss: 4.4261 - val_mae: 1.0506\n",
      "Epoch 23/100\n",
      "166/166 [==============================] - 0s 763us/step - loss: 4.5847 - mae: 1.1474 - val_loss: 4.3643 - val_mae: 1.0657\n",
      "Epoch 24/100\n",
      "166/166 [==============================] - 0s 741us/step - loss: 4.6155 - mae: 1.1515 - val_loss: 4.3839 - val_mae: 1.0227\n",
      "Epoch 25/100\n",
      "166/166 [==============================] - 0s 762us/step - loss: 4.5669 - mae: 1.1476 - val_loss: 4.4806 - val_mae: 1.1896\n",
      "Epoch 26/100\n",
      "166/166 [==============================] - 0s 789us/step - loss: 4.5723 - mae: 1.1436 - val_loss: 4.4140 - val_mae: 1.0955\n",
      "Epoch 27/100\n",
      "166/166 [==============================] - 0s 756us/step - loss: 4.5750 - mae: 1.1499 - val_loss: 4.3746 - val_mae: 1.0574\n",
      "Epoch 28/100\n",
      "166/166 [==============================] - 0s 864us/step - loss: 4.5747 - mae: 1.1484 - val_loss: 4.3845 - val_mae: 1.0646\n",
      "Epoch 29/100\n",
      "166/166 [==============================] - 0s 799us/step - loss: 4.5699 - mae: 1.1450 - val_loss: 4.3872 - val_mae: 1.1306\n",
      "Epoch 30/100\n",
      "166/166 [==============================] - 0s 819us/step - loss: 4.6005 - mae: 1.1577 - val_loss: 4.3634 - val_mae: 1.0881\n",
      "Epoch 31/100\n",
      "166/166 [==============================] - 0s 726us/step - loss: 4.5702 - mae: 1.1364 - val_loss: 4.4002 - val_mae: 1.1869\n",
      "Epoch 32/100\n",
      "166/166 [==============================] - 0s 753us/step - loss: 4.5901 - mae: 1.1534 - val_loss: 4.4033 - val_mae: 1.1122\n",
      "Epoch 33/100\n",
      "166/166 [==============================] - 0s 731us/step - loss: 4.5723 - mae: 1.1413 - val_loss: 4.3849 - val_mae: 1.0793\n",
      "Epoch 34/100\n",
      "166/166 [==============================] - 0s 784us/step - loss: 4.5594 - mae: 1.1468 - val_loss: 4.3975 - val_mae: 1.2237\n",
      "Epoch 35/100\n",
      "166/166 [==============================] - 0s 781us/step - loss: 4.5682 - mae: 1.1446 - val_loss: 4.4559 - val_mae: 1.0845\n",
      "Epoch 36/100\n",
      "166/166 [==============================] - 0s 768us/step - loss: 4.5675 - mae: 1.1399 - val_loss: 4.4891 - val_mae: 1.2076\n",
      "Epoch 37/100\n",
      "166/166 [==============================] - 0s 706us/step - loss: 4.5672 - mae: 1.1486 - val_loss: 4.3449 - val_mae: 1.0950\n",
      "Epoch 38/100\n",
      "166/166 [==============================] - 0s 740us/step - loss: 4.5561 - mae: 1.1462 - val_loss: 4.4056 - val_mae: 1.0934\n",
      "Epoch 39/100\n",
      "166/166 [==============================] - 0s 732us/step - loss: 4.5558 - mae: 1.1449 - val_loss: 4.3882 - val_mae: 1.1024\n",
      "Epoch 40/100\n",
      "166/166 [==============================] - 0s 716us/step - loss: 4.5673 - mae: 1.1448 - val_loss: 4.3558 - val_mae: 1.1471\n",
      "Epoch 41/100\n",
      "166/166 [==============================] - 0s 728us/step - loss: 4.5593 - mae: 1.1492 - val_loss: 4.3671 - val_mae: 1.0455\n",
      "Epoch 42/100\n",
      "166/166 [==============================] - 0s 748us/step - loss: 4.5422 - mae: 1.1458 - val_loss: 4.4153 - val_mae: 1.0272\n",
      "Epoch 43/100\n",
      "166/166 [==============================] - 0s 729us/step - loss: 4.5621 - mae: 1.1366 - val_loss: 4.3668 - val_mae: 1.0812\n",
      "Epoch 44/100\n",
      "166/166 [==============================] - 0s 753us/step - loss: 4.5422 - mae: 1.1406 - val_loss: 4.3828 - val_mae: 1.1571\n",
      "Epoch 45/100\n",
      "166/166 [==============================] - 0s 719us/step - loss: 4.5425 - mae: 1.1426 - val_loss: 4.3472 - val_mae: 1.1101\n",
      "Epoch 46/100\n",
      "166/166 [==============================] - 0s 856us/step - loss: 4.5391 - mae: 1.1382 - val_loss: 4.3767 - val_mae: 1.1178\n",
      "Epoch 47/100\n",
      "166/166 [==============================] - 0s 738us/step - loss: 4.5470 - mae: 1.1406 - val_loss: 4.3680 - val_mae: 1.1263\n",
      "Epoch 48/100\n",
      "166/166 [==============================] - 0s 768us/step - loss: 4.5451 - mae: 1.1413 - val_loss: 4.3654 - val_mae: 1.0784\n",
      "Epoch 49/100\n",
      "166/166 [==============================] - 0s 761us/step - loss: 4.5602 - mae: 1.1472 - val_loss: 4.3719 - val_mae: 1.0472\n",
      "Epoch 50/100\n",
      "166/166 [==============================] - 0s 770us/step - loss: 4.5506 - mae: 1.1415 - val_loss: 4.3997 - val_mae: 1.1257\n",
      "Epoch 51/100\n",
      "166/166 [==============================] - 0s 723us/step - loss: 4.5425 - mae: 1.1363 - val_loss: 4.3877 - val_mae: 1.0952\n",
      "Epoch 52/100\n",
      "166/166 [==============================] - 0s 818us/step - loss: 4.5643 - mae: 1.1539 - val_loss: 4.4000 - val_mae: 1.1201\n",
      "Epoch 53/100\n",
      "166/166 [==============================] - 0s 716us/step - loss: 4.5323 - mae: 1.1491 - val_loss: 4.4357 - val_mae: 1.1856\n",
      "Epoch 54/100\n",
      "166/166 [==============================] - 0s 763us/step - loss: 4.5583 - mae: 1.1458 - val_loss: 4.3749 - val_mae: 1.1072\n",
      "Epoch 55/100\n",
      "166/166 [==============================] - 0s 751us/step - loss: 4.5472 - mae: 1.1385 - val_loss: 4.4596 - val_mae: 1.2034\n",
      "Epoch 56/100\n",
      "166/166 [==============================] - 0s 755us/step - loss: 4.5388 - mae: 1.1444 - val_loss: 4.3983 - val_mae: 1.0119\n",
      "Epoch 57/100\n",
      "166/166 [==============================] - 0s 724us/step - loss: 4.5451 - mae: 1.1386 - val_loss: 4.3912 - val_mae: 1.0785\n",
      "Epoch 57: early stopping\n",
      "Test Loss (MSE): 4.041541576385498, Test Mean Absolute Error (MAE): 1.0976226329803467\n",
      "Epoch 1/100\n",
      "166/166 [==============================] - 0s 1ms/step - loss: 4.6117 - mae: 1.0729 - val_loss: 5.4006 - val_mae: 1.2853\n",
      "Epoch 2/100\n",
      "166/166 [==============================] - 0s 790us/step - loss: 4.2253 - mae: 1.0567 - val_loss: 5.7756 - val_mae: 1.3536\n",
      "Epoch 3/100\n",
      "166/166 [==============================] - 0s 740us/step - loss: 4.0767 - mae: 1.0398 - val_loss: 5.2168 - val_mae: 1.2210\n",
      "Epoch 4/100\n",
      "166/166 [==============================] - 0s 766us/step - loss: 4.0365 - mae: 1.0410 - val_loss: 5.3942 - val_mae: 1.1154\n",
      "Epoch 5/100\n",
      "166/166 [==============================] - 0s 734us/step - loss: 3.9919 - mae: 1.0211 - val_loss: 5.3363 - val_mae: 1.3639\n",
      "Epoch 6/100\n",
      "166/166 [==============================] - 0s 784us/step - loss: 3.9970 - mae: 1.0419 - val_loss: 5.2344 - val_mae: 1.2560\n",
      "Epoch 7/100\n",
      "166/166 [==============================] - 0s 751us/step - loss: 3.9657 - mae: 1.0282 - val_loss: 5.2275 - val_mae: 1.1649\n",
      "Epoch 8/100\n",
      "166/166 [==============================] - 0s 884us/step - loss: 3.9685 - mae: 1.0264 - val_loss: 5.2176 - val_mae: 1.1824\n",
      "Epoch 9/100\n",
      "166/166 [==============================] - 0s 730us/step - loss: 3.9401 - mae: 1.0270 - val_loss: 5.2161 - val_mae: 1.1647\n",
      "Epoch 10/100\n",
      "166/166 [==============================] - 0s 878us/step - loss: 3.9651 - mae: 1.0263 - val_loss: 5.1554 - val_mae: 1.2846\n",
      "Epoch 11/100\n",
      "166/166 [==============================] - 0s 835us/step - loss: 3.9144 - mae: 1.0220 - val_loss: 5.2524 - val_mae: 1.1391\n",
      "Epoch 12/100\n",
      "166/166 [==============================] - 0s 895us/step - loss: 3.9330 - mae: 1.0263 - val_loss: 5.4491 - val_mae: 1.3758\n",
      "Epoch 13/100\n",
      "166/166 [==============================] - 0s 772us/step - loss: 3.9493 - mae: 1.0310 - val_loss: 5.1590 - val_mae: 1.2925\n",
      "Epoch 14/100\n",
      "166/166 [==============================] - 0s 772us/step - loss: 3.9015 - mae: 1.0178 - val_loss: 5.2992 - val_mae: 1.3034\n",
      "Epoch 15/100\n",
      "166/166 [==============================] - 0s 751us/step - loss: 3.9322 - mae: 1.0333 - val_loss: 5.2263 - val_mae: 1.1600\n",
      "Epoch 16/100\n",
      "166/166 [==============================] - 0s 789us/step - loss: 3.9261 - mae: 1.0269 - val_loss: 5.2088 - val_mae: 1.2877\n",
      "Epoch 17/100\n",
      "166/166 [==============================] - 0s 810us/step - loss: 3.9083 - mae: 1.0233 - val_loss: 5.1558 - val_mae: 1.2505\n",
      "Epoch 18/100\n",
      "166/166 [==============================] - 0s 779us/step - loss: 3.9243 - mae: 1.0164 - val_loss: 5.2883 - val_mae: 1.3665\n",
      "Epoch 19/100\n",
      "166/166 [==============================] - 0s 740us/step - loss: 3.9417 - mae: 1.0315 - val_loss: 5.2320 - val_mae: 1.1774\n",
      "Epoch 20/100\n",
      "166/166 [==============================] - 0s 765us/step - loss: 3.9041 - mae: 1.0251 - val_loss: 5.1788 - val_mae: 1.2549\n",
      "Epoch 21/100\n",
      "166/166 [==============================] - 0s 722us/step - loss: 3.8983 - mae: 1.0117 - val_loss: 5.1525 - val_mae: 1.2138\n",
      "Epoch 22/100\n",
      "166/166 [==============================] - 0s 761us/step - loss: 3.8990 - mae: 1.0287 - val_loss: 5.2265 - val_mae: 1.1663\n",
      "Epoch 23/100\n",
      "166/166 [==============================] - 0s 716us/step - loss: 3.9185 - mae: 1.0161 - val_loss: 5.1344 - val_mae: 1.2549\n",
      "Epoch 24/100\n",
      "166/166 [==============================] - 0s 775us/step - loss: 3.9322 - mae: 1.0313 - val_loss: 5.1547 - val_mae: 1.1983\n",
      "Epoch 25/100\n",
      "166/166 [==============================] - 0s 755us/step - loss: 3.8881 - mae: 1.0164 - val_loss: 5.2328 - val_mae: 1.2577\n",
      "Epoch 26/100\n",
      "166/166 [==============================] - 0s 784us/step - loss: 3.9370 - mae: 1.0211 - val_loss: 5.1864 - val_mae: 1.1717\n",
      "Epoch 27/100\n",
      "166/166 [==============================] - 0s 736us/step - loss: 3.9037 - mae: 1.0221 - val_loss: 5.1786 - val_mae: 1.1998\n",
      "Epoch 28/100\n",
      "166/166 [==============================] - 0s 763us/step - loss: 3.9070 - mae: 1.0255 - val_loss: 5.2022 - val_mae: 1.2017\n",
      "Epoch 29/100\n",
      "166/166 [==============================] - 0s 722us/step - loss: 3.8838 - mae: 1.0164 - val_loss: 5.1909 - val_mae: 1.1765\n",
      "Epoch 30/100\n",
      "166/166 [==============================] - 0s 781us/step - loss: 3.9065 - mae: 1.0203 - val_loss: 5.1857 - val_mae: 1.1916\n",
      "Epoch 31/100\n",
      "166/166 [==============================] - 0s 753us/step - loss: 3.9060 - mae: 1.0159 - val_loss: 5.1895 - val_mae: 1.1911\n",
      "Epoch 32/100\n",
      "166/166 [==============================] - 0s 793us/step - loss: 3.8960 - mae: 1.0206 - val_loss: 5.1913 - val_mae: 1.2094\n",
      "Epoch 33/100\n",
      "166/166 [==============================] - 0s 761us/step - loss: 3.9051 - mae: 1.0242 - val_loss: 5.1946 - val_mae: 1.1639\n",
      "Epoch 34/100\n",
      "166/166 [==============================] - 0s 768us/step - loss: 3.8991 - mae: 1.0107 - val_loss: 5.1838 - val_mae: 1.2113\n",
      "Epoch 35/100\n",
      "166/166 [==============================] - 0s 772us/step - loss: 3.9079 - mae: 1.0275 - val_loss: 5.2041 - val_mae: 1.1601\n",
      "Epoch 36/100\n",
      "166/166 [==============================] - 0s 771us/step - loss: 3.9088 - mae: 1.0186 - val_loss: 5.1925 - val_mae: 1.2501\n",
      "Epoch 37/100\n",
      "166/166 [==============================] - 0s 772us/step - loss: 3.8999 - mae: 1.0268 - val_loss: 5.2334 - val_mae: 1.1960\n",
      "Epoch 38/100\n",
      "166/166 [==============================] - 0s 757us/step - loss: 3.8938 - mae: 1.0130 - val_loss: 5.1658 - val_mae: 1.2409\n",
      "Epoch 39/100\n",
      "166/166 [==============================] - 0s 786us/step - loss: 3.9072 - mae: 1.0205 - val_loss: 5.1818 - val_mae: 1.1932\n",
      "Epoch 40/100\n",
      "166/166 [==============================] - 0s 736us/step - loss: 3.9024 - mae: 1.0149 - val_loss: 5.2046 - val_mae: 1.1979\n",
      "Epoch 41/100\n",
      "166/166 [==============================] - 0s 738us/step - loss: 3.8987 - mae: 1.0182 - val_loss: 5.1860 - val_mae: 1.2060\n",
      "Epoch 42/100\n",
      "166/166 [==============================] - 0s 858us/step - loss: 3.9366 - mae: 1.0224 - val_loss: 5.2757 - val_mae: 1.2575\n",
      "Epoch 43/100\n",
      "166/166 [==============================] - 0s 753us/step - loss: 3.9008 - mae: 1.0132 - val_loss: 5.2812 - val_mae: 1.2240\n",
      "Epoch 43: early stopping\n",
      "Test Loss (MSE): 5.321935176849365, Test Mean Absolute Error (MAE): 1.2363626956939697\n",
      "Epoch 1/100\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 5.2194 - mae: 1.1459 - val_loss: 5.2594 - val_mae: 1.2818\n",
      "Epoch 2/100\n",
      "165/165 [==============================] - 0s 709us/step - loss: 4.6613 - mae: 1.1097 - val_loss: 4.9912 - val_mae: 1.1599\n",
      "Epoch 3/100\n",
      "165/165 [==============================] - 0s 729us/step - loss: 4.5430 - mae: 1.1082 - val_loss: 4.8667 - val_mae: 1.1465\n",
      "Epoch 4/100\n",
      "165/165 [==============================] - 0s 855us/step - loss: 4.5010 - mae: 1.1143 - val_loss: 4.8758 - val_mae: 1.1653\n",
      "Epoch 5/100\n",
      "165/165 [==============================] - 0s 701us/step - loss: 4.4666 - mae: 1.1070 - val_loss: 4.7786 - val_mae: 1.1995\n",
      "Epoch 6/100\n",
      "165/165 [==============================] - 0s 682us/step - loss: 4.4493 - mae: 1.0991 - val_loss: 4.8904 - val_mae: 1.1625\n",
      "Epoch 7/100\n",
      "165/165 [==============================] - 0s 933us/step - loss: 4.4560 - mae: 1.1172 - val_loss: 4.9066 - val_mae: 1.2180\n",
      "Epoch 8/100\n",
      "165/165 [==============================] - 0s 830us/step - loss: 4.3911 - mae: 1.1051 - val_loss: 4.8116 - val_mae: 1.2472\n",
      "Epoch 9/100\n",
      "165/165 [==============================] - 0s 814us/step - loss: 4.3566 - mae: 1.0951 - val_loss: 4.8160 - val_mae: 1.1652\n",
      "Epoch 10/100\n",
      "165/165 [==============================] - 0s 815us/step - loss: 4.3562 - mae: 1.0936 - val_loss: 4.8935 - val_mae: 1.3110\n",
      "Epoch 11/100\n",
      "165/165 [==============================] - 0s 757us/step - loss: 4.3307 - mae: 1.0932 - val_loss: 4.8992 - val_mae: 1.2289\n",
      "Epoch 12/100\n",
      "165/165 [==============================] - 0s 733us/step - loss: 4.3290 - mae: 1.0919 - val_loss: 4.9690 - val_mae: 1.2842\n",
      "Epoch 13/100\n",
      "165/165 [==============================] - 0s 722us/step - loss: 4.3350 - mae: 1.0860 - val_loss: 5.0505 - val_mae: 1.1704\n",
      "Epoch 14/100\n",
      "165/165 [==============================] - 0s 738us/step - loss: 4.3272 - mae: 1.0925 - val_loss: 4.9624 - val_mae: 1.1647\n",
      "Epoch 15/100\n",
      "165/165 [==============================] - 0s 708us/step - loss: 4.3040 - mae: 1.0932 - val_loss: 4.9039 - val_mae: 1.1244\n",
      "Epoch 16/100\n",
      "165/165 [==============================] - 0s 722us/step - loss: 4.3183 - mae: 1.0852 - val_loss: 4.8539 - val_mae: 1.2233\n",
      "Epoch 17/100\n",
      "165/165 [==============================] - 0s 735us/step - loss: 4.2956 - mae: 1.0805 - val_loss: 4.8997 - val_mae: 1.1723\n",
      "Epoch 18/100\n",
      "165/165 [==============================] - 0s 741us/step - loss: 4.2994 - mae: 1.0855 - val_loss: 4.9296 - val_mae: 1.2285\n",
      "Epoch 19/100\n",
      "165/165 [==============================] - 0s 772us/step - loss: 4.3251 - mae: 1.1045 - val_loss: 4.8646 - val_mae: 1.2245\n",
      "Epoch 20/100\n",
      "165/165 [==============================] - 0s 746us/step - loss: 4.2628 - mae: 1.0735 - val_loss: 4.9213 - val_mae: 1.2957\n",
      "Epoch 21/100\n",
      "165/165 [==============================] - 0s 669us/step - loss: 4.2836 - mae: 1.0851 - val_loss: 4.9873 - val_mae: 1.2532\n",
      "Epoch 22/100\n",
      "165/165 [==============================] - 0s 808us/step - loss: 4.2517 - mae: 1.0912 - val_loss: 4.9927 - val_mae: 1.2285\n",
      "Epoch 23/100\n",
      "165/165 [==============================] - 0s 832us/step - loss: 4.2844 - mae: 1.0806 - val_loss: 4.9426 - val_mae: 1.3197\n",
      "Epoch 24/100\n",
      "165/165 [==============================] - 0s 735us/step - loss: 4.2293 - mae: 1.0797 - val_loss: 4.9930 - val_mae: 1.1360\n",
      "Epoch 25/100\n",
      "165/165 [==============================] - 0s 763us/step - loss: 4.2767 - mae: 1.0757 - val_loss: 4.9129 - val_mae: 1.1961\n",
      "Epoch 25: early stopping\n",
      "Test Loss (MSE): 4.687535285949707, Test Mean Absolute Error (MAE): 1.1646990776062012\n",
      "Epoch 1/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 8.5189 - mae: 1.8322 - val_loss: 7.7610 - val_mae: 1.7657\n",
      "Epoch 2/100\n",
      "93/93 [==============================] - 0s 728us/step - loss: 8.0336 - mae: 1.7775 - val_loss: 7.7065 - val_mae: 1.8885\n",
      "Epoch 3/100\n",
      "93/93 [==============================] - 0s 697us/step - loss: 7.8680 - mae: 1.7922 - val_loss: 7.7415 - val_mae: 1.8808\n",
      "Epoch 4/100\n",
      "93/93 [==============================] - 0s 751us/step - loss: 7.8200 - mae: 1.7695 - val_loss: 7.5361 - val_mae: 1.7250\n",
      "Epoch 5/100\n",
      "93/93 [==============================] - 0s 715us/step - loss: 7.7326 - mae: 1.7632 - val_loss: 7.5215 - val_mae: 1.8350\n",
      "Epoch 6/100\n",
      "93/93 [==============================] - 0s 718us/step - loss: 7.7482 - mae: 1.7746 - val_loss: 7.4505 - val_mae: 1.7756\n",
      "Epoch 7/100\n",
      "93/93 [==============================] - 0s 693us/step - loss: 7.8421 - mae: 1.7693 - val_loss: 7.5310 - val_mae: 1.7385\n",
      "Epoch 8/100\n",
      "93/93 [==============================] - 0s 681us/step - loss: 7.7079 - mae: 1.7869 - val_loss: 7.5940 - val_mae: 1.6816\n",
      "Epoch 9/100\n",
      "93/93 [==============================] - 0s 713us/step - loss: 7.7861 - mae: 1.7554 - val_loss: 7.9464 - val_mae: 1.6923\n",
      "Epoch 10/100\n",
      "93/93 [==============================] - 0s 799us/step - loss: 7.7384 - mae: 1.7701 - val_loss: 7.4907 - val_mae: 1.7765\n",
      "Epoch 11/100\n",
      "93/93 [==============================] - 0s 685us/step - loss: 7.6696 - mae: 1.7697 - val_loss: 7.4824 - val_mae: 1.8546\n",
      "Epoch 12/100\n",
      "93/93 [==============================] - 0s 716us/step - loss: 7.6653 - mae: 1.7733 - val_loss: 7.5094 - val_mae: 1.7243\n",
      "Epoch 13/100\n",
      "93/93 [==============================] - 0s 725us/step - loss: 7.7380 - mae: 1.7554 - val_loss: 7.4848 - val_mae: 1.8450\n",
      "Epoch 14/100\n",
      "93/93 [==============================] - 0s 729us/step - loss: 7.6748 - mae: 1.7870 - val_loss: 7.4651 - val_mae: 1.7985\n",
      "Epoch 15/100\n",
      "93/93 [==============================] - 0s 796us/step - loss: 7.6876 - mae: 1.7691 - val_loss: 7.4574 - val_mae: 1.7818\n",
      "Epoch 16/100\n",
      "93/93 [==============================] - 0s 700us/step - loss: 7.6724 - mae: 1.7736 - val_loss: 7.5132 - val_mae: 1.8632\n",
      "Epoch 17/100\n",
      "93/93 [==============================] - 0s 734us/step - loss: 7.6979 - mae: 1.7820 - val_loss: 7.4446 - val_mae: 1.7594\n",
      "Epoch 18/100\n",
      "93/93 [==============================] - 0s 648us/step - loss: 7.6800 - mae: 1.7616 - val_loss: 7.4534 - val_mae: 1.7921\n",
      "Epoch 19/100\n",
      "93/93 [==============================] - 0s 653us/step - loss: 7.6965 - mae: 1.7639 - val_loss: 7.4918 - val_mae: 1.8690\n",
      "Epoch 20/100\n",
      "93/93 [==============================] - 0s 732us/step - loss: 7.6457 - mae: 1.7664 - val_loss: 7.4960 - val_mae: 1.8228\n",
      "Epoch 21/100\n",
      "93/93 [==============================] - 0s 704us/step - loss: 7.6811 - mae: 1.7728 - val_loss: 7.4478 - val_mae: 1.7898\n",
      "Epoch 22/100\n",
      "93/93 [==============================] - 0s 750us/step - loss: 7.6482 - mae: 1.7588 - val_loss: 7.5246 - val_mae: 1.8741\n",
      "Epoch 23/100\n",
      "93/93 [==============================] - 0s 846us/step - loss: 7.7312 - mae: 1.7666 - val_loss: 7.4506 - val_mae: 1.8231\n",
      "Epoch 24/100\n",
      "93/93 [==============================] - 0s 758us/step - loss: 7.6480 - mae: 1.7785 - val_loss: 7.5550 - val_mae: 1.7718\n",
      "Epoch 25/100\n",
      "93/93 [==============================] - 0s 776us/step - loss: 7.6480 - mae: 1.7712 - val_loss: 7.4449 - val_mae: 1.7800\n",
      "Epoch 26/100\n",
      "93/93 [==============================] - 0s 796us/step - loss: 7.6505 - mae: 1.7700 - val_loss: 7.5202 - val_mae: 1.7327\n",
      "Epoch 27/100\n",
      "93/93 [==============================] - 0s 745us/step - loss: 7.6150 - mae: 1.7631 - val_loss: 7.5510 - val_mae: 1.9133\n",
      "Epoch 28/100\n",
      "93/93 [==============================] - 0s 770us/step - loss: 7.6676 - mae: 1.7609 - val_loss: 7.5247 - val_mae: 1.8585\n",
      "Epoch 29/100\n",
      "93/93 [==============================] - 0s 863us/step - loss: 7.6470 - mae: 1.7934 - val_loss: 7.5221 - val_mae: 1.7197\n",
      "Epoch 30/100\n",
      "93/93 [==============================] - 0s 818us/step - loss: 7.6362 - mae: 1.7692 - val_loss: 7.5850 - val_mae: 1.6884\n",
      "Epoch 31/100\n",
      "93/93 [==============================] - 0s 756us/step - loss: 7.6449 - mae: 1.7556 - val_loss: 7.4496 - val_mae: 1.7918\n",
      "Epoch 32/100\n",
      "93/93 [==============================] - 0s 847us/step - loss: 7.6120 - mae: 1.7594 - val_loss: 7.4629 - val_mae: 1.8130\n",
      "Epoch 33/100\n",
      "93/93 [==============================] - 0s 781us/step - loss: 7.6862 - mae: 1.7622 - val_loss: 7.4765 - val_mae: 1.7827\n",
      "Epoch 34/100\n",
      "93/93 [==============================] - 0s 745us/step - loss: 7.6342 - mae: 1.7755 - val_loss: 7.4741 - val_mae: 1.7794\n",
      "Epoch 35/100\n",
      "93/93 [==============================] - 0s 721us/step - loss: 7.6410 - mae: 1.7685 - val_loss: 7.4575 - val_mae: 1.7626\n",
      "Epoch 36/100\n",
      "93/93 [==============================] - 0s 743us/step - loss: 7.6165 - mae: 1.7749 - val_loss: 7.4954 - val_mae: 1.7667\n",
      "Epoch 37/100\n",
      "93/93 [==============================] - 0s 705us/step - loss: 7.6389 - mae: 1.7795 - val_loss: 7.4845 - val_mae: 1.7988\n",
      "Epoch 37: early stopping\n",
      "Test Loss (MSE): 6.40241003036499, Test Mean Absolute Error (MAE): 1.697885513305664\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 8.6645 - mae: 1.7970 - val_loss: 7.9075 - val_mae: 1.9016\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 813us/step - loss: 7.9696 - mae: 1.7422 - val_loss: 7.6598 - val_mae: 1.8780\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 769us/step - loss: 7.7322 - mae: 1.7522 - val_loss: 7.7325 - val_mae: 1.7656\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 7.7478 - mae: 1.7324 - val_loss: 7.5407 - val_mae: 1.7661\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 795us/step - loss: 7.7138 - mae: 1.7577 - val_loss: 7.5325 - val_mae: 1.7645\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 743us/step - loss: 7.6111 - mae: 1.7241 - val_loss: 7.6110 - val_mae: 1.7548\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 801us/step - loss: 7.6171 - mae: 1.7437 - val_loss: 7.5197 - val_mae: 1.7758\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 823us/step - loss: 7.5912 - mae: 1.7411 - val_loss: 7.4482 - val_mae: 1.7796\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 837us/step - loss: 7.5493 - mae: 1.7602 - val_loss: 7.5056 - val_mae: 1.7854\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 776us/step - loss: 7.5948 - mae: 1.7307 - val_loss: 7.6023 - val_mae: 1.7246\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 766us/step - loss: 7.5351 - mae: 1.7391 - val_loss: 7.5701 - val_mae: 1.6925\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 760us/step - loss: 7.5099 - mae: 1.7374 - val_loss: 7.4721 - val_mae: 1.7246\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 734us/step - loss: 7.5160 - mae: 1.7243 - val_loss: 7.4122 - val_mae: 1.7971\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 753us/step - loss: 7.5740 - mae: 1.7439 - val_loss: 7.5925 - val_mae: 1.7413\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 720us/step - loss: 7.5027 - mae: 1.7312 - val_loss: 7.4798 - val_mae: 1.7885\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 867us/step - loss: 7.5010 - mae: 1.7243 - val_loss: 7.6319 - val_mae: 1.8996\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 784us/step - loss: 7.5695 - mae: 1.7506 - val_loss: 7.6004 - val_mae: 1.7290\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 889us/step - loss: 7.4689 - mae: 1.7197 - val_loss: 7.5732 - val_mae: 1.7148\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 794us/step - loss: 7.4467 - mae: 1.7113 - val_loss: 7.5167 - val_mae: 1.7979\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 872us/step - loss: 7.4699 - mae: 1.7262 - val_loss: 7.5006 - val_mae: 1.8424\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 836us/step - loss: 7.4902 - mae: 1.7364 - val_loss: 7.5470 - val_mae: 1.7709\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 828us/step - loss: 7.4448 - mae: 1.7306 - val_loss: 7.5032 - val_mae: 1.7916\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 881us/step - loss: 7.4256 - mae: 1.7149 - val_loss: 7.5498 - val_mae: 1.7698\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 842us/step - loss: 7.4375 - mae: 1.7251 - val_loss: 7.5334 - val_mae: 1.8294\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 792us/step - loss: 7.4341 - mae: 1.7396 - val_loss: 7.5438 - val_mae: 1.7477\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 781us/step - loss: 7.4477 - mae: 1.7139 - val_loss: 7.5217 - val_mae: 1.8643\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 0s 787us/step - loss: 7.4250 - mae: 1.7277 - val_loss: 7.5314 - val_mae: 1.8574\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 884us/step - loss: 7.4097 - mae: 1.7343 - val_loss: 7.4852 - val_mae: 1.7713\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 774us/step - loss: 7.4391 - mae: 1.7149 - val_loss: 7.7194 - val_mae: 1.9269\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 966us/step - loss: 7.4584 - mae: 1.7368 - val_loss: 7.5603 - val_mae: 1.8592\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 861us/step - loss: 7.4242 - mae: 1.7182 - val_loss: 7.6213 - val_mae: 1.9083\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 0s 886us/step - loss: 7.4223 - mae: 1.7330 - val_loss: 7.5065 - val_mae: 1.7754\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 0s 870us/step - loss: 7.3960 - mae: 1.7277 - val_loss: 7.5163 - val_mae: 1.7743\n",
      "Epoch 33: early stopping\n",
      "Test Loss (MSE): 7.030679225921631, Test Mean Absolute Error (MAE): 1.7255196571350098\n",
      "Epoch 1/100\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 8.9661 - mae: 1.8683 - val_loss: 7.0706 - val_mae: 1.6561\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 0s 824us/step - loss: 8.3087 - mae: 1.8275 - val_loss: 6.9533 - val_mae: 1.5371\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 0s 791us/step - loss: 8.1598 - mae: 1.8099 - val_loss: 6.8423 - val_mae: 1.6811\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 0s 896us/step - loss: 8.0724 - mae: 1.8345 - val_loss: 6.8799 - val_mae: 1.6511\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 0s 783us/step - loss: 8.0793 - mae: 1.8205 - val_loss: 6.8188 - val_mae: 1.6049\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 0s 751us/step - loss: 7.9710 - mae: 1.8172 - val_loss: 6.9723 - val_mae: 1.5870\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 0s 764us/step - loss: 7.8742 - mae: 1.8054 - val_loss: 6.9446 - val_mae: 1.7408\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 0s 797us/step - loss: 7.9017 - mae: 1.8194 - val_loss: 6.8872 - val_mae: 1.6631\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 0s 876us/step - loss: 7.9216 - mae: 1.8249 - val_loss: 6.8654 - val_mae: 1.6486\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 0s 808us/step - loss: 7.8011 - mae: 1.8193 - val_loss: 6.7913 - val_mae: 1.6184\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 0s 819us/step - loss: 7.8339 - mae: 1.8071 - val_loss: 6.9324 - val_mae: 1.5788\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 0s 827us/step - loss: 7.8077 - mae: 1.8160 - val_loss: 6.7423 - val_mae: 1.6600\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 0s 818us/step - loss: 7.7556 - mae: 1.7907 - val_loss: 6.7949 - val_mae: 1.6825\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 0s 833us/step - loss: 7.7767 - mae: 1.8161 - val_loss: 6.7677 - val_mae: 1.6494\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 0s 800us/step - loss: 7.7072 - mae: 1.8029 - val_loss: 6.8229 - val_mae: 1.5616\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 0s 750us/step - loss: 7.8360 - mae: 1.8016 - val_loss: 6.8259 - val_mae: 1.7195\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 0s 762us/step - loss: 7.7127 - mae: 1.8069 - val_loss: 6.8436 - val_mae: 1.6470\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 0s 767us/step - loss: 7.7640 - mae: 1.7970 - val_loss: 7.0621 - val_mae: 1.8259\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 0s 747us/step - loss: 7.7926 - mae: 1.8128 - val_loss: 6.8993 - val_mae: 1.7225\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 0s 763us/step - loss: 7.6965 - mae: 1.7982 - val_loss: 7.0396 - val_mae: 1.7356\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 0s 756us/step - loss: 7.6447 - mae: 1.7980 - val_loss: 6.7687 - val_mae: 1.6736\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 0s 757us/step - loss: 7.6270 - mae: 1.8085 - val_loss: 7.0180 - val_mae: 1.6738\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 0s 904us/step - loss: 7.7266 - mae: 1.7915 - val_loss: 6.9102 - val_mae: 1.6562\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 0s 809us/step - loss: 7.6827 - mae: 1.8005 - val_loss: 6.8550 - val_mae: 1.6418\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 0s 779us/step - loss: 7.7121 - mae: 1.8106 - val_loss: 6.8891 - val_mae: 1.6721\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 0s 836us/step - loss: 7.6851 - mae: 1.7992 - val_loss: 6.8593 - val_mae: 1.6824\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 0s 822us/step - loss: 7.5679 - mae: 1.8079 - val_loss: 6.8177 - val_mae: 1.5742\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 0s 924us/step - loss: 7.6699 - mae: 1.7842 - val_loss: 6.8891 - val_mae: 1.6311\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 0s 801us/step - loss: 7.6813 - mae: 1.8215 - val_loss: 6.9904 - val_mae: 1.6995\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 0s 774us/step - loss: 7.6215 - mae: 1.7941 - val_loss: 6.8564 - val_mae: 1.6687\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 0s 761us/step - loss: 7.6394 - mae: 1.7993 - val_loss: 6.9698 - val_mae: 1.6625\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 0s 773us/step - loss: 7.5663 - mae: 1.7874 - val_loss: 6.8767 - val_mae: 1.6194\n",
      "Epoch 32: early stopping\n",
      "Test Loss (MSE): 7.511586666107178, Test Mean Absolute Error (MAE): 1.6964927911758423\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 10.0135 - mae: 1.9646 - val_loss: 6.3842 - val_mae: 1.7265\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 0s 804us/step - loss: 9.4383 - mae: 1.9458 - val_loss: 6.0707 - val_mae: 1.5549\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 0s 780us/step - loss: 9.1821 - mae: 1.9292 - val_loss: 5.9969 - val_mae: 1.6583\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 0s 900us/step - loss: 8.9646 - mae: 1.9401 - val_loss: 5.7833 - val_mae: 1.6023\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 0s 817us/step - loss: 8.8299 - mae: 1.9118 - val_loss: 6.7256 - val_mae: 1.8947\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 0s 767us/step - loss: 8.9152 - mae: 1.9383 - val_loss: 5.4687 - val_mae: 1.4617\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 0s 734us/step - loss: 8.7425 - mae: 1.9065 - val_loss: 5.5044 - val_mae: 1.4687\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 0s 746us/step - loss: 8.7586 - mae: 1.9244 - val_loss: 5.5103 - val_mae: 1.4643\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 0s 753us/step - loss: 8.6650 - mae: 1.9177 - val_loss: 5.4987 - val_mae: 1.4645\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 0s 827us/step - loss: 8.6252 - mae: 1.9057 - val_loss: 5.8731 - val_mae: 1.6330\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 0s 764us/step - loss: 8.7492 - mae: 1.9191 - val_loss: 5.6930 - val_mae: 1.6279\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 0s 807us/step - loss: 8.6458 - mae: 1.9080 - val_loss: 5.8192 - val_mae: 1.6390\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 0s 744us/step - loss: 8.6853 - mae: 1.9195 - val_loss: 5.5458 - val_mae: 1.5320\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 0s 760us/step - loss: 8.6725 - mae: 1.9358 - val_loss: 5.4461 - val_mae: 1.4812\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 0s 733us/step - loss: 8.6378 - mae: 1.9071 - val_loss: 5.5125 - val_mae: 1.5146\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 0s 779us/step - loss: 8.5632 - mae: 1.9074 - val_loss: 5.4647 - val_mae: 1.5090\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 0s 752us/step - loss: 8.5454 - mae: 1.9026 - val_loss: 5.4428 - val_mae: 1.4941\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 0s 759us/step - loss: 8.5992 - mae: 1.9165 - val_loss: 5.5364 - val_mae: 1.5250\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 0s 796us/step - loss: 8.6196 - mae: 1.9203 - val_loss: 5.6400 - val_mae: 1.4993\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 0s 764us/step - loss: 8.5777 - mae: 1.8921 - val_loss: 5.8598 - val_mae: 1.6543\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 0s 662us/step - loss: 8.5259 - mae: 1.9040 - val_loss: 5.6479 - val_mae: 1.5975\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 0s 817us/step - loss: 8.5147 - mae: 1.8893 - val_loss: 5.9726 - val_mae: 1.7327\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 0s 681us/step - loss: 8.5718 - mae: 1.9212 - val_loss: 5.9869 - val_mae: 1.7410\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 0s 802us/step - loss: 8.4452 - mae: 1.9038 - val_loss: 5.9478 - val_mae: 1.6880\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 0s 725us/step - loss: 8.4962 - mae: 1.9021 - val_loss: 5.6263 - val_mae: 1.5495\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 0s 710us/step - loss: 8.4566 - mae: 1.8980 - val_loss: 5.7972 - val_mae: 1.6380\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 0s 759us/step - loss: 8.4417 - mae: 1.9048 - val_loss: 6.0155 - val_mae: 1.6418\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 0s 776us/step - loss: 8.4935 - mae: 1.8874 - val_loss: 5.8436 - val_mae: 1.6456\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 0s 821us/step - loss: 8.4390 - mae: 1.8917 - val_loss: 5.8422 - val_mae: 1.6356\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 0s 859us/step - loss: 8.3720 - mae: 1.8920 - val_loss: 5.6209 - val_mae: 1.5397\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 0s 828us/step - loss: 8.3931 - mae: 1.8854 - val_loss: 5.8114 - val_mae: 1.6000\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 0s 887us/step - loss: 8.3618 - mae: 1.8767 - val_loss: 6.0844 - val_mae: 1.7178\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 0s 965us/step - loss: 8.3273 - mae: 1.8672 - val_loss: 5.6971 - val_mae: 1.5999\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 0s 781us/step - loss: 8.3759 - mae: 1.8768 - val_loss: 6.1923 - val_mae: 1.7525\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 0s 737us/step - loss: 8.3215 - mae: 1.8818 - val_loss: 6.0074 - val_mae: 1.6437\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 0s 658us/step - loss: 8.3574 - mae: 1.8802 - val_loss: 5.6825 - val_mae: 1.5146\n",
      "Epoch 37/100\n",
      "91/91 [==============================] - 0s 666us/step - loss: 8.3135 - mae: 1.8655 - val_loss: 5.7889 - val_mae: 1.6043\n",
      "Epoch 37: early stopping\n",
      "Test Loss (MSE): 6.555785179138184, Test Mean Absolute Error (MAE): 1.737601637840271\n",
      "Epoch 1/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 4.6890 - mae: 1.1348 - val_loss: 5.6909 - val_mae: 1.2818\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 670us/step - loss: 4.2676 - mae: 1.1037 - val_loss: 5.4421 - val_mae: 1.2731\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 701us/step - loss: 4.2190 - mae: 1.1030 - val_loss: 5.8536 - val_mae: 1.2366\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 685us/step - loss: 4.2043 - mae: 1.0946 - val_loss: 5.4211 - val_mae: 1.3106\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 766us/step - loss: 4.1943 - mae: 1.0952 - val_loss: 5.4241 - val_mae: 1.2840\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 840us/step - loss: 4.1685 - mae: 1.0885 - val_loss: 5.4298 - val_mae: 1.3006\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 789us/step - loss: 4.2139 - mae: 1.0976 - val_loss: 5.4622 - val_mae: 1.2456\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 923us/step - loss: 4.1944 - mae: 1.0984 - val_loss: 5.5562 - val_mae: 1.4476\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 845us/step - loss: 4.1213 - mae: 1.0913 - val_loss: 5.4097 - val_mae: 1.2704\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 817us/step - loss: 4.1536 - mae: 1.0898 - val_loss: 5.5118 - val_mae: 1.3928\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 980us/step - loss: 4.1142 - mae: 1.0727 - val_loss: 5.3824 - val_mae: 1.3225\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 764us/step - loss: 4.0693 - mae: 1.0742 - val_loss: 5.4677 - val_mae: 1.2213\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 790us/step - loss: 4.1109 - mae: 1.0748 - val_loss: 5.4493 - val_mae: 1.2603\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 746us/step - loss: 4.0987 - mae: 1.0686 - val_loss: 5.3769 - val_mae: 1.3252\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 778us/step - loss: 4.0943 - mae: 1.0837 - val_loss: 5.3827 - val_mae: 1.3065\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 743us/step - loss: 4.1154 - mae: 1.0769 - val_loss: 5.4051 - val_mae: 1.2428\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 741us/step - loss: 4.0698 - mae: 1.0587 - val_loss: 5.3842 - val_mae: 1.3588\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 745us/step - loss: 4.0868 - mae: 1.0728 - val_loss: 5.3567 - val_mae: 1.2988\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 780us/step - loss: 4.0610 - mae: 1.0625 - val_loss: 5.3852 - val_mae: 1.3518\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 744us/step - loss: 4.0666 - mae: 1.0739 - val_loss: 5.3628 - val_mae: 1.2724\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 724us/step - loss: 4.0640 - mae: 1.0697 - val_loss: 5.4091 - val_mae: 1.2587\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 761us/step - loss: 4.0659 - mae: 1.0596 - val_loss: 5.3978 - val_mae: 1.3070\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 834us/step - loss: 4.0657 - mae: 1.0623 - val_loss: 5.3929 - val_mae: 1.2775\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 762us/step - loss: 4.0503 - mae: 1.0630 - val_loss: 5.3676 - val_mae: 1.3476\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 788us/step - loss: 4.0571 - mae: 1.0676 - val_loss: 5.4364 - val_mae: 1.3532\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 829us/step - loss: 4.0330 - mae: 1.0641 - val_loss: 5.3748 - val_mae: 1.2773\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 833us/step - loss: 4.0602 - mae: 1.0622 - val_loss: 5.3725 - val_mae: 1.2616\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 740us/step - loss: 4.0446 - mae: 1.0541 - val_loss: 5.3969 - val_mae: 1.3769\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 763us/step - loss: 4.0630 - mae: 1.0648 - val_loss: 5.3665 - val_mae: 1.2798\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 778us/step - loss: 4.0586 - mae: 1.0710 - val_loss: 5.4015 - val_mae: 1.3164\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 763us/step - loss: 4.0526 - mae: 1.0622 - val_loss: 5.4505 - val_mae: 1.2991\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 763us/step - loss: 4.0656 - mae: 1.0603 - val_loss: 5.3803 - val_mae: 1.2685\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 791us/step - loss: 4.0773 - mae: 1.0681 - val_loss: 5.3944 - val_mae: 1.3054\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 761us/step - loss: 4.0653 - mae: 1.0643 - val_loss: 5.3934 - val_mae: 1.2617\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 785us/step - loss: 4.0912 - mae: 1.0696 - val_loss: 5.5820 - val_mae: 1.2111\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 953us/step - loss: 4.0776 - mae: 1.0705 - val_loss: 5.5005 - val_mae: 1.2268\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 870us/step - loss: 4.0508 - mae: 1.0629 - val_loss: 5.3907 - val_mae: 1.2943\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 838us/step - loss: 4.0595 - mae: 1.0597 - val_loss: 5.3747 - val_mae: 1.3045\n",
      "Epoch 38: early stopping\n",
      "Test Loss (MSE): 4.339994430541992, Test Mean Absolute Error (MAE): 1.1081669330596924\n",
      "Epoch 1/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 5.6869 - mae: 1.2387 - val_loss: 4.6282 - val_mae: 1.1168\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 767us/step - loss: 4.9985 - mae: 1.1952 - val_loss: 4.5396 - val_mae: 1.3137\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 785us/step - loss: 4.9413 - mae: 1.1834 - val_loss: 4.3860 - val_mae: 1.1960\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 725us/step - loss: 4.9317 - mae: 1.1892 - val_loss: 4.3589 - val_mae: 1.0907\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 848us/step - loss: 4.8730 - mae: 1.1797 - val_loss: 4.4179 - val_mae: 1.1349\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 802us/step - loss: 4.8424 - mae: 1.1642 - val_loss: 4.3255 - val_mae: 1.1678\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 899us/step - loss: 4.8021 - mae: 1.1831 - val_loss: 4.3566 - val_mae: 1.0546\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 845us/step - loss: 4.8165 - mae: 1.1707 - val_loss: 4.3395 - val_mae: 1.0498\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 785us/step - loss: 4.7873 - mae: 1.1653 - val_loss: 4.3700 - val_mae: 1.1956\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 751us/step - loss: 4.8456 - mae: 1.1685 - val_loss: 4.3346 - val_mae: 1.1257\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 741us/step - loss: 4.7635 - mae: 1.1618 - val_loss: 4.3246 - val_mae: 1.1297\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 765us/step - loss: 4.7412 - mae: 1.1543 - val_loss: 4.3248 - val_mae: 1.1219\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 720us/step - loss: 4.7669 - mae: 1.1619 - val_loss: 4.3627 - val_mae: 1.0583\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 761us/step - loss: 4.7548 - mae: 1.1632 - val_loss: 4.3488 - val_mae: 1.1530\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 737us/step - loss: 4.7461 - mae: 1.1834 - val_loss: 4.4114 - val_mae: 1.1713\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 754us/step - loss: 4.7458 - mae: 1.1644 - val_loss: 4.3842 - val_mae: 1.0775\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 732us/step - loss: 4.7255 - mae: 1.1570 - val_loss: 4.6241 - val_mae: 1.0738\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 765us/step - loss: 4.7297 - mae: 1.1592 - val_loss: 4.3706 - val_mae: 1.1242\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 729us/step - loss: 4.7513 - mae: 1.1732 - val_loss: 4.3831 - val_mae: 1.1205\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 762us/step - loss: 4.7622 - mae: 1.1662 - val_loss: 4.6655 - val_mae: 1.3658\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 731us/step - loss: 4.7254 - mae: 1.1688 - val_loss: 4.4086 - val_mae: 1.1396\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 762us/step - loss: 4.7239 - mae: 1.1671 - val_loss: 4.4158 - val_mae: 1.0790\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 747us/step - loss: 4.7596 - mae: 1.1700 - val_loss: 4.3837 - val_mae: 1.1879\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 753us/step - loss: 4.7330 - mae: 1.1640 - val_loss: 4.3844 - val_mae: 1.0852\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 696us/step - loss: 4.7051 - mae: 1.1559 - val_loss: 4.3897 - val_mae: 1.0715\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 736us/step - loss: 4.7142 - mae: 1.1663 - val_loss: 4.4013 - val_mae: 1.1433\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 715us/step - loss: 4.7010 - mae: 1.1539 - val_loss: 4.4122 - val_mae: 1.2024\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 778us/step - loss: 4.7124 - mae: 1.1706 - val_loss: 4.4216 - val_mae: 1.1291\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 804us/step - loss: 4.6754 - mae: 1.1574 - val_loss: 4.4261 - val_mae: 1.1349\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 796us/step - loss: 4.7165 - mae: 1.1526 - val_loss: 4.4086 - val_mae: 1.0587\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 790us/step - loss: 4.6888 - mae: 1.1565 - val_loss: 4.4495 - val_mae: 1.1511\n",
      "Epoch 31: early stopping\n",
      "Test Loss (MSE): 3.4925217628479004, Test Mean Absolute Error (MAE): 1.038196086883545\n",
      "Epoch 1/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 5.4594 - mae: 1.2021 - val_loss: 5.2028 - val_mae: 1.4059\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 884us/step - loss: 4.8092 - mae: 1.1902 - val_loss: 4.8848 - val_mae: 1.1698\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 966us/step - loss: 4.6202 - mae: 1.1848 - val_loss: 4.8306 - val_mae: 1.2277\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 794us/step - loss: 4.5430 - mae: 1.1740 - val_loss: 5.0991 - val_mae: 1.1090\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 861us/step - loss: 4.5118 - mae: 1.1735 - val_loss: 4.7949 - val_mae: 1.2084\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 788us/step - loss: 4.4817 - mae: 1.1675 - val_loss: 4.7938 - val_mae: 1.1649\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 843us/step - loss: 4.4466 - mae: 1.1600 - val_loss: 4.8275 - val_mae: 1.2369\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 851us/step - loss: 4.4285 - mae: 1.1659 - val_loss: 4.8329 - val_mae: 1.1318\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 901us/step - loss: 4.4169 - mae: 1.1492 - val_loss: 4.7661 - val_mae: 1.1717\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 854us/step - loss: 4.4376 - mae: 1.1488 - val_loss: 4.7734 - val_mae: 1.1143\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 894us/step - loss: 4.4484 - mae: 1.1538 - val_loss: 4.7755 - val_mae: 1.1485\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 961us/step - loss: 4.4329 - mae: 1.1483 - val_loss: 4.7603 - val_mae: 1.2063\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 930us/step - loss: 4.4019 - mae: 1.1497 - val_loss: 4.9148 - val_mae: 1.2875\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 4.3909 - mae: 1.1398 - val_loss: 4.8372 - val_mae: 1.3035\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 842us/step - loss: 4.4370 - mae: 1.1582 - val_loss: 4.7657 - val_mae: 1.1619\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 887us/step - loss: 4.4281 - mae: 1.1569 - val_loss: 4.7982 - val_mae: 1.1177\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 816us/step - loss: 4.3825 - mae: 1.1371 - val_loss: 4.7922 - val_mae: 1.2092\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 4.4040 - mae: 1.1474 - val_loss: 4.8464 - val_mae: 1.2447\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 800us/step - loss: 4.4102 - mae: 1.1457 - val_loss: 4.7945 - val_mae: 1.1413\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 791us/step - loss: 4.4064 - mae: 1.1437 - val_loss: 4.8857 - val_mae: 1.2505\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 889us/step - loss: 4.4305 - mae: 1.1408 - val_loss: 4.8154 - val_mae: 1.2753\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 887us/step - loss: 4.4052 - mae: 1.1574 - val_loss: 4.7804 - val_mae: 1.1810\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 836us/step - loss: 4.3957 - mae: 1.1501 - val_loss: 4.7475 - val_mae: 1.1567\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 818us/step - loss: 4.3906 - mae: 1.1307 - val_loss: 4.8522 - val_mae: 1.1815\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 809us/step - loss: 4.4034 - mae: 1.1448 - val_loss: 4.8304 - val_mae: 1.2543\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 808us/step - loss: 4.4014 - mae: 1.1478 - val_loss: 4.8240 - val_mae: 1.1006\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 807us/step - loss: 4.4018 - mae: 1.1422 - val_loss: 4.8132 - val_mae: 1.1886\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 841us/step - loss: 4.4045 - mae: 1.1389 - val_loss: 4.7811 - val_mae: 1.1394\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 791us/step - loss: 4.3981 - mae: 1.1457 - val_loss: 4.7788 - val_mae: 1.1456\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 822us/step - loss: 4.3764 - mae: 1.1342 - val_loss: 4.7971 - val_mae: 1.1187\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 838us/step - loss: 4.3730 - mae: 1.1341 - val_loss: 4.8135 - val_mae: 1.1575\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 887us/step - loss: 4.3645 - mae: 1.1298 - val_loss: 4.8023 - val_mae: 1.2298\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 844us/step - loss: 4.3754 - mae: 1.1379 - val_loss: 4.7766 - val_mae: 1.2013\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 838us/step - loss: 4.4072 - mae: 1.1420 - val_loss: 4.8111 - val_mae: 1.1442\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 803us/step - loss: 4.3865 - mae: 1.1342 - val_loss: 4.8177 - val_mae: 1.1317\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 842us/step - loss: 4.3913 - mae: 1.1373 - val_loss: 4.8222 - val_mae: 1.1265\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 960us/step - loss: 4.3637 - mae: 1.1348 - val_loss: 4.8414 - val_mae: 1.1016\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 950us/step - loss: 4.3659 - mae: 1.1342 - val_loss: 4.8038 - val_mae: 1.1448\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 829us/step - loss: 4.3897 - mae: 1.1336 - val_loss: 4.7932 - val_mae: 1.1459\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 801us/step - loss: 4.3668 - mae: 1.1299 - val_loss: 4.8357 - val_mae: 1.2218\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 804us/step - loss: 4.3779 - mae: 1.1354 - val_loss: 4.8385 - val_mae: 1.2368\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 816us/step - loss: 4.3779 - mae: 1.1416 - val_loss: 4.8174 - val_mae: 1.1913\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 801us/step - loss: 4.3479 - mae: 1.1283 - val_loss: 4.8986 - val_mae: 1.1438\n",
      "Epoch 43: early stopping\n",
      "Test Loss (MSE): 4.107071399688721, Test Mean Absolute Error (MAE): 1.03509521484375\n",
      "Epoch 1/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 5.7951 - mae: 1.2214 - val_loss: 4.8686 - val_mae: 1.2992\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 942us/step - loss: 4.9929 - mae: 1.1827 - val_loss: 4.6865 - val_mae: 1.0743\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 917us/step - loss: 4.8719 - mae: 1.1780 - val_loss: 4.6903 - val_mae: 1.1691\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 921us/step - loss: 4.7960 - mae: 1.1662 - val_loss: 5.3114 - val_mae: 1.4095\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 816us/step - loss: 4.7891 - mae: 1.1520 - val_loss: 4.8713 - val_mae: 1.0598\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 833us/step - loss: 4.7484 - mae: 1.1518 - val_loss: 4.5910 - val_mae: 1.2178\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 754us/step - loss: 4.7206 - mae: 1.1540 - val_loss: 4.6727 - val_mae: 1.0613\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 757us/step - loss: 4.7189 - mae: 1.1481 - val_loss: 4.5641 - val_mae: 1.2515\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 762us/step - loss: 4.6750 - mae: 1.1491 - val_loss: 4.5428 - val_mae: 1.1500\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 905us/step - loss: 4.6927 - mae: 1.1452 - val_loss: 4.6230 - val_mae: 1.2131\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 866us/step - loss: 4.6684 - mae: 1.1454 - val_loss: 4.5541 - val_mae: 1.0929\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 879us/step - loss: 4.6702 - mae: 1.1354 - val_loss: 4.5515 - val_mae: 1.1402\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 820us/step - loss: 4.6902 - mae: 1.1528 - val_loss: 4.6741 - val_mae: 1.1961\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 803us/step - loss: 4.6447 - mae: 1.1400 - val_loss: 4.5965 - val_mae: 1.2670\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 889us/step - loss: 4.6593 - mae: 1.1358 - val_loss: 4.5342 - val_mae: 1.1609\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 913us/step - loss: 4.6929 - mae: 1.1446 - val_loss: 4.5612 - val_mae: 1.1862\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 840us/step - loss: 4.6663 - mae: 1.1426 - val_loss: 4.5367 - val_mae: 1.2380\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 809us/step - loss: 4.6453 - mae: 1.1678 - val_loss: 4.6187 - val_mae: 1.1120\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 778us/step - loss: 4.6814 - mae: 1.1477 - val_loss: 4.5178 - val_mae: 1.1662\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 941us/step - loss: 4.6403 - mae: 1.1401 - val_loss: 4.5726 - val_mae: 1.1497\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 4.5883 - mae: 1.1378 - val_loss: 4.6203 - val_mae: 1.1093\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 880us/step - loss: 4.5981 - mae: 1.1348 - val_loss: 4.8167 - val_mae: 1.2464\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 816us/step - loss: 4.6180 - mae: 1.1347 - val_loss: 4.5648 - val_mae: 1.1354\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 802us/step - loss: 4.5909 - mae: 1.1323 - val_loss: 4.8626 - val_mae: 1.2552\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 878us/step - loss: 4.6417 - mae: 1.1663 - val_loss: 4.5775 - val_mae: 1.1253\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 815us/step - loss: 4.5851 - mae: 1.1323 - val_loss: 4.6706 - val_mae: 1.3100\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 806us/step - loss: 4.5890 - mae: 1.1480 - val_loss: 4.6707 - val_mae: 1.1727\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 788us/step - loss: 4.6563 - mae: 1.1485 - val_loss: 4.6032 - val_mae: 1.1820\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 783us/step - loss: 4.5735 - mae: 1.1280 - val_loss: 4.6218 - val_mae: 1.2571\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 822us/step - loss: 4.5473 - mae: 1.1342 - val_loss: 5.0102 - val_mae: 1.3679\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 792us/step - loss: 4.7220 - mae: 1.2066 - val_loss: 4.6657 - val_mae: 1.1834\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 779us/step - loss: 4.5126 - mae: 1.1129 - val_loss: 4.7013 - val_mae: 1.1272\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 767us/step - loss: 4.5198 - mae: 1.1211 - val_loss: 4.6845 - val_mae: 1.1541\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 855us/step - loss: 4.5068 - mae: 1.1154 - val_loss: 4.7270 - val_mae: 1.1802\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 820us/step - loss: 4.5508 - mae: 1.1201 - val_loss: 4.6782 - val_mae: 1.2224\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 849us/step - loss: 4.5288 - mae: 1.1132 - val_loss: 4.7542 - val_mae: 1.1117\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 868us/step - loss: 4.4984 - mae: 1.1088 - val_loss: 4.6661 - val_mae: 1.1268\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 800us/step - loss: 4.5390 - mae: 1.1343 - val_loss: 4.6884 - val_mae: 1.0772\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 931us/step - loss: 4.5827 - mae: 1.1180 - val_loss: 4.6950 - val_mae: 1.1099\n",
      "Epoch 39: early stopping\n",
      "Test Loss (MSE): 3.756592273712158, Test Mean Absolute Error (MAE): 1.0004771947860718\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.8699 - mae: 1.7220 - val_loss: 9.8162 - val_mae: 1.9158\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 825us/step - loss: 7.0224 - mae: 1.6672 - val_loss: 9.9750 - val_mae: 2.2111\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 897us/step - loss: 7.2485 - mae: 1.7178 - val_loss: 10.2064 - val_mae: 1.8024\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 787us/step - loss: 6.9564 - mae: 1.6623 - val_loss: 9.4896 - val_mae: 2.0188\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 801us/step - loss: 6.8871 - mae: 1.6601 - val_loss: 9.5621 - val_mae: 1.9458\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 919us/step - loss: 6.8173 - mae: 1.6672 - val_loss: 9.4723 - val_mae: 2.0405\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 839us/step - loss: 6.8584 - mae: 1.6653 - val_loss: 9.4464 - val_mae: 2.0439\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 778us/step - loss: 6.8379 - mae: 1.6767 - val_loss: 9.5620 - val_mae: 1.9151\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 0s 782us/step - loss: 6.8417 - mae: 1.6663 - val_loss: 9.8729 - val_mae: 2.2182\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 0s 838us/step - loss: 6.8960 - mae: 1.6664 - val_loss: 9.6574 - val_mae: 1.8742\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 0s 805us/step - loss: 6.8127 - mae: 1.6565 - val_loss: 9.4919 - val_mae: 2.0787\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 0s 796us/step - loss: 6.8679 - mae: 1.6799 - val_loss: 9.7031 - val_mae: 1.8527\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 0s 771us/step - loss: 6.7776 - mae: 1.6570 - val_loss: 9.8860 - val_mae: 1.8337\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 0s 836us/step - loss: 6.7657 - mae: 1.6711 - val_loss: 9.5073 - val_mae: 1.9063\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 0s 889us/step - loss: 6.8510 - mae: 1.6799 - val_loss: 9.4303 - val_mae: 1.9751\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 0s 854us/step - loss: 6.7346 - mae: 1.6611 - val_loss: 9.5809 - val_mae: 1.8735\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 0s 842us/step - loss: 6.7594 - mae: 1.6724 - val_loss: 9.5157 - val_mae: 1.8927\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 0s 791us/step - loss: 6.7309 - mae: 1.6625 - val_loss: 9.4775 - val_mae: 1.9324\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 0s 783us/step - loss: 6.7447 - mae: 1.6743 - val_loss: 9.5091 - val_mae: 1.8980\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 0s 802us/step - loss: 6.7137 - mae: 1.6667 - val_loss: 9.4493 - val_mae: 1.9173\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 0s 819us/step - loss: 6.7588 - mae: 1.6696 - val_loss: 9.4557 - val_mae: 1.9298\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 0s 836us/step - loss: 6.7358 - mae: 1.6642 - val_loss: 9.4572 - val_mae: 1.9843\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 0s 787us/step - loss: 6.7405 - mae: 1.6659 - val_loss: 9.4007 - val_mae: 2.0054\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 0s 789us/step - loss: 6.7359 - mae: 1.6579 - val_loss: 9.4189 - val_mae: 1.9719\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 0s 782us/step - loss: 6.7633 - mae: 1.6758 - val_loss: 9.6332 - val_mae: 1.8597\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 0s 776us/step - loss: 6.7423 - mae: 1.6719 - val_loss: 9.4600 - val_mae: 1.9309\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 0s 765us/step - loss: 6.7363 - mae: 1.6723 - val_loss: 9.6899 - val_mae: 1.8498\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 0s 761us/step - loss: 6.7385 - mae: 1.6640 - val_loss: 9.6021 - val_mae: 1.8723\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 0s 929us/step - loss: 6.7177 - mae: 1.6618 - val_loss: 9.4027 - val_mae: 2.0189\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 0s 864us/step - loss: 6.7243 - mae: 1.6690 - val_loss: 9.6012 - val_mae: 1.8647\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 0s 890us/step - loss: 6.7157 - mae: 1.6823 - val_loss: 9.7474 - val_mae: 1.8503\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 0s 837us/step - loss: 6.7232 - mae: 1.6587 - val_loss: 9.6691 - val_mae: 1.8545\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 0s 832us/step - loss: 6.7422 - mae: 1.6653 - val_loss: 9.5906 - val_mae: 1.8750\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 0s 820us/step - loss: 6.7391 - mae: 1.6608 - val_loss: 9.6606 - val_mae: 1.8570\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 0s 809us/step - loss: 6.6888 - mae: 1.6573 - val_loss: 9.5757 - val_mae: 1.8854\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 0s 811us/step - loss: 6.7038 - mae: 1.6711 - val_loss: 9.6734 - val_mae: 1.8635\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 0s 761us/step - loss: 6.7397 - mae: 1.6659 - val_loss: 9.5279 - val_mae: 1.8968\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 0s 774us/step - loss: 6.6918 - mae: 1.6604 - val_loss: 9.4556 - val_mae: 1.9257\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 0s 788us/step - loss: 6.6916 - mae: 1.6717 - val_loss: 9.4333 - val_mae: 1.9502\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 0s 766us/step - loss: 6.6841 - mae: 1.6573 - val_loss: 9.4299 - val_mae: 2.0303\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 0s 896us/step - loss: 6.7247 - mae: 1.6683 - val_loss: 9.4599 - val_mae: 1.9352\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 0s 801us/step - loss: 6.7251 - mae: 1.6687 - val_loss: 9.6487 - val_mae: 1.8576\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 0s 802us/step - loss: 6.7391 - mae: 1.6708 - val_loss: 9.6815 - val_mae: 1.8517\n",
      "Epoch 43: early stopping\n",
      "Test Loss (MSE): 6.4757890701293945, Test Mean Absolute Error (MAE): 1.61329185962677\n",
      "Epoch 1/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 9.6861 - mae: 1.8947 - val_loss: 7.4229 - val_mae: 1.8962\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 0s 828us/step - loss: 8.3639 - mae: 1.8495 - val_loss: 6.7136 - val_mae: 1.6343\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 0s 767us/step - loss: 8.1773 - mae: 1.8253 - val_loss: 6.8126 - val_mae: 1.8035\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 0s 776us/step - loss: 8.0947 - mae: 1.8536 - val_loss: 6.5389 - val_mae: 1.6059\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 0s 909us/step - loss: 8.1358 - mae: 1.8360 - val_loss: 6.5522 - val_mae: 1.6769\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 0s 884us/step - loss: 7.9007 - mae: 1.8332 - val_loss: 6.6089 - val_mae: 1.5166\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 0s 819us/step - loss: 8.0221 - mae: 1.8345 - val_loss: 6.4469 - val_mae: 1.6823\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 0s 834us/step - loss: 7.8712 - mae: 1.8190 - val_loss: 6.5875 - val_mae: 1.7525\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 0s 802us/step - loss: 7.8331 - mae: 1.8275 - val_loss: 6.4024 - val_mae: 1.6173\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 0s 831us/step - loss: 7.8324 - mae: 1.8302 - val_loss: 6.5692 - val_mae: 1.7882\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 0s 770us/step - loss: 7.8430 - mae: 1.8258 - val_loss: 6.4595 - val_mae: 1.6559\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 0s 805us/step - loss: 7.8402 - mae: 1.8185 - val_loss: 6.4410 - val_mae: 1.5804\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 0s 798us/step - loss: 7.7676 - mae: 1.8107 - val_loss: 6.5375 - val_mae: 1.7660\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 0s 785us/step - loss: 7.7854 - mae: 1.8216 - val_loss: 6.4984 - val_mae: 1.7455\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 0s 769us/step - loss: 7.8485 - mae: 1.8161 - val_loss: 6.5290 - val_mae: 1.7729\n",
      "Epoch 16/100\n",
      "84/84 [==============================] - 0s 810us/step - loss: 7.7672 - mae: 1.8103 - val_loss: 6.7216 - val_mae: 1.8895\n",
      "Epoch 17/100\n",
      "84/84 [==============================] - 0s 854us/step - loss: 7.8786 - mae: 1.8431 - val_loss: 6.4421 - val_mae: 1.6851\n",
      "Epoch 18/100\n",
      "84/84 [==============================] - 0s 801us/step - loss: 7.7463 - mae: 1.8015 - val_loss: 6.5602 - val_mae: 1.8038\n",
      "Epoch 19/100\n",
      "84/84 [==============================] - 0s 795us/step - loss: 7.7237 - mae: 1.8247 - val_loss: 6.3596 - val_mae: 1.5659\n",
      "Epoch 20/100\n",
      "84/84 [==============================] - 0s 760us/step - loss: 7.7295 - mae: 1.8094 - val_loss: 6.6987 - val_mae: 1.8385\n",
      "Epoch 21/100\n",
      "84/84 [==============================] - 0s 785us/step - loss: 7.8299 - mae: 1.8276 - val_loss: 6.3753 - val_mae: 1.5893\n",
      "Epoch 22/100\n",
      "84/84 [==============================] - 0s 756us/step - loss: 7.8152 - mae: 1.8099 - val_loss: 6.3658 - val_mae: 1.6149\n",
      "Epoch 23/100\n",
      "84/84 [==============================] - 0s 795us/step - loss: 7.7512 - mae: 1.8070 - val_loss: 6.3847 - val_mae: 1.6931\n",
      "Epoch 24/100\n",
      "84/84 [==============================] - 0s 791us/step - loss: 7.7180 - mae: 1.8178 - val_loss: 6.3957 - val_mae: 1.6637\n",
      "Epoch 25/100\n",
      "84/84 [==============================] - 0s 787us/step - loss: 7.7197 - mae: 1.8313 - val_loss: 6.3943 - val_mae: 1.6731\n",
      "Epoch 26/100\n",
      "84/84 [==============================] - 0s 805us/step - loss: 7.6896 - mae: 1.8078 - val_loss: 6.7228 - val_mae: 1.8440\n",
      "Epoch 27/100\n",
      "84/84 [==============================] - 0s 842us/step - loss: 7.7306 - mae: 1.8211 - val_loss: 6.4050 - val_mae: 1.6294\n",
      "Epoch 28/100\n",
      "84/84 [==============================] - 0s 802us/step - loss: 7.7085 - mae: 1.7995 - val_loss: 6.5163 - val_mae: 1.7271\n",
      "Epoch 29/100\n",
      "84/84 [==============================] - 0s 794us/step - loss: 7.7211 - mae: 1.8225 - val_loss: 6.5070 - val_mae: 1.7586\n",
      "Epoch 30/100\n",
      "84/84 [==============================] - 0s 855us/step - loss: 7.7073 - mae: 1.8123 - val_loss: 6.4856 - val_mae: 1.7342\n",
      "Epoch 31/100\n",
      "84/84 [==============================] - 0s 889us/step - loss: 7.7224 - mae: 1.8062 - val_loss: 6.4509 - val_mae: 1.6946\n",
      "Epoch 32/100\n",
      "84/84 [==============================] - 0s 821us/step - loss: 7.6579 - mae: 1.8103 - val_loss: 6.4989 - val_mae: 1.7295\n",
      "Epoch 33/100\n",
      "84/84 [==============================] - 0s 902us/step - loss: 7.6657 - mae: 1.8175 - val_loss: 6.3701 - val_mae: 1.5556\n",
      "Epoch 34/100\n",
      "84/84 [==============================] - 0s 892us/step - loss: 7.6937 - mae: 1.8069 - val_loss: 6.3820 - val_mae: 1.6424\n",
      "Epoch 35/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 7.6219 - mae: 1.7965 - val_loss: 6.5710 - val_mae: 1.7602\n",
      "Epoch 36/100\n",
      "84/84 [==============================] - 0s 840us/step - loss: 7.6344 - mae: 1.8083 - val_loss: 6.4638 - val_mae: 1.6943\n",
      "Epoch 37/100\n",
      "84/84 [==============================] - 0s 856us/step - loss: 7.6087 - mae: 1.8128 - val_loss: 6.4623 - val_mae: 1.5943\n",
      "Epoch 38/100\n",
      "84/84 [==============================] - 0s 922us/step - loss: 7.6059 - mae: 1.8050 - val_loss: 6.4339 - val_mae: 1.6647\n",
      "Epoch 39/100\n",
      "84/84 [==============================] - 0s 809us/step - loss: 7.6236 - mae: 1.7781 - val_loss: 6.5712 - val_mae: 1.7603\n",
      "Epoch 39: early stopping\n",
      "Test Loss (MSE): 7.722267150878906, Test Mean Absolute Error (MAE): 1.7932353019714355\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 8.6716 - mae: 1.7681 - val_loss: 9.3883 - val_mae: 2.0919\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 861us/step - loss: 7.9002 - mae: 1.7467 - val_loss: 8.8256 - val_mae: 1.8259\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 874us/step - loss: 7.6453 - mae: 1.7249 - val_loss: 8.7595 - val_mae: 1.9937\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 829us/step - loss: 7.4798 - mae: 1.7163 - val_loss: 8.6872 - val_mae: 1.9582\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 854us/step - loss: 7.4388 - mae: 1.7176 - val_loss: 8.5783 - val_mae: 1.9312\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 865us/step - loss: 7.4257 - mae: 1.7087 - val_loss: 8.5710 - val_mae: 2.0285\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 838us/step - loss: 7.4052 - mae: 1.7245 - val_loss: 8.4817 - val_mae: 1.9248\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 843us/step - loss: 7.3104 - mae: 1.7111 - val_loss: 8.5342 - val_mae: 1.9555\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 0s 855us/step - loss: 7.2777 - mae: 1.7200 - val_loss: 8.8619 - val_mae: 1.7476\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 0s 846us/step - loss: 7.4074 - mae: 1.7039 - val_loss: 8.4113 - val_mae: 1.9021\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 0s 879us/step - loss: 7.2602 - mae: 1.7047 - val_loss: 8.5187 - val_mae: 1.8375\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 0s 851us/step - loss: 7.2795 - mae: 1.7037 - val_loss: 8.7863 - val_mae: 2.1165\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 0s 829us/step - loss: 7.2797 - mae: 1.7134 - val_loss: 8.5110 - val_mae: 1.8558\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 0s 848us/step - loss: 7.2636 - mae: 1.6985 - val_loss: 9.1241 - val_mae: 2.1364\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 0s 842us/step - loss: 7.3380 - mae: 1.7334 - val_loss: 8.4710 - val_mae: 1.8373\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 0s 837us/step - loss: 7.3867 - mae: 1.7027 - val_loss: 8.4992 - val_mae: 1.8338\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 0s 828us/step - loss: 7.2260 - mae: 1.7001 - val_loss: 8.4122 - val_mae: 1.9208\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 0s 879us/step - loss: 7.1548 - mae: 1.7118 - val_loss: 8.4438 - val_mae: 1.8662\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 0s 808us/step - loss: 7.2699 - mae: 1.6987 - val_loss: 8.4639 - val_mae: 1.8710\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 0s 879us/step - loss: 7.3527 - mae: 1.7205 - val_loss: 8.4645 - val_mae: 1.8073\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 0s 821us/step - loss: 7.2022 - mae: 1.7201 - val_loss: 8.6585 - val_mae: 1.8611\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 0s 816us/step - loss: 7.2443 - mae: 1.7079 - val_loss: 8.4821 - val_mae: 1.9073\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 0s 850us/step - loss: 7.2219 - mae: 1.7147 - val_loss: 8.7770 - val_mae: 1.7790\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 0s 887us/step - loss: 7.2647 - mae: 1.7033 - val_loss: 8.6851 - val_mae: 2.0558\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 0s 882us/step - loss: 7.2409 - mae: 1.7029 - val_loss: 8.4730 - val_mae: 1.8574\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 0s 795us/step - loss: 7.2032 - mae: 1.7201 - val_loss: 8.5059 - val_mae: 1.8196\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 0s 821us/step - loss: 7.2222 - mae: 1.7131 - val_loss: 8.4855 - val_mae: 1.8287\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 0s 839us/step - loss: 7.1525 - mae: 1.6963 - val_loss: 8.4471 - val_mae: 1.8477\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 0s 886us/step - loss: 7.1991 - mae: 1.7008 - val_loss: 8.5398 - val_mae: 1.9519\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 0s 870us/step - loss: 7.1701 - mae: 1.7013 - val_loss: 8.5521 - val_mae: 1.9301\n",
      "Epoch 30: early stopping\n",
      "Test Loss (MSE): 6.4268574714660645, Test Mean Absolute Error (MAE): 1.7397507429122925\n",
      "Epoch 1/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 8.9336 - mae: 1.7943 - val_loss: 9.3410 - val_mae: 1.7423\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 7.7467 - mae: 1.7176 - val_loss: 8.3857 - val_mae: 1.7188\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 0s 855us/step - loss: 7.5649 - mae: 1.6990 - val_loss: 8.2160 - val_mae: 1.9386\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 0s 849us/step - loss: 7.4173 - mae: 1.7063 - val_loss: 8.0961 - val_mae: 2.0105\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 0s 840us/step - loss: 7.2534 - mae: 1.6975 - val_loss: 7.9714 - val_mae: 1.7905\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 0s 917us/step - loss: 7.2988 - mae: 1.6886 - val_loss: 8.1022 - val_mae: 1.7889\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 7.3077 - mae: 1.7181 - val_loss: 8.5854 - val_mae: 1.7170\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 0s 964us/step - loss: 7.2343 - mae: 1.6906 - val_loss: 7.8690 - val_mae: 1.8532\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 0s 873us/step - loss: 7.1749 - mae: 1.6927 - val_loss: 7.8973 - val_mae: 1.8637\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 0s 863us/step - loss: 7.1544 - mae: 1.6969 - val_loss: 8.0109 - val_mae: 1.8010\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 0s 855us/step - loss: 7.2459 - mae: 1.6967 - val_loss: 8.0633 - val_mae: 1.7485\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 0s 931us/step - loss: 7.2226 - mae: 1.7020 - val_loss: 7.9213 - val_mae: 1.8209\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 0s 887us/step - loss: 7.0829 - mae: 1.6852 - val_loss: 7.8563 - val_mae: 1.8761\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 0s 879us/step - loss: 7.1224 - mae: 1.6956 - val_loss: 7.8528 - val_mae: 1.9281\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 0s 859us/step - loss: 7.1318 - mae: 1.6862 - val_loss: 7.9905 - val_mae: 1.9181\n",
      "Epoch 16/100\n",
      "84/84 [==============================] - 0s 911us/step - loss: 7.1346 - mae: 1.6857 - val_loss: 8.0394 - val_mae: 1.8277\n",
      "Epoch 17/100\n",
      "84/84 [==============================] - 0s 971us/step - loss: 7.0853 - mae: 1.6933 - val_loss: 8.0918 - val_mae: 1.9787\n",
      "Epoch 18/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 7.0808 - mae: 1.6760 - val_loss: 7.8801 - val_mae: 1.8554\n",
      "Epoch 19/100\n",
      "84/84 [==============================] - 0s 955us/step - loss: 7.0834 - mae: 1.6938 - val_loss: 7.9211 - val_mae: 1.8411\n",
      "Epoch 20/100\n",
      "84/84 [==============================] - 0s 878us/step - loss: 7.0213 - mae: 1.6776 - val_loss: 7.9029 - val_mae: 1.8334\n",
      "Epoch 21/100\n",
      "84/84 [==============================] - 0s 887us/step - loss: 7.1252 - mae: 1.6937 - val_loss: 8.1161 - val_mae: 1.7943\n",
      "Epoch 22/100\n",
      "84/84 [==============================] - 0s 862us/step - loss: 7.0584 - mae: 1.6756 - val_loss: 8.0375 - val_mae: 1.7884\n",
      "Epoch 23/100\n",
      "84/84 [==============================] - 0s 839us/step - loss: 7.0302 - mae: 1.6743 - val_loss: 7.9471 - val_mae: 1.8592\n",
      "Epoch 24/100\n",
      "84/84 [==============================] - 0s 858us/step - loss: 6.9911 - mae: 1.6779 - val_loss: 8.0853 - val_mae: 1.8579\n",
      "Epoch 25/100\n",
      "84/84 [==============================] - 0s 930us/step - loss: 6.9799 - mae: 1.6816 - val_loss: 8.0529 - val_mae: 1.9192\n",
      "Epoch 26/100\n",
      "84/84 [==============================] - 0s 872us/step - loss: 7.0171 - mae: 1.6584 - val_loss: 8.0519 - val_mae: 1.7837\n",
      "Epoch 27/100\n",
      "84/84 [==============================] - 0s 869us/step - loss: 6.9916 - mae: 1.6778 - val_loss: 8.1112 - val_mae: 1.9175\n",
      "Epoch 28/100\n",
      "84/84 [==============================] - 0s 831us/step - loss: 7.0510 - mae: 1.6798 - val_loss: 8.1935 - val_mae: 1.7941\n",
      "Epoch 29/100\n",
      "84/84 [==============================] - 0s 868us/step - loss: 6.9118 - mae: 1.6594 - val_loss: 8.1483 - val_mae: 1.9394\n",
      "Epoch 30/100\n",
      "84/84 [==============================] - 0s 845us/step - loss: 6.9299 - mae: 1.6704 - val_loss: 8.1296 - val_mae: 1.8854\n",
      "Epoch 31/100\n",
      "84/84 [==============================] - 0s 845us/step - loss: 6.9631 - mae: 1.6663 - val_loss: 8.3053 - val_mae: 1.9373\n",
      "Epoch 32/100\n",
      "84/84 [==============================] - 0s 967us/step - loss: 6.9111 - mae: 1.6635 - val_loss: 8.1431 - val_mae: 1.8124\n",
      "Epoch 33/100\n",
      "84/84 [==============================] - 0s 880us/step - loss: 6.8980 - mae: 1.6608 - val_loss: 8.3130 - val_mae: 1.7891\n",
      "Epoch 34/100\n",
      "84/84 [==============================] - 0s 856us/step - loss: 6.9145 - mae: 1.6522 - val_loss: 8.2374 - val_mae: 1.9188\n",
      "Epoch 34: early stopping\n",
      "Test Loss (MSE): 8.350210189819336, Test Mean Absolute Error (MAE): 1.921710729598999\n",
      "Epoch 1/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 4.7935 - mae: 1.1307 - val_loss: 5.5097 - val_mae: 1.3561\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 713us/step - loss: 4.2116 - mae: 1.1031 - val_loss: 5.7853 - val_mae: 1.5336\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 753us/step - loss: 4.1225 - mae: 1.0970 - val_loss: 5.6140 - val_mae: 1.2022\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 730us/step - loss: 4.1404 - mae: 1.0923 - val_loss: 5.5261 - val_mae: 1.1943\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 712us/step - loss: 4.1481 - mae: 1.0925 - val_loss: 5.3116 - val_mae: 1.2160\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 720us/step - loss: 4.0767 - mae: 1.0820 - val_loss: 5.2269 - val_mae: 1.3060\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 762us/step - loss: 4.0773 - mae: 1.0837 - val_loss: 5.2075 - val_mae: 1.2290\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 710us/step - loss: 4.0838 - mae: 1.0679 - val_loss: 5.3057 - val_mae: 1.4178\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 704us/step - loss: 4.0718 - mae: 1.0809 - val_loss: 5.1997 - val_mae: 1.2357\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 764us/step - loss: 4.0115 - mae: 1.0701 - val_loss: 5.2129 - val_mae: 1.2421\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 763us/step - loss: 4.0325 - mae: 1.0633 - val_loss: 5.2515 - val_mae: 1.3637\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 733us/step - loss: 4.0675 - mae: 1.0698 - val_loss: 5.2203 - val_mae: 1.2760\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 824us/step - loss: 4.0576 - mae: 1.0691 - val_loss: 5.1942 - val_mae: 1.3377\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 736us/step - loss: 4.0133 - mae: 1.0615 - val_loss: 5.2322 - val_mae: 1.2212\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 708us/step - loss: 4.0218 - mae: 1.0575 - val_loss: 5.1647 - val_mae: 1.2633\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 806us/step - loss: 4.0278 - mae: 1.0539 - val_loss: 5.2153 - val_mae: 1.2087\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 794us/step - loss: 4.0006 - mae: 1.0604 - val_loss: 5.2262 - val_mae: 1.2101\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 751us/step - loss: 4.0109 - mae: 1.0592 - val_loss: 5.2426 - val_mae: 1.1905\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 758us/step - loss: 4.0246 - mae: 1.0582 - val_loss: 5.2366 - val_mae: 1.1957\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 759us/step - loss: 4.0419 - mae: 1.0617 - val_loss: 5.1857 - val_mae: 1.3038\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 712us/step - loss: 4.0027 - mae: 1.0560 - val_loss: 5.1666 - val_mae: 1.3516\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 734us/step - loss: 4.0230 - mae: 1.0599 - val_loss: 5.1594 - val_mae: 1.2689\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 718us/step - loss: 4.0235 - mae: 1.0523 - val_loss: 5.1584 - val_mae: 1.2488\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 722us/step - loss: 3.9990 - mae: 1.0629 - val_loss: 5.2921 - val_mae: 1.1922\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 821us/step - loss: 4.0357 - mae: 1.0583 - val_loss: 5.1524 - val_mae: 1.2844\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 714us/step - loss: 3.9861 - mae: 1.0548 - val_loss: 5.2449 - val_mae: 1.2363\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 719us/step - loss: 4.0113 - mae: 1.0516 - val_loss: 5.2079 - val_mae: 1.2295\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 710us/step - loss: 4.0162 - mae: 1.0561 - val_loss: 5.1779 - val_mae: 1.2625\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 805us/step - loss: 3.9982 - mae: 1.0544 - val_loss: 5.1887 - val_mae: 1.2578\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 792us/step - loss: 4.0243 - mae: 1.0478 - val_loss: 5.1758 - val_mae: 1.2660\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 850us/step - loss: 4.0090 - mae: 1.0534 - val_loss: 5.2104 - val_mae: 1.2441\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 817us/step - loss: 4.0120 - mae: 1.0541 - val_loss: 5.1737 - val_mae: 1.2346\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 903us/step - loss: 4.0057 - mae: 1.0487 - val_loss: 5.1663 - val_mae: 1.2581\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 816us/step - loss: 3.9904 - mae: 1.0501 - val_loss: 5.1805 - val_mae: 1.2843\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 816us/step - loss: 4.0234 - mae: 1.0580 - val_loss: 5.1985 - val_mae: 1.2676\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 698us/step - loss: 3.9947 - mae: 1.0516 - val_loss: 5.1931 - val_mae: 1.3064\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 725us/step - loss: 4.0172 - mae: 1.0509 - val_loss: 5.2698 - val_mae: 1.2287\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 727us/step - loss: 4.0070 - mae: 1.0628 - val_loss: 5.2322 - val_mae: 1.3365\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 720us/step - loss: 4.0267 - mae: 1.0474 - val_loss: 5.2183 - val_mae: 1.2408\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 749us/step - loss: 4.0110 - mae: 1.0650 - val_loss: 5.2122 - val_mae: 1.2273\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 713us/step - loss: 4.0103 - mae: 1.0527 - val_loss: 5.2782 - val_mae: 1.1915\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 717us/step - loss: 4.0164 - mae: 1.0476 - val_loss: 5.1999 - val_mae: 1.2333\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 717us/step - loss: 4.0149 - mae: 1.0597 - val_loss: 5.2454 - val_mae: 1.3256\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 681us/step - loss: 4.0566 - mae: 1.0647 - val_loss: 5.2476 - val_mae: 1.2007\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 726us/step - loss: 3.9975 - mae: 1.0490 - val_loss: 5.1814 - val_mae: 1.2435\n",
      "Epoch 45: early stopping\n",
      "Test Loss (MSE): 5.061020851135254, Test Mean Absolute Error (MAE): 1.1425514221191406\n",
      "Epoch 1/100\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 5.6146 - mae: 1.2164 - val_loss: 4.2621 - val_mae: 1.2360\n",
      "Epoch 2/100\n",
      "151/151 [==============================] - 0s 863us/step - loss: 4.8605 - mae: 1.2087 - val_loss: 4.0592 - val_mae: 1.0504\n",
      "Epoch 3/100\n",
      "151/151 [==============================] - 0s 822us/step - loss: 4.7263 - mae: 1.1822 - val_loss: 5.7942 - val_mae: 1.5336\n",
      "Epoch 4/100\n",
      "151/151 [==============================] - 0s 768us/step - loss: 4.7893 - mae: 1.2017 - val_loss: 4.0639 - val_mae: 1.1872\n",
      "Epoch 5/100\n",
      "151/151 [==============================] - 0s 790us/step - loss: 4.6620 - mae: 1.1960 - val_loss: 4.0444 - val_mae: 1.1456\n",
      "Epoch 6/100\n",
      "151/151 [==============================] - 0s 763us/step - loss: 4.6410 - mae: 1.1694 - val_loss: 4.0987 - val_mae: 1.0179\n",
      "Epoch 7/100\n",
      "151/151 [==============================] - 0s 802us/step - loss: 4.6553 - mae: 1.1705 - val_loss: 3.9638 - val_mae: 1.0306\n",
      "Epoch 8/100\n",
      "151/151 [==============================] - 0s 763us/step - loss: 4.6707 - mae: 1.1601 - val_loss: 4.0927 - val_mae: 0.9998\n",
      "Epoch 9/100\n",
      "151/151 [==============================] - 0s 781us/step - loss: 4.6365 - mae: 1.1646 - val_loss: 4.0046 - val_mae: 1.0756\n",
      "Epoch 10/100\n",
      "151/151 [==============================] - 0s 767us/step - loss: 4.5944 - mae: 1.1547 - val_loss: 4.0005 - val_mae: 1.0891\n",
      "Epoch 11/100\n",
      "151/151 [==============================] - 0s 769us/step - loss: 4.5919 - mae: 1.1595 - val_loss: 4.1267 - val_mae: 1.1674\n",
      "Epoch 12/100\n",
      "151/151 [==============================] - 0s 750us/step - loss: 4.5902 - mae: 1.1616 - val_loss: 4.0317 - val_mae: 1.1434\n",
      "Epoch 13/100\n",
      "151/151 [==============================] - 0s 827us/step - loss: 4.5809 - mae: 1.1576 - val_loss: 4.0719 - val_mae: 1.1474\n",
      "Epoch 14/100\n",
      "151/151 [==============================] - 0s 821us/step - loss: 4.5790 - mae: 1.1527 - val_loss: 4.0464 - val_mae: 1.0244\n",
      "Epoch 15/100\n",
      "151/151 [==============================] - 0s 907us/step - loss: 4.5824 - mae: 1.1499 - val_loss: 4.0046 - val_mae: 1.0589\n",
      "Epoch 16/100\n",
      "151/151 [==============================] - 0s 844us/step - loss: 4.5678 - mae: 1.1569 - val_loss: 4.0591 - val_mae: 1.0875\n",
      "Epoch 17/100\n",
      "151/151 [==============================] - 0s 804us/step - loss: 4.5473 - mae: 1.1424 - val_loss: 4.0625 - val_mae: 1.0739\n",
      "Epoch 18/100\n",
      "151/151 [==============================] - 0s 962us/step - loss: 4.5857 - mae: 1.1498 - val_loss: 4.1016 - val_mae: 1.0881\n",
      "Epoch 19/100\n",
      "151/151 [==============================] - 0s 854us/step - loss: 4.5517 - mae: 1.1385 - val_loss: 4.0752 - val_mae: 1.0884\n",
      "Epoch 20/100\n",
      "151/151 [==============================] - 0s 910us/step - loss: 4.5827 - mae: 1.1566 - val_loss: 4.0203 - val_mae: 1.0856\n",
      "Epoch 21/100\n",
      "151/151 [==============================] - 0s 796us/step - loss: 4.5221 - mae: 1.1497 - val_loss: 4.0509 - val_mae: 1.0274\n",
      "Epoch 22/100\n",
      "151/151 [==============================] - 0s 760us/step - loss: 4.5223 - mae: 1.1397 - val_loss: 4.0734 - val_mae: 1.1202\n",
      "Epoch 23/100\n",
      "151/151 [==============================] - 0s 821us/step - loss: 4.5478 - mae: 1.1424 - val_loss: 4.0391 - val_mae: 1.1032\n",
      "Epoch 24/100\n",
      "151/151 [==============================] - 0s 772us/step - loss: 4.5338 - mae: 1.1542 - val_loss: 4.1134 - val_mae: 1.0900\n",
      "Epoch 25/100\n",
      "151/151 [==============================] - 0s 784us/step - loss: 4.5259 - mae: 1.1486 - val_loss: 4.3761 - val_mae: 1.2635\n",
      "Epoch 26/100\n",
      "151/151 [==============================] - 0s 779us/step - loss: 4.5902 - mae: 1.1646 - val_loss: 4.1134 - val_mae: 1.0666\n",
      "Epoch 27/100\n",
      "151/151 [==============================] - 0s 834us/step - loss: 4.5206 - mae: 1.1566 - val_loss: 4.0978 - val_mae: 1.0383\n",
      "Epoch 27: early stopping\n",
      "Test Loss (MSE): 4.857912063598633, Test Mean Absolute Error (MAE): 1.0869555473327637\n",
      "Epoch 1/100\n",
      "153/153 [==============================] - 0s 1ms/step - loss: 5.4294 - mae: 1.1997 - val_loss: 5.2914 - val_mae: 1.2724\n",
      "Epoch 2/100\n",
      "153/153 [==============================] - 0s 713us/step - loss: 4.8060 - mae: 1.1753 - val_loss: 5.1343 - val_mae: 1.2750\n",
      "Epoch 3/100\n",
      "153/153 [==============================] - 0s 845us/step - loss: 4.6041 - mae: 1.1607 - val_loss: 4.9448 - val_mae: 1.1058\n",
      "Epoch 4/100\n",
      "153/153 [==============================] - 0s 775us/step - loss: 4.5562 - mae: 1.1499 - val_loss: 4.9090 - val_mae: 1.1238\n",
      "Epoch 5/100\n",
      "153/153 [==============================] - 0s 946us/step - loss: 4.5320 - mae: 1.1585 - val_loss: 4.8712 - val_mae: 1.1806\n",
      "Epoch 6/100\n",
      "153/153 [==============================] - 0s 847us/step - loss: 4.4809 - mae: 1.1336 - val_loss: 4.9990 - val_mae: 1.2522\n",
      "Epoch 7/100\n",
      "153/153 [==============================] - 0s 898us/step - loss: 4.5004 - mae: 1.1551 - val_loss: 4.9600 - val_mae: 1.1028\n",
      "Epoch 8/100\n",
      "153/153 [==============================] - 0s 947us/step - loss: 4.5542 - mae: 1.1482 - val_loss: 4.9792 - val_mae: 1.0841\n",
      "Epoch 9/100\n",
      "153/153 [==============================] - 0s 904us/step - loss: 4.5125 - mae: 1.1375 - val_loss: 5.1163 - val_mae: 1.3306\n",
      "Epoch 10/100\n",
      "153/153 [==============================] - 0s 788us/step - loss: 4.4706 - mae: 1.1420 - val_loss: 4.9042 - val_mae: 1.2560\n",
      "Epoch 11/100\n",
      "153/153 [==============================] - 0s 826us/step - loss: 4.4396 - mae: 1.1334 - val_loss: 4.9020 - val_mae: 1.2194\n",
      "Epoch 12/100\n",
      "153/153 [==============================] - 0s 774us/step - loss: 4.4661 - mae: 1.1473 - val_loss: 4.9021 - val_mae: 1.1044\n",
      "Epoch 13/100\n",
      "153/153 [==============================] - 0s 784us/step - loss: 4.4294 - mae: 1.1215 - val_loss: 4.9038 - val_mae: 1.2174\n",
      "Epoch 14/100\n",
      "153/153 [==============================] - 0s 834us/step - loss: 4.4750 - mae: 1.1538 - val_loss: 4.8792 - val_mae: 1.1065\n",
      "Epoch 15/100\n",
      "153/153 [==============================] - 0s 768us/step - loss: 4.4648 - mae: 1.1385 - val_loss: 4.8978 - val_mae: 1.1533\n",
      "Epoch 16/100\n",
      "153/153 [==============================] - 0s 796us/step - loss: 4.4520 - mae: 1.1308 - val_loss: 4.9413 - val_mae: 1.1307\n",
      "Epoch 17/100\n",
      "153/153 [==============================] - 0s 827us/step - loss: 4.4017 - mae: 1.1273 - val_loss: 4.9343 - val_mae: 1.2322\n",
      "Epoch 18/100\n",
      "153/153 [==============================] - 0s 845us/step - loss: 4.4126 - mae: 1.1384 - val_loss: 4.9848 - val_mae: 1.2819\n",
      "Epoch 19/100\n",
      "153/153 [==============================] - 0s 792us/step - loss: 4.4085 - mae: 1.1338 - val_loss: 4.9990 - val_mae: 1.1967\n",
      "Epoch 20/100\n",
      "153/153 [==============================] - 0s 774us/step - loss: 4.3893 - mae: 1.1375 - val_loss: 4.9473 - val_mae: 1.2257\n",
      "Epoch 21/100\n",
      "153/153 [==============================] - 0s 809us/step - loss: 4.4107 - mae: 1.1319 - val_loss: 4.8864 - val_mae: 1.2177\n",
      "Epoch 22/100\n",
      "153/153 [==============================] - 0s 843us/step - loss: 4.3711 - mae: 1.1318 - val_loss: 4.9663 - val_mae: 1.1221\n",
      "Epoch 23/100\n",
      "153/153 [==============================] - 0s 799us/step - loss: 4.3461 - mae: 1.1273 - val_loss: 5.1027 - val_mae: 1.1000\n",
      "Epoch 24/100\n",
      "153/153 [==============================] - 0s 820us/step - loss: 4.3462 - mae: 1.1283 - val_loss: 5.0788 - val_mae: 1.1442\n",
      "Epoch 25/100\n",
      "153/153 [==============================] - 0s 783us/step - loss: 4.3511 - mae: 1.1324 - val_loss: 5.1052 - val_mae: 1.1006\n",
      "Epoch 25: early stopping\n",
      "Test Loss (MSE): 4.14361047744751, Test Mean Absolute Error (MAE): 1.023841142654419\n",
      "Epoch 1/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 5.8335 - mae: 1.2819 - val_loss: 3.9953 - val_mae: 0.9077\n",
      "Epoch 2/100\n",
      "154/154 [==============================] - 0s 856us/step - loss: 5.1489 - mae: 1.2632 - val_loss: 3.7195 - val_mae: 0.9949\n",
      "Epoch 3/100\n",
      "154/154 [==============================] - 0s 809us/step - loss: 4.8921 - mae: 1.2556 - val_loss: 3.7188 - val_mae: 0.9173\n",
      "Epoch 4/100\n",
      "154/154 [==============================] - 0s 773us/step - loss: 4.8587 - mae: 1.2475 - val_loss: 3.6742 - val_mae: 1.0041\n",
      "Epoch 5/100\n",
      "154/154 [==============================] - 0s 796us/step - loss: 4.7923 - mae: 1.2430 - val_loss: 3.6605 - val_mae: 0.9920\n",
      "Epoch 6/100\n",
      "154/154 [==============================] - 0s 793us/step - loss: 4.7843 - mae: 1.2425 - val_loss: 3.5873 - val_mae: 0.9558\n",
      "Epoch 7/100\n",
      "154/154 [==============================] - 0s 783us/step - loss: 4.7633 - mae: 1.2399 - val_loss: 3.5683 - val_mae: 0.9476\n",
      "Epoch 8/100\n",
      "154/154 [==============================] - 0s 776us/step - loss: 4.7605 - mae: 1.2192 - val_loss: 3.6287 - val_mae: 0.9997\n",
      "Epoch 9/100\n",
      "154/154 [==============================] - 0s 779us/step - loss: 4.7379 - mae: 1.2281 - val_loss: 3.7189 - val_mae: 1.0616\n",
      "Epoch 10/100\n",
      "154/154 [==============================] - 0s 801us/step - loss: 4.6812 - mae: 1.2331 - val_loss: 3.5938 - val_mae: 0.8971\n",
      "Epoch 11/100\n",
      "154/154 [==============================] - 0s 787us/step - loss: 4.7192 - mae: 1.2139 - val_loss: 3.6190 - val_mae: 0.9776\n",
      "Epoch 12/100\n",
      "154/154 [==============================] - 0s 787us/step - loss: 4.6874 - mae: 1.2152 - val_loss: 3.6396 - val_mae: 1.0110\n",
      "Epoch 13/100\n",
      "154/154 [==============================] - 0s 773us/step - loss: 4.7176 - mae: 1.2147 - val_loss: 3.6814 - val_mae: 1.0295\n",
      "Epoch 14/100\n",
      "154/154 [==============================] - 0s 795us/step - loss: 4.6857 - mae: 1.2070 - val_loss: 3.6546 - val_mae: 1.0037\n",
      "Epoch 15/100\n",
      "154/154 [==============================] - 0s 788us/step - loss: 4.6510 - mae: 1.2119 - val_loss: 3.6070 - val_mae: 0.9162\n",
      "Epoch 16/100\n",
      "154/154 [==============================] - 0s 776us/step - loss: 4.7508 - mae: 1.2142 - val_loss: 3.6474 - val_mae: 0.9487\n",
      "Epoch 17/100\n",
      "154/154 [==============================] - 0s 786us/step - loss: 4.6621 - mae: 1.2008 - val_loss: 3.6180 - val_mae: 0.9781\n",
      "Epoch 18/100\n",
      "154/154 [==============================] - 0s 810us/step - loss: 4.6250 - mae: 1.2057 - val_loss: 3.6295 - val_mae: 0.9981\n",
      "Epoch 19/100\n",
      "154/154 [==============================] - 0s 807us/step - loss: 4.6363 - mae: 1.2058 - val_loss: 3.6217 - val_mae: 0.9732\n",
      "Epoch 20/100\n",
      "154/154 [==============================] - 0s 782us/step - loss: 4.6132 - mae: 1.1978 - val_loss: 3.5897 - val_mae: 0.9334\n",
      "Epoch 21/100\n",
      "154/154 [==============================] - 0s 772us/step - loss: 4.6083 - mae: 1.1958 - val_loss: 3.6836 - val_mae: 1.0806\n",
      "Epoch 22/100\n",
      "154/154 [==============================] - 0s 791us/step - loss: 4.6412 - mae: 1.2086 - val_loss: 3.6113 - val_mae: 0.9270\n",
      "Epoch 23/100\n",
      "154/154 [==============================] - 0s 782us/step - loss: 4.6189 - mae: 1.1986 - val_loss: 3.6604 - val_mae: 0.9175\n",
      "Epoch 24/100\n",
      "154/154 [==============================] - 0s 825us/step - loss: 4.6129 - mae: 1.1899 - val_loss: 3.7604 - val_mae: 1.0045\n",
      "Epoch 25/100\n",
      "154/154 [==============================] - 0s 789us/step - loss: 4.6249 - mae: 1.2000 - val_loss: 3.7300 - val_mae: 0.9892\n",
      "Epoch 26/100\n",
      "154/154 [==============================] - 0s 788us/step - loss: 4.5902 - mae: 1.1985 - val_loss: 3.7508 - val_mae: 0.9486\n",
      "Epoch 27/100\n",
      "154/154 [==============================] - 0s 784us/step - loss: 4.5830 - mae: 1.1888 - val_loss: 3.6576 - val_mae: 0.9650\n",
      "Epoch 27: early stopping\n",
      "Test Loss (MSE): 5.059491157531738, Test Mean Absolute Error (MAE): 1.229997158050537\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 8.5736 - mae: 1.8331 - val_loss: 6.6313 - val_mae: 1.7186\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 789us/step - loss: 7.7288 - mae: 1.7749 - val_loss: 6.4821 - val_mae: 1.5684\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 734us/step - loss: 7.8047 - mae: 1.7753 - val_loss: 6.6965 - val_mae: 1.5258\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 785us/step - loss: 7.8000 - mae: 1.7813 - val_loss: 6.5154 - val_mae: 1.5410\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 840us/step - loss: 7.5970 - mae: 1.7665 - val_loss: 7.3646 - val_mae: 2.0027\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 757us/step - loss: 7.6206 - mae: 1.7671 - val_loss: 6.4013 - val_mae: 1.6432\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 762us/step - loss: 7.6069 - mae: 1.7565 - val_loss: 6.5415 - val_mae: 1.5416\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 778us/step - loss: 7.6861 - mae: 1.7744 - val_loss: 6.4293 - val_mae: 1.5600\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 0s 760us/step - loss: 7.4938 - mae: 1.7548 - val_loss: 6.3700 - val_mae: 1.6022\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 0s 805us/step - loss: 7.5195 - mae: 1.7529 - val_loss: 6.4305 - val_mae: 1.5620\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 0s 774us/step - loss: 7.5148 - mae: 1.7536 - val_loss: 6.4679 - val_mae: 1.5845\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 0s 831us/step - loss: 7.5306 - mae: 1.7719 - val_loss: 6.3525 - val_mae: 1.6360\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 0s 765us/step - loss: 7.5388 - mae: 1.7577 - val_loss: 6.3809 - val_mae: 1.6964\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 0s 707us/step - loss: 7.5132 - mae: 1.7677 - val_loss: 6.3725 - val_mae: 1.6236\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 0s 767us/step - loss: 7.5025 - mae: 1.7586 - val_loss: 6.3693 - val_mae: 1.5995\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 0s 795us/step - loss: 7.5196 - mae: 1.7592 - val_loss: 6.4026 - val_mae: 1.7197\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 0s 822us/step - loss: 7.4480 - mae: 1.7646 - val_loss: 6.3918 - val_mae: 1.6782\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 0s 768us/step - loss: 7.4895 - mae: 1.7615 - val_loss: 6.5582 - val_mae: 1.5441\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 0s 769us/step - loss: 7.4994 - mae: 1.7590 - val_loss: 6.3675 - val_mae: 1.6580\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 0s 760us/step - loss: 7.4409 - mae: 1.7611 - val_loss: 6.4055 - val_mae: 1.6063\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 0s 896us/step - loss: 7.4782 - mae: 1.7581 - val_loss: 6.3966 - val_mae: 1.7135\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 0s 787us/step - loss: 7.5014 - mae: 1.7674 - val_loss: 6.4373 - val_mae: 1.7235\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 0s 806us/step - loss: 7.4414 - mae: 1.7595 - val_loss: 6.4064 - val_mae: 1.6939\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 0s 961us/step - loss: 7.4398 - mae: 1.7600 - val_loss: 6.3762 - val_mae: 1.6824\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 0s 853us/step - loss: 7.4168 - mae: 1.7650 - val_loss: 6.3654 - val_mae: 1.6647\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 0s 814us/step - loss: 7.4283 - mae: 1.7584 - val_loss: 6.3750 - val_mae: 1.6063\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 0s 794us/step - loss: 7.4749 - mae: 1.7618 - val_loss: 6.3943 - val_mae: 1.6917\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 0s 775us/step - loss: 7.3976 - mae: 1.7567 - val_loss: 6.3887 - val_mae: 1.6289\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 0s 775us/step - loss: 7.4394 - mae: 1.7480 - val_loss: 6.3797 - val_mae: 1.6746\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 0s 746us/step - loss: 7.4700 - mae: 1.7660 - val_loss: 6.3730 - val_mae: 1.6551\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 0s 746us/step - loss: 7.4833 - mae: 1.7581 - val_loss: 6.4049 - val_mae: 1.6415\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 0s 760us/step - loss: 7.4272 - mae: 1.7641 - val_loss: 6.4035 - val_mae: 1.6709\n",
      "Epoch 32: early stopping\n",
      "Test Loss (MSE): 8.61631965637207, Test Mean Absolute Error (MAE): 1.8872437477111816\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 9.5086 - mae: 1.8853 - val_loss: 8.0442 - val_mae: 1.5634\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 827us/step - loss: 8.2284 - mae: 1.7848 - val_loss: 7.3122 - val_mae: 1.6149\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 885us/step - loss: 7.9462 - mae: 1.7679 - val_loss: 7.2175 - val_mae: 1.6625\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 804us/step - loss: 7.8478 - mae: 1.7738 - val_loss: 7.0550 - val_mae: 1.6199\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 835us/step - loss: 7.7292 - mae: 1.7772 - val_loss: 7.0954 - val_mae: 1.6319\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 793us/step - loss: 7.7418 - mae: 1.7575 - val_loss: 7.3370 - val_mae: 1.5201\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 805us/step - loss: 7.6807 - mae: 1.7703 - val_loss: 7.0014 - val_mae: 1.6852\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 786us/step - loss: 7.7346 - mae: 1.7720 - val_loss: 7.1086 - val_mae: 1.6082\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 0s 790us/step - loss: 7.6673 - mae: 1.7663 - val_loss: 7.0217 - val_mae: 1.5882\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 0s 798us/step - loss: 7.6069 - mae: 1.7563 - val_loss: 7.0547 - val_mae: 1.6250\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 0s 796us/step - loss: 7.6141 - mae: 1.7406 - val_loss: 7.1249 - val_mae: 1.7150\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 0s 793us/step - loss: 7.5742 - mae: 1.7558 - val_loss: 7.0721 - val_mae: 1.5757\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 0s 937us/step - loss: 7.5525 - mae: 1.7609 - val_loss: 7.2289 - val_mae: 1.5758\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 0s 815us/step - loss: 7.4921 - mae: 1.7551 - val_loss: 7.0442 - val_mae: 1.7306\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 0s 829us/step - loss: 7.6035 - mae: 1.7507 - val_loss: 7.2091 - val_mae: 1.7065\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 0s 833us/step - loss: 7.4544 - mae: 1.7412 - val_loss: 7.2798 - val_mae: 1.7196\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 0s 808us/step - loss: 7.4507 - mae: 1.7354 - val_loss: 7.3369 - val_mae: 1.7202\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 0s 801us/step - loss: 7.4238 - mae: 1.7424 - val_loss: 7.2612 - val_mae: 1.7294\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 0s 941us/step - loss: 7.3314 - mae: 1.7358 - val_loss: 7.2018 - val_mae: 1.7166\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 0s 723us/step - loss: 7.3701 - mae: 1.7459 - val_loss: 7.3496 - val_mae: 1.7168\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 0s 758us/step - loss: 7.3386 - mae: 1.7169 - val_loss: 7.5659 - val_mae: 1.7881\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 0s 810us/step - loss: 7.3918 - mae: 1.7311 - val_loss: 7.3155 - val_mae: 1.6325\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 0s 808us/step - loss: 7.3356 - mae: 1.7321 - val_loss: 7.5520 - val_mae: 1.7791\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 0s 821us/step - loss: 7.2593 - mae: 1.7312 - val_loss: 7.4891 - val_mae: 1.6510\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 0s 805us/step - loss: 7.2823 - mae: 1.7143 - val_loss: 7.3738 - val_mae: 1.6535\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 0s 813us/step - loss: 7.1848 - mae: 1.7161 - val_loss: 7.7837 - val_mae: 1.7390\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 0s 796us/step - loss: 7.1932 - mae: 1.7094 - val_loss: 7.6828 - val_mae: 1.8126\n",
      "Epoch 27: early stopping\n",
      "Test Loss (MSE): 7.817258358001709, Test Mean Absolute Error (MAE): 1.92196524143219\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 7.9778 - mae: 1.7206 - val_loss: 9.6384 - val_mae: 1.8986\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 895us/step - loss: 7.0967 - mae: 1.6636 - val_loss: 9.2538 - val_mae: 1.8264\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 924us/step - loss: 6.8876 - mae: 1.6559 - val_loss: 8.9911 - val_mae: 1.9039\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 865us/step - loss: 6.8465 - mae: 1.6632 - val_loss: 9.0214 - val_mae: 1.9108\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 846us/step - loss: 6.6680 - mae: 1.6276 - val_loss: 8.8668 - val_mae: 1.9249\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 850us/step - loss: 6.7109 - mae: 1.6240 - val_loss: 9.3853 - val_mae: 1.8386\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 847us/step - loss: 6.6266 - mae: 1.6518 - val_loss: 8.8831 - val_mae: 1.9085\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 867us/step - loss: 6.7047 - mae: 1.6417 - val_loss: 8.9505 - val_mae: 1.8888\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 0s 860us/step - loss: 6.5810 - mae: 1.6315 - val_loss: 8.9572 - val_mae: 1.9776\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 0s 852us/step - loss: 6.5531 - mae: 1.6291 - val_loss: 8.8692 - val_mae: 1.8785\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 0s 866us/step - loss: 6.5570 - mae: 1.6341 - val_loss: 8.9578 - val_mae: 1.8874\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 0s 858us/step - loss: 6.5012 - mae: 1.6214 - val_loss: 8.9452 - val_mae: 1.9316\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 0s 834us/step - loss: 6.5435 - mae: 1.6299 - val_loss: 9.0553 - val_mae: 1.8588\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 0s 866us/step - loss: 6.5368 - mae: 1.6306 - val_loss: 9.0790 - val_mae: 2.0061\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 0s 847us/step - loss: 6.5469 - mae: 1.6384 - val_loss: 9.2257 - val_mae: 1.8459\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 0s 865us/step - loss: 6.5133 - mae: 1.6293 - val_loss: 8.8953 - val_mae: 1.9398\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 0s 853us/step - loss: 6.4196 - mae: 1.6290 - val_loss: 8.9926 - val_mae: 1.9478\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 0s 862us/step - loss: 6.5560 - mae: 1.6279 - val_loss: 9.1910 - val_mae: 1.8996\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 0s 859us/step - loss: 6.5081 - mae: 1.6329 - val_loss: 9.0641 - val_mae: 1.8548\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 0s 858us/step - loss: 6.4802 - mae: 1.6316 - val_loss: 9.6293 - val_mae: 1.8030\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 0s 864us/step - loss: 6.4260 - mae: 1.6258 - val_loss: 9.0457 - val_mae: 1.8631\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 0s 857us/step - loss: 6.3720 - mae: 1.6199 - val_loss: 9.1328 - val_mae: 1.8596\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 0s 834us/step - loss: 6.4049 - mae: 1.6277 - val_loss: 9.0560 - val_mae: 1.8877\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 0s 878us/step - loss: 6.4246 - mae: 1.6240 - val_loss: 9.2256 - val_mae: 1.8881\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 0s 862us/step - loss: 6.3815 - mae: 1.6099 - val_loss: 9.1395 - val_mae: 1.9367\n",
      "Epoch 25: early stopping\n",
      "Test Loss (MSE): 8.557011604309082, Test Mean Absolute Error (MAE): 1.8599231243133545\n",
      "Epoch 1/100\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 9.3952 - mae: 1.8196 - val_loss: 8.5014 - val_mae: 1.7287\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 0s 867us/step - loss: 8.1522 - mae: 1.7636 - val_loss: 8.2089 - val_mae: 1.9219\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 0s 907us/step - loss: 7.8700 - mae: 1.7547 - val_loss: 7.9672 - val_mae: 1.7603\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 0s 857us/step - loss: 8.0421 - mae: 1.7702 - val_loss: 7.8638 - val_mae: 1.7548\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 0s 840us/step - loss: 7.6767 - mae: 1.7463 - val_loss: 7.8423 - val_mae: 1.7479\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 0s 847us/step - loss: 7.4754 - mae: 1.7383 - val_loss: 7.7743 - val_mae: 1.7487\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 0s 837us/step - loss: 7.4450 - mae: 1.7345 - val_loss: 7.7757 - val_mae: 1.7308\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 0s 755us/step - loss: 7.5991 - mae: 1.7426 - val_loss: 8.0996 - val_mae: 1.6685\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 0s 807us/step - loss: 7.4095 - mae: 1.7453 - val_loss: 7.8784 - val_mae: 1.7552\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 0s 749us/step - loss: 7.4095 - mae: 1.7389 - val_loss: 7.8757 - val_mae: 1.7277\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 0s 744us/step - loss: 7.4538 - mae: 1.7453 - val_loss: 7.8397 - val_mae: 1.7015\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 0s 791us/step - loss: 7.3541 - mae: 1.7292 - val_loss: 7.8786 - val_mae: 1.7002\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 0s 814us/step - loss: 7.3869 - mae: 1.7516 - val_loss: 7.8992 - val_mae: 1.7605\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 0s 884us/step - loss: 7.4857 - mae: 1.7746 - val_loss: 8.0401 - val_mae: 1.6913\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 0s 873us/step - loss: 7.3436 - mae: 1.7327 - val_loss: 7.8882 - val_mae: 1.7114\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 0s 891us/step - loss: 7.2798 - mae: 1.7305 - val_loss: 7.8626 - val_mae: 1.7393\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 0s 948us/step - loss: 7.2856 - mae: 1.7313 - val_loss: 7.9062 - val_mae: 1.7221\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 0s 874us/step - loss: 7.2438 - mae: 1.7524 - val_loss: 8.2104 - val_mae: 1.6679\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 0s 836us/step - loss: 7.2669 - mae: 1.7145 - val_loss: 8.0754 - val_mae: 1.6967\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 0s 799us/step - loss: 7.2491 - mae: 1.7209 - val_loss: 7.9595 - val_mae: 1.6996\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 0s 795us/step - loss: 7.2129 - mae: 1.7239 - val_loss: 7.9855 - val_mae: 1.7446\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 0s 790us/step - loss: 7.1092 - mae: 1.7039 - val_loss: 7.8580 - val_mae: 1.7766\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 0s 798us/step - loss: 7.1296 - mae: 1.7155 - val_loss: 8.1787 - val_mae: 1.7444\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 0s 784us/step - loss: 7.1745 - mae: 1.7095 - val_loss: 8.0834 - val_mae: 1.8135\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 0s 872us/step - loss: 7.1943 - mae: 1.7189 - val_loss: 8.0619 - val_mae: 1.7375\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 0s 847us/step - loss: 7.1073 - mae: 1.7095 - val_loss: 8.2066 - val_mae: 1.7285\n",
      "Epoch 26: early stopping\n",
      "Test Loss (MSE): 7.808119297027588, Test Mean Absolute Error (MAE): 1.675553321838379\n",
      "Epoch 1/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 5.5944 - mae: 1.2573 - val_loss: 3.6105 - val_mae: 0.9267\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 760us/step - loss: 5.2349 - mae: 1.2509 - val_loss: 3.6282 - val_mae: 0.9583\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 743us/step - loss: 5.0909 - mae: 1.2268 - val_loss: 3.6040 - val_mae: 1.0617\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 794us/step - loss: 5.0532 - mae: 1.2245 - val_loss: 3.5148 - val_mae: 1.1301\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 752us/step - loss: 4.9782 - mae: 1.2239 - val_loss: 3.4979 - val_mae: 1.1484\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 791us/step - loss: 5.0217 - mae: 1.2137 - val_loss: 3.4306 - val_mae: 0.9989\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 767us/step - loss: 4.9407 - mae: 1.2023 - val_loss: 3.3758 - val_mae: 0.9424\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 721us/step - loss: 4.9584 - mae: 1.2098 - val_loss: 3.4137 - val_mae: 0.8954\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 707us/step - loss: 4.9323 - mae: 1.1957 - val_loss: 3.3688 - val_mae: 0.9917\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 737us/step - loss: 4.9659 - mae: 1.2097 - val_loss: 3.3729 - val_mae: 0.9574\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 680us/step - loss: 4.9336 - mae: 1.1971 - val_loss: 3.3567 - val_mae: 0.9894\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 684us/step - loss: 4.9128 - mae: 1.1954 - val_loss: 3.3581 - val_mae: 1.0165\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 645us/step - loss: 4.8998 - mae: 1.2031 - val_loss: 3.3745 - val_mae: 0.9519\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 702us/step - loss: 4.9005 - mae: 1.1901 - val_loss: 3.3603 - val_mae: 0.9815\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 714us/step - loss: 4.9631 - mae: 1.2059 - val_loss: 3.3659 - val_mae: 0.9576\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 691us/step - loss: 4.8829 - mae: 1.2030 - val_loss: 3.3625 - val_mae: 0.9574\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 716us/step - loss: 4.8962 - mae: 1.1901 - val_loss: 3.3982 - val_mae: 1.0038\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 749us/step - loss: 4.8663 - mae: 1.1918 - val_loss: 3.3531 - val_mae: 0.9829\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 681us/step - loss: 4.9092 - mae: 1.1939 - val_loss: 3.3758 - val_mae: 1.0032\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 771us/step - loss: 4.8461 - mae: 1.1933 - val_loss: 3.4042 - val_mae: 1.0623\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 711us/step - loss: 4.8800 - mae: 1.1976 - val_loss: 3.4270 - val_mae: 1.0290\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 724us/step - loss: 4.8703 - mae: 1.1878 - val_loss: 3.3515 - val_mae: 0.9708\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 698us/step - loss: 4.8696 - mae: 1.1930 - val_loss: 3.3674 - val_mae: 0.9543\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 677us/step - loss: 4.8689 - mae: 1.1904 - val_loss: 3.3805 - val_mae: 1.0011\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 662us/step - loss: 4.8494 - mae: 1.1830 - val_loss: 3.4838 - val_mae: 1.0820\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 699us/step - loss: 4.9074 - mae: 1.2119 - val_loss: 3.4064 - val_mae: 1.0691\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 730us/step - loss: 4.8437 - mae: 1.1917 - val_loss: 3.4245 - val_mae: 1.0530\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 704us/step - loss: 4.8493 - mae: 1.1923 - val_loss: 3.4481 - val_mae: 1.0452\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 683us/step - loss: 4.8851 - mae: 1.1918 - val_loss: 3.4116 - val_mae: 1.0269\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 697us/step - loss: 4.8670 - mae: 1.1945 - val_loss: 3.4361 - val_mae: 1.0231\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 707us/step - loss: 4.8546 - mae: 1.1953 - val_loss: 3.3833 - val_mae: 0.9295\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 688us/step - loss: 4.8568 - mae: 1.1910 - val_loss: 3.4276 - val_mae: 1.0497\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 694us/step - loss: 4.8606 - mae: 1.1941 - val_loss: 3.4178 - val_mae: 1.0183\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 691us/step - loss: 4.8509 - mae: 1.1818 - val_loss: 3.4193 - val_mae: 1.0178\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 699us/step - loss: 4.8471 - mae: 1.1949 - val_loss: 3.3707 - val_mae: 0.9790\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 683us/step - loss: 4.8568 - mae: 1.1790 - val_loss: 3.3834 - val_mae: 1.0193\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 682us/step - loss: 4.8568 - mae: 1.2047 - val_loss: 3.4449 - val_mae: 1.0348\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 682us/step - loss: 4.8545 - mae: 1.1908 - val_loss: 3.4664 - val_mae: 1.0482\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 703us/step - loss: 4.8440 - mae: 1.1841 - val_loss: 3.4748 - val_mae: 1.1655\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 698us/step - loss: 4.8279 - mae: 1.2114 - val_loss: 3.3686 - val_mae: 0.9632\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 691us/step - loss: 4.8574 - mae: 1.1850 - val_loss: 3.4123 - val_mae: 1.0343\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 699us/step - loss: 4.8404 - mae: 1.1868 - val_loss: 3.4280 - val_mae: 1.0062\n",
      "Epoch 42: early stopping\n",
      "Test Loss (MSE): 4.836062431335449, Test Mean Absolute Error (MAE): 1.1838167905807495\n",
      "Epoch 1/100\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 5.3402 - mae: 1.1956 - val_loss: 4.7866 - val_mae: 1.1500\n",
      "Epoch 2/100\n",
      "154/154 [==============================] - 0s 769us/step - loss: 4.6999 - mae: 1.1661 - val_loss: 4.6177 - val_mae: 1.1681\n",
      "Epoch 3/100\n",
      "154/154 [==============================] - 0s 864us/step - loss: 4.5089 - mae: 1.1597 - val_loss: 4.5760 - val_mae: 1.1250\n",
      "Epoch 4/100\n",
      "154/154 [==============================] - 0s 783us/step - loss: 4.5511 - mae: 1.1549 - val_loss: 4.5503 - val_mae: 1.1360\n",
      "Epoch 5/100\n",
      "154/154 [==============================] - 0s 861us/step - loss: 4.5258 - mae: 1.1632 - val_loss: 4.9891 - val_mae: 0.9942\n",
      "Epoch 6/100\n",
      "154/154 [==============================] - 0s 842us/step - loss: 4.4652 - mae: 1.1315 - val_loss: 4.4596 - val_mae: 1.0983\n",
      "Epoch 7/100\n",
      "154/154 [==============================] - 0s 831us/step - loss: 4.4292 - mae: 1.1321 - val_loss: 4.5534 - val_mae: 1.1963\n",
      "Epoch 8/100\n",
      "154/154 [==============================] - 0s 818us/step - loss: 4.4231 - mae: 1.1238 - val_loss: 4.5290 - val_mae: 1.0615\n",
      "Epoch 9/100\n",
      "154/154 [==============================] - 0s 808us/step - loss: 4.4157 - mae: 1.1280 - val_loss: 4.5334 - val_mae: 1.0982\n",
      "Epoch 10/100\n",
      "154/154 [==============================] - 0s 745us/step - loss: 4.4104 - mae: 1.1284 - val_loss: 4.6195 - val_mae: 1.0239\n",
      "Epoch 11/100\n",
      "154/154 [==============================] - 0s 751us/step - loss: 4.3912 - mae: 1.1105 - val_loss: 4.5298 - val_mae: 1.1845\n",
      "Epoch 12/100\n",
      "154/154 [==============================] - 0s 777us/step - loss: 4.4388 - mae: 1.1176 - val_loss: 4.7199 - val_mae: 1.0963\n",
      "Epoch 13/100\n",
      "154/154 [==============================] - 0s 744us/step - loss: 4.4297 - mae: 1.1212 - val_loss: 4.4863 - val_mae: 1.1029\n",
      "Epoch 14/100\n",
      "154/154 [==============================] - 0s 760us/step - loss: 4.3971 - mae: 1.1190 - val_loss: 4.5247 - val_mae: 1.1138\n",
      "Epoch 15/100\n",
      "154/154 [==============================] - 0s 827us/step - loss: 4.3637 - mae: 1.1128 - val_loss: 4.6365 - val_mae: 1.1116\n",
      "Epoch 16/100\n",
      "154/154 [==============================] - 0s 797us/step - loss: 4.4164 - mae: 1.1154 - val_loss: 4.6331 - val_mae: 1.0375\n",
      "Epoch 17/100\n",
      "154/154 [==============================] - 0s 792us/step - loss: 4.3626 - mae: 1.1110 - val_loss: 4.5683 - val_mae: 1.1852\n",
      "Epoch 18/100\n",
      "154/154 [==============================] - 0s 771us/step - loss: 4.3529 - mae: 1.1195 - val_loss: 4.7019 - val_mae: 1.0249\n",
      "Epoch 19/100\n",
      "154/154 [==============================] - 0s 856us/step - loss: 4.3576 - mae: 1.1041 - val_loss: 4.5008 - val_mae: 1.0617\n",
      "Epoch 20/100\n",
      "154/154 [==============================] - 0s 827us/step - loss: 4.3713 - mae: 1.1174 - val_loss: 4.5428 - val_mae: 1.1834\n",
      "Epoch 21/100\n",
      "154/154 [==============================] - 0s 826us/step - loss: 4.3869 - mae: 1.1194 - val_loss: 4.5344 - val_mae: 1.0754\n",
      "Epoch 22/100\n",
      "154/154 [==============================] - 0s 740us/step - loss: 4.3255 - mae: 1.1117 - val_loss: 4.5087 - val_mae: 1.0543\n",
      "Epoch 23/100\n",
      "154/154 [==============================] - 0s 769us/step - loss: 4.3424 - mae: 1.1087 - val_loss: 4.4853 - val_mae: 1.0920\n",
      "Epoch 24/100\n",
      "154/154 [==============================] - 0s 745us/step - loss: 4.3380 - mae: 1.1092 - val_loss: 4.5131 - val_mae: 1.0925\n",
      "Epoch 25/100\n",
      "154/154 [==============================] - 0s 754us/step - loss: 4.3400 - mae: 1.1194 - val_loss: 4.6428 - val_mae: 1.1288\n",
      "Epoch 26/100\n",
      "154/154 [==============================] - 0s 763us/step - loss: 4.3219 - mae: 1.1061 - val_loss: 4.7478 - val_mae: 1.0276\n",
      "Epoch 26: early stopping\n",
      "Test Loss (MSE): 5.088318347930908, Test Mean Absolute Error (MAE): 1.0782136917114258\n",
      "Epoch 1/100\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 5.4497 - mae: 1.2135 - val_loss: 5.1286 - val_mae: 1.0191\n",
      "Epoch 2/100\n",
      "151/151 [==============================] - 0s 941us/step - loss: 4.8700 - mae: 1.1753 - val_loss: 4.7823 - val_mae: 1.2737\n",
      "Epoch 3/100\n",
      "151/151 [==============================] - 0s 890us/step - loss: 4.6741 - mae: 1.1587 - val_loss: 4.6516 - val_mae: 1.0638\n",
      "Epoch 4/100\n",
      "151/151 [==============================] - 0s 830us/step - loss: 4.6441 - mae: 1.1543 - val_loss: 4.5456 - val_mae: 1.1272\n",
      "Epoch 5/100\n",
      "151/151 [==============================] - 0s 806us/step - loss: 4.6206 - mae: 1.1660 - val_loss: 4.4709 - val_mae: 1.0627\n",
      "Epoch 6/100\n",
      "151/151 [==============================] - 0s 745us/step - loss: 4.5448 - mae: 1.1462 - val_loss: 4.4793 - val_mae: 1.1716\n",
      "Epoch 7/100\n",
      "151/151 [==============================] - 0s 766us/step - loss: 4.5609 - mae: 1.1623 - val_loss: 4.4652 - val_mae: 1.0369\n",
      "Epoch 8/100\n",
      "151/151 [==============================] - 0s 753us/step - loss: 4.5109 - mae: 1.1381 - val_loss: 4.4929 - val_mae: 1.1212\n",
      "Epoch 9/100\n",
      "151/151 [==============================] - 0s 802us/step - loss: 4.4779 - mae: 1.1385 - val_loss: 4.5723 - val_mae: 1.3152\n",
      "Epoch 10/100\n",
      "151/151 [==============================] - 0s 807us/step - loss: 4.6336 - mae: 1.1874 - val_loss: 4.4951 - val_mae: 1.0764\n",
      "Epoch 11/100\n",
      "151/151 [==============================] - 0s 773us/step - loss: 4.4722 - mae: 1.1437 - val_loss: 4.4972 - val_mae: 1.0639\n",
      "Epoch 12/100\n",
      "151/151 [==============================] - 0s 761us/step - loss: 4.4932 - mae: 1.1337 - val_loss: 4.5900 - val_mae: 1.0899\n",
      "Epoch 13/100\n",
      "151/151 [==============================] - 0s 799us/step - loss: 4.5456 - mae: 1.1630 - val_loss: 4.5029 - val_mae: 1.1347\n",
      "Epoch 14/100\n",
      "151/151 [==============================] - 0s 852us/step - loss: 4.4679 - mae: 1.1408 - val_loss: 4.5293 - val_mae: 1.1496\n",
      "Epoch 15/100\n",
      "151/151 [==============================] - 0s 760us/step - loss: 4.4239 - mae: 1.1272 - val_loss: 4.5070 - val_mae: 1.1444\n",
      "Epoch 16/100\n",
      "151/151 [==============================] - 0s 761us/step - loss: 4.4149 - mae: 1.1372 - val_loss: 4.5911 - val_mae: 1.0332\n",
      "Epoch 17/100\n",
      "151/151 [==============================] - 0s 764us/step - loss: 4.3916 - mae: 1.1287 - val_loss: 4.6021 - val_mae: 1.1119\n",
      "Epoch 18/100\n",
      "151/151 [==============================] - 0s 763us/step - loss: 4.4030 - mae: 1.1197 - val_loss: 4.5801 - val_mae: 1.1658\n",
      "Epoch 19/100\n",
      "151/151 [==============================] - 0s 750us/step - loss: 4.4317 - mae: 1.1320 - val_loss: 4.5990 - val_mae: 1.0846\n",
      "Epoch 20/100\n",
      "151/151 [==============================] - 0s 812us/step - loss: 4.3872 - mae: 1.1225 - val_loss: 4.5950 - val_mae: 1.1235\n",
      "Epoch 21/100\n",
      "151/151 [==============================] - 0s 766us/step - loss: 4.3908 - mae: 1.1274 - val_loss: 4.5782 - val_mae: 1.1010\n",
      "Epoch 22/100\n",
      "151/151 [==============================] - 0s 756us/step - loss: 4.3893 - mae: 1.1256 - val_loss: 4.5869 - val_mae: 1.0851\n",
      "Epoch 23/100\n",
      "151/151 [==============================] - 0s 766us/step - loss: 4.3672 - mae: 1.1345 - val_loss: 4.5418 - val_mae: 1.0932\n",
      "Epoch 24/100\n",
      "151/151 [==============================] - 0s 759us/step - loss: 4.3549 - mae: 1.1232 - val_loss: 4.5943 - val_mae: 1.1433\n",
      "Epoch 25/100\n",
      "151/151 [==============================] - 0s 762us/step - loss: 4.3616 - mae: 1.1249 - val_loss: 4.5519 - val_mae: 1.1419\n",
      "Epoch 26/100\n",
      "151/151 [==============================] - 0s 796us/step - loss: 4.3643 - mae: 1.1267 - val_loss: 4.6296 - val_mae: 1.1207\n",
      "Epoch 27/100\n",
      "151/151 [==============================] - 0s 767us/step - loss: 4.3412 - mae: 1.1294 - val_loss: 4.5832 - val_mae: 1.1087\n",
      "Epoch 27: early stopping\n",
      "Test Loss (MSE): 4.531702041625977, Test Mean Absolute Error (MAE): 1.0934079885482788\n",
      "Epoch 1/100\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 5.9798 - mae: 1.2516 - val_loss: 4.4955 - val_mae: 1.1702\n",
      "Epoch 2/100\n",
      "151/151 [==============================] - 0s 925us/step - loss: 5.2399 - mae: 1.2121 - val_loss: 4.5167 - val_mae: 1.2705\n",
      "Epoch 3/100\n",
      "151/151 [==============================] - 0s 814us/step - loss: 5.0745 - mae: 1.1909 - val_loss: 4.1719 - val_mae: 1.1272\n",
      "Epoch 4/100\n",
      "151/151 [==============================] - 0s 797us/step - loss: 5.0169 - mae: 1.1767 - val_loss: 4.5163 - val_mae: 1.3378\n",
      "Epoch 5/100\n",
      "151/151 [==============================] - 0s 889us/step - loss: 4.8702 - mae: 1.1697 - val_loss: 4.5024 - val_mae: 0.9883\n",
      "Epoch 6/100\n",
      "151/151 [==============================] - 0s 941us/step - loss: 4.9088 - mae: 1.2155 - val_loss: 4.1576 - val_mae: 1.1243\n",
      "Epoch 7/100\n",
      "151/151 [==============================] - 0s 792us/step - loss: 4.8859 - mae: 1.1768 - val_loss: 4.1729 - val_mae: 1.0870\n",
      "Epoch 8/100\n",
      "151/151 [==============================] - 0s 774us/step - loss: 4.8117 - mae: 1.1563 - val_loss: 4.1581 - val_mae: 1.1131\n",
      "Epoch 9/100\n",
      "151/151 [==============================] - 0s 807us/step - loss: 4.7357 - mae: 1.1576 - val_loss: 4.2661 - val_mae: 1.1803\n",
      "Epoch 10/100\n",
      "151/151 [==============================] - 0s 765us/step - loss: 4.7640 - mae: 1.1599 - val_loss: 4.1647 - val_mae: 1.1182\n",
      "Epoch 11/100\n",
      "151/151 [==============================] - 0s 819us/step - loss: 4.6984 - mae: 1.1590 - val_loss: 4.3040 - val_mae: 1.1840\n",
      "Epoch 12/100\n",
      "151/151 [==============================] - 0s 778us/step - loss: 4.7097 - mae: 1.1522 - val_loss: 4.3541 - val_mae: 1.1491\n",
      "Epoch 13/100\n",
      "151/151 [==============================] - 0s 872us/step - loss: 4.7031 - mae: 1.1600 - val_loss: 4.3482 - val_mae: 1.1519\n",
      "Epoch 14/100\n",
      "151/151 [==============================] - 0s 813us/step - loss: 4.6843 - mae: 1.1460 - val_loss: 4.3381 - val_mae: 1.1279\n",
      "Epoch 15/100\n",
      "151/151 [==============================] - 0s 841us/step - loss: 4.7372 - mae: 1.1565 - val_loss: 4.4075 - val_mae: 1.1660\n",
      "Epoch 16/100\n",
      "151/151 [==============================] - 0s 893us/step - loss: 4.6958 - mae: 1.1434 - val_loss: 4.3334 - val_mae: 1.1113\n",
      "Epoch 17/100\n",
      "151/151 [==============================] - 0s 978us/step - loss: 4.6752 - mae: 1.1335 - val_loss: 4.3821 - val_mae: 1.1381\n",
      "Epoch 18/100\n",
      "151/151 [==============================] - 0s 842us/step - loss: 4.6531 - mae: 1.1383 - val_loss: 4.3733 - val_mae: 1.1167\n",
      "Epoch 19/100\n",
      "151/151 [==============================] - 0s 769us/step - loss: 4.6396 - mae: 1.1387 - val_loss: 4.3946 - val_mae: 1.1398\n",
      "Epoch 20/100\n",
      "151/151 [==============================] - 0s 809us/step - loss: 4.6806 - mae: 1.1539 - val_loss: 4.4517 - val_mae: 1.0776\n",
      "Epoch 21/100\n",
      "151/151 [==============================] - 0s 767us/step - loss: 4.5540 - mae: 1.1194 - val_loss: 4.4696 - val_mae: 1.1271\n",
      "Epoch 22/100\n",
      "151/151 [==============================] - 0s 773us/step - loss: 4.5687 - mae: 1.1355 - val_loss: 4.4656 - val_mae: 1.1544\n",
      "Epoch 23/100\n",
      "151/151 [==============================] - 0s 754us/step - loss: 4.5624 - mae: 1.1238 - val_loss: 4.6327 - val_mae: 1.2120\n",
      "Epoch 24/100\n",
      "151/151 [==============================] - 0s 758us/step - loss: 4.5192 - mae: 1.1213 - val_loss: 4.7212 - val_mae: 1.2017\n",
      "Epoch 25/100\n",
      "151/151 [==============================] - 0s 786us/step - loss: 4.5653 - mae: 1.1357 - val_loss: 4.5876 - val_mae: 1.1807\n",
      "Epoch 26/100\n",
      "151/151 [==============================] - 0s 763us/step - loss: 4.4672 - mae: 1.1067 - val_loss: 4.5735 - val_mae: 1.2026\n",
      "Epoch 26: early stopping\n",
      "Test Loss (MSE): 4.8233232498168945, Test Mean Absolute Error (MAE): 1.1803818941116333\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 8.8487 - mae: 1.8367 - val_loss: 8.3477 - val_mae: 1.7539\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 790us/step - loss: 8.0270 - mae: 1.7600 - val_loss: 8.2611 - val_mae: 1.9336\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 758us/step - loss: 7.9408 - mae: 1.7542 - val_loss: 8.1070 - val_mae: 1.7497\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 788us/step - loss: 7.8816 - mae: 1.7623 - val_loss: 8.1215 - val_mae: 1.7685\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 771us/step - loss: 7.7384 - mae: 1.7548 - val_loss: 8.1875 - val_mae: 1.7225\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 773us/step - loss: 7.6586 - mae: 1.7416 - val_loss: 7.9557 - val_mae: 1.7802\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 739us/step - loss: 7.7300 - mae: 1.7369 - val_loss: 8.2965 - val_mae: 2.1401\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 741us/step - loss: 7.6410 - mae: 1.7617 - val_loss: 8.1843 - val_mae: 1.7591\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 0s 753us/step - loss: 7.6830 - mae: 1.7312 - val_loss: 7.8795 - val_mae: 1.8358\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 0s 731us/step - loss: 7.6596 - mae: 1.7628 - val_loss: 7.9019 - val_mae: 1.8587\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 0s 792us/step - loss: 7.7099 - mae: 1.7661 - val_loss: 8.0485 - val_mae: 1.7510\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 0s 831us/step - loss: 7.5880 - mae: 1.7393 - val_loss: 7.8793 - val_mae: 1.9344\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 0s 740us/step - loss: 7.6527 - mae: 1.7460 - val_loss: 7.8431 - val_mae: 1.8522\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 0s 760us/step - loss: 7.5498 - mae: 1.7353 - val_loss: 7.9560 - val_mae: 2.0022\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 0s 757us/step - loss: 7.6108 - mae: 1.7475 - val_loss: 7.9056 - val_mae: 1.9064\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 0s 736us/step - loss: 7.5822 - mae: 1.7477 - val_loss: 7.9872 - val_mae: 1.7740\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 0s 747us/step - loss: 7.5858 - mae: 1.7489 - val_loss: 7.9898 - val_mae: 1.7816\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 0s 771us/step - loss: 7.6065 - mae: 1.7562 - val_loss: 7.9757 - val_mae: 1.7772\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 0s 761us/step - loss: 7.5985 - mae: 1.7423 - val_loss: 7.9643 - val_mae: 1.8224\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 0s 822us/step - loss: 7.5842 - mae: 1.7442 - val_loss: 7.8912 - val_mae: 1.8265\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 0s 775us/step - loss: 7.5937 - mae: 1.7424 - val_loss: 7.9369 - val_mae: 1.8116\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 0s 790us/step - loss: 7.5717 - mae: 1.7437 - val_loss: 8.0185 - val_mae: 1.7534\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 0s 764us/step - loss: 7.6371 - mae: 1.7423 - val_loss: 7.9984 - val_mae: 1.7642\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 0s 760us/step - loss: 7.5784 - mae: 1.7515 - val_loss: 7.9049 - val_mae: 1.9301\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 0s 751us/step - loss: 7.5505 - mae: 1.7416 - val_loss: 8.0188 - val_mae: 1.8241\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 0s 734us/step - loss: 7.5858 - mae: 1.7493 - val_loss: 7.9227 - val_mae: 1.9009\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 0s 755us/step - loss: 7.5456 - mae: 1.7430 - val_loss: 7.8976 - val_mae: 1.8509\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 0s 741us/step - loss: 7.5427 - mae: 1.7321 - val_loss: 7.8549 - val_mae: 1.9163\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 0s 773us/step - loss: 7.5699 - mae: 1.7558 - val_loss: 7.9888 - val_mae: 1.7917\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 0s 738us/step - loss: 7.5431 - mae: 1.7443 - val_loss: 7.9030 - val_mae: 1.8564\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 0s 751us/step - loss: 7.5539 - mae: 1.7314 - val_loss: 7.9443 - val_mae: 1.8658\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 0s 757us/step - loss: 7.5150 - mae: 1.7376 - val_loss: 7.9644 - val_mae: 1.9211\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 0s 739us/step - loss: 7.5345 - mae: 1.7515 - val_loss: 7.9850 - val_mae: 1.7946\n",
      "Epoch 33: early stopping\n",
      "Test Loss (MSE): 5.602823734283447, Test Mean Absolute Error (MAE): 1.5178616046905518\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 7.9831 - mae: 1.7137 - val_loss: 9.4532 - val_mae: 1.7563\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 835us/step - loss: 7.2187 - mae: 1.6686 - val_loss: 8.9809 - val_mae: 1.7307\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 803us/step - loss: 7.0183 - mae: 1.6555 - val_loss: 8.5853 - val_mae: 1.8319\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 884us/step - loss: 6.9006 - mae: 1.6352 - val_loss: 8.7672 - val_mae: 1.9836\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 816us/step - loss: 6.7325 - mae: 1.6364 - val_loss: 8.7051 - val_mae: 1.8718\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 784us/step - loss: 6.7346 - mae: 1.6253 - val_loss: 8.6038 - val_mae: 1.8052\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 832us/step - loss: 6.6541 - mae: 1.6318 - val_loss: 8.5618 - val_mae: 1.8912\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 826us/step - loss: 6.6442 - mae: 1.6302 - val_loss: 8.5059 - val_mae: 1.8173\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 0s 778us/step - loss: 6.6260 - mae: 1.6303 - val_loss: 8.4791 - val_mae: 1.7698\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 0s 797us/step - loss: 6.6042 - mae: 1.6347 - val_loss: 8.7136 - val_mae: 1.7179\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 0s 813us/step - loss: 6.6208 - mae: 1.6280 - val_loss: 8.5777 - val_mae: 1.7588\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 0s 781us/step - loss: 6.5542 - mae: 1.6288 - val_loss: 8.5070 - val_mae: 1.8009\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 0s 803us/step - loss: 6.5062 - mae: 1.6336 - val_loss: 8.5608 - val_mae: 1.8454\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 0s 816us/step - loss: 6.5962 - mae: 1.6321 - val_loss: 8.6235 - val_mae: 1.9525\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 0s 965us/step - loss: 6.4981 - mae: 1.6335 - val_loss: 8.6407 - val_mae: 1.7588\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 0s 849us/step - loss: 6.5200 - mae: 1.6140 - val_loss: 8.5891 - val_mae: 1.7942\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 0s 828us/step - loss: 6.4902 - mae: 1.6231 - val_loss: 8.5597 - val_mae: 1.8085\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 0s 875us/step - loss: 6.3744 - mae: 1.6105 - val_loss: 8.6610 - val_mae: 1.7515\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 0s 875us/step - loss: 6.4590 - mae: 1.6204 - val_loss: 8.5646 - val_mae: 1.8706\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 0s 837us/step - loss: 6.4765 - mae: 1.6122 - val_loss: 8.6132 - val_mae: 1.8201\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 0s 796us/step - loss: 6.4203 - mae: 1.6160 - val_loss: 8.6556 - val_mae: 1.8386\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 0s 820us/step - loss: 6.4321 - mae: 1.6041 - val_loss: 8.6860 - val_mae: 1.8503\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 0s 801us/step - loss: 6.3803 - mae: 1.6067 - val_loss: 8.7080 - val_mae: 1.7966\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 0s 778us/step - loss: 6.3137 - mae: 1.5972 - val_loss: 9.1580 - val_mae: 2.0118\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 0s 797us/step - loss: 6.3726 - mae: 1.6077 - val_loss: 9.1233 - val_mae: 2.0071\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 0s 862us/step - loss: 6.4242 - mae: 1.6132 - val_loss: 8.7992 - val_mae: 1.8734\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 0s 808us/step - loss: 6.3311 - mae: 1.5979 - val_loss: 8.7964 - val_mae: 1.7918\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 0s 802us/step - loss: 6.3633 - mae: 1.5908 - val_loss: 9.0396 - val_mae: 1.9035\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 0s 778us/step - loss: 6.2515 - mae: 1.5803 - val_loss: 9.0836 - val_mae: 1.9242\n",
      "Epoch 29: early stopping\n",
      "Test Loss (MSE): 10.230219841003418, Test Mean Absolute Error (MAE): 2.0298216342926025\n",
      "Epoch 1/100\n",
      "86/86 [==============================] - 0s 1ms/step - loss: 8.8621 - mae: 1.8143 - val_loss: 8.2981 - val_mae: 1.7916\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 0s 855us/step - loss: 7.8943 - mae: 1.7235 - val_loss: 7.9555 - val_mae: 1.8445\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 0s 808us/step - loss: 7.5961 - mae: 1.7203 - val_loss: 8.3700 - val_mae: 1.6424\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 0s 939us/step - loss: 7.4277 - mae: 1.7156 - val_loss: 7.8636 - val_mae: 1.6877\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 0s 840us/step - loss: 7.3426 - mae: 1.7131 - val_loss: 7.9535 - val_mae: 1.6523\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 0s 855us/step - loss: 7.3439 - mae: 1.7052 - val_loss: 8.0876 - val_mae: 1.6738\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 0s 858us/step - loss: 7.4294 - mae: 1.7124 - val_loss: 7.9774 - val_mae: 1.6639\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 0s 903us/step - loss: 7.2857 - mae: 1.6970 - val_loss: 8.1691 - val_mae: 1.6490\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 0s 926us/step - loss: 7.2235 - mae: 1.6995 - val_loss: 7.8844 - val_mae: 1.8209\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 0s 885us/step - loss: 7.1322 - mae: 1.6871 - val_loss: 7.7707 - val_mae: 1.7739\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 0s 900us/step - loss: 7.1284 - mae: 1.6904 - val_loss: 8.0741 - val_mae: 1.9478\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 0s 900us/step - loss: 7.0914 - mae: 1.6894 - val_loss: 7.8587 - val_mae: 1.8701\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 0s 907us/step - loss: 7.0638 - mae: 1.6789 - val_loss: 7.8430 - val_mae: 1.8375\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 0s 889us/step - loss: 7.0981 - mae: 1.6942 - val_loss: 8.0514 - val_mae: 1.7079\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 0s 990us/step - loss: 7.0165 - mae: 1.6804 - val_loss: 7.9576 - val_mae: 1.7764\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 0s 849us/step - loss: 6.9092 - mae: 1.6733 - val_loss: 8.0791 - val_mae: 1.8307\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 0s 823us/step - loss: 6.9552 - mae: 1.6822 - val_loss: 8.0735 - val_mae: 1.6999\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 0s 801us/step - loss: 6.9536 - mae: 1.6700 - val_loss: 8.1263 - val_mae: 1.7383\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 0s 794us/step - loss: 6.8264 - mae: 1.6601 - val_loss: 8.2377 - val_mae: 1.8403\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 0s 834us/step - loss: 6.9371 - mae: 1.6729 - val_loss: 8.3208 - val_mae: 1.7595\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 0s 795us/step - loss: 6.8801 - mae: 1.6613 - val_loss: 8.2361 - val_mae: 1.8045\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 0s 774us/step - loss: 6.9729 - mae: 1.6793 - val_loss: 8.3691 - val_mae: 1.8434\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 0s 779us/step - loss: 6.8090 - mae: 1.6523 - val_loss: 8.3853 - val_mae: 1.8402\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 0s 883us/step - loss: 6.7787 - mae: 1.6461 - val_loss: 8.4275 - val_mae: 1.7599\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 0s 808us/step - loss: 6.7425 - mae: 1.6400 - val_loss: 8.3796 - val_mae: 1.7290\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 0s 811us/step - loss: 6.7121 - mae: 1.6317 - val_loss: 8.4289 - val_mae: 1.7592\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 0s 819us/step - loss: 6.7041 - mae: 1.6387 - val_loss: 8.5686 - val_mae: 1.7278\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 0s 872us/step - loss: 6.6082 - mae: 1.6082 - val_loss: 8.9002 - val_mae: 1.7538\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 0s 834us/step - loss: 6.5360 - mae: 1.5968 - val_loss: 8.3763 - val_mae: 1.7239\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 0s 893us/step - loss: 6.4032 - mae: 1.5821 - val_loss: 8.4161 - val_mae: 1.7855\n",
      "Epoch 30: early stopping\n",
      "Test Loss (MSE): 8.189698219299316, Test Mean Absolute Error (MAE): 1.7373900413513184\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 9.1174 - mae: 1.8270 - val_loss: 8.8349 - val_mae: 1.7159\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 0s 830us/step - loss: 7.7136 - mae: 1.7169 - val_loss: 8.4644 - val_mae: 1.6610\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 0s 822us/step - loss: 7.4718 - mae: 1.6885 - val_loss: 8.3078 - val_mae: 1.7756\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 0s 1ms/step - loss: 7.2398 - mae: 1.6827 - val_loss: 8.4019 - val_mae: 1.9532\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 0s 898us/step - loss: 7.2236 - mae: 1.6928 - val_loss: 7.9737 - val_mae: 1.7676\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 0s 842us/step - loss: 7.1185 - mae: 1.6846 - val_loss: 8.1763 - val_mae: 1.7143\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 0s 870us/step - loss: 7.1414 - mae: 1.6672 - val_loss: 8.5259 - val_mae: 1.9414\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 0s 889us/step - loss: 7.2059 - mae: 1.7063 - val_loss: 8.1423 - val_mae: 1.7238\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 0s 891us/step - loss: 6.8786 - mae: 1.6619 - val_loss: 8.5165 - val_mae: 1.8894\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 0s 916us/step - loss: 6.9243 - mae: 1.6626 - val_loss: 8.2976 - val_mae: 1.7455\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 0s 889us/step - loss: 6.8864 - mae: 1.6474 - val_loss: 8.1876 - val_mae: 1.7975\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 0s 914us/step - loss: 6.7880 - mae: 1.6391 - val_loss: 8.7058 - val_mae: 2.0183\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 0s 903us/step - loss: 6.7962 - mae: 1.6519 - val_loss: 8.5129 - val_mae: 1.7964\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 0s 893us/step - loss: 6.7662 - mae: 1.6338 - val_loss: 8.7547 - val_mae: 1.9676\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 0s 913us/step - loss: 6.6998 - mae: 1.6306 - val_loss: 9.1924 - val_mae: 1.9786\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 0s 849us/step - loss: 6.6747 - mae: 1.5957 - val_loss: 9.1942 - val_mae: 2.0098\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 0s 846us/step - loss: 6.6367 - mae: 1.6139 - val_loss: 9.8751 - val_mae: 1.9887\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 0s 823us/step - loss: 6.5483 - mae: 1.5934 - val_loss: 9.0945 - val_mae: 1.8962\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 0s 786us/step - loss: 6.3477 - mae: 1.5771 - val_loss: 9.0432 - val_mae: 1.9151\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 0s 896us/step - loss: 6.2243 - mae: 1.5530 - val_loss: 9.3463 - val_mae: 1.9386\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 0s 838us/step - loss: 6.2312 - mae: 1.5620 - val_loss: 9.8378 - val_mae: 1.9187\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 0s 842us/step - loss: 6.1698 - mae: 1.5412 - val_loss: 10.7508 - val_mae: 2.0643\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 0s 783us/step - loss: 5.8464 - mae: 1.5042 - val_loss: 9.8605 - val_mae: 1.9989\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 0s 842us/step - loss: 5.8909 - mae: 1.4979 - val_loss: 9.5326 - val_mae: 1.8992\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 0s 847us/step - loss: 5.9811 - mae: 1.5006 - val_loss: 9.2159 - val_mae: 1.8381\n",
      "Epoch 25: early stopping\n",
      "Test Loss (MSE): 9.472947120666504, Test Mean Absolute Error (MAE): 1.804106593132019\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 5.6455 - mae: 1.2407 - val_loss: 4.2234 - val_mae: 1.0944\n",
      "Epoch 2/100\n",
      "134/134 [==============================] - 0s 856us/step - loss: 5.0716 - mae: 1.2258 - val_loss: 4.0562 - val_mae: 1.0769\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 0s 908us/step - loss: 4.9800 - mae: 1.2362 - val_loss: 4.1982 - val_mae: 1.0301\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 0s 855us/step - loss: 4.9254 - mae: 1.2184 - val_loss: 3.9870 - val_mae: 1.0605\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 0s 876us/step - loss: 4.8928 - mae: 1.2184 - val_loss: 4.0749 - val_mae: 1.1726\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 0s 875us/step - loss: 4.8408 - mae: 1.2159 - val_loss: 4.2220 - val_mae: 1.0198\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 0s 932us/step - loss: 4.7899 - mae: 1.2043 - val_loss: 3.9205 - val_mae: 1.1146\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 0s 997us/step - loss: 4.8195 - mae: 1.2012 - val_loss: 3.9053 - val_mae: 1.0619\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 0s 860us/step - loss: 4.7947 - mae: 1.2046 - val_loss: 3.9366 - val_mae: 1.1515\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 0s 849us/step - loss: 4.7772 - mae: 1.1954 - val_loss: 3.8988 - val_mae: 1.1124\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 0s 853us/step - loss: 4.7197 - mae: 1.1845 - val_loss: 3.8923 - val_mae: 1.0874\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 0s 966us/step - loss: 4.7293 - mae: 1.1835 - val_loss: 3.9097 - val_mae: 1.1298\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 0s 877us/step - loss: 4.7363 - mae: 1.1871 - val_loss: 4.0053 - val_mae: 1.1815\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 0s 916us/step - loss: 4.7507 - mae: 1.1858 - val_loss: 3.9298 - val_mae: 1.1610\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 0s 987us/step - loss: 4.7309 - mae: 1.1843 - val_loss: 3.9139 - val_mae: 1.1216\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 4.7728 - mae: 1.1890 - val_loss: 3.9677 - val_mae: 1.0352\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 0s 955us/step - loss: 4.7385 - mae: 1.1906 - val_loss: 3.8767 - val_mae: 1.0695\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 0s 961us/step - loss: 4.7256 - mae: 1.1890 - val_loss: 3.8933 - val_mae: 1.0440\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 0s 926us/step - loss: 4.7345 - mae: 1.1779 - val_loss: 3.8906 - val_mae: 1.1163\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 0s 939us/step - loss: 4.7245 - mae: 1.1792 - val_loss: 3.9240 - val_mae: 1.0144\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 0s 844us/step - loss: 4.7168 - mae: 1.1823 - val_loss: 3.9073 - val_mae: 1.1220\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 0s 853us/step - loss: 4.6903 - mae: 1.1858 - val_loss: 3.9202 - val_mae: 1.0295\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 0s 843us/step - loss: 4.7325 - mae: 1.1715 - val_loss: 3.8844 - val_mae: 1.0935\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 0s 887us/step - loss: 4.7234 - mae: 1.1794 - val_loss: 3.8922 - val_mae: 1.0235\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 0s 879us/step - loss: 4.7374 - mae: 1.1896 - val_loss: 3.8864 - val_mae: 1.0575\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 0s 844us/step - loss: 4.7136 - mae: 1.1853 - val_loss: 3.9346 - val_mae: 1.0434\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 0s 853us/step - loss: 4.7365 - mae: 1.1806 - val_loss: 3.9616 - val_mae: 0.9999\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 0s 854us/step - loss: 4.7231 - mae: 1.1738 - val_loss: 3.9087 - val_mae: 1.0261\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 0s 840us/step - loss: 4.7219 - mae: 1.1775 - val_loss: 3.9135 - val_mae: 1.1247\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 0s 927us/step - loss: 4.7250 - mae: 1.1895 - val_loss: 3.9140 - val_mae: 1.0232\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 0s 847us/step - loss: 4.6988 - mae: 1.1712 - val_loss: 3.9032 - val_mae: 1.0484\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 0s 897us/step - loss: 4.7449 - mae: 1.1847 - val_loss: 3.9532 - val_mae: 1.0793\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 0s 893us/step - loss: 4.7234 - mae: 1.1809 - val_loss: 3.9078 - val_mae: 1.0194\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 4.7294 - mae: 1.1755 - val_loss: 3.9143 - val_mae: 1.1013\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 0s 951us/step - loss: 4.7153 - mae: 1.1809 - val_loss: 3.8770 - val_mae: 1.0653\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 4.7145 - mae: 1.1748 - val_loss: 3.9098 - val_mae: 1.1258\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 4.7262 - mae: 1.1789 - val_loss: 3.9264 - val_mae: 1.0178\n",
      "Epoch 37: early stopping\n",
      "Test Loss (MSE): 4.323486804962158, Test Mean Absolute Error (MAE): 1.1036525964736938\n",
      "Epoch 1/100\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 6.3683 - mae: 1.2985 - val_loss: 3.8537 - val_mae: 1.1118\n",
      "Epoch 2/100\n",
      "136/136 [==============================] - 0s 860us/step - loss: 5.5274 - mae: 1.2614 - val_loss: 3.7398 - val_mae: 1.1151\n",
      "Epoch 3/100\n",
      "136/136 [==============================] - 0s 826us/step - loss: 5.2422 - mae: 1.2370 - val_loss: 3.6448 - val_mae: 1.0100\n",
      "Epoch 4/100\n",
      "136/136 [==============================] - 0s 868us/step - loss: 5.1660 - mae: 1.2476 - val_loss: 3.7198 - val_mae: 1.2317\n",
      "Epoch 5/100\n",
      "136/136 [==============================] - 0s 860us/step - loss: 5.1514 - mae: 1.2350 - val_loss: 3.5799 - val_mae: 0.9344\n",
      "Epoch 6/100\n",
      "136/136 [==============================] - 0s 933us/step - loss: 5.1236 - mae: 1.2446 - val_loss: 3.6340 - val_mae: 1.0971\n",
      "Epoch 7/100\n",
      "136/136 [==============================] - 0s 879us/step - loss: 5.1253 - mae: 1.2481 - val_loss: 3.7834 - val_mae: 1.0759\n",
      "Epoch 8/100\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 5.1033 - mae: 1.2238 - val_loss: 3.5945 - val_mae: 1.1151\n",
      "Epoch 9/100\n",
      "136/136 [==============================] - 0s 931us/step - loss: 5.0730 - mae: 1.2212 - val_loss: 3.5795 - val_mae: 1.0892\n",
      "Epoch 10/100\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 5.0609 - mae: 1.2248 - val_loss: 3.5036 - val_mae: 0.9690\n",
      "Epoch 11/100\n",
      "136/136 [==============================] - 0s 961us/step - loss: 5.0690 - mae: 1.2355 - val_loss: 3.5423 - val_mae: 1.0343\n",
      "Epoch 12/100\n",
      "136/136 [==============================] - 0s 951us/step - loss: 5.0264 - mae: 1.2223 - val_loss: 3.5981 - val_mae: 1.0917\n",
      "Epoch 13/100\n",
      "136/136 [==============================] - 0s 841us/step - loss: 5.0658 - mae: 1.2333 - val_loss: 3.5224 - val_mae: 0.9422\n",
      "Epoch 14/100\n",
      "136/136 [==============================] - 0s 858us/step - loss: 4.9883 - mae: 1.2169 - val_loss: 3.6198 - val_mae: 1.0732\n",
      "Epoch 15/100\n",
      "136/136 [==============================] - 0s 840us/step - loss: 4.9800 - mae: 1.2166 - val_loss: 3.6208 - val_mae: 1.1275\n",
      "Epoch 16/100\n",
      "136/136 [==============================] - 0s 879us/step - loss: 4.9791 - mae: 1.2311 - val_loss: 3.5775 - val_mae: 0.9453\n",
      "Epoch 17/100\n",
      "136/136 [==============================] - 0s 874us/step - loss: 4.9990 - mae: 1.2431 - val_loss: 3.5578 - val_mae: 0.9951\n",
      "Epoch 18/100\n",
      "136/136 [==============================] - 0s 862us/step - loss: 4.9583 - mae: 1.2216 - val_loss: 3.6834 - val_mae: 1.0703\n",
      "Epoch 19/100\n",
      "136/136 [==============================] - 0s 851us/step - loss: 4.9858 - mae: 1.2227 - val_loss: 3.5530 - val_mae: 1.0545\n",
      "Epoch 20/100\n",
      "136/136 [==============================] - 0s 846us/step - loss: 4.9908 - mae: 1.2147 - val_loss: 3.5599 - val_mae: 0.9187\n",
      "Epoch 21/100\n",
      "136/136 [==============================] - 0s 863us/step - loss: 4.9762 - mae: 1.2169 - val_loss: 3.5679 - val_mae: 0.9522\n",
      "Epoch 22/100\n",
      "136/136 [==============================] - 0s 839us/step - loss: 4.9380 - mae: 1.2074 - val_loss: 3.6094 - val_mae: 0.9342\n",
      "Epoch 23/100\n",
      "136/136 [==============================] - 0s 844us/step - loss: 4.9308 - mae: 1.2073 - val_loss: 3.5675 - val_mae: 1.0233\n",
      "Epoch 24/100\n",
      "136/136 [==============================] - 0s 873us/step - loss: 4.9102 - mae: 1.2187 - val_loss: 3.7848 - val_mae: 1.1378\n",
      "Epoch 25/100\n",
      "136/136 [==============================] - 0s 867us/step - loss: 4.9430 - mae: 1.2130 - val_loss: 3.6423 - val_mae: 0.9986\n",
      "Epoch 26/100\n",
      "136/136 [==============================] - 0s 843us/step - loss: 4.9170 - mae: 1.2122 - val_loss: 3.5729 - val_mae: 0.9979\n",
      "Epoch 27/100\n",
      "136/136 [==============================] - 0s 845us/step - loss: 4.9055 - mae: 1.2205 - val_loss: 3.6881 - val_mae: 1.0253\n",
      "Epoch 28/100\n",
      "136/136 [==============================] - 0s 841us/step - loss: 4.9065 - mae: 1.2172 - val_loss: 3.6442 - val_mae: 1.0033\n",
      "Epoch 29/100\n",
      "136/136 [==============================] - 0s 860us/step - loss: 4.9137 - mae: 1.2096 - val_loss: 3.6079 - val_mae: 1.0510\n",
      "Epoch 30/100\n",
      "136/136 [==============================] - 0s 866us/step - loss: 4.9075 - mae: 1.2020 - val_loss: 3.8027 - val_mae: 1.0913\n",
      "Epoch 30: early stopping\n",
      "Test Loss (MSE): 3.9485061168670654, Test Mean Absolute Error (MAE): 1.1029038429260254\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 5.5129 - mae: 1.1756 - val_loss: 5.1639 - val_mae: 1.1422\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 917us/step - loss: 4.6118 - mae: 1.1455 - val_loss: 4.9344 - val_mae: 1.1752\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 952us/step - loss: 4.4591 - mae: 1.1307 - val_loss: 5.1017 - val_mae: 1.3968\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 910us/step - loss: 4.3822 - mae: 1.1574 - val_loss: 4.8265 - val_mae: 1.1813\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 884us/step - loss: 4.3257 - mae: 1.1488 - val_loss: 4.8862 - val_mae: 1.2698\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 917us/step - loss: 4.2798 - mae: 1.1438 - val_loss: 4.9058 - val_mae: 1.1352\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 903us/step - loss: 4.3406 - mae: 1.1395 - val_loss: 4.8797 - val_mae: 1.2992\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 4.2520 - mae: 1.1388 - val_loss: 4.8662 - val_mae: 1.1500\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 924us/step - loss: 4.3067 - mae: 1.1453 - val_loss: 4.9229 - val_mae: 1.1914\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 998us/step - loss: 4.2142 - mae: 1.1163 - val_loss: 5.1821 - val_mae: 1.1400\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 976us/step - loss: 4.2358 - mae: 1.1237 - val_loss: 4.8256 - val_mae: 1.2193\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 4.2224 - mae: 1.1201 - val_loss: 4.9493 - val_mae: 1.1492\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 987us/step - loss: 4.1829 - mae: 1.1135 - val_loss: 4.8379 - val_mae: 1.3187\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 978us/step - loss: 4.1557 - mae: 1.1183 - val_loss: 4.8288 - val_mae: 1.2232\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 938us/step - loss: 4.1747 - mae: 1.1007 - val_loss: 4.7877 - val_mae: 1.2212\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 936us/step - loss: 4.1552 - mae: 1.1049 - val_loss: 4.8009 - val_mae: 1.1781\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 904us/step - loss: 4.1569 - mae: 1.0984 - val_loss: 4.9460 - val_mae: 1.3532\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 941us/step - loss: 4.1885 - mae: 1.1047 - val_loss: 4.8432 - val_mae: 1.2795\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 4.1026 - mae: 1.0932 - val_loss: 4.7982 - val_mae: 1.1845\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 954us/step - loss: 4.0891 - mae: 1.0908 - val_loss: 4.9323 - val_mae: 1.1291\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 926us/step - loss: 4.1007 - mae: 1.0899 - val_loss: 4.8917 - val_mae: 1.1389\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 886us/step - loss: 4.1096 - mae: 1.0853 - val_loss: 4.8372 - val_mae: 1.2342\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 887us/step - loss: 4.0964 - mae: 1.0933 - val_loss: 4.9633 - val_mae: 1.2756\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 945us/step - loss: 4.1656 - mae: 1.0852 - val_loss: 4.9436 - val_mae: 1.1611\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 893us/step - loss: 4.0717 - mae: 1.0722 - val_loss: 4.9541 - val_mae: 1.2629\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 902us/step - loss: 4.0231 - mae: 1.0610 - val_loss: 4.9500 - val_mae: 1.2042\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 914us/step - loss: 4.0456 - mae: 1.0730 - val_loss: 4.8962 - val_mae: 1.1670\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 953us/step - loss: 4.0109 - mae: 1.0486 - val_loss: 5.0145 - val_mae: 1.2156\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 935us/step - loss: 4.0130 - mae: 1.0790 - val_loss: 5.0139 - val_mae: 1.1349\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 908us/step - loss: 4.0118 - mae: 1.0570 - val_loss: 5.0647 - val_mae: 1.1640\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 939us/step - loss: 3.9938 - mae: 1.0617 - val_loss: 5.1033 - val_mae: 1.2253\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 976us/step - loss: 3.9122 - mae: 1.0356 - val_loss: 5.4350 - val_mae: 1.2955\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 878us/step - loss: 3.9763 - mae: 1.0687 - val_loss: 5.1285 - val_mae: 1.1622\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 924us/step - loss: 3.8844 - mae: 1.0358 - val_loss: 5.1432 - val_mae: 1.2362\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 900us/step - loss: 3.9400 - mae: 1.0584 - val_loss: 5.2224 - val_mae: 1.1677\n",
      "Epoch 35: early stopping\n",
      "Test Loss (MSE): 6.004119396209717, Test Mean Absolute Error (MAE): 1.1565337181091309\n",
      "Epoch 1/100\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 5.7338 - mae: 1.2173 - val_loss: 5.5591 - val_mae: 1.1911\n",
      "Epoch 2/100\n",
      "136/136 [==============================] - 0s 930us/step - loss: 4.6883 - mae: 1.1480 - val_loss: 5.3380 - val_mae: 1.0993\n",
      "Epoch 3/100\n",
      "136/136 [==============================] - 0s 912us/step - loss: 4.5696 - mae: 1.1504 - val_loss: 5.1964 - val_mae: 1.3167\n",
      "Epoch 4/100\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 4.5841 - mae: 1.1475 - val_loss: 5.2211 - val_mae: 1.1898\n",
      "Epoch 5/100\n",
      "136/136 [==============================] - 0s 901us/step - loss: 4.4387 - mae: 1.1240 - val_loss: 5.1071 - val_mae: 1.3641\n",
      "Epoch 6/100\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 4.3992 - mae: 1.1228 - val_loss: 5.0346 - val_mae: 1.1767\n",
      "Epoch 7/100\n",
      "136/136 [==============================] - 0s 961us/step - loss: 4.4076 - mae: 1.1247 - val_loss: 5.0653 - val_mae: 1.2217\n",
      "Epoch 8/100\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 4.4047 - mae: 1.1182 - val_loss: 5.1034 - val_mae: 1.1537\n",
      "Epoch 9/100\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 4.3699 - mae: 1.1235 - val_loss: 5.0805 - val_mae: 1.2524\n",
      "Epoch 10/100\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 4.4127 - mae: 1.1331 - val_loss: 5.1244 - val_mae: 1.1556\n",
      "Epoch 11/100\n",
      "136/136 [==============================] - 0s 980us/step - loss: 4.3848 - mae: 1.1167 - val_loss: 5.1444 - val_mae: 1.2248\n",
      "Epoch 12/100\n",
      "136/136 [==============================] - 0s 902us/step - loss: 4.3511 - mae: 1.1083 - val_loss: 5.2055 - val_mae: 1.1323\n",
      "Epoch 13/100\n",
      "136/136 [==============================] - 0s 928us/step - loss: 4.3559 - mae: 1.1270 - val_loss: 5.0687 - val_mae: 1.1793\n",
      "Epoch 14/100\n",
      "136/136 [==============================] - 0s 886us/step - loss: 4.2981 - mae: 1.1111 - val_loss: 5.1986 - val_mae: 1.1325\n",
      "Epoch 15/100\n",
      "136/136 [==============================] - 0s 883us/step - loss: 4.3477 - mae: 1.1218 - val_loss: 5.1146 - val_mae: 1.2447\n",
      "Epoch 16/100\n",
      "136/136 [==============================] - 0s 916us/step - loss: 4.3455 - mae: 1.1381 - val_loss: 5.2587 - val_mae: 1.1641\n",
      "Epoch 17/100\n",
      "136/136 [==============================] - 0s 930us/step - loss: 4.3349 - mae: 1.1074 - val_loss: 5.1971 - val_mae: 1.1737\n",
      "Epoch 18/100\n",
      "136/136 [==============================] - 0s 935us/step - loss: 4.2931 - mae: 1.1106 - val_loss: 5.3352 - val_mae: 1.1783\n",
      "Epoch 19/100\n",
      "136/136 [==============================] - 0s 940us/step - loss: 4.3203 - mae: 1.1115 - val_loss: 5.2317 - val_mae: 1.1852\n",
      "Epoch 20/100\n",
      "136/136 [==============================] - 0s 985us/step - loss: 4.3077 - mae: 1.1157 - val_loss: 5.4670 - val_mae: 1.1318\n",
      "Epoch 21/100\n",
      "136/136 [==============================] - 0s 953us/step - loss: 4.3411 - mae: 1.0994 - val_loss: 5.3237 - val_mae: 1.1872\n",
      "Epoch 22/100\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 4.2877 - mae: 1.1087 - val_loss: 5.2588 - val_mae: 1.1532\n",
      "Epoch 23/100\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 4.2674 - mae: 1.0953 - val_loss: 5.3413 - val_mae: 1.1318\n",
      "Epoch 24/100\n",
      "136/136 [==============================] - 0s 962us/step - loss: 4.2594 - mae: 1.1078 - val_loss: 5.2761 - val_mae: 1.2144\n",
      "Epoch 25/100\n",
      "136/136 [==============================] - 0s 894us/step - loss: 4.2219 - mae: 1.0853 - val_loss: 5.3532 - val_mae: 1.1352\n",
      "Epoch 26/100\n",
      "136/136 [==============================] - 0s 926us/step - loss: 4.2200 - mae: 1.1198 - val_loss: 5.3819 - val_mae: 1.3109\n",
      "Epoch 26: early stopping\n",
      "Test Loss (MSE): 4.492920875549316, Test Mean Absolute Error (MAE): 1.201337218284607\n",
      "Epoch 1/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 8.5513 - mae: 1.7930 - val_loss: 8.3572 - val_mae: 1.8695\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.4978 - mae: 1.7459 - val_loss: 8.8680 - val_mae: 2.1787\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 888us/step - loss: 7.3053 - mae: 1.7208 - val_loss: 8.2741 - val_mae: 1.7793\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 857us/step - loss: 7.1256 - mae: 1.6942 - val_loss: 8.3476 - val_mae: 1.9842\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 0s 912us/step - loss: 7.1099 - mae: 1.6931 - val_loss: 8.2580 - val_mae: 1.6991\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 0s 956us/step - loss: 7.0577 - mae: 1.6993 - val_loss: 8.1262 - val_mae: 1.9406\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.0724 - mae: 1.7148 - val_loss: 8.0613 - val_mae: 1.7521\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 959us/step - loss: 7.0336 - mae: 1.6942 - val_loss: 8.0315 - val_mae: 1.7929\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 935us/step - loss: 6.9469 - mae: 1.6829 - val_loss: 8.0091 - val_mae: 1.7734\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 0s 923us/step - loss: 6.9370 - mae: 1.7077 - val_loss: 8.2342 - val_mae: 1.7136\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.0617 - mae: 1.6935 - val_loss: 8.2289 - val_mae: 1.7157\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 962us/step - loss: 6.9672 - mae: 1.6928 - val_loss: 8.0272 - val_mae: 1.8602\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 0s 945us/step - loss: 6.9270 - mae: 1.7096 - val_loss: 8.1826 - val_mae: 1.8235\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 0s 982us/step - loss: 6.9693 - mae: 1.6802 - val_loss: 8.1715 - val_mae: 1.9314\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 982us/step - loss: 7.0292 - mae: 1.7118 - val_loss: 8.0030 - val_mae: 1.8384\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 944us/step - loss: 6.8687 - mae: 1.6855 - val_loss: 8.0368 - val_mae: 1.8028\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 900us/step - loss: 6.8347 - mae: 1.6757 - val_loss: 8.0004 - val_mae: 1.8060\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 884us/step - loss: 6.8850 - mae: 1.6941 - val_loss: 8.0801 - val_mae: 1.7873\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 867us/step - loss: 6.8566 - mae: 1.6794 - val_loss: 8.0933 - val_mae: 1.9508\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 873us/step - loss: 6.8801 - mae: 1.7012 - val_loss: 8.0807 - val_mae: 1.7518\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 898us/step - loss: 6.8216 - mae: 1.6840 - val_loss: 8.1455 - val_mae: 1.7283\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 0s 831us/step - loss: 6.8246 - mae: 1.6681 - val_loss: 8.0427 - val_mae: 1.8894\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 0s 960us/step - loss: 6.8534 - mae: 1.7030 - val_loss: 8.0355 - val_mae: 1.7927\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 0s 893us/step - loss: 6.8609 - mae: 1.6741 - val_loss: 7.9711 - val_mae: 1.8717\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 0s 896us/step - loss: 6.8442 - mae: 1.6982 - val_loss: 8.1519 - val_mae: 1.8983\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 0s 882us/step - loss: 6.8314 - mae: 1.6890 - val_loss: 8.0531 - val_mae: 1.8012\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 0s 871us/step - loss: 6.8106 - mae: 1.6778 - val_loss: 8.0999 - val_mae: 1.8204\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 0s 884us/step - loss: 6.7725 - mae: 1.6795 - val_loss: 8.0913 - val_mae: 1.7358\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 0s 892us/step - loss: 6.8630 - mae: 1.6894 - val_loss: 8.0076 - val_mae: 1.8235\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 0s 858us/step - loss: 6.8028 - mae: 1.6731 - val_loss: 8.0134 - val_mae: 1.7913\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 0s 862us/step - loss: 6.8073 - mae: 1.6719 - val_loss: 8.1131 - val_mae: 1.9199\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 0s 856us/step - loss: 6.7958 - mae: 1.6853 - val_loss: 8.0227 - val_mae: 1.8508\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 0s 969us/step - loss: 6.7780 - mae: 1.6910 - val_loss: 8.1650 - val_mae: 1.7885\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 0s 900us/step - loss: 6.7793 - mae: 1.6827 - val_loss: 8.0400 - val_mae: 1.7597\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 0s 845us/step - loss: 6.8276 - mae: 1.6753 - val_loss: 8.0812 - val_mae: 1.8556\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 0s 825us/step - loss: 6.7875 - mae: 1.6620 - val_loss: 8.0651 - val_mae: 1.7680\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 0s 896us/step - loss: 6.7681 - mae: 1.6926 - val_loss: 8.0879 - val_mae: 1.7652\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 0s 867us/step - loss: 6.7761 - mae: 1.6629 - val_loss: 8.0578 - val_mae: 1.8342\n",
      "Epoch 39/100\n",
      "77/77 [==============================] - 0s 829us/step - loss: 6.8014 - mae: 1.6906 - val_loss: 8.0261 - val_mae: 1.8158\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 0s 874us/step - loss: 6.7880 - mae: 1.6860 - val_loss: 8.0870 - val_mae: 1.7621\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 0s 838us/step - loss: 6.7557 - mae: 1.6583 - val_loss: 8.0939 - val_mae: 1.8859\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 0s 998us/step - loss: 6.7572 - mae: 1.6874 - val_loss: 8.0597 - val_mae: 1.8519\n",
      "Epoch 43/100\n",
      "77/77 [==============================] - 0s 898us/step - loss: 6.7847 - mae: 1.6852 - val_loss: 8.0760 - val_mae: 1.7763\n",
      "Epoch 44/100\n",
      "77/77 [==============================] - 0s 918us/step - loss: 6.7761 - mae: 1.6733 - val_loss: 8.0213 - val_mae: 1.8781\n",
      "Epoch 44: early stopping\n",
      "Test Loss (MSE): 7.687356948852539, Test Mean Absolute Error (MAE): 1.835326910018921\n",
      "Epoch 1/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 9.6151 - mae: 1.8584 - val_loss: 7.3175 - val_mae: 1.6241\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 0s 960us/step - loss: 8.2857 - mae: 1.8146 - val_loss: 7.1419 - val_mae: 1.6162\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 983us/step - loss: 8.1534 - mae: 1.7916 - val_loss: 7.1965 - val_mae: 1.5867\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 970us/step - loss: 8.1531 - mae: 1.8161 - val_loss: 6.7664 - val_mae: 1.7335\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 0s 877us/step - loss: 7.9755 - mae: 1.7910 - val_loss: 6.7495 - val_mae: 1.7351\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 0s 897us/step - loss: 7.9167 - mae: 1.8023 - val_loss: 6.7082 - val_mae: 1.6914\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 909us/step - loss: 7.9065 - mae: 1.7910 - val_loss: 6.7480 - val_mae: 1.6570\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 921us/step - loss: 7.9812 - mae: 1.8014 - val_loss: 6.7802 - val_mae: 1.7470\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 991us/step - loss: 7.8745 - mae: 1.7818 - val_loss: 6.7864 - val_mae: 1.6512\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 0s 921us/step - loss: 7.8745 - mae: 1.7856 - val_loss: 6.7519 - val_mae: 1.7351\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 875us/step - loss: 7.7579 - mae: 1.7793 - val_loss: 7.0164 - val_mae: 1.6178\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 899us/step - loss: 7.7855 - mae: 1.7884 - val_loss: 7.0624 - val_mae: 1.5883\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 0s 883us/step - loss: 7.7929 - mae: 1.7774 - val_loss: 6.7414 - val_mae: 1.6616\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 0s 865us/step - loss: 7.7529 - mae: 1.7842 - val_loss: 6.6948 - val_mae: 1.6696\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 896us/step - loss: 7.7087 - mae: 1.7725 - val_loss: 6.7803 - val_mae: 1.6900\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 857us/step - loss: 7.6778 - mae: 1.7681 - val_loss: 6.7481 - val_mae: 1.7332\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 939us/step - loss: 7.6646 - mae: 1.7767 - val_loss: 6.7314 - val_mae: 1.6848\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 859us/step - loss: 7.6615 - mae: 1.7695 - val_loss: 6.7201 - val_mae: 1.7544\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 879us/step - loss: 7.6356 - mae: 1.7830 - val_loss: 6.8926 - val_mae: 1.8235\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 886us/step - loss: 7.5901 - mae: 1.7696 - val_loss: 7.0162 - val_mae: 1.5995\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 898us/step - loss: 7.5873 - mae: 1.7527 - val_loss: 6.8303 - val_mae: 1.6430\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 0s 898us/step - loss: 7.5340 - mae: 1.7709 - val_loss: 6.7978 - val_mae: 1.6926\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 0s 863us/step - loss: 7.4845 - mae: 1.7450 - val_loss: 6.8053 - val_mae: 1.7468\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 0s 871us/step - loss: 7.4966 - mae: 1.7672 - val_loss: 6.8336 - val_mae: 1.7030\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 0s 904us/step - loss: 7.4851 - mae: 1.7462 - val_loss: 6.7478 - val_mae: 1.6735\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 0s 902us/step - loss: 7.4673 - mae: 1.7614 - val_loss: 6.9020 - val_mae: 1.6958\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 0s 882us/step - loss: 7.4082 - mae: 1.7593 - val_loss: 6.9219 - val_mae: 1.6445\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 0s 971us/step - loss: 7.5521 - mae: 1.7372 - val_loss: 7.0179 - val_mae: 1.7843\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 0s 948us/step - loss: 7.4105 - mae: 1.7625 - val_loss: 6.8602 - val_mae: 1.6879\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 0s 904us/step - loss: 7.4780 - mae: 1.7615 - val_loss: 7.0432 - val_mae: 1.7694\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 0s 893us/step - loss: 7.3364 - mae: 1.7282 - val_loss: 6.9547 - val_mae: 1.6332\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 0s 869us/step - loss: 7.3002 - mae: 1.7422 - val_loss: 7.0305 - val_mae: 1.6525\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 0s 877us/step - loss: 7.3456 - mae: 1.7423 - val_loss: 7.0465 - val_mae: 1.6421\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 0s 886us/step - loss: 7.3063 - mae: 1.7217 - val_loss: 7.0644 - val_mae: 1.7439\n",
      "Epoch 34: early stopping\n",
      "Test Loss (MSE): 7.353148937225342, Test Mean Absolute Error (MAE): 1.7440783977508545\n",
      "Epoch 1/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 9.2138 - mae: 1.8088 - val_loss: 8.0818 - val_mae: 1.6004\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.9177 - mae: 1.7044 - val_loss: 7.6375 - val_mae: 1.9004\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.4722 - mae: 1.7086 - val_loss: 7.2699 - val_mae: 1.8666\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 984us/step - loss: 7.4558 - mae: 1.7016 - val_loss: 7.2699 - val_mae: 1.6156\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 0s 967us/step - loss: 7.4168 - mae: 1.7151 - val_loss: 7.1503 - val_mae: 1.8645\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 0s 967us/step - loss: 7.2581 - mae: 1.6856 - val_loss: 7.0337 - val_mae: 1.7941\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 958us/step - loss: 7.1497 - mae: 1.6852 - val_loss: 7.0492 - val_mae: 1.7394\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 994us/step - loss: 7.2450 - mae: 1.6912 - val_loss: 7.0562 - val_mae: 1.7157\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 985us/step - loss: 7.2213 - mae: 1.6700 - val_loss: 7.0356 - val_mae: 1.7353\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 0s 959us/step - loss: 7.0805 - mae: 1.6699 - val_loss: 8.0436 - val_mae: 2.0288\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.0449 - mae: 1.6532 - val_loss: 7.1403 - val_mae: 1.6325\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 965us/step - loss: 7.0188 - mae: 1.6741 - val_loss: 7.1594 - val_mae: 1.6210\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 0s 969us/step - loss: 6.8720 - mae: 1.6362 - val_loss: 7.1818 - val_mae: 1.6152\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 0s 953us/step - loss: 6.9575 - mae: 1.6514 - val_loss: 7.0887 - val_mae: 1.6765\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 959us/step - loss: 6.6717 - mae: 1.6172 - val_loss: 7.3049 - val_mae: 1.7309\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 952us/step - loss: 6.5868 - mae: 1.5991 - val_loss: 7.3237 - val_mae: 1.7995\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 984us/step - loss: 6.4631 - mae: 1.5964 - val_loss: 7.5968 - val_mae: 1.7001\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 942us/step - loss: 6.3410 - mae: 1.5757 - val_loss: 7.9391 - val_mae: 1.7171\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 919us/step - loss: 6.4217 - mae: 1.5641 - val_loss: 7.6452 - val_mae: 1.7135\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 913us/step - loss: 6.1759 - mae: 1.5562 - val_loss: 7.7739 - val_mae: 1.6824\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 940us/step - loss: 6.0533 - mae: 1.5282 - val_loss: 8.3960 - val_mae: 1.7554\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 0s 957us/step - loss: 5.8832 - mae: 1.4881 - val_loss: 8.3147 - val_mae: 1.8435\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 0s 955us/step - loss: 5.8513 - mae: 1.5245 - val_loss: 7.8405 - val_mae: 1.7266\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 0s 952us/step - loss: 5.8043 - mae: 1.5019 - val_loss: 8.1099 - val_mae: 1.7473\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 0s 927us/step - loss: 5.7431 - mae: 1.4887 - val_loss: 8.1712 - val_mae: 1.7649\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 0s 967us/step - loss: 5.6742 - mae: 1.4671 - val_loss: 8.4183 - val_mae: 1.8309\n",
      "Epoch 26: early stopping\n",
      "Test Loss (MSE): 11.382569313049316, Test Mean Absolute Error (MAE): 2.1560187339782715\n",
      "Epoch 1/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 9.4981 - mae: 1.8621 - val_loss: 8.0163 - val_mae: 1.6082\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 0s 935us/step - loss: 7.9316 - mae: 1.7648 - val_loss: 7.3101 - val_mae: 1.7072\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 962us/step - loss: 7.6985 - mae: 1.7419 - val_loss: 7.3488 - val_mae: 1.7113\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 983us/step - loss: 7.6214 - mae: 1.7495 - val_loss: 7.3236 - val_mae: 1.7269\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.5647 - mae: 1.7488 - val_loss: 7.6214 - val_mae: 2.0607\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 0s 966us/step - loss: 7.5525 - mae: 1.7573 - val_loss: 7.2336 - val_mae: 1.6594\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 954us/step - loss: 7.4600 - mae: 1.7412 - val_loss: 7.1854 - val_mae: 1.6405\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 983us/step - loss: 7.4409 - mae: 1.7427 - val_loss: 7.1405 - val_mae: 1.7922\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 906us/step - loss: 7.3250 - mae: 1.7340 - val_loss: 7.1919 - val_mae: 1.6588\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 0s 961us/step - loss: 7.3398 - mae: 1.7217 - val_loss: 7.3513 - val_mae: 1.6306\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 964us/step - loss: 7.3127 - mae: 1.7338 - val_loss: 7.3024 - val_mae: 1.6534\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 942us/step - loss: 7.1745 - mae: 1.7024 - val_loss: 7.4826 - val_mae: 1.9383\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.1198 - mae: 1.7175 - val_loss: 7.3087 - val_mae: 1.6808\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 0s 977us/step - loss: 7.1146 - mae: 1.7017 - val_loss: 7.3812 - val_mae: 1.7156\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.1528 - mae: 1.6975 - val_loss: 7.4039 - val_mae: 1.7301\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 909us/step - loss: 7.0248 - mae: 1.6842 - val_loss: 7.5813 - val_mae: 1.6842\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 955us/step - loss: 7.0274 - mae: 1.6800 - val_loss: 7.6460 - val_mae: 1.7678\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 6.8826 - mae: 1.6632 - val_loss: 7.3505 - val_mae: 1.7318\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 958us/step - loss: 6.9423 - mae: 1.6842 - val_loss: 7.6746 - val_mae: 1.7581\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 6.8596 - mae: 1.6388 - val_loss: 7.5316 - val_mae: 1.7375\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 948us/step - loss: 6.7520 - mae: 1.6600 - val_loss: 7.8247 - val_mae: 1.8189\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 0s 943us/step - loss: 6.5895 - mae: 1.6251 - val_loss: 7.5760 - val_mae: 1.6988\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 0s 979us/step - loss: 6.5916 - mae: 1.6289 - val_loss: 7.6031 - val_mae: 1.6834\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 0s 938us/step - loss: 6.5030 - mae: 1.6131 - val_loss: 7.9501 - val_mae: 1.7409\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 0s 973us/step - loss: 6.4941 - mae: 1.6228 - val_loss: 7.9068 - val_mae: 1.7429\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 0s 975us/step - loss: 6.3303 - mae: 1.5768 - val_loss: 7.9194 - val_mae: 1.7567\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 0s 931us/step - loss: 6.4086 - mae: 1.5863 - val_loss: 7.8080 - val_mae: 1.8000\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 0s 968us/step - loss: 6.3065 - mae: 1.5835 - val_loss: 8.3944 - val_mae: 1.7705\n",
      "Epoch 28: early stopping\n",
      "Test Loss (MSE): 10.806920051574707, Test Mean Absolute Error (MAE): 1.9571629762649536\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 5.2045 - mae: 1.1959 - val_loss: 6.4592 - val_mae: 1.1983\n",
      "Epoch 2/100\n",
      "134/134 [==============================] - 0s 854us/step - loss: 4.3547 - mae: 1.1532 - val_loss: 5.3434 - val_mae: 1.3304\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 0s 853us/step - loss: 4.2506 - mae: 1.1534 - val_loss: 5.4273 - val_mae: 1.1813\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 0s 778us/step - loss: 4.2874 - mae: 1.1500 - val_loss: 5.1807 - val_mae: 1.2280\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 0s 782us/step - loss: 4.2770 - mae: 1.1442 - val_loss: 5.2797 - val_mae: 1.2077\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 0s 793us/step - loss: 4.1787 - mae: 1.1497 - val_loss: 5.2506 - val_mae: 1.1989\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 0s 872us/step - loss: 4.2100 - mae: 1.1381 - val_loss: 5.1418 - val_mae: 1.2834\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 0s 795us/step - loss: 4.2340 - mae: 1.1505 - val_loss: 5.1198 - val_mae: 1.2282\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 0s 819us/step - loss: 4.1551 - mae: 1.1374 - val_loss: 5.2759 - val_mae: 1.3732\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 0s 782us/step - loss: 4.1334 - mae: 1.1223 - val_loss: 5.1459 - val_mae: 1.2233\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 0s 816us/step - loss: 4.2207 - mae: 1.1344 - val_loss: 5.1333 - val_mae: 1.3228\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 0s 835us/step - loss: 4.1680 - mae: 1.1321 - val_loss: 5.0927 - val_mae: 1.2432\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 0s 827us/step - loss: 4.1266 - mae: 1.1248 - val_loss: 5.1316 - val_mae: 1.2352\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 0s 864us/step - loss: 4.1163 - mae: 1.1177 - val_loss: 5.5577 - val_mae: 1.1441\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 0s 809us/step - loss: 4.1787 - mae: 1.1271 - val_loss: 5.1126 - val_mae: 1.2482\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 0s 968us/step - loss: 4.0946 - mae: 1.1089 - val_loss: 5.1343 - val_mae: 1.2494\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 0s 839us/step - loss: 4.1464 - mae: 1.1292 - val_loss: 5.1761 - val_mae: 1.2221\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 0s 865us/step - loss: 4.1039 - mae: 1.1160 - val_loss: 5.1884 - val_mae: 1.1800\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 0s 822us/step - loss: 4.1083 - mae: 1.1193 - val_loss: 5.1188 - val_mae: 1.2265\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 0s 805us/step - loss: 4.0917 - mae: 1.1038 - val_loss: 5.1394 - val_mae: 1.2226\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 0s 782us/step - loss: 4.1083 - mae: 1.1212 - val_loss: 5.6264 - val_mae: 1.1320\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 0s 779us/step - loss: 4.1258 - mae: 1.1165 - val_loss: 5.2105 - val_mae: 1.1924\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 0s 769us/step - loss: 4.0756 - mae: 1.1064 - val_loss: 5.1644 - val_mae: 1.2800\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 0s 819us/step - loss: 4.0893 - mae: 1.1069 - val_loss: 5.2962 - val_mae: 1.1672\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 0s 783us/step - loss: 4.0591 - mae: 1.1041 - val_loss: 5.1618 - val_mae: 1.2638\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 0s 784us/step - loss: 4.0946 - mae: 1.1154 - val_loss: 5.1523 - val_mae: 1.3014\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 0s 775us/step - loss: 4.0732 - mae: 1.1102 - val_loss: 5.1447 - val_mae: 1.2412\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 0s 744us/step - loss: 4.0814 - mae: 1.1011 - val_loss: 5.2209 - val_mae: 1.1762\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 0s 803us/step - loss: 4.0529 - mae: 1.0960 - val_loss: 5.1797 - val_mae: 1.3225\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 0s 764us/step - loss: 4.1338 - mae: 1.1155 - val_loss: 5.4109 - val_mae: 1.1337\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 0s 784us/step - loss: 4.0667 - mae: 1.1078 - val_loss: 5.2187 - val_mae: 1.2072\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 0s 775us/step - loss: 4.0604 - mae: 1.0998 - val_loss: 5.2248 - val_mae: 1.1795\n",
      "Epoch 32: early stopping\n",
      "Test Loss (MSE): 4.641432285308838, Test Mean Absolute Error (MAE): 1.085686445236206\n",
      "Epoch 1/100\n",
      "137/137 [==============================] - 0s 1ms/step - loss: 5.2458 - mae: 1.1681 - val_loss: 5.5124 - val_mae: 1.2871\n",
      "Epoch 2/100\n",
      "137/137 [==============================] - 0s 881us/step - loss: 4.4344 - mae: 1.1421 - val_loss: 6.0094 - val_mae: 1.2063\n",
      "Epoch 3/100\n",
      "137/137 [==============================] - 0s 853us/step - loss: 4.4370 - mae: 1.1511 - val_loss: 5.4072 - val_mae: 1.1782\n",
      "Epoch 4/100\n",
      "137/137 [==============================] - 0s 854us/step - loss: 4.2287 - mae: 1.1359 - val_loss: 5.1395 - val_mae: 1.1907\n",
      "Epoch 5/100\n",
      "137/137 [==============================] - 0s 837us/step - loss: 4.1654 - mae: 1.1232 - val_loss: 5.1994 - val_mae: 1.1767\n",
      "Epoch 6/100\n",
      "137/137 [==============================] - 0s 838us/step - loss: 4.2143 - mae: 1.1257 - val_loss: 5.2356 - val_mae: 1.1777\n",
      "Epoch 7/100\n",
      "137/137 [==============================] - 0s 884us/step - loss: 4.1500 - mae: 1.1177 - val_loss: 5.0771 - val_mae: 1.1993\n",
      "Epoch 8/100\n",
      "137/137 [==============================] - 0s 1ms/step - loss: 4.1913 - mae: 1.1192 - val_loss: 5.0536 - val_mae: 1.2879\n",
      "Epoch 9/100\n",
      "137/137 [==============================] - 0s 922us/step - loss: 4.1567 - mae: 1.1255 - val_loss: 5.1944 - val_mae: 1.1960\n",
      "Epoch 10/100\n",
      "137/137 [==============================] - 0s 902us/step - loss: 4.1138 - mae: 1.1159 - val_loss: 4.9619 - val_mae: 1.2613\n",
      "Epoch 11/100\n",
      "137/137 [==============================] - 0s 928us/step - loss: 4.0546 - mae: 1.1018 - val_loss: 5.1349 - val_mae: 1.2943\n",
      "Epoch 12/100\n",
      "137/137 [==============================] - 0s 1ms/step - loss: 4.0276 - mae: 1.1046 - val_loss: 5.2439 - val_mae: 1.3418\n",
      "Epoch 13/100\n",
      "137/137 [==============================] - 0s 925us/step - loss: 4.0541 - mae: 1.1027 - val_loss: 5.3319 - val_mae: 1.1832\n",
      "Epoch 14/100\n",
      "137/137 [==============================] - 0s 871us/step - loss: 4.1000 - mae: 1.1058 - val_loss: 5.2395 - val_mae: 1.1836\n",
      "Epoch 15/100\n",
      "137/137 [==============================] - 0s 817us/step - loss: 4.0616 - mae: 1.1020 - val_loss: 5.1558 - val_mae: 1.1893\n",
      "Epoch 16/100\n",
      "137/137 [==============================] - 0s 808us/step - loss: 4.0701 - mae: 1.0959 - val_loss: 5.1007 - val_mae: 1.1962\n",
      "Epoch 17/100\n",
      "137/137 [==============================] - 0s 876us/step - loss: 4.0670 - mae: 1.1007 - val_loss: 5.1335 - val_mae: 1.2090\n",
      "Epoch 18/100\n",
      "137/137 [==============================] - 0s 798us/step - loss: 4.0198 - mae: 1.0993 - val_loss: 5.2087 - val_mae: 1.1819\n",
      "Epoch 19/100\n",
      "137/137 [==============================] - 0s 824us/step - loss: 4.0611 - mae: 1.0831 - val_loss: 5.2106 - val_mae: 1.1997\n",
      "Epoch 20/100\n",
      "137/137 [==============================] - 0s 828us/step - loss: 3.9765 - mae: 1.0858 - val_loss: 5.0968 - val_mae: 1.2719\n",
      "Epoch 21/100\n",
      "137/137 [==============================] - 0s 834us/step - loss: 4.0405 - mae: 1.0795 - val_loss: 5.1388 - val_mae: 1.2574\n",
      "Epoch 22/100\n",
      "137/137 [==============================] - 0s 820us/step - loss: 4.0606 - mae: 1.0958 - val_loss: 5.0808 - val_mae: 1.2101\n",
      "Epoch 23/100\n",
      "137/137 [==============================] - 0s 869us/step - loss: 3.9692 - mae: 1.0878 - val_loss: 5.0931 - val_mae: 1.2187\n",
      "Epoch 24/100\n",
      "137/137 [==============================] - 0s 826us/step - loss: 3.9788 - mae: 1.0814 - val_loss: 5.2073 - val_mae: 1.1882\n",
      "Epoch 25/100\n",
      "137/137 [==============================] - 0s 835us/step - loss: 4.0300 - mae: 1.0898 - val_loss: 5.1952 - val_mae: 1.2585\n",
      "Epoch 26/100\n",
      "137/137 [==============================] - 0s 842us/step - loss: 3.9783 - mae: 1.0924 - val_loss: 5.1508 - val_mae: 1.2334\n",
      "Epoch 27/100\n",
      "137/137 [==============================] - 0s 826us/step - loss: 3.9622 - mae: 1.0851 - val_loss: 5.2011 - val_mae: 1.2462\n",
      "Epoch 28/100\n",
      "137/137 [==============================] - 0s 860us/step - loss: 3.9464 - mae: 1.0766 - val_loss: 5.3285 - val_mae: 1.1838\n",
      "Epoch 29/100\n",
      "137/137 [==============================] - 0s 828us/step - loss: 3.9463 - mae: 1.0775 - val_loss: 5.1321 - val_mae: 1.2248\n",
      "Epoch 30/100\n",
      "137/137 [==============================] - 0s 889us/step - loss: 3.9347 - mae: 1.0871 - val_loss: 5.2886 - val_mae: 1.2499\n",
      "Epoch 30: early stopping\n",
      "Test Loss (MSE): 5.261481761932373, Test Mean Absolute Error (MAE): 1.176954746246338\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 5.8878 - mae: 1.2330 - val_loss: 5.1941 - val_mae: 1.3313\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 973us/step - loss: 4.9343 - mae: 1.1904 - val_loss: 5.5855 - val_mae: 1.4206\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 929us/step - loss: 4.8500 - mae: 1.2134 - val_loss: 4.7851 - val_mae: 1.2453\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 4.6801 - mae: 1.2013 - val_loss: 4.7035 - val_mae: 1.1089\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 954us/step - loss: 4.6525 - mae: 1.1900 - val_loss: 4.8225 - val_mae: 1.2441\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 4.5723 - mae: 1.1865 - val_loss: 4.7711 - val_mae: 1.2068\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 4.5709 - mae: 1.1882 - val_loss: 4.8935 - val_mae: 1.0666\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 4.5619 - mae: 1.1846 - val_loss: 4.6424 - val_mae: 1.1141\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 952us/step - loss: 4.5973 - mae: 1.1858 - val_loss: 4.6384 - val_mae: 1.1667\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 865us/step - loss: 4.5515 - mae: 1.1946 - val_loss: 4.6493 - val_mae: 1.1662\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 881us/step - loss: 4.4645 - mae: 1.1840 - val_loss: 4.8295 - val_mae: 1.1638\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 895us/step - loss: 4.5190 - mae: 1.1616 - val_loss: 4.7488 - val_mae: 1.2138\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 947us/step - loss: 4.4991 - mae: 1.1731 - val_loss: 4.8286 - val_mae: 1.0628\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 826us/step - loss: 4.4455 - mae: 1.1640 - val_loss: 4.8030 - val_mae: 1.2412\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 866us/step - loss: 4.4999 - mae: 1.1610 - val_loss: 4.6741 - val_mae: 1.1196\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 860us/step - loss: 4.5390 - mae: 1.1721 - val_loss: 4.7945 - val_mae: 1.1305\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 851us/step - loss: 4.4480 - mae: 1.1529 - val_loss: 5.0241 - val_mae: 1.3255\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 830us/step - loss: 4.5253 - mae: 1.1698 - val_loss: 4.7271 - val_mae: 1.1537\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 849us/step - loss: 4.3843 - mae: 1.1404 - val_loss: 4.9208 - val_mae: 1.2332\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 848us/step - loss: 4.4098 - mae: 1.1550 - val_loss: 4.9766 - val_mae: 1.0915\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 836us/step - loss: 4.4594 - mae: 1.1418 - val_loss: 4.8094 - val_mae: 1.1156\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 847us/step - loss: 4.3632 - mae: 1.1391 - val_loss: 4.8942 - val_mae: 1.1995\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 834us/step - loss: 4.4203 - mae: 1.1511 - val_loss: 4.8593 - val_mae: 1.0953\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 869us/step - loss: 4.4038 - mae: 1.1455 - val_loss: 5.0879 - val_mae: 1.1960\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 879us/step - loss: 4.4136 - mae: 1.1415 - val_loss: 4.9535 - val_mae: 1.0949\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 865us/step - loss: 4.3551 - mae: 1.1295 - val_loss: 4.9193 - val_mae: 1.1677\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 862us/step - loss: 4.2821 - mae: 1.1277 - val_loss: 4.8808 - val_mae: 1.1792\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 861us/step - loss: 4.2705 - mae: 1.1246 - val_loss: 4.8552 - val_mae: 1.1654\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 863us/step - loss: 4.2799 - mae: 1.1230 - val_loss: 5.4407 - val_mae: 1.2248\n",
      "Epoch 29: early stopping\n",
      "Test Loss (MSE): 4.8128838539123535, Test Mean Absolute Error (MAE): 1.1457834243774414\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 5.7714 - mae: 1.2426 - val_loss: 5.7141 - val_mae: 1.3262\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 901us/step - loss: 4.6970 - mae: 1.1791 - val_loss: 5.2210 - val_mae: 1.2287\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 866us/step - loss: 4.4560 - mae: 1.1811 - val_loss: 5.2960 - val_mae: 1.2914\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 880us/step - loss: 4.4119 - mae: 1.1832 - val_loss: 5.0588 - val_mae: 1.1564\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 919us/step - loss: 4.3950 - mae: 1.1668 - val_loss: 5.1106 - val_mae: 1.1028\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 970us/step - loss: 4.4311 - mae: 1.1759 - val_loss: 5.3047 - val_mae: 1.1000\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 896us/step - loss: 4.4303 - mae: 1.1806 - val_loss: 5.0607 - val_mae: 1.1728\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 954us/step - loss: 4.2885 - mae: 1.1700 - val_loss: 5.1310 - val_mae: 1.2034\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 4.3014 - mae: 1.1564 - val_loss: 5.1864 - val_mae: 1.0531\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 956us/step - loss: 4.2255 - mae: 1.1297 - val_loss: 5.2409 - val_mae: 1.3193\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 874us/step - loss: 4.3449 - mae: 1.1638 - val_loss: 5.1980 - val_mae: 1.1461\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 859us/step - loss: 4.2781 - mae: 1.1681 - val_loss: 5.1624 - val_mae: 1.1736\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 858us/step - loss: 4.2998 - mae: 1.1606 - val_loss: 5.2030 - val_mae: 1.2269\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 852us/step - loss: 4.1997 - mae: 1.1467 - val_loss: 5.1712 - val_mae: 1.1254\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 836us/step - loss: 4.1776 - mae: 1.1403 - val_loss: 5.1968 - val_mae: 1.0868\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 841us/step - loss: 4.2144 - mae: 1.1384 - val_loss: 5.1840 - val_mae: 1.1677\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 866us/step - loss: 4.4823 - mae: 1.1698 - val_loss: 5.3235 - val_mae: 1.1669\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 849us/step - loss: 4.2199 - mae: 1.1199 - val_loss: 5.2250 - val_mae: 1.1264\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 883us/step - loss: 4.3404 - mae: 1.1453 - val_loss: 5.2273 - val_mae: 1.1527\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 841us/step - loss: 4.1757 - mae: 1.1172 - val_loss: 5.3427 - val_mae: 1.2026\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 846us/step - loss: 4.1973 - mae: 1.1662 - val_loss: 5.3198 - val_mae: 1.1880\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 860us/step - loss: 4.1730 - mae: 1.1291 - val_loss: 5.3436 - val_mae: 1.3278\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 842us/step - loss: 4.1255 - mae: 1.1276 - val_loss: 5.2473 - val_mae: 1.1487\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 871us/step - loss: 4.1350 - mae: 1.1176 - val_loss: 5.2506 - val_mae: 1.1386\n",
      "Epoch 24: early stopping\n",
      "Test Loss (MSE): 4.768286228179932, Test Mean Absolute Error (MAE): 1.2112748622894287\n",
      "Epoch 1/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 9.4271 - mae: 1.8779 - val_loss: 8.7224 - val_mae: 2.0607\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 0s 881us/step - loss: 8.0435 - mae: 1.7961 - val_loss: 7.7497 - val_mae: 1.7585\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 849us/step - loss: 7.8906 - mae: 1.7910 - val_loss: 7.7849 - val_mae: 1.6772\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 860us/step - loss: 7.7568 - mae: 1.7500 - val_loss: 7.9022 - val_mae: 1.6847\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 0s 839us/step - loss: 7.6713 - mae: 1.7710 - val_loss: 7.8360 - val_mae: 1.6799\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 0s 819us/step - loss: 7.6385 - mae: 1.7537 - val_loss: 7.6993 - val_mae: 1.6794\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 842us/step - loss: 7.6312 - mae: 1.7556 - val_loss: 7.4918 - val_mae: 1.7880\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 810us/step - loss: 7.4672 - mae: 1.7438 - val_loss: 7.8118 - val_mae: 1.9829\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 862us/step - loss: 7.5483 - mae: 1.7510 - val_loss: 7.7339 - val_mae: 1.9127\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 0s 834us/step - loss: 7.5437 - mae: 1.7548 - val_loss: 7.6225 - val_mae: 1.6946\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 813us/step - loss: 7.4641 - mae: 1.7477 - val_loss: 7.7552 - val_mae: 1.6679\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 814us/step - loss: 7.4760 - mae: 1.7319 - val_loss: 7.5849 - val_mae: 1.8646\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 0s 783us/step - loss: 7.4661 - mae: 1.7724 - val_loss: 7.6605 - val_mae: 1.7046\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 0s 816us/step - loss: 7.6013 - mae: 1.7498 - val_loss: 7.7316 - val_mae: 1.6608\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 819us/step - loss: 7.4091 - mae: 1.7399 - val_loss: 7.5557 - val_mae: 1.7097\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 830us/step - loss: 7.4406 - mae: 1.7394 - val_loss: 7.4684 - val_mae: 1.7471\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 850us/step - loss: 7.4825 - mae: 1.7378 - val_loss: 7.5164 - val_mae: 1.7828\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 871us/step - loss: 7.3970 - mae: 1.7604 - val_loss: 7.7276 - val_mae: 1.6704\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 812us/step - loss: 7.4163 - mae: 1.7448 - val_loss: 7.8231 - val_mae: 1.6680\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 822us/step - loss: 7.4333 - mae: 1.7266 - val_loss: 7.5412 - val_mae: 1.7612\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 819us/step - loss: 7.3487 - mae: 1.7311 - val_loss: 7.6733 - val_mae: 1.8568\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 0s 810us/step - loss: 7.3851 - mae: 1.7572 - val_loss: 7.5096 - val_mae: 1.8180\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 0s 809us/step - loss: 7.3164 - mae: 1.7366 - val_loss: 7.5705 - val_mae: 1.8512\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 0s 856us/step - loss: 7.3344 - mae: 1.7418 - val_loss: 7.6031 - val_mae: 1.7120\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 0s 824us/step - loss: 7.3195 - mae: 1.7391 - val_loss: 7.5971 - val_mae: 1.8680\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 0s 814us/step - loss: 7.3307 - mae: 1.7423 - val_loss: 7.5684 - val_mae: 1.7750\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 0s 817us/step - loss: 7.2852 - mae: 1.7338 - val_loss: 7.5633 - val_mae: 1.7449\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 0s 825us/step - loss: 7.3042 - mae: 1.7389 - val_loss: 7.5761 - val_mae: 1.7639\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 0s 947us/step - loss: 7.3257 - mae: 1.7224 - val_loss: 7.5131 - val_mae: 1.7893\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 0s 824us/step - loss: 7.3867 - mae: 1.7338 - val_loss: 7.5714 - val_mae: 1.8156\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 0s 846us/step - loss: 7.2511 - mae: 1.7296 - val_loss: 7.4782 - val_mae: 1.7927\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 0s 809us/step - loss: 7.2540 - mae: 1.7133 - val_loss: 7.5346 - val_mae: 1.7911\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 0s 833us/step - loss: 7.3147 - mae: 1.7314 - val_loss: 7.5115 - val_mae: 1.7731\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 0s 857us/step - loss: 7.3285 - mae: 1.7395 - val_loss: 7.5520 - val_mae: 1.7256\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 0s 890us/step - loss: 7.2313 - mae: 1.7341 - val_loss: 7.6214 - val_mae: 1.7259\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 0s 890us/step - loss: 7.2462 - mae: 1.7119 - val_loss: 7.6194 - val_mae: 1.7192\n",
      "Epoch 36: early stopping\n",
      "Test Loss (MSE): 6.47878360748291, Test Mean Absolute Error (MAE): 1.623714804649353\n",
      "Epoch 1/100\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 8.9676 - mae: 1.8105 - val_loss: 8.4962 - val_mae: 1.6885\n",
      "Epoch 2/100\n",
      "78/78 [==============================] - 0s 949us/step - loss: 7.9137 - mae: 1.7668 - val_loss: 8.3643 - val_mae: 1.9913\n",
      "Epoch 3/100\n",
      "78/78 [==============================] - 0s 970us/step - loss: 7.5402 - mae: 1.7467 - val_loss: 7.9567 - val_mae: 1.7661\n",
      "Epoch 4/100\n",
      "78/78 [==============================] - 0s 940us/step - loss: 7.5090 - mae: 1.7434 - val_loss: 7.7771 - val_mae: 1.7184\n",
      "Epoch 5/100\n",
      "78/78 [==============================] - 0s 890us/step - loss: 7.3130 - mae: 1.7294 - val_loss: 7.8705 - val_mae: 1.7708\n",
      "Epoch 6/100\n",
      "78/78 [==============================] - 0s 878us/step - loss: 7.3343 - mae: 1.7556 - val_loss: 7.7720 - val_mae: 1.6995\n",
      "Epoch 7/100\n",
      "78/78 [==============================] - 0s 938us/step - loss: 7.3188 - mae: 1.7373 - val_loss: 7.6951 - val_mae: 1.7608\n",
      "Epoch 8/100\n",
      "78/78 [==============================] - 0s 891us/step - loss: 7.1307 - mae: 1.7324 - val_loss: 7.7553 - val_mae: 1.7364\n",
      "Epoch 9/100\n",
      "78/78 [==============================] - 0s 849us/step - loss: 7.1727 - mae: 1.7202 - val_loss: 7.7964 - val_mae: 1.7337\n",
      "Epoch 10/100\n",
      "78/78 [==============================] - 0s 864us/step - loss: 7.1166 - mae: 1.7376 - val_loss: 8.0314 - val_mae: 1.6719\n",
      "Epoch 11/100\n",
      "78/78 [==============================] - 0s 832us/step - loss: 7.1302 - mae: 1.7127 - val_loss: 7.7231 - val_mae: 1.7677\n",
      "Epoch 12/100\n",
      "78/78 [==============================] - 0s 843us/step - loss: 7.0120 - mae: 1.7141 - val_loss: 7.8133 - val_mae: 1.7196\n",
      "Epoch 13/100\n",
      "78/78 [==============================] - 0s 876us/step - loss: 7.0314 - mae: 1.7244 - val_loss: 7.9363 - val_mae: 1.6804\n",
      "Epoch 14/100\n",
      "78/78 [==============================] - 0s 870us/step - loss: 7.0890 - mae: 1.6988 - val_loss: 7.9905 - val_mae: 1.9343\n",
      "Epoch 15/100\n",
      "78/78 [==============================] - 0s 910us/step - loss: 7.0532 - mae: 1.7340 - val_loss: 8.0783 - val_mae: 1.9256\n",
      "Epoch 16/100\n",
      "78/78 [==============================] - 0s 885us/step - loss: 6.9512 - mae: 1.7135 - val_loss: 7.7558 - val_mae: 1.7897\n",
      "Epoch 17/100\n",
      "78/78 [==============================] - 0s 909us/step - loss: 6.9545 - mae: 1.6987 - val_loss: 8.8460 - val_mae: 2.0865\n",
      "Epoch 18/100\n",
      "78/78 [==============================] - 0s 873us/step - loss: 6.9846 - mae: 1.7202 - val_loss: 7.9899 - val_mae: 1.8230\n",
      "Epoch 19/100\n",
      "78/78 [==============================] - 0s 927us/step - loss: 6.8997 - mae: 1.7049 - val_loss: 8.0872 - val_mae: 1.9191\n",
      "Epoch 20/100\n",
      "78/78 [==============================] - 0s 850us/step - loss: 6.8709 - mae: 1.6931 - val_loss: 7.8953 - val_mae: 1.7290\n",
      "Epoch 21/100\n",
      "78/78 [==============================] - 0s 860us/step - loss: 6.8497 - mae: 1.6794 - val_loss: 8.3046 - val_mae: 2.0344\n",
      "Epoch 22/100\n",
      "78/78 [==============================] - 0s 867us/step - loss: 6.8609 - mae: 1.7155 - val_loss: 7.9226 - val_mae: 1.7534\n",
      "Epoch 23/100\n",
      "78/78 [==============================] - 0s 875us/step - loss: 6.7224 - mae: 1.6642 - val_loss: 8.0711 - val_mae: 1.8287\n",
      "Epoch 24/100\n",
      "78/78 [==============================] - 0s 903us/step - loss: 6.6912 - mae: 1.6815 - val_loss: 8.1266 - val_mae: 1.8117\n",
      "Epoch 25/100\n",
      "78/78 [==============================] - 0s 909us/step - loss: 7.0832 - mae: 1.7142 - val_loss: 8.2211 - val_mae: 1.7707\n",
      "Epoch 26/100\n",
      "78/78 [==============================] - 0s 875us/step - loss: 6.6116 - mae: 1.6583 - val_loss: 8.1704 - val_mae: 1.7349\n",
      "Epoch 27/100\n",
      "78/78 [==============================] - 0s 903us/step - loss: 6.6086 - mae: 1.6492 - val_loss: 8.1852 - val_mae: 1.8257\n",
      "Epoch 27: early stopping\n",
      "Test Loss (MSE): 7.826010227203369, Test Mean Absolute Error (MAE): 1.7936173677444458\n",
      "Epoch 1/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 9.4649 - mae: 1.8570 - val_loss: 7.1207 - val_mae: 1.6406\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 0s 943us/step - loss: 8.2637 - mae: 1.8217 - val_loss: 7.0412 - val_mae: 1.5627\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 8.0175 - mae: 1.7834 - val_loss: 6.6954 - val_mae: 1.6937\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 955us/step - loss: 7.8893 - mae: 1.7916 - val_loss: 6.7275 - val_mae: 1.7432\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 0s 951us/step - loss: 7.8452 - mae: 1.7744 - val_loss: 6.6956 - val_mae: 1.7060\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 0s 908us/step - loss: 7.7427 - mae: 1.7702 - val_loss: 6.9709 - val_mae: 1.6169\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.5343 - mae: 1.7409 - val_loss: 6.7642 - val_mae: 1.7494\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 939us/step - loss: 7.6986 - mae: 1.7715 - val_loss: 6.6834 - val_mae: 1.6695\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 922us/step - loss: 7.5813 - mae: 1.7475 - val_loss: 6.6957 - val_mae: 1.6910\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 0s 920us/step - loss: 7.5889 - mae: 1.7392 - val_loss: 7.0074 - val_mae: 1.8572\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.4001 - mae: 1.7340 - val_loss: 7.0171 - val_mae: 1.6015\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 911us/step - loss: 7.4712 - mae: 1.7477 - val_loss: 6.8797 - val_mae: 1.6579\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 0s 946us/step - loss: 7.2703 - mae: 1.7210 - val_loss: 7.0485 - val_mae: 1.6827\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 0s 924us/step - loss: 7.2810 - mae: 1.7083 - val_loss: 6.9512 - val_mae: 1.5849\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 934us/step - loss: 7.0689 - mae: 1.6842 - val_loss: 7.0643 - val_mae: 1.6028\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 905us/step - loss: 7.0382 - mae: 1.6929 - val_loss: 7.0673 - val_mae: 1.6402\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 908us/step - loss: 6.9815 - mae: 1.6634 - val_loss: 7.0016 - val_mae: 1.6176\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 6.9108 - mae: 1.6650 - val_loss: 7.7535 - val_mae: 1.6935\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 944us/step - loss: 6.7943 - mae: 1.6244 - val_loss: 7.7840 - val_mae: 1.6418\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 925us/step - loss: 6.5008 - mae: 1.5949 - val_loss: 7.4141 - val_mae: 1.6550\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 911us/step - loss: 6.5031 - mae: 1.5857 - val_loss: 7.6704 - val_mae: 1.7647\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 0s 940us/step - loss: 6.3831 - mae: 1.5930 - val_loss: 7.5937 - val_mae: 1.6994\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 0s 923us/step - loss: 6.3703 - mae: 1.5721 - val_loss: 7.6676 - val_mae: 1.6979\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 0s 901us/step - loss: 6.2333 - mae: 1.5623 - val_loss: 7.9861 - val_mae: 1.7357\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 0s 945us/step - loss: 6.1575 - mae: 1.5452 - val_loss: 8.1728 - val_mae: 1.7495\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 0s 951us/step - loss: 5.9451 - mae: 1.4955 - val_loss: 8.2886 - val_mae: 1.7554\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 0s 925us/step - loss: 5.9570 - mae: 1.5017 - val_loss: 8.8225 - val_mae: 1.8673\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 0s 966us/step - loss: 6.1265 - mae: 1.5255 - val_loss: 8.5963 - val_mae: 1.7194\n",
      "Epoch 28: early stopping\n",
      "Test Loss (MSE): 10.06684684753418, Test Mean Absolute Error (MAE): 1.8417370319366455\n",
      "Epoch 1/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 9.8507 - mae: 1.8952 - val_loss: 7.5752 - val_mae: 1.7795\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 0s 947us/step - loss: 8.6208 - mae: 1.8123 - val_loss: 7.2390 - val_mae: 1.8090\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 994us/step - loss: 8.1317 - mae: 1.7863 - val_loss: 7.0154 - val_mae: 1.6126\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 919us/step - loss: 7.9737 - mae: 1.7961 - val_loss: 6.8823 - val_mae: 1.6042\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 0s 916us/step - loss: 7.8574 - mae: 1.7658 - val_loss: 6.8042 - val_mae: 1.7637\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 0s 933us/step - loss: 7.9815 - mae: 1.8053 - val_loss: 6.9755 - val_mae: 1.8282\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 901us/step - loss: 7.7727 - mae: 1.7681 - val_loss: 6.6576 - val_mae: 1.6401\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 887us/step - loss: 7.6376 - mae: 1.7712 - val_loss: 6.7454 - val_mae: 1.6885\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 971us/step - loss: 7.5995 - mae: 1.7614 - val_loss: 7.0041 - val_mae: 1.7369\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 0s 939us/step - loss: 7.3566 - mae: 1.7358 - val_loss: 7.2081 - val_mae: 1.7097\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 909us/step - loss: 7.5677 - mae: 1.7349 - val_loss: 8.0271 - val_mae: 2.0026\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 907us/step - loss: 7.4354 - mae: 1.7214 - val_loss: 7.6024 - val_mae: 1.8008\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 0s 882us/step - loss: 7.2736 - mae: 1.7053 - val_loss: 7.4717 - val_mae: 1.6193\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 0s 903us/step - loss: 7.1139 - mae: 1.6587 - val_loss: 8.1924 - val_mae: 1.8274\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 957us/step - loss: 6.9201 - mae: 1.6397 - val_loss: 8.0106 - val_mae: 1.8064\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 953us/step - loss: 6.7389 - mae: 1.6267 - val_loss: 7.8231 - val_mae: 1.6599\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 918us/step - loss: 6.6926 - mae: 1.6050 - val_loss: 8.4553 - val_mae: 1.7241\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 6.4695 - mae: 1.5974 - val_loss: 8.2766 - val_mae: 1.6960\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 6.6491 - mae: 1.6017 - val_loss: 8.3356 - val_mae: 1.7752\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 944us/step - loss: 6.8196 - mae: 1.6094 - val_loss: 9.0868 - val_mae: 1.7924\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 920us/step - loss: 6.5177 - mae: 1.5651 - val_loss: 9.8815 - val_mae: 1.9089\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 0s 916us/step - loss: 6.4204 - mae: 1.5452 - val_loss: 8.8211 - val_mae: 1.8698\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 0s 925us/step - loss: 6.1649 - mae: 1.5089 - val_loss: 9.2427 - val_mae: 1.8401\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 0s 927us/step - loss: 6.1269 - mae: 1.5078 - val_loss: 9.2268 - val_mae: 1.8001\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 0s 905us/step - loss: 5.8878 - mae: 1.4917 - val_loss: 10.1867 - val_mae: 1.8811\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 0s 884us/step - loss: 5.6780 - mae: 1.4414 - val_loss: 9.7215 - val_mae: 1.8439\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 0s 898us/step - loss: 5.8842 - mae: 1.4779 - val_loss: 9.6882 - val_mae: 1.8810\n",
      "Epoch 27: early stopping\n",
      "Test Loss (MSE): 9.576148986816406, Test Mean Absolute Error (MAE): 1.9211019277572632\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 4.9400 - mae: 1.1569 - val_loss: 5.3663 - val_mae: 1.2609\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 836us/step - loss: 4.4437 - mae: 1.1359 - val_loss: 5.5237 - val_mae: 1.4214\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 770us/step - loss: 4.3256 - mae: 1.1063 - val_loss: 5.6170 - val_mae: 1.4147\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 770us/step - loss: 4.3901 - mae: 1.1259 - val_loss: 5.2682 - val_mae: 1.2898\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 769us/step - loss: 4.3353 - mae: 1.0958 - val_loss: 5.2888 - val_mae: 1.1888\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 784us/step - loss: 4.2981 - mae: 1.1027 - val_loss: 5.1608 - val_mae: 1.2314\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 795us/step - loss: 4.2233 - mae: 1.0805 - val_loss: 5.1886 - val_mae: 1.2392\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 795us/step - loss: 4.2782 - mae: 1.0999 - val_loss: 5.1957 - val_mae: 1.2049\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 822us/step - loss: 4.2367 - mae: 1.0909 - val_loss: 5.2054 - val_mae: 1.2030\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 896us/step - loss: 4.2044 - mae: 1.0875 - val_loss: 5.1373 - val_mae: 1.2826\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 830us/step - loss: 4.2204 - mae: 1.0802 - val_loss: 5.1219 - val_mae: 1.2665\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 946us/step - loss: 4.2614 - mae: 1.0945 - val_loss: 5.1400 - val_mae: 1.2274\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 907us/step - loss: 4.2041 - mae: 1.0884 - val_loss: 5.3426 - val_mae: 1.2109\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 850us/step - loss: 4.2464 - mae: 1.1005 - val_loss: 5.2253 - val_mae: 1.3260\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 962us/step - loss: 4.1938 - mae: 1.0883 - val_loss: 5.1499 - val_mae: 1.2763\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 879us/step - loss: 4.1857 - mae: 1.0822 - val_loss: 5.1221 - val_mae: 1.2315\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 864us/step - loss: 4.1788 - mae: 1.0875 - val_loss: 5.1289 - val_mae: 1.2587\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 846us/step - loss: 4.1822 - mae: 1.0789 - val_loss: 5.1278 - val_mae: 1.2903\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 786us/step - loss: 4.1754 - mae: 1.0879 - val_loss: 5.1221 - val_mae: 1.2646\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 770us/step - loss: 4.2162 - mae: 1.0863 - val_loss: 5.1298 - val_mae: 1.2305\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 811us/step - loss: 4.1644 - mae: 1.0772 - val_loss: 5.2583 - val_mae: 1.1621\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 772us/step - loss: 4.1452 - mae: 1.0862 - val_loss: 5.1676 - val_mae: 1.2094\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 780us/step - loss: 4.1813 - mae: 1.0808 - val_loss: 5.1273 - val_mae: 1.2220\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 783us/step - loss: 4.1454 - mae: 1.0782 - val_loss: 5.1732 - val_mae: 1.2874\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 749us/step - loss: 4.1592 - mae: 1.0856 - val_loss: 5.1498 - val_mae: 1.2286\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 784us/step - loss: 4.1400 - mae: 1.0725 - val_loss: 5.1636 - val_mae: 1.3009\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 762us/step - loss: 4.1481 - mae: 1.0836 - val_loss: 5.2031 - val_mae: 1.1851\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 807us/step - loss: 4.1327 - mae: 1.0679 - val_loss: 5.2299 - val_mae: 1.3044\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 773us/step - loss: 4.1523 - mae: 1.0847 - val_loss: 5.1317 - val_mae: 1.2699\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 773us/step - loss: 4.1302 - mae: 1.0702 - val_loss: 5.1538 - val_mae: 1.2115\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 770us/step - loss: 4.1537 - mae: 1.0939 - val_loss: 5.2036 - val_mae: 1.1795\n",
      "Epoch 31: early stopping\n",
      "Test Loss (MSE): 4.437637805938721, Test Mean Absolute Error (MAE): 1.0135043859481812\n",
      "Epoch 1/100\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 6.0447 - mae: 1.2443 - val_loss: 4.8501 - val_mae: 1.0653\n",
      "Epoch 2/100\n",
      "133/133 [==============================] - 0s 1ms/step - loss: 5.1365 - mae: 1.1859 - val_loss: 4.3237 - val_mae: 1.1662\n",
      "Epoch 3/100\n",
      "133/133 [==============================] - 0s 938us/step - loss: 4.9871 - mae: 1.1827 - val_loss: 4.2094 - val_mae: 1.1209\n",
      "Epoch 4/100\n",
      "133/133 [==============================] - 0s 841us/step - loss: 4.9297 - mae: 1.1674 - val_loss: 4.2685 - val_mae: 1.2283\n",
      "Epoch 5/100\n",
      "133/133 [==============================] - 0s 846us/step - loss: 4.9354 - mae: 1.1715 - val_loss: 4.3424 - val_mae: 1.0255\n",
      "Epoch 6/100\n",
      "133/133 [==============================] - 0s 913us/step - loss: 5.0199 - mae: 1.1735 - val_loss: 4.3354 - val_mae: 1.3214\n",
      "Epoch 7/100\n",
      "133/133 [==============================] - 0s 892us/step - loss: 4.8092 - mae: 1.1722 - val_loss: 4.2025 - val_mae: 1.1694\n",
      "Epoch 8/100\n",
      "133/133 [==============================] - 0s 881us/step - loss: 4.8283 - mae: 1.1641 - val_loss: 4.3204 - val_mae: 1.1874\n",
      "Epoch 9/100\n",
      "133/133 [==============================] - 0s 899us/step - loss: 4.7569 - mae: 1.1433 - val_loss: 4.5295 - val_mae: 1.2509\n",
      "Epoch 10/100\n",
      "133/133 [==============================] - 0s 981us/step - loss: 4.8190 - mae: 1.1526 - val_loss: 4.2139 - val_mae: 1.1996\n",
      "Epoch 11/100\n",
      "133/133 [==============================] - 0s 931us/step - loss: 4.7916 - mae: 1.1677 - val_loss: 4.3495 - val_mae: 1.1968\n",
      "Epoch 12/100\n",
      "133/133 [==============================] - 0s 987us/step - loss: 4.7955 - mae: 1.1548 - val_loss: 4.3108 - val_mae: 1.1197\n",
      "Epoch 13/100\n",
      "133/133 [==============================] - 0s 966us/step - loss: 4.7713 - mae: 1.1429 - val_loss: 4.3559 - val_mae: 1.2733\n",
      "Epoch 14/100\n",
      "133/133 [==============================] - 0s 953us/step - loss: 4.7227 - mae: 1.1483 - val_loss: 4.3029 - val_mae: 1.1632\n",
      "Epoch 15/100\n",
      "133/133 [==============================] - 0s 946us/step - loss: 4.7277 - mae: 1.1586 - val_loss: 4.2860 - val_mae: 1.1616\n",
      "Epoch 16/100\n",
      "133/133 [==============================] - 0s 866us/step - loss: 4.6582 - mae: 1.1373 - val_loss: 4.3356 - val_mae: 1.1343\n",
      "Epoch 17/100\n",
      "133/133 [==============================] - 0s 846us/step - loss: 4.6403 - mae: 1.1359 - val_loss: 4.3905 - val_mae: 1.1341\n",
      "Epoch 18/100\n",
      "133/133 [==============================] - 0s 838us/step - loss: 4.6256 - mae: 1.1403 - val_loss: 4.5199 - val_mae: 1.2540\n",
      "Epoch 19/100\n",
      "133/133 [==============================] - 0s 908us/step - loss: 4.6753 - mae: 1.1466 - val_loss: 4.3828 - val_mae: 1.1459\n",
      "Epoch 20/100\n",
      "133/133 [==============================] - 0s 860us/step - loss: 4.6655 - mae: 1.1351 - val_loss: 4.3876 - val_mae: 1.1904\n",
      "Epoch 21/100\n",
      "133/133 [==============================] - 0s 869us/step - loss: 4.6267 - mae: 1.1321 - val_loss: 4.4438 - val_mae: 1.1955\n",
      "Epoch 22/100\n",
      "133/133 [==============================] - 0s 842us/step - loss: 4.6544 - mae: 1.1235 - val_loss: 4.4286 - val_mae: 1.0991\n",
      "Epoch 23/100\n",
      "133/133 [==============================] - 0s 860us/step - loss: 4.6662 - mae: 1.1414 - val_loss: 4.3560 - val_mae: 1.1158\n",
      "Epoch 24/100\n",
      "133/133 [==============================] - 0s 911us/step - loss: 4.5734 - mae: 1.1307 - val_loss: 4.7324 - val_mae: 1.2773\n",
      "Epoch 25/100\n",
      "133/133 [==============================] - 0s 879us/step - loss: 4.5657 - mae: 1.1398 - val_loss: 4.5943 - val_mae: 1.2376\n",
      "Epoch 26/100\n",
      "133/133 [==============================] - 0s 843us/step - loss: 4.5323 - mae: 1.1108 - val_loss: 4.7970 - val_mae: 1.2555\n",
      "Epoch 27/100\n",
      "133/133 [==============================] - 0s 839us/step - loss: 4.5448 - mae: 1.1220 - val_loss: 4.4645 - val_mae: 1.2098\n",
      "Epoch 27: early stopping\n",
      "Test Loss (MSE): 4.1649956703186035, Test Mean Absolute Error (MAE): 1.1243360042572021\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 5.5568 - mae: 1.1797 - val_loss: 5.5746 - val_mae: 1.2252\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 934us/step - loss: 4.5154 - mae: 1.1183 - val_loss: 5.3382 - val_mae: 1.1995\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 888us/step - loss: 4.2468 - mae: 1.1084 - val_loss: 5.3126 - val_mae: 1.1462\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 908us/step - loss: 4.1420 - mae: 1.0730 - val_loss: 5.2107 - val_mae: 1.2997\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 911us/step - loss: 4.1699 - mae: 1.1011 - val_loss: 5.2547 - val_mae: 1.1829\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 957us/step - loss: 4.0377 - mae: 1.0688 - val_loss: 5.2183 - val_mae: 1.1317\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 3.9665 - mae: 1.0735 - val_loss: 5.3301 - val_mae: 1.1158\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 974us/step - loss: 3.9599 - mae: 1.0650 - val_loss: 5.2374 - val_mae: 1.2344\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 881us/step - loss: 3.9870 - mae: 1.0748 - val_loss: 5.6751 - val_mae: 1.1275\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 879us/step - loss: 4.0326 - mae: 1.0667 - val_loss: 5.3929 - val_mae: 1.2483\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 974us/step - loss: 3.9108 - mae: 1.0557 - val_loss: 5.3872 - val_mae: 1.3208\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 861us/step - loss: 3.8322 - mae: 1.0553 - val_loss: 5.4402 - val_mae: 1.2111\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 880us/step - loss: 3.8761 - mae: 1.0385 - val_loss: 5.4389 - val_mae: 1.2060\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 883us/step - loss: 3.8509 - mae: 1.0505 - val_loss: 5.9353 - val_mae: 1.1946\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 848us/step - loss: 3.8091 - mae: 1.0389 - val_loss: 5.5981 - val_mae: 1.1995\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 870us/step - loss: 3.8656 - mae: 1.0484 - val_loss: 5.4620 - val_mae: 1.2246\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 977us/step - loss: 3.7622 - mae: 1.0126 - val_loss: 5.7770 - val_mae: 1.2366\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 865us/step - loss: 3.6986 - mae: 1.0082 - val_loss: 6.0196 - val_mae: 1.3012\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 870us/step - loss: 3.6683 - mae: 1.0144 - val_loss: 5.6794 - val_mae: 1.2320\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 866us/step - loss: 3.8379 - mae: 1.0257 - val_loss: 5.7167 - val_mae: 1.2010\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 848us/step - loss: 3.6129 - mae: 0.9996 - val_loss: 5.7803 - val_mae: 1.2265\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 875us/step - loss: 3.5320 - mae: 0.9971 - val_loss: 5.8494 - val_mae: 1.2505\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 874us/step - loss: 3.5640 - mae: 0.9895 - val_loss: 6.0137 - val_mae: 1.2581\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 847us/step - loss: 3.4512 - mae: 0.9861 - val_loss: 5.9540 - val_mae: 1.2651\n",
      "Epoch 24: early stopping\n",
      "Test Loss (MSE): 5.900315284729004, Test Mean Absolute Error (MAE): 1.2854987382888794\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 5.8350 - mae: 1.2098 - val_loss: 4.6248 - val_mae: 1.1705\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 974us/step - loss: 4.9214 - mae: 1.1679 - val_loss: 4.5001 - val_mae: 1.1509\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 921us/step - loss: 4.9320 - mae: 1.1693 - val_loss: 4.3615 - val_mae: 1.1782\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 4.7163 - mae: 1.1560 - val_loss: 4.4084 - val_mae: 1.0496\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 991us/step - loss: 4.7246 - mae: 1.1396 - val_loss: 4.3563 - val_mae: 1.1780\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 4.5843 - mae: 1.1231 - val_loss: 4.4795 - val_mae: 1.1130\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 963us/step - loss: 4.6481 - mae: 1.1180 - val_loss: 4.3899 - val_mae: 1.1514\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 4.5949 - mae: 1.1164 - val_loss: 4.5884 - val_mae: 1.2373\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 4.6281 - mae: 1.1274 - val_loss: 4.4545 - val_mae: 1.1887\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 4.5456 - mae: 1.1175 - val_loss: 4.5378 - val_mae: 1.1597\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 919us/step - loss: 4.5260 - mae: 1.1156 - val_loss: 4.4335 - val_mae: 1.0988\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 894us/step - loss: 4.4584 - mae: 1.1169 - val_loss: 4.5769 - val_mae: 1.1546\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 927us/step - loss: 4.4477 - mae: 1.1047 - val_loss: 4.5503 - val_mae: 1.0892\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 919us/step - loss: 4.3649 - mae: 1.0921 - val_loss: 4.8074 - val_mae: 1.1513\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 886us/step - loss: 4.3591 - mae: 1.0949 - val_loss: 4.7560 - val_mae: 1.1307\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 891us/step - loss: 4.2901 - mae: 1.0939 - val_loss: 4.6978 - val_mae: 1.1239\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 893us/step - loss: 4.2662 - mae: 1.0629 - val_loss: 4.9730 - val_mae: 1.2374\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 869us/step - loss: 4.5610 - mae: 1.1347 - val_loss: 4.9351 - val_mae: 1.1177\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 924us/step - loss: 4.1943 - mae: 1.0775 - val_loss: 5.0268 - val_mae: 1.1345\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 877us/step - loss: 4.1252 - mae: 1.0642 - val_loss: 5.0569 - val_mae: 1.1957\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 867us/step - loss: 4.0526 - mae: 1.0562 - val_loss: 5.1989 - val_mae: 1.1703\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 891us/step - loss: 4.0098 - mae: 1.0542 - val_loss: 5.5432 - val_mae: 1.2015\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 892us/step - loss: 4.0233 - mae: 1.0363 - val_loss: 5.3943 - val_mae: 1.2489\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 912us/step - loss: 4.0317 - mae: 1.0505 - val_loss: 5.2897 - val_mae: 1.1827\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 871us/step - loss: 4.0066 - mae: 1.0396 - val_loss: 5.3748 - val_mae: 1.1831\n",
      "Epoch 25: early stopping\n",
      "Test Loss (MSE): 5.75963020324707, Test Mean Absolute Error (MAE): 1.1756006479263306\n",
      "Epoch 1/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 8.6545 - mae: 1.8203 - val_loss: 8.2249 - val_mae: 1.7823\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 0s 858us/step - loss: 7.4468 - mae: 1.7495 - val_loss: 8.0884 - val_mae: 1.9425\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 862us/step - loss: 7.3545 - mae: 1.7476 - val_loss: 7.8604 - val_mae: 1.7304\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 900us/step - loss: 7.1829 - mae: 1.7198 - val_loss: 7.8093 - val_mae: 1.7249\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 0s 794us/step - loss: 7.1667 - mae: 1.7251 - val_loss: 7.6436 - val_mae: 1.8104\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 0s 768us/step - loss: 7.0877 - mae: 1.7303 - val_loss: 7.8468 - val_mae: 1.7177\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 812us/step - loss: 7.1816 - mae: 1.7296 - val_loss: 7.6892 - val_mae: 1.7541\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 817us/step - loss: 7.0559 - mae: 1.7189 - val_loss: 7.8332 - val_mae: 1.9321\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 801us/step - loss: 7.0151 - mae: 1.7120 - val_loss: 7.6387 - val_mae: 1.7900\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 0s 812us/step - loss: 6.9925 - mae: 1.7129 - val_loss: 7.6515 - val_mae: 1.8668\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 816us/step - loss: 7.0300 - mae: 1.6993 - val_loss: 7.6766 - val_mae: 1.7529\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 809us/step - loss: 6.9929 - mae: 1.7207 - val_loss: 7.7057 - val_mae: 1.7499\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 0s 823us/step - loss: 7.0359 - mae: 1.7140 - val_loss: 7.6758 - val_mae: 1.7573\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 0s 865us/step - loss: 7.0296 - mae: 1.7295 - val_loss: 7.6470 - val_mae: 1.7854\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 827us/step - loss: 7.0809 - mae: 1.7048 - val_loss: 7.6857 - val_mae: 1.8073\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 832us/step - loss: 6.9624 - mae: 1.7194 - val_loss: 7.7549 - val_mae: 1.7034\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 815us/step - loss: 6.9732 - mae: 1.7150 - val_loss: 7.6408 - val_mae: 1.7876\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 837us/step - loss: 7.0315 - mae: 1.7219 - val_loss: 7.7024 - val_mae: 1.8488\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 791us/step - loss: 6.9609 - mae: 1.7261 - val_loss: 7.8032 - val_mae: 1.8991\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 859us/step - loss: 6.9394 - mae: 1.7129 - val_loss: 7.8052 - val_mae: 1.9078\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 845us/step - loss: 6.9654 - mae: 1.7175 - val_loss: 7.8760 - val_mae: 1.6618\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 0s 821us/step - loss: 6.9293 - mae: 1.6990 - val_loss: 7.6708 - val_mae: 1.8763\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 0s 836us/step - loss: 6.9623 - mae: 1.7348 - val_loss: 7.6092 - val_mae: 1.7503\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 0s 813us/step - loss: 6.9362 - mae: 1.7020 - val_loss: 7.6643 - val_mae: 1.8015\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 0s 859us/step - loss: 6.8801 - mae: 1.7115 - val_loss: 7.6846 - val_mae: 1.7564\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 6.8919 - mae: 1.7167 - val_loss: 7.6561 - val_mae: 1.7810\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 0s 874us/step - loss: 6.9571 - mae: 1.7123 - val_loss: 7.6632 - val_mae: 1.8101\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 0s 880us/step - loss: 6.8829 - mae: 1.7030 - val_loss: 7.6728 - val_mae: 1.8116\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 0s 864us/step - loss: 6.8641 - mae: 1.7058 - val_loss: 7.7200 - val_mae: 1.7814\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 0s 887us/step - loss: 6.8477 - mae: 1.7061 - val_loss: 7.8024 - val_mae: 1.7130\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 0s 959us/step - loss: 6.9170 - mae: 1.6961 - val_loss: 7.6987 - val_mae: 1.7849\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 0s 812us/step - loss: 6.8630 - mae: 1.7067 - val_loss: 7.7350 - val_mae: 1.7956\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 0s 901us/step - loss: 6.8873 - mae: 1.6988 - val_loss: 7.7993 - val_mae: 1.8358\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 0s 809us/step - loss: 6.8697 - mae: 1.7085 - val_loss: 7.8383 - val_mae: 1.7448\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 0s 944us/step - loss: 6.8596 - mae: 1.6973 - val_loss: 7.7480 - val_mae: 1.7758\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 0s 853us/step - loss: 6.8344 - mae: 1.7058 - val_loss: 7.8041 - val_mae: 1.7888\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 0s 841us/step - loss: 6.8650 - mae: 1.6903 - val_loss: 7.7613 - val_mae: 1.7374\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 0s 880us/step - loss: 6.8641 - mae: 1.7187 - val_loss: 7.9923 - val_mae: 1.6975\n",
      "Epoch 39/100\n",
      "77/77 [==============================] - 0s 923us/step - loss: 6.7683 - mae: 1.6781 - val_loss: 8.2797 - val_mae: 1.9821\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 0s 867us/step - loss: 6.8524 - mae: 1.7110 - val_loss: 7.7459 - val_mae: 1.7786\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 0s 849us/step - loss: 6.7665 - mae: 1.6955 - val_loss: 7.8725 - val_mae: 1.7723\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 0s 903us/step - loss: 6.7831 - mae: 1.6801 - val_loss: 7.9967 - val_mae: 1.8747\n",
      "Epoch 43/100\n",
      "77/77 [==============================] - 0s 892us/step - loss: 6.8040 - mae: 1.6958 - val_loss: 7.8966 - val_mae: 1.8169\n",
      "Epoch 43: early stopping\n",
      "Test Loss (MSE): 7.861507892608643, Test Mean Absolute Error (MAE): 1.786019206047058\n",
      "Epoch 1/100\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 8.8317 - mae: 1.8003 - val_loss: 8.5357 - val_mae: 1.6419\n",
      "Epoch 2/100\n",
      "78/78 [==============================] - 0s 901us/step - loss: 7.3672 - mae: 1.7132 - val_loss: 7.7973 - val_mae: 1.8165\n",
      "Epoch 3/100\n",
      "78/78 [==============================] - 0s 922us/step - loss: 7.0606 - mae: 1.7008 - val_loss: 7.4724 - val_mae: 1.6893\n",
      "Epoch 4/100\n",
      "78/78 [==============================] - 0s 947us/step - loss: 7.3612 - mae: 1.7379 - val_loss: 7.4658 - val_mae: 1.7709\n",
      "Epoch 5/100\n",
      "78/78 [==============================] - 0s 940us/step - loss: 7.0697 - mae: 1.7398 - val_loss: 7.3799 - val_mae: 1.6923\n",
      "Epoch 6/100\n",
      "78/78 [==============================] - 0s 892us/step - loss: 6.8331 - mae: 1.6749 - val_loss: 7.5690 - val_mae: 1.6382\n",
      "Epoch 7/100\n",
      "78/78 [==============================] - 0s 911us/step - loss: 6.7109 - mae: 1.6568 - val_loss: 7.4391 - val_mae: 1.6623\n",
      "Epoch 8/100\n",
      "78/78 [==============================] - 0s 912us/step - loss: 6.7487 - mae: 1.6595 - val_loss: 7.4909 - val_mae: 1.6365\n",
      "Epoch 9/100\n",
      "78/78 [==============================] - 0s 918us/step - loss: 6.6367 - mae: 1.6656 - val_loss: 7.3662 - val_mae: 1.6998\n",
      "Epoch 10/100\n",
      "78/78 [==============================] - 0s 875us/step - loss: 6.7719 - mae: 1.6818 - val_loss: 7.3676 - val_mae: 1.6570\n",
      "Epoch 11/100\n",
      "78/78 [==============================] - 0s 890us/step - loss: 6.6031 - mae: 1.6417 - val_loss: 7.4282 - val_mae: 1.7915\n",
      "Epoch 12/100\n",
      "78/78 [==============================] - 0s 866us/step - loss: 6.6656 - mae: 1.6684 - val_loss: 7.3939 - val_mae: 1.6531\n",
      "Epoch 13/100\n",
      "78/78 [==============================] - 0s 883us/step - loss: 6.6280 - mae: 1.6707 - val_loss: 7.3820 - val_mae: 1.6792\n",
      "Epoch 14/100\n",
      "78/78 [==============================] - 0s 883us/step - loss: 6.5601 - mae: 1.6578 - val_loss: 7.3623 - val_mae: 1.6835\n",
      "Epoch 15/100\n",
      "78/78 [==============================] - 0s 913us/step - loss: 6.6872 - mae: 1.6551 - val_loss: 7.5577 - val_mae: 1.8611\n",
      "Epoch 16/100\n",
      "78/78 [==============================] - 0s 973us/step - loss: 6.6106 - mae: 1.6659 - val_loss: 7.4612 - val_mae: 1.6930\n",
      "Epoch 17/100\n",
      "78/78 [==============================] - 0s 921us/step - loss: 6.5122 - mae: 1.6592 - val_loss: 7.4657 - val_mae: 1.7604\n",
      "Epoch 18/100\n",
      "78/78 [==============================] - 0s 912us/step - loss: 6.5825 - mae: 1.6664 - val_loss: 7.3990 - val_mae: 1.7211\n",
      "Epoch 19/100\n",
      "78/78 [==============================] - 0s 894us/step - loss: 6.4713 - mae: 1.6597 - val_loss: 7.4611 - val_mae: 1.7179\n",
      "Epoch 20/100\n",
      "78/78 [==============================] - 0s 910us/step - loss: 6.3958 - mae: 1.6515 - val_loss: 7.5816 - val_mae: 1.6949\n",
      "Epoch 21/100\n",
      "78/78 [==============================] - 0s 897us/step - loss: 6.5932 - mae: 1.6533 - val_loss: 7.5324 - val_mae: 1.7367\n",
      "Epoch 22/100\n",
      "78/78 [==============================] - 0s 883us/step - loss: 6.5564 - mae: 1.6843 - val_loss: 7.7809 - val_mae: 1.7002\n",
      "Epoch 23/100\n",
      "78/78 [==============================] - 0s 882us/step - loss: 6.3633 - mae: 1.6400 - val_loss: 7.7353 - val_mae: 1.7130\n",
      "Epoch 24/100\n",
      "78/78 [==============================] - 0s 893us/step - loss: 6.3360 - mae: 1.6159 - val_loss: 7.5508 - val_mae: 1.7658\n",
      "Epoch 25/100\n",
      "78/78 [==============================] - 0s 856us/step - loss: 6.2789 - mae: 1.6159 - val_loss: 7.6254 - val_mae: 1.6837\n",
      "Epoch 26/100\n",
      "78/78 [==============================] - 0s 899us/step - loss: 6.2389 - mae: 1.6155 - val_loss: 7.6937 - val_mae: 1.6833\n",
      "Epoch 27/100\n",
      "78/78 [==============================] - 0s 870us/step - loss: 6.2333 - mae: 1.5896 - val_loss: 7.8623 - val_mae: 1.6943\n",
      "Epoch 28/100\n",
      "78/78 [==============================] - 0s 962us/step - loss: 6.2161 - mae: 1.5897 - val_loss: 7.6792 - val_mae: 1.7672\n",
      "Epoch 29/100\n",
      "78/78 [==============================] - 0s 923us/step - loss: 6.1180 - mae: 1.5831 - val_loss: 8.1961 - val_mae: 1.8467\n",
      "Epoch 30/100\n",
      "78/78 [==============================] - 0s 872us/step - loss: 6.1744 - mae: 1.5976 - val_loss: 7.8296 - val_mae: 1.7678\n",
      "Epoch 31/100\n",
      "78/78 [==============================] - 0s 898us/step - loss: 6.0320 - mae: 1.5967 - val_loss: 7.9165 - val_mae: 1.6616\n",
      "Epoch 32/100\n",
      "78/78 [==============================] - 0s 883us/step - loss: 6.0221 - mae: 1.5610 - val_loss: 8.0221 - val_mae: 1.8785\n",
      "Epoch 33/100\n",
      "78/78 [==============================] - 0s 876us/step - loss: 5.9621 - mae: 1.5615 - val_loss: 7.9155 - val_mae: 1.7358\n",
      "Epoch 34/100\n",
      "78/78 [==============================] - 0s 879us/step - loss: 5.9959 - mae: 1.5471 - val_loss: 8.1503 - val_mae: 1.8170\n",
      "Epoch 34: early stopping\n",
      "Test Loss (MSE): 12.173781394958496, Test Mean Absolute Error (MAE): 2.127596616744995\n"
     ]
    }
   ],
   "source": [
    "from mlpremier.cnn.experiment import gridsearch_cnn\n",
    "\n",
    "gridsearch_cnn(epochs=100, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate GridSearch Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mode Best Hyperparameters for Each Position\n",
      "Via Top 1 Models by Position\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>position</th>\n",
       "      <th>window_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>num_filters</th>\n",
       "      <th>num_dense</th>\n",
       "      <th>conv_activation</th>\n",
       "      <th>dense_activation</th>\n",
       "      <th>drop_low_playtime</th>\n",
       "      <th>low_playtime_cutoff</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss</th>\n",
       "      <th>metrics</th>\n",
       "      <th>regularization</th>\n",
       "      <th>early_stopping</th>\n",
       "      <th>tolerance</th>\n",
       "      <th>patience</th>\n",
       "      <th>standardize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GK</th>\n",
       "      <td>['2020-21', '2021-22']</td>\n",
       "      <td>GK</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.01</td>\n",
       "      <td>mse</td>\n",
       "      <td>['mae']</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEF</th>\n",
       "      <td>2020-21</td>\n",
       "      <td>DEF</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.01</td>\n",
       "      <td>mse</td>\n",
       "      <td>['mae']</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MID</th>\n",
       "      <td>2021-22</td>\n",
       "      <td>MID</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.01</td>\n",
       "      <td>mse</td>\n",
       "      <td>['mae']</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FWD</th>\n",
       "      <td>2020-21</td>\n",
       "      <td>FWD</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.01</td>\n",
       "      <td>mse</td>\n",
       "      <td>['mae']</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     season position window_size kernel_size num_filters  \\\n",
       "GK   ['2020-21', '2021-22']       GK           6           2          64   \n",
       "DEF                 2020-21      DEF           9           2          64   \n",
       "MID                 2021-22      MID           6           1          64   \n",
       "FWD                 2020-21      FWD           9           1          64   \n",
       "\n",
       "    num_dense conv_activation dense_activation drop_low_playtime  \\\n",
       "GK         64            relu             relu              True   \n",
       "DEF        64            relu             relu              True   \n",
       "MID        64            relu             relu              True   \n",
       "FWD        64            relu             relu              True   \n",
       "\n",
       "    low_playtime_cutoff optimizer learning_rate loss  metrics regularization  \\\n",
       "GK                    0      adam          0.01  mse  ['mae']          0.001   \n",
       "DEF                   0      adam          0.01  mse  ['mae']          0.001   \n",
       "MID                   0      adam          0.01  mse  ['mae']          0.001   \n",
       "FWD                   0      adam          0.01  mse  ['mae']          0.001   \n",
       "\n",
       "    early_stopping tolerance patience standardize  \n",
       "GK            True   0.00001       20        True  \n",
       "DEF           True   0.00001       20        True  \n",
       "MID           True   0.00001       20        True  \n",
       "FWD           True   0.00001       20        True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Performance of Top 1 Model by Position\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mse</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>test_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GK</th>\n",
       "      <td>3.017067</td>\n",
       "      <td>1.354558</td>\n",
       "      <td>3.231826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEF</th>\n",
       "      <td>4.899445</td>\n",
       "      <td>3.858049</td>\n",
       "      <td>4.501652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MID</th>\n",
       "      <td>5.071956</td>\n",
       "      <td>3.148513</td>\n",
       "      <td>4.797949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FWD</th>\n",
       "      <td>5.450167</td>\n",
       "      <td>3.623432</td>\n",
       "      <td>4.579809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     train_mse   val_mse  test_mse\n",
       "GK    3.017067  1.354558  3.231826\n",
       "DEF   4.899445  3.858049  4.501652\n",
       "MID   5.071956  3.148513  4.797949\n",
       "FWD   5.450167  3.623432  4.579809"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gridsearch_analysis('results/gridsearch_v4.csv', eval_top=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tflow3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
