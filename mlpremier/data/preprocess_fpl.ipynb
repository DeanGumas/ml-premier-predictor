{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "import warnings\n",
    "from urllib.parse import unquote   #for cleanup of bad folder player names from encoded URLS\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Func for Cleaning Player Folder Names for Fuzzy Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_url(url):\n",
    "    # Define a regular expression pattern to match URL-encoded sequences\n",
    "    pattern = re.compile('%[0-9a-fA-F]{2}')\n",
    "\n",
    "    # Use a lambda function to replace each match with its decoded equivalent\n",
    "    decoded_url = pattern.sub(lambda x: unquote(x.group(0)), url)\n",
    "\n",
    "    return decoded_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab Player Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_player_meta_csv(season:str, \n",
    "                           save_dir:str=os.path.join('clean_data', 'meta')):\n",
    "    \"\"\" \n",
    "    Create a csv of player metadata.\n",
    "\n",
    "    :param str season: Which season of EPL data to process metadata for. Should \n",
    "        follow the format 20XX-X(X+1).\n",
    "    :param str save_dir: path within repo to desired data folder for the metadata\n",
    "      /path/to/data\n",
    "\n",
    "    :returns: Nothing\n",
    "    :rtype: None\n",
    "    \"\"\"\n",
    "    RAW_DATA_DIR = 'raw_data'\n",
    "    meta_data_list = []\n",
    "\n",
    "    # Check if raw_data/season/gws exists\n",
    "    season_dir = os.path.join(RAW_DATA_DIR, season, 'gws')\n",
    "    if not os.path.exists(season_dir):\n",
    "        print(f\"No data found for {season}/gws. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Iterate through all CSV files in gws folder\n",
    "    for filename in os.listdir(season_dir):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            csv_path = os.path.join(season_dir, filename)\n",
    "            df = pd.read_csv(csv_path)\n",
    "            df = df.loc[:,['name', 'position', 'team']]\n",
    "\n",
    "            meta_data_list.append(df)\n",
    "\n",
    "    # Concatenate all gw metadata (we do this because players may transfer\n",
    "    # in and out of the league)\n",
    "    meta_data_df = pd.concat(meta_data_list, axis=0, ignore_index=True)\n",
    "    meta_data_df = meta_data_df.drop_duplicates(subset=['name'], keep='first')\n",
    "    \n",
    "    # Check if 'name', 'position', 'team' are consistent for each 'name'\n",
    "    #assert meta_data_df.groupby('name')['position'].nunique().eq(1).all()\n",
    "    #assert meta_data_df.groupby('name')['team'].nunique().eq(1).all()\n",
    "\n",
    "    # Write the cleaned dataframe to a CSV file\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    save_path = os.path.join(save_dir, f'player_meta_{season}.csv')\n",
    "    meta_data_df.to_csv(save_path, index=False)\n",
    "    print(f\"Player metadata saved to {save_path}\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player metadata saved to clean_data/meta/player_meta_2020-21.csv\n"
     ]
    }
   ],
   "source": [
    "create_player_meta_csv('2020-21')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reorder and Clean Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_and_limit_gwdata_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Reorders and limits columns of the provided dataframe to the following \n",
    "    format:\n",
    "\n",
    "    cols = name, position, team, opponent_team, minutes, goals_scored, assists, \n",
    "    goals_conceded, clean_sheets, bps, yellow_cards, red_cards, own_goals, \n",
    "    saves, penalties_missed, penalties_saved, ict_index, influence, creativity, \n",
    "    threat, was_home, total_points \n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # Define the desired column order\n",
    "    desired_cols = ['name', 'position', 'team', 'opponent_team', 'minutes', \n",
    "                    'goals_scored', 'assists', 'goals_conceded', 'clean_sheets', \n",
    "                    'bps', 'yellow_cards', 'red_cards', 'own_goals', 'saves', \n",
    "                    'penalties_missed', 'penalties_saved', 'ict_index', \n",
    "                    'influence', 'creativity', 'threat', 'was_home', \n",
    "                    'total_points']\n",
    "\n",
    "    # Reorder and limit the columns\n",
    "    df = df[desired_cols]\n",
    "\n",
    "    return df\n",
    "\n",
    "def fill_in_opponent_team(df: pd.DataFrame, season: str = '2020-21') -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Fills in the actual opponent team name from the team ID.\n",
    "\n",
    "    The `master_team_list.csv` file must be downloaded (see `get_master_team_list`\n",
    "    in `scrape_fpl_data`).\n",
    "    \"\"\"\n",
    "    df = df.copy() \n",
    "    \n",
    "    CLEAN_DATA_DIR = 'clean_data'\n",
    "    MASTER_TEAM_LIST_PATH = os.path.join(CLEAN_DATA_DIR, 'master_team_list.csv')\n",
    "\n",
    "    # Load the master_team_list.csv\n",
    "    master_team_list = pd.read_csv(MASTER_TEAM_LIST_PATH)\n",
    "\n",
    "    # Create a mapping dictionary using both 'season' and 'team' columns\n",
    "    mapping_df = master_team_list[(master_team_list['season'] == season)][['team', 'team_name']]\n",
    "    team_mapping = dict(list(zip(mapping_df['team'], mapping_df['team_name'])))\n",
    "    #print(team_mapping)\n",
    "\n",
    "    # Map the opponent_team column using the created mapping\n",
    "    df['opponent_team'] = df['opponent_team'].apply(lambda team: team_mapping[team])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_player_data(season: str, \n",
    "                    save_dir: str = os.path.join('clean_data'),\n",
    "                    verbose:bool = False):\n",
    "    \"\"\"\n",
    "    Appends player metadata into player gw-by-gw CSVs. Also cleans player data \n",
    "    cols.\n",
    "\n",
    "    :param str season: Which season of EPL data to process metadata for. Should \n",
    "        follow the format 20XX-X(X+1).\n",
    "    :param str save_dir: path within repo to desired data folder for the metadata\n",
    "        /path/to/data\n",
    "\n",
    "    :returns: Nothing\n",
    "    :rtype: None\n",
    "    \"\"\"\n",
    "    RAW_DATA_DIR = 'raw_data'\n",
    "    PLAYER_META_CSV_PATH = os.path.join('clean_data', 'meta', f'player_meta_{season}.csv')\n",
    "\n",
    "    # Load player metadata CSV\n",
    "    player_meta_df = pd.read_csv(PLAYER_META_CSV_PATH)\n",
    "\n",
    "    # Iterate through all player_name_folders in the raw_data/players directory\n",
    "    player_dirs = [f for f in os.listdir(os.path.join(RAW_DATA_DIR, season, 'players')) \n",
    "                   if os.path.isdir(os.path.join(RAW_DATA_DIR, season, 'players', f))]\n",
    "    \n",
    "    used_names = []\n",
    "\n",
    "    for player_folder in player_dirs:\n",
    "        player_name = decode_url(player_folder)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Appending metadata via fuzzy match for player: \\n{player_folder}\\n\")\n",
    "        player_folder_path = os.path.join(RAW_DATA_DIR, season, 'players', player_folder)\n",
    "        player_csv_path = os.path.join(player_folder_path, 'gw.csv')\n",
    "\n",
    "        # Load player gw CSV\n",
    "        if verbose:\n",
    "            print(f\"Reading player data for {player_csv_path}\")\n",
    "        player_gw_df = pd.read_csv(player_csv_path)\n",
    "\n",
    "        # Fuzzy match based on the closest name in PLAYER_META_CSV\n",
    "        # with player name extracted via raw data player directory name. \n",
    "        # column name to match on is 'name'.\n",
    "        matches = process.extractOne(player_name.replace('_', ' '), \n",
    "                                     player_meta_df['name'])\n",
    "        top_match = matches[0]\n",
    "\n",
    "        if top_match in used_names:\n",
    "            warnings.warn((\"Attempted to assign an already matched\" \n",
    "                          f\"player name. Player Folder: {player_folder}.\" \n",
    "                          f\"Top Match: {matches[0]}. Skipping this player.\"))\n",
    "            continue\n",
    "        else:\n",
    "            player_metadata = player_meta_df[player_meta_df['name'] == matches[0]]\n",
    "\n",
    "            # Append player_metadata columns to player_gw_df\n",
    "            for col in player_metadata.columns:\n",
    "                player_gw_df[col] = player_metadata[col].values[0]\n",
    "\n",
    "            #Clean up player_gw_df columns\n",
    "            player_gw_df = reorder_and_limit_gwdata_cols(player_gw_df)\n",
    "\n",
    "            #Fill in Opponent Team\n",
    "            player_gw_df = fill_in_opponent_team(player_gw_df)\n",
    "\n",
    "            # Save the updated player_gw_df to the appropriate path\n",
    "            full_save_dir = os.path.join(save_dir, season, 'players', player_name)\n",
    "            if not os.path.exists(full_save_dir):\n",
    "                os.makedirs(full_save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "            if verbose: \n",
    "                print(f\"Saving appended player data to: {full_save_dir}\")\n",
    "            player_gw_df.to_csv(os.path.join(full_save_dir, 'gw.csv'), \n",
    "                                index=False)\n",
    "            \n",
    "            # Mark the player name as used\n",
    "            used_names.append(top_match)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1h/lbnzt8g120v24tjmpg9439ww0000gn/T/ipykernel_12889/268396204.py:49: UserWarning: Attempted to assign an already matchedplayer name. Player Folder: Ben_Davies_395.Top Match: Ben Davies. Skipping this player.\n",
      "  warnings.warn((\"Attempted to assign an already matched\"\n"
     ]
    }
   ],
   "source": [
    "clean_player_data('2020-21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tflow3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
