{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import ast\n",
    "sys.path.append(os.path.join(os.getcwd(), '..','..'))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from premier_league_models.processing.preprocess import generate_cnn_data, split_preprocess_cnn_data, preprocess_cnn_data\n",
    "from premier_league_models.rnn.model import build_train_rnn, full_rnn_pipeline\n",
    "from premier_league_models.processing.evaluate import gridsearch_analysis\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "\n",
    "\n",
    "from config import STANDARD_CAT_FEATURES, STANDARD_NUM_FEATURES, NUM_FEATURES_DICT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Full Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Generating CNN Data for Season: ['2024-25'], Position: GK =======\n",
      "Dropping Players with Avg. Playtime < 1e-06...\n",
      "\n",
      "Total players of type GK = 77.\n",
      "38 players dropped due to low average playtime.\n",
      "Generated windowed dataframe for CNN of shape: (643, 7).\n",
      "Generated combined features dataframe for preprocessing of shape: (874, 9).\n",
      "\n",
      "========== EDA ==========\n",
      "========== Done Generating CNN Data ==========\n",
      "\n",
      "========== Splitting CNN Data ==========\n",
      "\n",
      "=== Stratifying Split by : Stdev ===\n",
      "Shape of windowed_df: (643, 7)\n",
      "Shape of a given window (prior to preprocessing): (6, 9)\n",
      "stdev Distribution of Players:\n",
      "\n",
      "========== Preprocessing CNN Data ==========\n",
      "\n",
      "Mean of Standard Scaler:\n",
      "[1.69306931e+00 4.77168317e+01 0.00000000e+00 7.92079208e-03\n",
      " 1.06930693e-01 6.40792079e+00 4.75247525e-02 0.00000000e+00]\n",
      "\n",
      "Standard Deviation of Standard Scaler:\n",
      "[ 2.47259264 44.54483795  1.          0.08864566  0.30902511  9.70086944\n",
      "  0.21275843  1.        ]\n",
      "Transforming features using StandardScaler + OHE Pipeline.\n",
      "========== Done Preprocessing CNN Data ==========\n",
      "\n",
      "========== Done Splitting CNN Data ==========\n",
      "\n",
      "====== Building rnn Architecture ======\n",
      "====== Done Building rnn Architecture ======\n",
      "Epoch 1/2000, Train Loss: 8.921118204459429, Val Loss: 9.74542524368458, Val MAE: 1.722058653831482\n",
      "Epoch 2/2000, Train Loss: 8.894832136803593, Val Loss: 9.714066369148592, Val MAE: 1.718047022819519\n",
      "Epoch 3/2000, Train Loss: 8.869267378032367, Val Loss: 9.68196183292284, Val MAE: 1.713890790939331\n",
      "Epoch 4/2000, Train Loss: 8.842367744957155, Val Loss: 9.650720994742144, Val MAE: 1.709894061088562\n",
      "Epoch 5/2000, Train Loss: 8.816018477841293, Val Loss: 9.619135684954623, Val MAE: 1.705846905708313\n",
      "Epoch 6/2000, Train Loss: 8.790338979010288, Val Loss: 9.5864751601503, Val MAE: 1.701601266860962\n",
      "Epoch 7/2000, Train Loss: 8.763844160228249, Val Loss: 9.554720879665442, Val MAE: 1.6976006031036377\n",
      "Epoch 8/2000, Train Loss: 8.73788852793921, Val Loss: 9.522285629329938, Val MAE: 1.6936349868774414\n",
      "Epoch 9/2000, Train Loss: 8.711322510849694, Val Loss: 9.491251195160052, Val MAE: 1.6899785995483398\n",
      "Epoch 10/2000, Train Loss: 8.686199722596852, Val Loss: 9.458707896282984, Val MAE: 1.6862974166870117\n",
      "Epoch 11/2000, Train Loss: 8.659481196876506, Val Loss: 9.427118910166124, Val MAE: 1.682739496231079\n",
      "Epoch 12/2000, Train Loss: 8.633794684831962, Val Loss: 9.396133981024226, Val MAE: 1.679331660270691\n",
      "Epoch 13/2000, Train Loss: 8.607712456751765, Val Loss: 9.365191746192673, Val MAE: 1.6760199069976807\n",
      "Epoch 14/2000, Train Loss: 8.581769245239748, Val Loss: 9.333622831052967, Val MAE: 1.6726012229919434\n",
      "Epoch 15/2000, Train Loss: 8.555310289597703, Val Loss: 9.302613257341797, Val MAE: 1.669272780418396\n",
      "Epoch 16/2000, Train Loss: 8.530305709020702, Val Loss: 9.270566197733084, Val MAE: 1.6658179759979248\n",
      "Epoch 17/2000, Train Loss: 8.503946076768973, Val Loss: 9.238848250359297, Val MAE: 1.6623382568359375\n",
      "Epoch 18/2000, Train Loss: 8.477688518350309, Val Loss: 9.207832212692924, Val MAE: 1.658979892730713\n",
      "Epoch 19/2000, Train Loss: 8.451579290804212, Val Loss: 9.175994008202993, Val MAE: 1.6554784774780273\n",
      "Epoch 20/2000, Train Loss: 8.425013811914274, Val Loss: 9.144771058644567, Val MAE: 1.6520541906356812\n",
      "Epoch 21/2000, Train Loss: 8.398901119948073, Val Loss: 9.113085315341042, Val MAE: 1.6485517024993896\n",
      "Epoch 22/2000, Train Loss: 8.372580576837862, Val Loss: 9.081054719209316, Val MAE: 1.6450074911117554\n",
      "Epoch 23/2000, Train Loss: 8.345978463303307, Val Loss: 9.048528677163025, Val MAE: 1.6413719654083252\n",
      "Epoch 24/2000, Train Loss: 8.31860461503507, Val Loss: 9.0166389337253, Val MAE: 1.6378684043884277\n",
      "Epoch 25/2000, Train Loss: 8.292510270433196, Val Loss: 8.983305067489189, Val MAE: 1.6341981887817383\n",
      "Epoch 26/2000, Train Loss: 8.264828653821358, Val Loss: 8.951519118355852, Val MAE: 1.630759596824646\n",
      "Epoch 27/2000, Train Loss: 8.23828994812339, Val Loss: 8.918678852463406, Val MAE: 1.6271077394485474\n",
      "Epoch 28/2000, Train Loss: 8.21019067073955, Val Loss: 8.887646432832948, Val MAE: 1.6237375736236572\n",
      "Epoch 29/2000, Train Loss: 8.18349568262177, Val Loss: 8.855172662640966, Val MAE: 1.6201622486114502\n",
      "Epoch 30/2000, Train Loss: 8.156896491472587, Val Loss: 8.821181584282645, Val MAE: 1.6163370609283447\n",
      "Epoch 31/2000, Train Loss: 8.128442194123052, Val Loss: 8.788219348837933, Val MAE: 1.6127092838287354\n",
      "Epoch 32/2000, Train Loss: 8.100342627824471, Val Loss: 8.754419233428226, Val MAE: 1.6089019775390625\n",
      "Epoch 33/2000, Train Loss: 8.071744287301645, Val Loss: 8.721723856271378, Val MAE: 1.6052675247192383\n",
      "Epoch 34/2000, Train Loss: 8.044813915487909, Val Loss: 8.687456422130621, Val MAE: 1.6014258861541748\n",
      "Epoch 35/2000, Train Loss: 8.015340305205644, Val Loss: 8.65496369025537, Val MAE: 1.5978001356124878\n",
      "Epoch 36/2000, Train Loss: 7.987594608007743, Val Loss: 8.621264547641788, Val MAE: 1.593968152999878\n",
      "Epoch 37/2000, Train Loss: 7.958913608786248, Val Loss: 8.588296502340762, Val MAE: 1.5902230739593506\n",
      "Epoch 38/2000, Train Loss: 7.930726912961249, Val Loss: 8.553686809193875, Val MAE: 1.5861979722976685\n",
      "Epoch 39/2000, Train Loss: 7.901481917332708, Val Loss: 8.519649693653697, Val MAE: 1.5822416543960571\n",
      "Epoch 40/2000, Train Loss: 7.873124667211129, Val Loss: 8.484748630784452, Val MAE: 1.5782194137573242\n",
      "Epoch 41/2000, Train Loss: 7.843052573881584, Val Loss: 8.45188557933129, Val MAE: 1.5744926929473877\n",
      "Epoch 42/2000, Train Loss: 7.814722957304272, Val Loss: 8.416931742757914, Val MAE: 1.5703541040420532\n",
      "Epoch 43/2000, Train Loss: 7.7846555939947955, Val Loss: 8.383192544758675, Val MAE: 1.566422462463379\n",
      "Epoch 44/2000, Train Loss: 7.75594537187837, Val Loss: 8.347694636455604, Val MAE: 1.5622291564941406\n",
      "Epoch 45/2000, Train Loss: 7.726513550684215, Val Loss: 8.312061560561968, Val MAE: 1.5580683946609497\n",
      "Epoch 46/2000, Train Loss: 7.695128259326434, Val Loss: 8.278611464958106, Val MAE: 1.5541743040084839\n",
      "Epoch 47/2000, Train Loss: 7.665705976153826, Val Loss: 8.242963068142888, Val MAE: 1.5498930215835571\n",
      "Epoch 48/2000, Train Loss: 7.6354426506697015, Val Loss: 8.207936454431287, Val MAE: 1.5457346439361572\n",
      "Epoch 49/2000, Train Loss: 7.605979479669566, Val Loss: 8.171993933972859, Val MAE: 1.5413836240768433\n",
      "Epoch 50/2000, Train Loss: 7.574115791525342, Val Loss: 8.138606586094413, Val MAE: 1.5374804735183716\n",
      "Epoch 51/2000, Train Loss: 7.544711931141707, Val Loss: 8.102259820238466, Val MAE: 1.5330381393432617\n",
      "Epoch 52/2000, Train Loss: 7.513566130927037, Val Loss: 8.066327986218745, Val MAE: 1.5286022424697876\n",
      "Epoch 53/2000, Train Loss: 7.483106877784627, Val Loss: 8.029835543816997, Val MAE: 1.5241502523422241\n",
      "Epoch 54/2000, Train Loss: 7.451565782122573, Val Loss: 7.994232491900523, Val MAE: 1.5198255777359009\n",
      "Epoch 55/2000, Train Loss: 7.420530927724557, Val Loss: 7.958801206910894, Val MAE: 1.515415906906128\n",
      "Epoch 56/2000, Train Loss: 7.389841560384224, Val Loss: 7.922989700211301, Val MAE: 1.5109268426895142\n",
      "Epoch 57/2000, Train Loss: 7.3587944066556465, Val Loss: 7.887961247625451, Val MAE: 1.5066766738891602\n",
      "Epoch 58/2000, Train Loss: 7.328434270444569, Val Loss: 7.851108862752361, Val MAE: 1.5020411014556885\n",
      "Epoch 59/2000, Train Loss: 7.2975667385888805, Val Loss: 7.8138892856382185, Val MAE: 1.49728524684906\n",
      "Epoch 60/2000, Train Loss: 7.264074182382537, Val Loss: 7.780780152240324, Val MAE: 1.4932492971420288\n",
      "Epoch 61/2000, Train Loss: 7.235066654215549, Val Loss: 7.744208516109557, Val MAE: 1.4886096715927124\n",
      "Epoch 62/2000, Train Loss: 7.202902931949728, Val Loss: 7.708492995993722, Val MAE: 1.4840385913848877\n",
      "Epoch 63/2000, Train Loss: 7.171764019666984, Val Loss: 7.673014234041884, Val MAE: 1.4795656204223633\n",
      "Epoch 64/2000, Train Loss: 7.140081699667923, Val Loss: 7.6372420857882215, Val MAE: 1.474911093711853\n",
      "Epoch 65/2000, Train Loss: 7.108981024324095, Val Loss: 7.601205126692851, Val MAE: 1.4702357053756714\n",
      "Epoch 66/2000, Train Loss: 7.077704337582831, Val Loss: 7.565550701914444, Val MAE: 1.4655966758728027\n",
      "Epoch 67/2000, Train Loss: 7.046842964980302, Val Loss: 7.528386106758955, Val MAE: 1.4607291221618652\n",
      "Epoch 68/2000, Train Loss: 7.014746474197019, Val Loss: 7.491985479458457, Val MAE: 1.4561777114868164\n",
      "Epoch 69/2000, Train Loss: 6.9818908727201, Val Loss: 7.457556034482661, Val MAE: 1.4520362615585327\n",
      "Epoch 70/2000, Train Loss: 6.951474059363153, Val Loss: 7.420866128545077, Val MAE: 1.447691559791565\n",
      "Epoch 71/2000, Train Loss: 6.918978921210159, Val Loss: 7.384710189531601, Val MAE: 1.4436941146850586\n",
      "Epoch 72/2000, Train Loss: 6.886848892027826, Val Loss: 7.3485258583955115, Val MAE: 1.4396770000457764\n",
      "Epoch 73/2000, Train Loss: 6.855678975741921, Val Loss: 7.312264290194781, Val MAE: 1.4356956481933594\n",
      "Epoch 74/2000, Train Loss: 6.82367924135428, Val Loss: 7.276641798560464, Val MAE: 1.4318559169769287\n",
      "Epoch 75/2000, Train Loss: 6.79168376718066, Val Loss: 7.242409460867445, Val MAE: 1.4282437562942505\n",
      "Epoch 76/2000, Train Loss: 6.762109010532778, Val Loss: 7.204420865025549, Val MAE: 1.4241183996200562\n",
      "Epoch 77/2000, Train Loss: 6.727696528703214, Val Loss: 7.170509685895273, Val MAE: 1.4203928709030151\n",
      "Epoch 78/2000, Train Loss: 6.699223200054015, Val Loss: 7.132817029287772, Val MAE: 1.4166010618209839\n",
      "Epoch 79/2000, Train Loss: 6.665359448491728, Val Loss: 7.098473072406792, Val MAE: 1.4134794473648071\n",
      "Epoch 80/2000, Train Loss: 6.6348126000118, Val Loss: 7.063799969319787, Val MAE: 1.410288691520691\n",
      "Epoch 81/2000, Train Loss: 6.603680398445027, Val Loss: 7.030265358187968, Val MAE: 1.4072707891464233\n",
      "Epoch 82/2000, Train Loss: 6.57373462094059, Val Loss: 6.995018134248399, Val MAE: 1.404247522354126\n",
      "Epoch 83/2000, Train Loss: 6.543883806898511, Val Loss: 6.958699011953459, Val MAE: 1.4010332822799683\n",
      "Epoch 84/2000, Train Loss: 6.5110151825257985, Val Loss: 6.925919312229824, Val MAE: 1.3982027769088745\n",
      "Epoch 85/2000, Train Loss: 6.480375940614348, Val Loss: 6.893475233887632, Val MAE: 1.3955625295639038\n",
      "Epoch 86/2000, Train Loss: 6.4529774783443825, Val Loss: 6.8572322405608634, Val MAE: 1.3926225900650024\n",
      "Epoch 87/2000, Train Loss: 6.420129980542385, Val Loss: 6.824623998742373, Val MAE: 1.390123724937439\n",
      "Epoch 88/2000, Train Loss: 6.39156424136328, Val Loss: 6.789604853705636, Val MAE: 1.3873865604400635\n",
      "Epoch 89/2000, Train Loss: 6.358884248912494, Val Loss: 6.758028530737474, Val MAE: 1.3849345445632935\n",
      "Epoch 90/2000, Train Loss: 6.3301251078419005, Val Loss: 6.722758840237345, Val MAE: 1.3821035623550415\n",
      "Epoch 91/2000, Train Loss: 6.300208486756435, Val Loss: 6.689549728341046, Val MAE: 1.3798000812530518\n",
      "Epoch 92/2000, Train Loss: 6.270681141688421, Val Loss: 6.656577284669592, Val MAE: 1.3772573471069336\n",
      "Epoch 93/2000, Train Loss: 6.241076950093697, Val Loss: 6.625292855891443, Val MAE: 1.3749372959136963\n",
      "Epoch 94/2000, Train Loss: 6.2121763203802445, Val Loss: 6.59323117890883, Val MAE: 1.3724946975708008\n",
      "Epoch 95/2000, Train Loss: 6.182946037670882, Val Loss: 6.561699755844616, Val MAE: 1.3700190782546997\n",
      "Epoch 96/2000, Train Loss: 6.155341300504137, Val Loss: 6.530138274477351, Val MAE: 1.3679002523422241\n",
      "Epoch 97/2000, Train Loss: 6.126734380747614, Val Loss: 6.498246405539768, Val MAE: 1.365689992904663\n",
      "Epoch 98/2000, Train Loss: 6.097790888103659, Val Loss: 6.46686572670227, Val MAE: 1.363468885421753\n",
      "Epoch 99/2000, Train Loss: 6.069066013152094, Val Loss: 6.4366851808237175, Val MAE: 1.3613888025283813\n",
      "Epoch 100/2000, Train Loss: 6.042507440091458, Val Loss: 6.405162336570876, Val MAE: 1.359235167503357\n",
      "Epoch 101/2000, Train Loss: 6.01438807418455, Val Loss: 6.375009098045883, Val MAE: 1.3571388721466064\n",
      "Epoch 102/2000, Train Loss: 5.987336138298301, Val Loss: 6.3445161038211415, Val MAE: 1.3550727367401123\n",
      "Epoch 103/2000, Train Loss: 5.959070890902194, Val Loss: 6.31547293217764, Val MAE: 1.3531216382980347\n",
      "Epoch 104/2000, Train Loss: 5.93273729421498, Val Loss: 6.28650931996249, Val MAE: 1.3510621786117554\n",
      "Epoch 105/2000, Train Loss: 5.906826568992145, Val Loss: 6.256101893349772, Val MAE: 1.3488659858703613\n",
      "Epoch 106/2000, Train Loss: 5.879633779500189, Val Loss: 6.227698547765613, Val MAE: 1.3470518589019775\n",
      "Epoch 107/2000, Train Loss: 5.853215313469117, Val Loss: 6.199975073603647, Val MAE: 1.345375418663025\n",
      "Epoch 108/2000, Train Loss: 5.828414385184526, Val Loss: 6.170904142693395, Val MAE: 1.3434253931045532\n",
      "Epoch 109/2000, Train Loss: 5.802090678074404, Val Loss: 6.143981580578146, Val MAE: 1.3419359922409058\n",
      "Epoch 110/2000, Train Loss: 5.777904142323512, Val Loss: 6.115323880776053, Val MAE: 1.3404593467712402\n",
      "Epoch 111/2000, Train Loss: 5.75096512096497, Val Loss: 6.089826791236798, Val MAE: 1.339866042137146\n",
      "Epoch 112/2000, Train Loss: 5.727797775421961, Val Loss: 6.061694289601984, Val MAE: 1.3387877941131592\n",
      "Epoch 113/2000, Train Loss: 5.701665954998926, Val Loss: 6.036425120951164, Val MAE: 1.337929129600525\n",
      "Epoch 114/2000, Train Loss: 5.6788830450329, Val Loss: 6.009382792526767, Val MAE: 1.3371200561523438\n",
      "Epoch 115/2000, Train Loss: 5.653809886196024, Val Loss: 5.9839021774629755, Val MAE: 1.3363196849822998\n",
      "Epoch 116/2000, Train Loss: 5.629884985752463, Val Loss: 5.959852206210296, Val MAE: 1.3356473445892334\n",
      "Epoch 117/2000, Train Loss: 5.607115764720191, Val Loss: 5.93537183159164, Val MAE: 1.335087776184082\n",
      "Epoch 118/2000, Train Loss: 5.585732503487022, Val Loss: 5.909853021303813, Val MAE: 1.3348501920700073\n",
      "Epoch 119/2000, Train Loss: 5.562230474507841, Val Loss: 5.88611884539326, Val MAE: 1.3350112438201904\n",
      "Epoch 120/2000, Train Loss: 5.539789626809291, Val Loss: 5.862479320949032, Val MAE: 1.3346511125564575\n",
      "Epoch 121/2000, Train Loss: 5.519695674126654, Val Loss: 5.8379085007168, Val MAE: 1.3347861766815186\n",
      "Epoch 122/2000, Train Loss: 5.4969455857059595, Val Loss: 5.815965342911936, Val MAE: 1.3350706100463867\n",
      "Epoch 123/2000, Train Loss: 5.475840989769943, Val Loss: 5.7944454697980765, Val MAE: 1.3353221416473389\n",
      "Epoch 124/2000, Train Loss: 5.455455928321818, Val Loss: 5.773743989921751, Val MAE: 1.3360811471939087\n",
      "Epoch 125/2000, Train Loss: 5.435824354596177, Val Loss: 5.752721486347062, Val MAE: 1.3368866443634033\n",
      "Epoch 126/2000, Train Loss: 5.416056726317623, Val Loss: 5.732577320365679, Val MAE: 1.337846279144287\n",
      "Epoch 127/2000, Train Loss: 5.397758724542469, Val Loss: 5.711059834630716, Val MAE: 1.338856816291809\n",
      "Epoch 128/2000, Train Loss: 5.377442345862095, Val Loss: 5.691299355810597, Val MAE: 1.3397642374038696\n",
      "Epoch 129/2000, Train Loss: 5.359314795154029, Val Loss: 5.671392553618976, Val MAE: 1.341022253036499\n",
      "Epoch 130/2000, Train Loss: 5.341943394402716, Val Loss: 5.6520089166505, Val MAE: 1.342987298965454\n",
      "Epoch 131/2000, Train Loss: 5.323006284780221, Val Loss: 5.63333974956047, Val MAE: 1.3443936109542847\n",
      "Epoch 132/2000, Train Loss: 5.306474148747748, Val Loss: 5.613695227674076, Val MAE: 1.3460216522216797\n",
      "Epoch 133/2000, Train Loss: 5.287909120401173, Val Loss: 5.596519947761581, Val MAE: 1.3479989767074585\n",
      "Epoch 134/2000, Train Loss: 5.270147574171624, Val Loss: 5.582109967867534, Val MAE: 1.3502994775772095\n",
      "Epoch 135/2000, Train Loss: 5.255626604320536, Val Loss: 5.563696549761863, Val MAE: 1.353031039237976\n",
      "Epoch 136/2000, Train Loss: 5.238316636942027, Val Loss: 5.546010997323763, Val MAE: 1.3553895950317383\n",
      "Epoch 137/2000, Train Loss: 5.222335415295557, Val Loss: 5.528800201557932, Val MAE: 1.358033537864685\n",
      "Epoch 138/2000, Train Loss: 5.206002480862288, Val Loss: 5.51248575817971, Val MAE: 1.3602029085159302\n",
      "Epoch 139/2000, Train Loss: 5.192199390950855, Val Loss: 5.495394158576216, Val MAE: 1.3635573387145996\n",
      "Epoch 140/2000, Train Loss: 5.176604226191626, Val Loss: 5.479483966671285, Val MAE: 1.3665735721588135\n",
      "Epoch 141/2000, Train Loss: 5.161031734527915, Val Loss: 5.465745842172986, Val MAE: 1.3694082498550415\n",
      "Epoch 142/2000, Train Loss: 5.14916546510947, Val Loss: 5.449673741346314, Val MAE: 1.3722954988479614\n",
      "Epoch 143/2000, Train Loss: 5.133386466202723, Val Loss: 5.4366474357389265, Val MAE: 1.3748464584350586\n",
      "Epoch 144/2000, Train Loss: 5.120146925264006, Val Loss: 5.423235476016998, Val MAE: 1.3774058818817139\n",
      "Epoch 145/2000, Train Loss: 5.107811708552588, Val Loss: 5.40901788856302, Val MAE: 1.3804634809494019\n",
      "Epoch 146/2000, Train Loss: 5.094217040263936, Val Loss: 5.396351937027204, Val MAE: 1.3834269046783447\n",
      "Epoch 147/2000, Train Loss: 5.081899898621097, Val Loss: 5.383003004959652, Val MAE: 1.386048674583435\n",
      "Epoch 148/2000, Train Loss: 5.070240714914358, Val Loss: 5.369884603080296, Val MAE: 1.3894025087356567\n",
      "Epoch 149/2000, Train Loss: 5.057691503785571, Val Loss: 5.3580448890016195, Val MAE: 1.3926817178726196\n",
      "Epoch 150/2000, Train Loss: 5.046894950457617, Val Loss: 5.346025136964662, Val MAE: 1.3959287405014038\n",
      "Epoch 151/2000, Train Loss: 5.034035189222075, Val Loss: 5.336138875711532, Val MAE: 1.3983434438705444\n",
      "Epoch 152/2000, Train Loss: 5.025053644947328, Val Loss: 5.323859280063992, Val MAE: 1.4019091129302979\n",
      "Epoch 153/2000, Train Loss: 5.0131439165519325, Val Loss: 5.313449323177338, Val MAE: 1.4043471813201904\n",
      "Epoch 154/2000, Train Loss: 5.003599710822425, Val Loss: 5.3022956394013905, Val MAE: 1.4070258140563965\n",
      "Epoch 155/2000, Train Loss: 4.994465250112416, Val Loss: 5.29111225335371, Val MAE: 1.4101258516311646\n",
      "Epoch 156/2000, Train Loss: 4.983736421723148, Val Loss: 5.280871692867506, Val MAE: 1.41262948513031\n",
      "Epoch 157/2000, Train Loss: 4.974382730335717, Val Loss: 5.271009901449794, Val MAE: 1.415533185005188\n",
      "Epoch 158/2000, Train Loss: 4.964809013755328, Val Loss: 5.262449615058445, Val MAE: 1.4184343814849854\n",
      "Epoch 159/2000, Train Loss: 4.956622141615635, Val Loss: 5.2527873657998585, Val MAE: 1.4208602905273438\n",
      "Epoch 160/2000, Train Loss: 4.947938479303355, Val Loss: 5.243921946911585, Val MAE: 1.423457145690918\n",
      "Epoch 161/2000, Train Loss: 4.939349843733432, Val Loss: 5.235752247628712, Val MAE: 1.4261648654937744\n",
      "Epoch 162/2000, Train Loss: 4.932700233868555, Val Loss: 5.226608062074298, Val MAE: 1.4292211532592773\n",
      "Epoch 163/2000, Train Loss: 4.923922237058747, Val Loss: 5.219267437855403, Val MAE: 1.4316554069519043\n",
      "Epoch 164/2000, Train Loss: 4.917036514179956, Val Loss: 5.21077946467059, Val MAE: 1.4342352151870728\n",
      "Epoch 165/2000, Train Loss: 4.908981739995307, Val Loss: 5.203923515620685, Val MAE: 1.435904860496521\n",
      "Epoch 166/2000, Train Loss: 4.902935006343648, Val Loss: 5.196143766244252, Val MAE: 1.4384907484054565\n",
      "Epoch 167/2000, Train Loss: 4.8959169349465865, Val Loss: 5.1892635722955065, Val MAE: 1.4412946701049805\n",
      "Epoch 168/2000, Train Loss: 4.889599393583814, Val Loss: 5.181682114799817, Val MAE: 1.4432458877563477\n",
      "Epoch 169/2000, Train Loss: 4.883383303481197, Val Loss: 5.174714989605404, Val MAE: 1.4453033208847046\n",
      "Epoch 170/2000, Train Loss: 4.876934395398915, Val Loss: 5.168113947624252, Val MAE: 1.4463874101638794\n",
      "Epoch 171/2000, Train Loss: 4.871058118886666, Val Loss: 5.162267691322735, Val MAE: 1.4481807947158813\n",
      "Epoch 172/2000, Train Loss: 4.866595787273336, Val Loss: 5.155047424492382, Val MAE: 1.4512509107589722\n",
      "Epoch 173/2000, Train Loss: 4.859742261129793, Val Loss: 5.148748990325701, Val MAE: 1.4534884691238403\n",
      "Epoch 174/2000, Train Loss: 4.855518443654753, Val Loss: 5.1425100948129385, Val MAE: 1.4560441970825195\n",
      "Epoch 175/2000, Train Loss: 4.848945218180843, Val Loss: 5.137232671181361, Val MAE: 1.456533670425415\n",
      "Epoch 176/2000, Train Loss: 4.844585584411672, Val Loss: 5.1317725373165946, Val MAE: 1.458091378211975\n",
      "Epoch 177/2000, Train Loss: 4.839785425017411, Val Loss: 5.126645061231795, Val MAE: 1.459186315536499\n",
      "Epoch 178/2000, Train Loss: 4.8355055635160795, Val Loss: 5.120919165157137, Val MAE: 1.4612860679626465\n",
      "Epoch 179/2000, Train Loss: 4.830347540551152, Val Loss: 5.115232648594039, Val MAE: 1.4626649618148804\n",
      "Epoch 180/2000, Train Loss: 4.826119338539267, Val Loss: 5.109837971982502, Val MAE: 1.4645260572433472\n",
      "Epoch 181/2000, Train Loss: 4.821594068256204, Val Loss: 5.104407422599339, Val MAE: 1.4660320281982422\n",
      "Epoch 182/2000, Train Loss: 4.817440055330701, Val Loss: 5.0988927980264025, Val MAE: 1.4669438600540161\n",
      "Epoch 183/2000, Train Loss: 4.813981944690122, Val Loss: 5.093429061628523, Val MAE: 1.4678361415863037\n",
      "Epoch 184/2000, Train Loss: 4.809625821203073, Val Loss: 5.088914957784471, Val MAE: 1.4687108993530273\n",
      "Epoch 185/2000, Train Loss: 4.806023769659906, Val Loss: 5.0847960242203305, Val MAE: 1.4700555801391602\n",
      "Epoch 186/2000, Train Loss: 4.802346873858659, Val Loss: 5.0807804110504335, Val MAE: 1.4707725048065186\n",
      "Epoch 187/2000, Train Loss: 4.798914871011279, Val Loss: 5.076025629327411, Val MAE: 1.471651554107666\n",
      "Epoch 188/2000, Train Loss: 4.795412058485097, Val Loss: 5.071231217611404, Val MAE: 1.4727028608322144\n",
      "Epoch 189/2000, Train Loss: 4.792250285519352, Val Loss: 5.066390090045475, Val MAE: 1.4738848209381104\n",
      "Epoch 190/2000, Train Loss: 4.788560168672823, Val Loss: 5.061704453967867, Val MAE: 1.474058747291565\n",
      "Epoch 191/2000, Train Loss: 4.785569617320002, Val Loss: 5.057137919323785, Val MAE: 1.4735581874847412\n",
      "Epoch 192/2000, Train Loss: 4.782566803709751, Val Loss: 5.053191654738926, Val MAE: 1.4743527173995972\n",
      "Epoch 193/2000, Train Loss: 4.779429545670988, Val Loss: 5.049420727150781, Val MAE: 1.474523901939392\n",
      "Epoch 194/2000, Train Loss: 4.777488926460532, Val Loss: 5.044908842870167, Val MAE: 1.4763753414154053\n",
      "Epoch 195/2000, Train Loss: 4.77364658925872, Val Loss: 5.041442875351224, Val MAE: 1.4771333932876587\n",
      "Epoch 196/2000, Train Loss: 4.771545210089185, Val Loss: 5.037227728537151, Val MAE: 1.4781709909439087\n",
      "Epoch 197/2000, Train Loss: 4.768127785291493, Val Loss: 5.033659707932245, Val MAE: 1.4783529043197632\n",
      "Epoch 198/2000, Train Loss: 4.765412019340985, Val Loss: 5.029742695036388, Val MAE: 1.4778952598571777\n",
      "Epoch 199/2000, Train Loss: 4.763094145874555, Val Loss: 5.025576006798517, Val MAE: 1.4778238534927368\n",
      "Epoch 200/2000, Train Loss: 4.760456232219215, Val Loss: 5.022199813808713, Val MAE: 1.478100061416626\n",
      "Epoch 201/2000, Train Loss: 4.758567347283657, Val Loss: 5.018244509186063, Val MAE: 1.4792232513427734\n",
      "Epoch 202/2000, Train Loss: 4.755619566817706, Val Loss: 5.014169414838155, Val MAE: 1.4791340827941895\n",
      "Epoch 203/2000, Train Loss: 4.7529850773133795, Val Loss: 5.011311550935109, Val MAE: 1.4796582460403442\n",
      "Epoch 204/2000, Train Loss: 4.750540213035195, Val Loss: 5.008336776778812, Val MAE: 1.4796996116638184\n",
      "Epoch 205/2000, Train Loss: 4.7490727601038545, Val Loss: 5.004649592297418, Val MAE: 1.4806734323501587\n",
      "Epoch 206/2000, Train Loss: 4.74594879278229, Val Loss: 5.001330585706802, Val MAE: 1.4800910949707031\n",
      "Epoch 207/2000, Train Loss: 4.744592398165378, Val Loss: 4.998051429078693, Val MAE: 1.48154616355896\n",
      "Epoch 208/2000, Train Loss: 4.741761271499756, Val Loss: 4.994016179016659, Val MAE: 1.480365514755249\n",
      "Epoch 209/2000, Train Loss: 4.739600758130685, Val Loss: 4.991307742538906, Val MAE: 1.480454921722412\n",
      "Epoch 210/2000, Train Loss: 4.737608647538254, Val Loss: 4.988472184964588, Val MAE: 1.4798643589019775\n",
      "Epoch 211/2000, Train Loss: 4.735961232683933, Val Loss: 4.983852458851678, Val MAE: 1.4798834323883057\n",
      "Epoch 212/2000, Train Loss: 4.733607200770851, Val Loss: 4.980361765339261, Val MAE: 1.480724811553955\n",
      "Epoch 213/2000, Train Loss: 4.73120659861424, Val Loss: 4.977515918867929, Val MAE: 1.4803777933120728\n",
      "Epoch 214/2000, Train Loss: 4.729644415525585, Val Loss: 4.973633923700878, Val MAE: 1.4792696237564087\n",
      "Epoch 215/2000, Train Loss: 4.727775465067846, Val Loss: 4.971730720429194, Val MAE: 1.4809558391571045\n",
      "Epoch 216/2000, Train Loss: 4.72548099113853, Val Loss: 4.9682760905651815, Val MAE: 1.4797953367233276\n",
      "Epoch 217/2000, Train Loss: 4.723865881042889, Val Loss: 4.965385224137988, Val MAE: 1.4804986715316772\n",
      "Epoch 218/2000, Train Loss: 4.721727423629556, Val Loss: 4.962927762951169, Val MAE: 1.4806922674179077\n",
      "Epoch 219/2000, Train Loss: 4.720290951051277, Val Loss: 4.960906472944078, Val MAE: 1.4810556173324585\n",
      "Epoch 220/2000, Train Loss: 4.718380764406424, Val Loss: 4.957151246922357, Val MAE: 1.4793496131896973\n",
      "Epoch 221/2000, Train Loss: 4.716472193638697, Val Loss: 4.954320927460988, Val MAE: 1.4794976711273193\n",
      "Epoch 222/2000, Train Loss: 4.714606126575624, Val Loss: 4.95101815816902, Val MAE: 1.4792581796646118\n",
      "Epoch 223/2000, Train Loss: 4.712899231079756, Val Loss: 4.947838499432518, Val MAE: 1.4793015718460083\n",
      "Epoch 224/2000, Train Loss: 4.7109062869810865, Val Loss: 4.944957433002336, Val MAE: 1.478853464126587\n",
      "Epoch 225/2000, Train Loss: 4.709215021005584, Val Loss: 4.942164665886334, Val MAE: 1.4789063930511475\n",
      "Epoch 226/2000, Train Loss: 4.707591938269362, Val Loss: 4.938569174635978, Val MAE: 1.4778192043304443\n",
      "Epoch 227/2000, Train Loss: 4.705780031853642, Val Loss: 4.935922416902724, Val MAE: 1.4776315689086914\n",
      "Epoch 228/2000, Train Loss: 4.703931460112093, Val Loss: 4.933807255256744, Val MAE: 1.4787020683288574\n",
      "Epoch 229/2000, Train Loss: 4.702522784072017, Val Loss: 4.93103422721227, Val MAE: 1.4789769649505615\n",
      "Epoch 230/2000, Train Loss: 4.700653014809452, Val Loss: 4.927841730770611, Val MAE: 1.4780170917510986\n",
      "Epoch 231/2000, Train Loss: 4.699075181107099, Val Loss: 4.9246407342808585, Val MAE: 1.4775997400283813\n",
      "Epoch 232/2000, Train Loss: 4.697336728707076, Val Loss: 4.922159593020167, Val MAE: 1.4773035049438477\n",
      "Epoch 233/2000, Train Loss: 4.695717047110959, Val Loss: 4.919944521217119, Val MAE: 1.477689504623413\n",
      "Epoch 234/2000, Train Loss: 4.69433657988786, Val Loss: 4.916712191842851, Val MAE: 1.4770233631134033\n",
      "Epoch 235/2000, Train Loss: 4.69281613091681, Val Loss: 4.913484716699237, Val MAE: 1.4757957458496094\n",
      "Epoch 236/2000, Train Loss: 4.691266315552249, Val Loss: 4.9109373199088235, Val MAE: 1.4754812717437744\n",
      "Epoch 237/2000, Train Loss: 4.689507587985124, Val Loss: 4.908529248975572, Val MAE: 1.4746854305267334\n",
      "Epoch 238/2000, Train Loss: 4.688794141160899, Val Loss: 4.90490254404999, Val MAE: 1.474052906036377\n",
      "Epoch 239/2000, Train Loss: 4.686874936796705, Val Loss: 4.903268872272401, Val MAE: 1.474926233291626\n",
      "Epoch 240/2000, Train Loss: 4.685237966338048, Val Loss: 4.901501081529117, Val MAE: 1.4750338792800903\n",
      "Epoch 241/2000, Train Loss: 4.683796490165567, Val Loss: 4.8987535046679636, Val MAE: 1.4744969606399536\n",
      "Epoch 242/2000, Train Loss: 4.683205158397276, Val Loss: 4.896274784491176, Val MAE: 1.4750566482543945\n",
      "Epoch 243/2000, Train Loss: 4.680749922591304, Val Loss: 4.894066558707328, Val MAE: 1.4738397598266602\n",
      "Epoch 244/2000, Train Loss: 4.6799369996098985, Val Loss: 4.892197252029464, Val MAE: 1.4741941690444946\n",
      "Epoch 245/2000, Train Loss: 4.67836156159879, Val Loss: 4.8902218363114764, Val MAE: 1.473635196685791\n",
      "Epoch 246/2000, Train Loss: 4.676954160746557, Val Loss: 4.886745296063877, Val MAE: 1.4712090492248535\n",
      "Epoch 247/2000, Train Loss: 4.6754007671857325, Val Loss: 4.884715721011162, Val MAE: 1.4705785512924194\n",
      "Epoch 248/2000, Train Loss: 4.674108942456284, Val Loss: 4.881961413792202, Val MAE: 1.4694119691848755\n",
      "Epoch 249/2000, Train Loss: 4.672986125179015, Val Loss: 4.880020834860348, Val MAE: 1.4700376987457275\n",
      "Epoch 250/2000, Train Loss: 4.671529266853435, Val Loss: 4.87712477289495, Val MAE: 1.4688444137573242\n",
      "Epoch 251/2000, Train Loss: 4.670119454330158, Val Loss: 4.8745025389251255, Val MAE: 1.467964768409729\n",
      "Epoch 252/2000, Train Loss: 4.668579134800479, Val Loss: 4.872728071752048, Val MAE: 1.4677317142486572\n",
      "Epoch 253/2000, Train Loss: 4.667685509367219, Val Loss: 4.869933331296558, Val MAE: 1.4674444198608398\n",
      "Epoch 254/2000, Train Loss: 4.665985703148727, Val Loss: 4.867933635200773, Val MAE: 1.4669772386550903\n",
      "Epoch 255/2000, Train Loss: 4.665062869202355, Val Loss: 4.865692738266218, Val MAE: 1.4670805931091309\n",
      "Epoch 256/2000, Train Loss: 4.6633116495833, Val Loss: 4.862890546520551, Val MAE: 1.4651319980621338\n",
      "Epoch 257/2000, Train Loss: 4.662108899441225, Val Loss: 4.861357502284504, Val MAE: 1.4652104377746582\n",
      "Epoch 258/2000, Train Loss: 4.66113236890082, Val Loss: 4.858434486247244, Val MAE: 1.4643765687942505\n",
      "Epoch 259/2000, Train Loss: 4.6596923123735525, Val Loss: 4.856718090318498, Val MAE: 1.464596152305603\n",
      "Epoch 260/2000, Train Loss: 4.658387637969316, Val Loss: 4.854938216862225, Val MAE: 1.464274525642395\n",
      "Epoch 261/2000, Train Loss: 4.657106266584218, Val Loss: 4.853162467479706, Val MAE: 1.4644824266433716\n",
      "Epoch 262/2000, Train Loss: 4.655893062458601, Val Loss: 4.850956527250154, Val MAE: 1.4642248153686523\n",
      "Epoch 263/2000, Train Loss: 4.654696098920807, Val Loss: 4.847543414859545, Val MAE: 1.4623545408248901\n",
      "Epoch 264/2000, Train Loss: 4.653132673882287, Val Loss: 4.84561410404387, Val MAE: 1.4619927406311035\n",
      "Epoch 265/2000, Train Loss: 4.652088399227439, Val Loss: 4.844338774681091, Val MAE: 1.4629592895507812\n",
      "Epoch 266/2000, Train Loss: 4.650934444355901, Val Loss: 4.84267473362741, Val MAE: 1.4640510082244873\n",
      "Epoch 267/2000, Train Loss: 4.650034861014931, Val Loss: 4.84078334129992, Val MAE: 1.462838053703308\n",
      "Epoch 268/2000, Train Loss: 4.648480725991503, Val Loss: 4.839221329206512, Val MAE: 1.463701844215393\n",
      "Epoch 269/2000, Train Loss: 4.647178468371844, Val Loss: 4.837084476436887, Val MAE: 1.463686227798462\n",
      "Epoch 270/2000, Train Loss: 4.645765530839363, Val Loss: 4.8343752054941085, Val MAE: 1.4621340036392212\n",
      "Epoch 271/2000, Train Loss: 4.64473010068285, Val Loss: 4.831669236222903, Val MAE: 1.4614744186401367\n",
      "Epoch 272/2000, Train Loss: 4.643373240095041, Val Loss: 4.829248537619908, Val MAE: 1.4599488973617554\n",
      "Epoch 273/2000, Train Loss: 4.642363610919615, Val Loss: 4.827379973161788, Val MAE: 1.4596366882324219\n",
      "Epoch 274/2000, Train Loss: 4.641360943183183, Val Loss: 4.824347498161452, Val MAE: 1.4577884674072266\n",
      "Epoch 275/2000, Train Loss: 4.6399747705331755, Val Loss: 4.822829424625351, Val MAE: 1.458016037940979\n",
      "Epoch 276/2000, Train Loss: 4.638918713654014, Val Loss: 4.82060979164782, Val MAE: 1.457581877708435\n",
      "Epoch 277/2000, Train Loss: 4.637732226151883, Val Loss: 4.819054039461272, Val MAE: 1.4578076601028442\n",
      "Epoch 278/2000, Train Loss: 4.636479157864568, Val Loss: 4.817020725636255, Val MAE: 1.456755518913269\n",
      "Epoch 279/2000, Train Loss: 4.635296913318276, Val Loss: 4.815212287363552, Val MAE: 1.4565461874008179\n",
      "Epoch 280/2000, Train Loss: 4.63421924376296, Val Loss: 4.812652946228073, Val MAE: 1.4547007083892822\n",
      "Epoch 281/2000, Train Loss: 4.633149109960561, Val Loss: 4.810322652970042, Val MAE: 1.453779697418213\n",
      "Epoch 282/2000, Train Loss: 4.632063677739202, Val Loss: 4.808761225569816, Val MAE: 1.454036831855774\n",
      "Epoch 283/2000, Train Loss: 4.630804973377299, Val Loss: 4.807257247822625, Val MAE: 1.4544681310653687\n",
      "Epoch 284/2000, Train Loss: 4.62983251321092, Val Loss: 4.805671712472325, Val MAE: 1.4541382789611816\n",
      "Epoch 285/2000, Train Loss: 4.62846050121829, Val Loss: 4.803310214054017, Val MAE: 1.4536715745925903\n",
      "Epoch 286/2000, Train Loss: 4.6275688291554795, Val Loss: 4.8013605418659395, Val MAE: 1.4541993141174316\n",
      "Epoch 287/2000, Train Loss: 4.626369963382588, Val Loss: 4.7999598908992045, Val MAE: 1.453988790512085\n",
      "Epoch 288/2000, Train Loss: 4.6252071787141285, Val Loss: 4.797851397877648, Val MAE: 1.4533402919769287\n",
      "Epoch 289/2000, Train Loss: 4.624121384070961, Val Loss: 4.796823578221457, Val MAE: 1.4535186290740967\n",
      "Epoch 290/2000, Train Loss: 4.623502205907499, Val Loss: 4.795561260410717, Val MAE: 1.4527040719985962\n",
      "Epoch 291/2000, Train Loss: 4.622343891747196, Val Loss: 4.793408510940416, Val MAE: 1.452086091041565\n",
      "Epoch 292/2000, Train Loss: 4.6212403454665525, Val Loss: 4.792044081858227, Val MAE: 1.4525411128997803\n",
      "Epoch 293/2000, Train Loss: 4.62054679029429, Val Loss: 4.7896394296771, Val MAE: 1.450545310974121\n",
      "Epoch 294/2000, Train Loss: 4.619407776213843, Val Loss: 4.788266696390652, Val MAE: 1.4510372877120972\n",
      "Epoch 295/2000, Train Loss: 4.618488876813219, Val Loss: 4.786276384478524, Val MAE: 1.4494259357452393\n",
      "Epoch 296/2000, Train Loss: 4.6181590569882225, Val Loss: 4.785754315909886, Val MAE: 1.4514830112457275\n",
      "Epoch 297/2000, Train Loss: 4.6161691912377485, Val Loss: 4.7835057363623665, Val MAE: 1.4498647451400757\n",
      "Epoch 298/2000, Train Loss: 4.6152518684039485, Val Loss: 4.781518675032116, Val MAE: 1.4492719173431396\n",
      "Epoch 299/2000, Train Loss: 4.614359169159754, Val Loss: 4.779347778076217, Val MAE: 1.4476182460784912\n",
      "Epoch 300/2000, Train Loss: 4.613572676763458, Val Loss: 4.778192573360035, Val MAE: 1.44834566116333\n",
      "Epoch 301/2000, Train Loss: 4.612395528174598, Val Loss: 4.776287480479195, Val MAE: 1.4466853141784668\n",
      "Epoch 302/2000, Train Loss: 4.611375239835028, Val Loss: 4.775196233675594, Val MAE: 1.4465937614440918\n",
      "Epoch 303/2000, Train Loss: 4.611176686376413, Val Loss: 4.772278626759847, Val MAE: 1.4461021423339844\n",
      "Epoch 304/2000, Train Loss: 4.60959370845764, Val Loss: 4.771747741670835, Val MAE: 1.4463289976119995\n",
      "Epoch 305/2000, Train Loss: 4.608584044765851, Val Loss: 4.7702444571824305, Val MAE: 1.4475634098052979\n",
      "Epoch 306/2000, Train Loss: 4.607465645583002, Val Loss: 4.768501657815206, Val MAE: 1.4464190006256104\n",
      "Epoch 307/2000, Train Loss: 4.607465043464231, Val Loss: 4.766693811331477, Val MAE: 1.4471445083618164\n",
      "Epoch 308/2000, Train Loss: 4.605668947460185, Val Loss: 4.764378044576872, Val MAE: 1.4447369575500488\n",
      "Epoch 309/2000, Train Loss: 4.60484237389654, Val Loss: 4.762847315697443, Val MAE: 1.445167899131775\n",
      "Epoch 310/2000, Train Loss: 4.603467092437335, Val Loss: 4.76147459376426, Val MAE: 1.4447157382965088\n",
      "Epoch 311/2000, Train Loss: 4.602964492010367, Val Loss: 4.760809393865721, Val MAE: 1.4460477828979492\n",
      "Epoch 312/2000, Train Loss: 4.602048088334521, Val Loss: 4.758817945917447, Val MAE: 1.4446766376495361\n",
      "Epoch 313/2000, Train Loss: 4.600866257664984, Val Loss: 4.757532432675362, Val MAE: 1.4444469213485718\n",
      "Epoch 314/2000, Train Loss: 4.6004386894185165, Val Loss: 4.755559580666678, Val MAE: 1.4428772926330566\n",
      "Epoch 315/2000, Train Loss: 4.599018297630085, Val Loss: 4.75458225607872, Val MAE: 1.4433636665344238\n",
      "Epoch 316/2000, Train Loss: 4.598078606595303, Val Loss: 4.753748751112393, Val MAE: 1.4441053867340088\n",
      "Epoch 317/2000, Train Loss: 4.5974705566030405, Val Loss: 4.753234162217095, Val MAE: 1.4446595907211304\n",
      "Epoch 318/2000, Train Loss: 4.596915848453307, Val Loss: 4.749947827486765, Val MAE: 1.4415380954742432\n",
      "Epoch 319/2000, Train Loss: 4.5957572351511935, Val Loss: 4.748571726537886, Val MAE: 1.441769003868103\n",
      "Epoch 320/2000, Train Loss: 4.594873083820292, Val Loss: 4.747889828823862, Val MAE: 1.4426605701446533\n",
      "Epoch 321/2000, Train Loss: 4.5940206172319265, Val Loss: 4.746800092714174, Val MAE: 1.4411180019378662\n",
      "Epoch 322/2000, Train Loss: 4.593284871559041, Val Loss: 4.74625775147052, Val MAE: 1.4415230751037598\n",
      "Epoch 323/2000, Train Loss: 4.592635681418248, Val Loss: 4.744938633981205, Val MAE: 1.4419424533843994\n",
      "Epoch 324/2000, Train Loss: 4.591853702995157, Val Loss: 4.7421346207459765, Val MAE: 1.439028024673462\n",
      "Epoch 325/2000, Train Loss: 4.590834468683033, Val Loss: 4.740086082191694, Val MAE: 1.4390490055084229\n",
      "Epoch 326/2000, Train Loss: 4.58999393197231, Val Loss: 4.738841863615172, Val MAE: 1.4396653175354004\n",
      "Epoch 327/2000, Train Loss: 4.5889438061547985, Val Loss: 4.737431629073052, Val MAE: 1.4384785890579224\n",
      "Epoch 328/2000, Train Loss: 4.588437605799044, Val Loss: 4.737541981396221, Val MAE: 1.4395551681518555\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 329/2000, Train Loss: 4.587399976183199, Val Loss: 4.736014888400123, Val MAE: 1.4395456314086914\n",
      "Epoch 330/2000, Train Loss: 4.586534656084894, Val Loss: 4.734293443816049, Val MAE: 1.4390618801116943\n",
      "Epoch 331/2000, Train Loss: 4.585721235172998, Val Loss: 4.733114601600738, Val MAE: 1.4387952089309692\n",
      "Epoch 332/2000, Train Loss: 4.585006748063954, Val Loss: 4.732299212898527, Val MAE: 1.4390963315963745\n",
      "Epoch 333/2000, Train Loss: 4.584174884867732, Val Loss: 4.730491937625976, Val MAE: 1.4377210140228271\n",
      "Epoch 334/2000, Train Loss: 4.58362513221301, Val Loss: 4.728442967647598, Val MAE: 1.435734748840332\n",
      "Epoch 335/2000, Train Loss: 4.582639849537499, Val Loss: 4.7273038412843436, Val MAE: 1.4358932971954346\n",
      "Epoch 336/2000, Train Loss: 4.581956064413444, Val Loss: 4.725493436058362, Val MAE: 1.4347081184387207\n",
      "Epoch 337/2000, Train Loss: 4.5815665421473115, Val Loss: 4.72442919299716, Val MAE: 1.4339700937271118\n",
      "Epoch 338/2000, Train Loss: 4.580399797685025, Val Loss: 4.7230878209783915, Val MAE: 1.4344502687454224\n",
      "Epoch 339/2000, Train Loss: 4.579693794250488, Val Loss: 4.722877239187558, Val MAE: 1.434792160987854\n",
      "Epoch 340/2000, Train Loss: 4.578992584116018, Val Loss: 4.7218806857154485, Val MAE: 1.435315489768982\n",
      "Epoch 341/2000, Train Loss: 4.5781294040321985, Val Loss: 4.720086311300595, Val MAE: 1.4335333108901978\n",
      "Epoch 342/2000, Train Loss: 4.577426620207268, Val Loss: 4.719075752865701, Val MAE: 1.433667540550232\n",
      "Epoch 343/2000, Train Loss: 4.576767149943129, Val Loss: 4.717167502357846, Val MAE: 1.4329259395599365\n",
      "Epoch 344/2000, Train Loss: 4.575846558281947, Val Loss: 4.715539499407723, Val MAE: 1.4320751428604126\n",
      "Epoch 345/2000, Train Loss: 4.5753256290272155, Val Loss: 4.713796976066771, Val MAE: 1.4316219091415405\n",
      "Epoch 346/2000, Train Loss: 4.57449832231046, Val Loss: 4.712634468362445, Val MAE: 1.430561900138855\n",
      "Epoch 347/2000, Train Loss: 4.573986424198099, Val Loss: 4.712458658786047, Val MAE: 1.4324798583984375\n",
      "Epoch 348/2000, Train Loss: 4.5728950807300395, Val Loss: 4.711769419766608, Val MAE: 1.4330097436904907\n",
      "Epoch 349/2000, Train Loss: 4.572186231613159, Val Loss: 4.711519533679599, Val MAE: 1.4335191249847412\n",
      "Epoch 350/2000, Train Loss: 4.571850254132984, Val Loss: 4.710474783465976, Val MAE: 1.434044599533081\n",
      "Epoch 351/2000, Train Loss: 4.570926270599979, Val Loss: 4.708513208798, Val MAE: 1.4315872192382812\n",
      "Epoch 352/2000, Train Loss: 4.570178269061582, Val Loss: 4.707789464365868, Val MAE: 1.4313372373580933\n",
      "Epoch 353/2000, Train Loss: 4.569907561703597, Val Loss: 4.707895359822682, Val MAE: 1.433609962463379\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 354/2000, Train Loss: 4.568745434124412, Val Loss: 4.706464087679272, Val MAE: 1.4325439929962158\n",
      "Epoch 355/2000, Train Loss: 4.568193684953787, Val Loss: 4.705716069965136, Val MAE: 1.4334193468093872\n",
      "Epoch 356/2000, Train Loss: 4.56753076880611, Val Loss: 4.704073663268771, Val MAE: 1.4327201843261719\n",
      "Epoch 357/2000, Train Loss: 4.56659158113495, Val Loss: 4.7028994751828055, Val MAE: 1.4313397407531738\n",
      "Epoch 358/2000, Train Loss: 4.565873584542773, Val Loss: 4.701628994374048, Val MAE: 1.4316381216049194\n",
      "Epoch 359/2000, Train Loss: 4.565161249912456, Val Loss: 4.700919258452597, Val MAE: 1.4320842027664185\n",
      "Epoch 360/2000, Train Loss: 4.564768832107013, Val Loss: 4.698455661535263, Val MAE: 1.4303499460220337\n",
      "Epoch 361/2000, Train Loss: 4.563773955480663, Val Loss: 4.698545505603154, Val MAE: 1.430794358253479\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 362/2000, Train Loss: 4.563140989308702, Val Loss: 4.69716698427995, Val MAE: 1.4296600818634033\n",
      "Epoch 363/2000, Train Loss: 4.562589934939673, Val Loss: 4.696018913672084, Val MAE: 1.4291187524795532\n",
      "Epoch 364/2000, Train Loss: 4.5621720689870715, Val Loss: 4.695381053146862, Val MAE: 1.4289058446884155\n",
      "Epoch 365/2000, Train Loss: 4.5610796913065155, Val Loss: 4.694195557208288, Val MAE: 1.4290095567703247\n",
      "Epoch 366/2000, Train Loss: 4.56096818683614, Val Loss: 4.692521100952511, Val MAE: 1.4289458990097046\n",
      "Epoch 367/2000, Train Loss: 4.5597332284533625, Val Loss: 4.691657534667423, Val MAE: 1.4284573793411255\n",
      "Epoch 368/2000, Train Loss: 4.559334255095781, Val Loss: 4.69004800135181, Val MAE: 1.4266996383666992\n",
      "Epoch 369/2000, Train Loss: 4.558752151340966, Val Loss: 4.688866083820661, Val MAE: 1.425980567932129\n",
      "Epoch 370/2000, Train Loss: 4.558211052385795, Val Loss: 4.688975650639761, Val MAE: 1.4271575212478638\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 371/2000, Train Loss: 4.5573552159777275, Val Loss: 4.687370595477876, Val MAE: 1.4260039329528809\n",
      "Epoch 372/2000, Train Loss: 4.55697938967646, Val Loss: 4.685517844699678, Val MAE: 1.4243680238723755\n",
      "Epoch 373/2000, Train Loss: 4.5561215321436, Val Loss: 4.684959693323998, Val MAE: 1.4252163171768188\n",
      "Epoch 374/2000, Train Loss: 4.555482875885337, Val Loss: 4.684165354995501, Val MAE: 1.4245294332504272\n",
      "Epoch 375/2000, Train Loss: 4.554962182492417, Val Loss: 4.6836372791301635, Val MAE: 1.4260284900665283\n",
      "Epoch 376/2000, Train Loss: 4.554323493954962, Val Loss: 4.68315302616074, Val MAE: 1.4258288145065308\n",
      "Epoch 377/2000, Train Loss: 4.553643484857063, Val Loss: 4.682199747079895, Val MAE: 1.4253652095794678\n",
      "Epoch 378/2000, Train Loss: 4.552958854082123, Val Loss: 4.681104789177577, Val MAE: 1.425362229347229\n",
      "Epoch 379/2000, Train Loss: 4.552722085257318, Val Loss: 4.678873981748309, Val MAE: 1.4238545894622803\n",
      "Epoch 380/2000, Train Loss: 4.551858770304007, Val Loss: 4.677957944926762, Val MAE: 1.4225499629974365\n",
      "Epoch 381/2000, Train Loss: 4.551261100308825, Val Loss: 4.677397637849762, Val MAE: 1.422978401184082\n",
      "Epoch 382/2000, Train Loss: 4.550680542759218, Val Loss: 4.675984765092532, Val MAE: 1.4216617345809937\n",
      "Epoch 383/2000, Train Loss: 4.550552974117985, Val Loss: 4.676454598704974, Val MAE: 1.4227898120880127\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 384/2000, Train Loss: 4.549707754048201, Val Loss: 4.674377030559948, Val MAE: 1.4216933250427246\n",
      "Epoch 385/2000, Train Loss: 4.549087363337703, Val Loss: 4.674192998380888, Val MAE: 1.4232697486877441\n",
      "Epoch 386/2000, Train Loss: 4.548354176989189, Val Loss: 4.672428208447638, Val MAE: 1.421683669090271\n",
      "Epoch 387/2000, Train Loss: 4.547542355974622, Val Loss: 4.672275413359914, Val MAE: 1.4220819473266602\n",
      "Epoch 388/2000, Train Loss: 4.547361876306201, Val Loss: 4.672405702017603, Val MAE: 1.4238464832305908\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 389/2000, Train Loss: 4.546574594827503, Val Loss: 4.671080213217508, Val MAE: 1.4226889610290527\n",
      "Epoch 390/2000, Train Loss: 4.546272178757286, Val Loss: 4.6702291043031785, Val MAE: 1.421234369277954\n",
      "Epoch 391/2000, Train Loss: 4.545401482415903, Val Loss: 4.669205911102749, Val MAE: 1.420944094657898\n",
      "Epoch 392/2000, Train Loss: 4.545334147384275, Val Loss: 4.6689026675054, Val MAE: 1.4224600791931152\n",
      "Epoch 393/2000, Train Loss: 4.544426374077477, Val Loss: 4.66689342828024, Val MAE: 1.4209827184677124\n",
      "Epoch 394/2000, Train Loss: 4.5441554928592955, Val Loss: 4.665992563679104, Val MAE: 1.4191148281097412\n",
      "Epoch 395/2000, Train Loss: 4.5432589565461186, Val Loss: 4.664515517297245, Val MAE: 1.4190902709960938\n",
      "Epoch 396/2000, Train Loss: 4.542905288471293, Val Loss: 4.66346632369927, Val MAE: 1.4180272817611694\n",
      "Epoch 397/2000, Train Loss: 4.542410064318864, Val Loss: 4.66407252351443, Val MAE: 1.4200392961502075\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 398/2000, Train Loss: 4.541594256025217, Val Loss: 4.662923699333554, Val MAE: 1.4201303720474243\n",
      "Epoch 399/2000, Train Loss: 4.541449986577993, Val Loss: 4.662758655491329, Val MAE: 1.4214226007461548\n",
      "Epoch 400/2000, Train Loss: 4.540535108653215, Val Loss: 4.662040546536446, Val MAE: 1.4210461378097534\n",
      "Epoch 401/2000, Train Loss: 4.539938936923848, Val Loss: 4.6610118470021655, Val MAE: 1.4201322793960571\n",
      "Epoch 402/2000, Train Loss: 4.539553093207106, Val Loss: 4.660001678126199, Val MAE: 1.420379638671875\n",
      "Epoch 403/2000, Train Loss: 4.53924295601832, Val Loss: 4.659459370232764, Val MAE: 1.4207407236099243\n",
      "Epoch 404/2000, Train Loss: 4.538692122809689, Val Loss: 4.659455087922868, Val MAE: 1.4219937324523926\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 405/2000, Train Loss: 4.538141033924297, Val Loss: 4.657359172190938, Val MAE: 1.4191385507583618\n",
      "Epoch 406/2000, Train Loss: 4.537685103454795, Val Loss: 4.657279020973614, Val MAE: 1.4201620817184448\n",
      "Epoch 407/2000, Train Loss: 4.537004571817516, Val Loss: 4.656124455588205, Val MAE: 1.4198167324066162\n",
      "Epoch 408/2000, Train Loss: 4.536458850865709, Val Loss: 4.653953969478607, Val MAE: 1.416570782661438\n",
      "Epoch 409/2000, Train Loss: 4.53621181917574, Val Loss: 4.6547009767521, Val MAE: 1.417718768119812\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 410/2000, Train Loss: 4.535546231205918, Val Loss: 4.653500424254508, Val MAE: 1.4166905879974365\n",
      "Epoch 411/2000, Train Loss: 4.534831353870218, Val Loss: 4.653266557625362, Val MAE: 1.417968511581421\n",
      "Epoch 412/2000, Train Loss: 4.5349962244724145, Val Loss: 4.652632201711337, Val MAE: 1.4197118282318115\n",
      "Epoch 413/2000, Train Loss: 4.533970499166535, Val Loss: 4.652306450264795, Val MAE: 1.4199371337890625\n",
      "Epoch 414/2000, Train Loss: 4.533355178526196, Val Loss: 4.650919191184498, Val MAE: 1.4184608459472656\n",
      "Epoch 415/2000, Train Loss: 4.532923335364293, Val Loss: 4.650091620428221, Val MAE: 1.4176839590072632\n",
      "Epoch 416/2000, Train Loss: 4.532965914493592, Val Loss: 4.648359955066726, Val MAE: 1.4178037643432617\n",
      "Epoch 417/2000, Train Loss: 4.532009067228588, Val Loss: 4.647966901461284, Val MAE: 1.416969656944275\n",
      "Epoch 418/2000, Train Loss: 4.531430880441742, Val Loss: 4.647187056285994, Val MAE: 1.417522668838501\n",
      "Epoch 419/2000, Train Loss: 4.5309958592177075, Val Loss: 4.6468418552761985, Val MAE: 1.4171327352523804\n",
      "Epoch 420/2000, Train Loss: 4.530442362496425, Val Loss: 4.645349532365799, Val MAE: 1.4159284830093384\n",
      "Epoch 421/2000, Train Loss: 4.530061613139135, Val Loss: 4.64477637339206, Val MAE: 1.415476679801941\n",
      "Epoch 422/2000, Train Loss: 4.529602969939203, Val Loss: 4.643930259205046, Val MAE: 1.4160908460617065\n",
      "Epoch 423/2000, Train Loss: 4.529133630502001, Val Loss: 4.642808382000242, Val MAE: 1.4151357412338257\n",
      "Epoch 424/2000, Train Loss: 4.528357936933277, Val Loss: 4.642435977146739, Val MAE: 1.415433406829834\n",
      "Epoch 425/2000, Train Loss: 4.528230624927592, Val Loss: 4.642046942597344, Val MAE: 1.4162265062332153\n",
      "Epoch 426/2000, Train Loss: 4.527665392003813, Val Loss: 4.641059976958093, Val MAE: 1.4152425527572632\n",
      "Epoch 427/2000, Train Loss: 4.527323722200164, Val Loss: 4.640180601960137, Val MAE: 1.4155197143554688\n",
      "Epoch 428/2000, Train Loss: 4.527507706557778, Val Loss: 4.639903260128839, Val MAE: 1.4137166738510132\n",
      "Epoch 429/2000, Train Loss: 4.526366270898814, Val Loss: 4.639099297069368, Val MAE: 1.4137736558914185\n",
      "Epoch 430/2000, Train Loss: 4.525792753408806, Val Loss: 4.639205567183948, Val MAE: 1.4140701293945312\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 431/2000, Train Loss: 4.525668425470511, Val Loss: 4.6383653701770875, Val MAE: 1.4132051467895508\n",
      "Epoch 432/2000, Train Loss: 4.524919696531731, Val Loss: 4.638825112155506, Val MAE: 1.415493130683899\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 433/2000, Train Loss: 4.524553117419695, Val Loss: 4.637909897736141, Val MAE: 1.4148962497711182\n",
      "Epoch 434/2000, Train Loss: 4.524071079796185, Val Loss: 4.6376464530116035, Val MAE: 1.4151017665863037\n",
      "Epoch 435/2000, Train Loss: 4.52362134181782, Val Loss: 4.637399599665687, Val MAE: 1.4164159297943115\n",
      "Epoch 436/2000, Train Loss: 4.5230284101522, Val Loss: 4.636831299889655, Val MAE: 1.4163024425506592\n",
      "Epoch 437/2000, Train Loss: 4.522742899109787, Val Loss: 4.6372991502285, Val MAE: 1.417140245437622\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 438/2000, Train Loss: 4.522247389877769, Val Loss: 4.635728174022266, Val MAE: 1.4159173965454102\n",
      "Epoch 439/2000, Train Loss: 4.521859153665742, Val Loss: 4.635040322939555, Val MAE: 1.4149224758148193\n",
      "Epoch 440/2000, Train Loss: 4.521921925506387, Val Loss: 4.634287488602457, Val MAE: 1.4165290594100952\n",
      "Epoch 441/2000, Train Loss: 4.521081998584737, Val Loss: 4.633182009061177, Val MAE: 1.4145042896270752\n",
      "Epoch 442/2000, Train Loss: 4.5204759244944395, Val Loss: 4.632966978209359, Val MAE: 1.415684700012207\n",
      "Epoch 443/2000, Train Loss: 4.519913571130175, Val Loss: 4.631878789691698, Val MAE: 1.4149975776672363\n",
      "Epoch 444/2000, Train Loss: 4.520112102856265, Val Loss: 4.632585311219806, Val MAE: 1.4166549444198608\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 445/2000, Train Loss: 4.519467109010303, Val Loss: 4.6302023487431665, Val MAE: 1.4140350818634033\n",
      "Epoch 446/2000, Train Loss: 4.518852089429349, Val Loss: 4.630058732770738, Val MAE: 1.414091944694519\n",
      "Epoch 447/2000, Train Loss: 4.518427816217131, Val Loss: 4.629781013443356, Val MAE: 1.4142810106277466\n",
      "Epoch 448/2000, Train Loss: 4.518001555757293, Val Loss: 4.629039880065691, Val MAE: 1.4146177768707275\n",
      "Epoch 449/2000, Train Loss: 4.517765363483583, Val Loss: 4.626771946038518, Val MAE: 1.4117581844329834\n",
      "Epoch 450/2000, Train Loss: 4.517701653948418, Val Loss: 4.6282152363232205, Val MAE: 1.414647102355957\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 451/2000, Train Loss: 4.5169330205738385, Val Loss: 4.628054115743864, Val MAE: 1.4142354726791382\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 452/2000, Train Loss: 4.516493758950732, Val Loss: 4.626385869014831, Val MAE: 1.4138967990875244\n",
      "Epoch 453/2000, Train Loss: 4.516221951543486, Val Loss: 4.625284689522925, Val MAE: 1.4118764400482178\n",
      "Epoch 454/2000, Train Loss: 4.515621714553628, Val Loss: 4.624736658874012, Val MAE: 1.4125216007232666\n",
      "Epoch 455/2000, Train Loss: 4.515072574244747, Val Loss: 4.623296662455513, Val MAE: 1.4107885360717773\n",
      "Epoch 456/2000, Train Loss: 4.514996237153982, Val Loss: 4.622196866642861, Val MAE: 1.408448576927185\n",
      "Epoch 457/2000, Train Loss: 4.514684064778182, Val Loss: 4.62259856859843, Val MAE: 1.4092835187911987\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 458/2000, Train Loss: 4.513978021713748, Val Loss: 4.622591735351653, Val MAE: 1.4115229845046997\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 459/2000, Train Loss: 4.513588836301747, Val Loss: 4.6217824178082605, Val MAE: 1.41066575050354\n",
      "Epoch 460/2000, Train Loss: 4.513190306543345, Val Loss: 4.62061195856049, Val MAE: 1.4109923839569092\n",
      "Epoch 461/2000, Train Loss: 4.512489571967649, Val Loss: 4.619683854636692, Val MAE: 1.4102344512939453\n",
      "Epoch 462/2000, Train Loss: 4.512235544322324, Val Loss: 4.6195937756981165, Val MAE: 1.4103912115097046\n",
      "Epoch 463/2000, Train Loss: 4.512028235213047, Val Loss: 4.619040260002727, Val MAE: 1.4112143516540527\n",
      "Epoch 464/2000, Train Loss: 4.511349060580175, Val Loss: 4.6189720424867815, Val MAE: 1.4112728834152222\n",
      "Epoch 465/2000, Train Loss: 4.511461307791539, Val Loss: 4.619397154166585, Val MAE: 1.413128137588501\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 466/2000, Train Loss: 4.510691588429919, Val Loss: 4.618612165961947, Val MAE: 1.4122363328933716\n",
      "Epoch 467/2000, Train Loss: 4.51063316948612, Val Loss: 4.6165522783994675, Val MAE: 1.4107580184936523\n",
      "Epoch 468/2000, Train Loss: 4.5103585752021855, Val Loss: 4.61760587138789, Val MAE: 1.4106026887893677\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 469/2000, Train Loss: 4.509904411459097, Val Loss: 4.615379111397834, Val MAE: 1.40865159034729\n",
      "Epoch 470/2000, Train Loss: 4.509260561127445, Val Loss: 4.615501918253445, Val MAE: 1.4091520309448242\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 471/2000, Train Loss: 4.508768740032697, Val Loss: 4.616339239336195, Val MAE: 1.412003517150879\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 472/2000, Train Loss: 4.508333376201803, Val Loss: 4.616595931705975, Val MAE: 1.4130700826644897\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 473/2000, Train Loss: 4.508533504629263, Val Loss: 4.615745051276116, Val MAE: 1.4136590957641602\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 474/2000, Train Loss: 4.507731376320683, Val Loss: 4.614946594550496, Val MAE: 1.4120261669158936\n",
      "Epoch 475/2000, Train Loss: 4.50713992310593, Val Loss: 4.613589919039181, Val MAE: 1.4107511043548584\n",
      "Epoch 476/2000, Train Loss: 4.506960187456882, Val Loss: 4.613550587069421, Val MAE: 1.4117425680160522\n",
      "Epoch 477/2000, Train Loss: 4.506488576331662, Val Loss: 4.613166432295527, Val MAE: 1.4112756252288818\n",
      "Epoch 478/2000, Train Loss: 4.506115114401237, Val Loss: 4.611556229846818, Val MAE: 1.4094164371490479\n",
      "Epoch 479/2000, Train Loss: 4.505890820045574, Val Loss: 4.6113387282405585, Val MAE: 1.4084874391555786\n",
      "Epoch 480/2000, Train Loss: 4.505230653062263, Val Loss: 4.611507061691511, Val MAE: 1.4094356298446655\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 481/2000, Train Loss: 4.504935530491233, Val Loss: 4.610464096069336, Val MAE: 1.4087108373641968\n",
      "Epoch 482/2000, Train Loss: 4.504521844214473, Val Loss: 4.608776467896643, Val MAE: 1.4080393314361572\n",
      "Epoch 483/2000, Train Loss: 4.504372015715284, Val Loss: 4.608905449509621, Val MAE: 1.4098117351531982\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 484/2000, Train Loss: 4.503714556348867, Val Loss: 4.608708417131787, Val MAE: 1.4092795848846436\n",
      "Epoch 485/2000, Train Loss: 4.504024036448379, Val Loss: 4.6067428049587065, Val MAE: 1.4059683084487915\n",
      "Epoch 486/2000, Train Loss: 4.503698721967497, Val Loss: 4.608538379981404, Val MAE: 1.4088054895401\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 487/2000, Train Loss: 4.502680807267054, Val Loss: 4.608522542175793, Val MAE: 1.4100075960159302\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 488/2000, Train Loss: 4.50266064427813, Val Loss: 4.60643257981255, Val MAE: 1.4085384607315063\n",
      "Epoch 489/2000, Train Loss: 4.501975901325011, Val Loss: 4.606976231648808, Val MAE: 1.4095878601074219\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 490/2000, Train Loss: 4.5018598323852705, Val Loss: 4.604964942449615, Val MAE: 1.406052589416504\n",
      "Epoch 491/2000, Train Loss: 4.501128150694492, Val Loss: 4.604560382309414, Val MAE: 1.40592360496521\n",
      "Epoch 492/2000, Train Loss: 4.500966956724111, Val Loss: 4.605431389240992, Val MAE: 1.407767653465271\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 493/2000, Train Loss: 4.500443101248856, Val Loss: 4.604382624228795, Val MAE: 1.406847596168518\n",
      "Epoch 494/2000, Train Loss: 4.500134557565479, Val Loss: 4.602872180796805, Val MAE: 1.4057295322418213\n",
      "Epoch 495/2000, Train Loss: 4.499834019760663, Val Loss: 4.603127438397634, Val MAE: 1.4061050415039062\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 496/2000, Train Loss: 4.499669852269559, Val Loss: 4.603774851276761, Val MAE: 1.4089685678482056\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 497/2000, Train Loss: 4.4991080524454805, Val Loss: 4.603518079434123, Val MAE: 1.409423828125\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 498/2000, Train Loss: 4.498543576964105, Val Loss: 4.602877427424703, Val MAE: 1.408366322517395\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 499/2000, Train Loss: 4.498283345322187, Val Loss: 4.601315092472803, Val MAE: 1.406667947769165\n",
      "Epoch 500/2000, Train Loss: 4.4978370068859475, Val Loss: 4.599997481419926, Val MAE: 1.4065542221069336\n",
      "Epoch 501/2000, Train Loss: 4.497453088734808, Val Loss: 4.599821296476183, Val MAE: 1.4069719314575195\n",
      "Epoch 502/2000, Train Loss: 4.497203267611384, Val Loss: 4.59870107400985, Val MAE: 1.4064054489135742\n",
      "Epoch 503/2000, Train Loss: 4.496727148265685, Val Loss: 4.598137869721367, Val MAE: 1.405765175819397\n",
      "Epoch 504/2000, Train Loss: 4.496302451269237, Val Loss: 4.5966882684401105, Val MAE: 1.4046481847763062\n",
      "Epoch 505/2000, Train Loss: 4.496151795016536, Val Loss: 4.595222000564847, Val MAE: 1.4040789604187012\n",
      "Epoch 506/2000, Train Loss: 4.495687961578369, Val Loss: 4.595825937532243, Val MAE: 1.4060637950897217\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 507/2000, Train Loss: 4.495129462541268, Val Loss: 4.595285036734173, Val MAE: 1.4062155485153198\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 508/2000, Train Loss: 4.4950642106360466, Val Loss: 4.593733307861147, Val MAE: 1.405182123184204\n",
      "Epoch 509/2000, Train Loss: 4.494574126225694, Val Loss: 4.593960429231326, Val MAE: 1.406340479850769\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 510/2000, Train Loss: 4.494315443984944, Val Loss: 4.593742118704887, Val MAE: 1.4071455001831055\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 511/2000, Train Loss: 4.4937476907275, Val Loss: 4.592872567829632, Val MAE: 1.4054930210113525\n",
      "Epoch 512/2000, Train Loss: 4.493445018021735, Val Loss: 4.592184490391186, Val MAE: 1.4054001569747925\n",
      "Epoch 513/2000, Train Loss: 4.493157924979366, Val Loss: 4.591532815070379, Val MAE: 1.4054358005523682\n",
      "Epoch 514/2000, Train Loss: 4.493160765548175, Val Loss: 4.5895396165904545, Val MAE: 1.4038382768630981\n",
      "Epoch 515/2000, Train Loss: 4.492584045706741, Val Loss: 4.59052838456063, Val MAE: 1.4037268161773682\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 516/2000, Train Loss: 4.492249313691985, Val Loss: 4.589383199810982, Val MAE: 1.4036303758621216\n",
      "Epoch 517/2000, Train Loss: 4.491688269392735, Val Loss: 4.589060465494792, Val MAE: 1.4039077758789062\n",
      "Epoch 518/2000, Train Loss: 4.491789372932495, Val Loss: 4.588608954633985, Val MAE: 1.4024145603179932\n",
      "Epoch 519/2000, Train Loss: 4.491276073072296, Val Loss: 4.588299288636162, Val MAE: 1.4039195775985718\n",
      "Epoch 520/2000, Train Loss: 4.490752506511781, Val Loss: 4.587825508344741, Val MAE: 1.4038416147232056\n",
      "Epoch 521/2000, Train Loss: 4.4909593304744035, Val Loss: 4.585946242724146, Val MAE: 1.400738000869751\n",
      "Epoch 522/2000, Train Loss: 4.48990774793855, Val Loss: 4.5863368319613596, Val MAE: 1.401256799697876\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 523/2000, Train Loss: 4.489975103424317, Val Loss: 4.5874284491652535, Val MAE: 1.403779149055481\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 524/2000, Train Loss: 4.489774335165765, Val Loss: 4.5856894581090835, Val MAE: 1.4003286361694336\n",
      "Epoch 525/2000, Train Loss: 4.488940977858475, Val Loss: 4.585058137064888, Val MAE: 1.4005134105682373\n",
      "Epoch 526/2000, Train Loss: 4.488484846682715, Val Loss: 4.585262964169185, Val MAE: 1.4009332656860352\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 527/2000, Train Loss: 4.488418974761349, Val Loss: 4.584592255098479, Val MAE: 1.4018256664276123\n",
      "Epoch 528/2000, Train Loss: 4.488067264531317, Val Loss: 4.584245968432653, Val MAE: 1.400781512260437\n",
      "Epoch 529/2000, Train Loss: 4.487575785404236, Val Loss: 4.5846055164223625, Val MAE: 1.4019668102264404\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 530/2000, Train Loss: 4.487397677137769, Val Loss: 4.585403560172944, Val MAE: 1.404299259185791\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 531/2000, Train Loss: 4.48731118680325, Val Loss: 4.584293447080112, Val MAE: 1.4022939205169678\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 532/2000, Train Loss: 4.486352909026772, Val Loss: 4.583135681492942, Val MAE: 1.4023046493530273\n",
      "Epoch 533/2000, Train Loss: 4.486146598335246, Val Loss: 4.582071649886313, Val MAE: 1.4013055562973022\n",
      "Epoch 534/2000, Train Loss: 4.486001575919961, Val Loss: 4.581657475658825, Val MAE: 1.4024112224578857\n",
      "Epoch 535/2000, Train Loss: 4.485400595549923, Val Loss: 4.5820129329249975, Val MAE: 1.402613878250122\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 536/2000, Train Loss: 4.48511963683223, Val Loss: 4.580838996739614, Val MAE: 1.4015933275222778\n",
      "Epoch 537/2000, Train Loss: 4.484737874355776, Val Loss: 4.580758361589341, Val MAE: 1.4011659622192383\n",
      "Epoch 538/2000, Train Loss: 4.484396148942431, Val Loss: 4.5806787780353, Val MAE: 1.4015165567398071\n",
      "Epoch 539/2000, Train Loss: 4.484122391999886, Val Loss: 4.580393025562877, Val MAE: 1.4018710851669312\n",
      "Epoch 540/2000, Train Loss: 4.483860439014179, Val Loss: 4.580151530248778, Val MAE: 1.4009926319122314\n",
      "Epoch 541/2000, Train Loss: 4.48338932262349, Val Loss: 4.579646997508549, Val MAE: 1.4007867574691772\n",
      "Epoch 542/2000, Train Loss: 4.483138692283119, Val Loss: 4.579357139411426, Val MAE: 1.4016366004943848\n",
      "Epoch 543/2000, Train Loss: 4.482625183726763, Val Loss: 4.579143104808671, Val MAE: 1.401611328125\n",
      "Epoch 544/2000, Train Loss: 4.48250548449662, Val Loss: 4.578980307493891, Val MAE: 1.4023030996322632\n",
      "Epoch 545/2000, Train Loss: 4.482220953974583, Val Loss: 4.578112981149128, Val MAE: 1.4021782875061035\n",
      "Epoch 546/2000, Train Loss: 4.481834060065548, Val Loss: 4.576765320840336, Val MAE: 1.3999955654144287\n",
      "Epoch 547/2000, Train Loss: 4.481214181347762, Val Loss: 4.57666699446383, Val MAE: 1.3999723196029663\n",
      "Epoch 548/2000, Train Loss: 4.4810524274452765, Val Loss: 4.576601501731646, Val MAE: 1.400098204612732\n",
      "Epoch 549/2000, Train Loss: 4.480497814055742, Val Loss: 4.575890079140663, Val MAE: 1.3995256423950195\n",
      "Epoch 550/2000, Train Loss: 4.4804085598554435, Val Loss: 4.575286406136694, Val MAE: 1.398841142654419\n",
      "Epoch 551/2000, Train Loss: 4.4800467580636765, Val Loss: 4.575239854909125, Val MAE: 1.3995797634124756\n",
      "Epoch 552/2000, Train Loss: 4.479934500625242, Val Loss: 4.573469218753633, Val MAE: 1.397114872932434\n",
      "Epoch 553/2000, Train Loss: 4.479311550590372, Val Loss: 4.574200972914696, Val MAE: 1.399318814277649\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 554/2000, Train Loss: 4.479567407602919, Val Loss: 4.573682501202538, Val MAE: 1.4011024236679077\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 555/2000, Train Loss: 4.479386442148654, Val Loss: 4.573349508501234, Val MAE: 1.3989472389221191\n",
      "Epoch 556/2000, Train Loss: 4.4782135160614915, Val Loss: 4.572670303639912, Val MAE: 1.3990719318389893\n",
      "Epoch 557/2000, Train Loss: 4.477822476992978, Val Loss: 4.572827538564091, Val MAE: 1.3999518156051636\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 558/2000, Train Loss: 4.477946442509465, Val Loss: 4.573199971800759, Val MAE: 1.4006125926971436\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 559/2000, Train Loss: 4.4772415442377245, Val Loss: 4.573185231004443, Val MAE: 1.4017987251281738\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 560/2000, Train Loss: 4.476945358051371, Val Loss: 4.571940419929368, Val MAE: 1.4005327224731445\n",
      "Epoch 561/2000, Train Loss: 4.476502560418669, Val Loss: 4.571951401375589, Val MAE: 1.4019640684127808\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 562/2000, Train Loss: 4.476721498346201, Val Loss: 4.571904252682414, Val MAE: 1.4035032987594604\n",
      "Epoch 563/2000, Train Loss: 4.475874044300723, Val Loss: 4.569876050665265, Val MAE: 1.4010692834854126\n",
      "Epoch 564/2000, Train Loss: 4.4756419511646754, Val Loss: 4.568931426320757, Val MAE: 1.3990423679351807\n",
      "Epoch 565/2000, Train Loss: 4.475070222133605, Val Loss: 4.568715147319294, Val MAE: 1.3991913795471191\n",
      "Epoch 566/2000, Train Loss: 4.474823970896948, Val Loss: 4.569155387935185, Val MAE: 1.4016942977905273\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 567/2000, Train Loss: 4.4745975111189225, Val Loss: 4.569105261138508, Val MAE: 1.402509331703186\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 568/2000, Train Loss: 4.474612033399117, Val Loss: 4.568761902196067, Val MAE: 1.4006812572479248\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 569/2000, Train Loss: 4.474007524689784, Val Loss: 4.566988725747381, Val MAE: 1.3999956846237183\n",
      "Epoch 570/2000, Train Loss: 4.4743449873323415, Val Loss: 4.567135277958143, Val MAE: 1.3990217447280884\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 571/2000, Train Loss: 4.473005384286671, Val Loss: 4.566459513136318, Val MAE: 1.3989624977111816\n",
      "Epoch 572/2000, Train Loss: 4.472983679886478, Val Loss: 4.5664263147683375, Val MAE: 1.4012436866760254\n",
      "Epoch 573/2000, Train Loss: 4.47276715426918, Val Loss: 4.566511619658697, Val MAE: 1.4026075601577759\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 574/2000, Train Loss: 4.471903675682743, Val Loss: 4.565901789636839, Val MAE: 1.4017739295959473\n",
      "Epoch 575/2000, Train Loss: 4.471686695600003, Val Loss: 4.563654861989475, Val MAE: 1.3993366956710815\n",
      "Epoch 576/2000, Train Loss: 4.471550620592951, Val Loss: 4.563781290536835, Val MAE: 1.399465799331665\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 577/2000, Train Loss: 4.470886295027132, Val Loss: 4.563529005362874, Val MAE: 1.3998064994812012\n",
      "Epoch 578/2000, Train Loss: 4.470542158581936, Val Loss: 4.562834150024822, Val MAE: 1.3985419273376465\n",
      "Epoch 579/2000, Train Loss: 4.4705166088032655, Val Loss: 4.561370415346963, Val MAE: 1.3978723287582397\n",
      "Epoch 580/2000, Train Loss: 4.470515298140272, Val Loss: 4.561751022934914, Val MAE: 1.399731993675232\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 581/2000, Train Loss: 4.469342327629273, Val Loss: 4.560967042332604, Val MAE: 1.3980745077133179\n",
      "Epoch 582/2000, Train Loss: 4.46953943907096, Val Loss: 4.561803477860632, Val MAE: 1.3993797302246094\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 583/2000, Train Loss: 4.468820111681246, Val Loss: 4.560034592236791, Val MAE: 1.3971071243286133\n",
      "Epoch 584/2000, Train Loss: 4.468566491201161, Val Loss: 4.559684723615646, Val MAE: 1.3966331481933594\n",
      "Epoch 585/2000, Train Loss: 4.468238452164801, Val Loss: 4.5601808826128645, Val MAE: 1.3983243703842163\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 586/2000, Train Loss: 4.467942218678247, Val Loss: 4.560100165151415, Val MAE: 1.3985809087753296\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 587/2000, Train Loss: 4.46820116426606, Val Loss: 4.560224434449559, Val MAE: 1.3974554538726807\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 588/2000, Train Loss: 4.467541005592244, Val Loss: 4.559165117286501, Val MAE: 1.3980501890182495\n",
      "Epoch 589/2000, Train Loss: 4.466787142664114, Val Loss: 4.558289122013819, Val MAE: 1.3967686891555786\n",
      "Epoch 590/2000, Train Loss: 4.46674632323012, Val Loss: 4.5589711871885115, Val MAE: 1.3977664709091187\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 591/2000, Train Loss: 4.466381828522874, Val Loss: 4.557028739225297, Val MAE: 1.3950709104537964\n",
      "Epoch 592/2000, Train Loss: 4.465963866052295, Val Loss: 4.556880909062567, Val MAE: 1.396392822265625\n",
      "Epoch 593/2000, Train Loss: 4.466023547400098, Val Loss: 4.555882869731812, Val MAE: 1.3963518142700195\n",
      "Epoch 594/2000, Train Loss: 4.465290239605124, Val Loss: 4.556572801300457, Val MAE: 1.397202968597412\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 595/2000, Train Loss: 4.465042455905883, Val Loss: 4.557113244420006, Val MAE: 1.396660566329956\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 596/2000, Train Loss: 4.464526551019091, Val Loss: 4.557452351564453, Val MAE: 1.3969290256500244\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 597/2000, Train Loss: 4.464292746766323, Val Loss: 4.5563966156471345, Val MAE: 1.3958486318588257\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 598/2000, Train Loss: 4.4637985843116414, Val Loss: 4.555478982272602, Val MAE: 1.3962857723236084\n",
      "Epoch 599/2000, Train Loss: 4.46335538398804, Val Loss: 4.555757633986927, Val MAE: 1.3970414400100708\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 600/2000, Train Loss: 4.463373837458224, Val Loss: 4.555665677502041, Val MAE: 1.3969167470932007\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 601/2000, Train Loss: 4.462821437590244, Val Loss: 4.555750844024477, Val MAE: 1.3967626094818115\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 602/2000, Train Loss: 4.462770325249066, Val Loss: 4.554364442825317, Val MAE: 1.3946985006332397\n",
      "Epoch 603/2000, Train Loss: 4.462432286055414, Val Loss: 4.556066833081699, Val MAE: 1.39824378490448\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 604/2000, Train Loss: 4.461655688988939, Val Loss: 4.555140010657764, Val MAE: 1.3980414867401123\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 605/2000, Train Loss: 4.461545926316494, Val Loss: 4.553895315244084, Val MAE: 1.3976866006851196\n",
      "Epoch 606/2000, Train Loss: 4.460966083383433, Val Loss: 4.553473370415824, Val MAE: 1.3973661661148071\n",
      "Epoch 607/2000, Train Loss: 4.460665559001646, Val Loss: 4.552872496701422, Val MAE: 1.3967245817184448\n",
      "Epoch 608/2000, Train Loss: 4.460436836324492, Val Loss: 4.553723167095866, Val MAE: 1.3980761766433716\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 609/2000, Train Loss: 4.459865415383919, Val Loss: 4.55218193644569, Val MAE: 1.3961290121078491\n",
      "Epoch 610/2000, Train Loss: 4.459661121023244, Val Loss: 4.552288203012376, Val MAE: 1.3973276615142822\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 611/2000, Train Loss: 4.459264660968218, Val Loss: 4.551952547260693, Val MAE: 1.3971211910247803\n",
      "Epoch 612/2000, Train Loss: 4.458820493866867, Val Loss: 4.5510112174919675, Val MAE: 1.3957444429397583\n",
      "Epoch 613/2000, Train Loss: 4.458833636291545, Val Loss: 4.550158544665291, Val MAE: 1.3933534622192383\n",
      "Epoch 614/2000, Train Loss: 4.458306427615577, Val Loss: 4.549806618264744, Val MAE: 1.3938859701156616\n",
      "Epoch 615/2000, Train Loss: 4.45799982707558, Val Loss: 4.5497871687014895, Val MAE: 1.395554542541504\n",
      "Epoch 616/2000, Train Loss: 4.457555000008591, Val Loss: 4.550145782885098, Val MAE: 1.3953263759613037\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 617/2000, Train Loss: 4.457208021716203, Val Loss: 4.549032786772365, Val MAE: 1.3944807052612305\n",
      "Epoch 618/2000, Train Loss: 4.456930832952341, Val Loss: 4.549683704972267, Val MAE: 1.3956384658813477\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 619/2000, Train Loss: 4.457215366670337, Val Loss: 4.548537267815499, Val MAE: 1.396494746208191\n",
      "Epoch 620/2000, Train Loss: 4.455966197773215, Val Loss: 4.547896099232492, Val MAE: 1.3956482410430908\n",
      "Epoch 621/2000, Train Loss: 4.455546940939037, Val Loss: 4.547463269460769, Val MAE: 1.3956865072250366\n",
      "Epoch 622/2000, Train Loss: 4.4552240934192975, Val Loss: 4.546844052416938, Val MAE: 1.394681692123413\n",
      "Epoch 623/2000, Train Loss: 4.454847533325727, Val Loss: 4.5458330157257265, Val MAE: 1.3939473628997803\n",
      "Epoch 624/2000, Train Loss: 4.454981077772043, Val Loss: 4.543426402977535, Val MAE: 1.3920385837554932\n",
      "Epoch 625/2000, Train Loss: 4.454216131256349, Val Loss: 4.544682680141358, Val MAE: 1.3949639797210693\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 626/2000, Train Loss: 4.454296646424976, Val Loss: 4.545728924018996, Val MAE: 1.3952802419662476\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 627/2000, Train Loss: 4.453438670641615, Val Loss: 4.545738285496121, Val MAE: 1.3963377475738525\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 628/2000, Train Loss: 4.4530300365376405, Val Loss: 4.54536210781052, Val MAE: 1.3958137035369873\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 629/2000, Train Loss: 4.452834692461561, Val Loss: 4.545462382691247, Val MAE: 1.3958173990249634\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 630/2000, Train Loss: 4.452823481674808, Val Loss: 4.543920088381994, Val MAE: 1.3945564031600952\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 631/2000, Train Loss: 4.4521002865349, Val Loss: 4.544363880441303, Val MAE: 1.3955206871032715\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 632/2000, Train Loss: 4.4519846017494915, Val Loss: 4.543836877459571, Val MAE: 1.3966768980026245\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 633/2000, Train Loss: 4.451340468255828, Val Loss: 4.543201152057875, Val MAE: 1.3950374126434326\n",
      "Epoch 634/2000, Train Loss: 4.450895540196519, Val Loss: 4.542355665848369, Val MAE: 1.3950918912887573\n",
      "Epoch 635/2000, Train Loss: 4.450586985327283, Val Loss: 4.543045912470136, Val MAE: 1.3967036008834839\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 636/2000, Train Loss: 4.450253000208264, Val Loss: 4.542859921852748, Val MAE: 1.3964961767196655\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 637/2000, Train Loss: 4.449683878440959, Val Loss: 4.541933379002979, Val MAE: 1.3955885171890259\n",
      "Epoch 638/2000, Train Loss: 4.449364777224952, Val Loss: 4.541289975245793, Val MAE: 1.3944469690322876\n",
      "Epoch 639/2000, Train Loss: 4.449276898565625, Val Loss: 4.540614300540516, Val MAE: 1.3952804803848267\n",
      "Epoch 640/2000, Train Loss: 4.44962688169914, Val Loss: 4.539822843812761, Val MAE: 1.3928816318511963\n",
      "Epoch 641/2000, Train Loss: 4.448532377107533, Val Loss: 4.5388518536374685, Val MAE: 1.3943849802017212\n",
      "Epoch 642/2000, Train Loss: 4.447858273503607, Val Loss: 4.537877265186537, Val MAE: 1.3937342166900635\n",
      "Epoch 643/2000, Train Loss: 4.447452587352681, Val Loss: 4.5375503067459375, Val MAE: 1.3934282064437866\n",
      "Epoch 644/2000, Train Loss: 4.448025801865729, Val Loss: 4.535489039761679, Val MAE: 1.3895795345306396\n",
      "Epoch 645/2000, Train Loss: 4.446679378003282, Val Loss: 4.536846220493317, Val MAE: 1.3927325010299683\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 646/2000, Train Loss: 4.446518407110874, Val Loss: 4.537266570897329, Val MAE: 1.3934435844421387\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 647/2000, Train Loss: 4.4459139751045695, Val Loss: 4.537552066502117, Val MAE: 1.3944454193115234\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 648/2000, Train Loss: 4.4457014629732186, Val Loss: 4.535918800603776, Val MAE: 1.3934316635131836\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 649/2000, Train Loss: 4.445763122619956, Val Loss: 4.53476515909036, Val MAE: 1.3907339572906494\n",
      "Epoch 650/2000, Train Loss: 4.444719285172368, Val Loss: 4.535203641369229, Val MAE: 1.3921682834625244\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 651/2000, Train Loss: 4.444587620589433, Val Loss: 4.534249654128438, Val MAE: 1.3915557861328125\n",
      "Epoch 652/2000, Train Loss: 4.444498530661453, Val Loss: 4.533994207069988, Val MAE: 1.3920918703079224\n",
      "Epoch 653/2000, Train Loss: 4.443839181843775, Val Loss: 4.534376764581317, Val MAE: 1.3926039934158325\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 654/2000, Train Loss: 4.443291068396683, Val Loss: 4.5336187063228515, Val MAE: 1.3923532962799072\n",
      "Epoch 655/2000, Train Loss: 4.442931650790708, Val Loss: 4.533792988885017, Val MAE: 1.3925135135650635\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 656/2000, Train Loss: 4.44282569322765, Val Loss: 4.534022425611814, Val MAE: 1.39308500289917\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 657/2000, Train Loss: 4.442615966694604, Val Loss: 4.534964679962113, Val MAE: 1.3945552110671997\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 658/2000, Train Loss: 4.441785597609451, Val Loss: 4.533916917585191, Val MAE: 1.3940316438674927\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 659/2000, Train Loss: 4.441575936273979, Val Loss: 4.532688619125457, Val MAE: 1.3925317525863647\n",
      "Epoch 660/2000, Train Loss: 4.441303459632812, Val Loss: 4.5304116521562845, Val MAE: 1.3905723094940186\n",
      "Epoch 661/2000, Train Loss: 4.441046368340705, Val Loss: 4.530281010837782, Val MAE: 1.391841173171997\n",
      "Epoch 662/2000, Train Loss: 4.440317705553275, Val Loss: 4.529242002538273, Val MAE: 1.3907238245010376\n",
      "Epoch 663/2000, Train Loss: 4.439964356115612, Val Loss: 4.528493585331099, Val MAE: 1.3907278776168823\n",
      "Epoch 664/2000, Train Loss: 4.440080660597569, Val Loss: 4.528681996322813, Val MAE: 1.389626145362854\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 665/2000, Train Loss: 4.4392162117178255, Val Loss: 4.528095810186295, Val MAE: 1.3902050256729126\n",
      "Epoch 666/2000, Train Loss: 4.438689091250341, Val Loss: 4.5273978759845095, Val MAE: 1.3900161981582642\n",
      "Epoch 667/2000, Train Loss: 4.438287874648782, Val Loss: 4.527076907101131, Val MAE: 1.3901147842407227\n",
      "Epoch 668/2000, Train Loss: 4.438412750694131, Val Loss: 4.526233259411085, Val MAE: 1.3891081809997559\n",
      "Epoch 669/2000, Train Loss: 4.437728819195131, Val Loss: 4.527219931994166, Val MAE: 1.3898941278457642\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 670/2000, Train Loss: 4.437267643516888, Val Loss: 4.526795857009434, Val MAE: 1.3900489807128906\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 671/2000, Train Loss: 4.437053539478108, Val Loss: 4.5270329515139265, Val MAE: 1.3917741775512695\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 672/2000, Train Loss: 4.436433136303367, Val Loss: 4.525973813164802, Val MAE: 1.3901535272598267\n",
      "Epoch 673/2000, Train Loss: 4.436252312749704, Val Loss: 4.526592021187146, Val MAE: 1.3906021118164062\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 674/2000, Train Loss: 4.436074215029903, Val Loss: 4.524913374866758, Val MAE: 1.3907015323638916\n",
      "Epoch 675/2000, Train Loss: 4.435096502943269, Val Loss: 4.52393617729346, Val MAE: 1.3889939785003662\n",
      "Epoch 676/2000, Train Loss: 4.4348506480055905, Val Loss: 4.522978009922164, Val MAE: 1.3880383968353271\n",
      "Epoch 677/2000, Train Loss: 4.434450906339344, Val Loss: 4.522675722837448, Val MAE: 1.3879785537719727\n",
      "Epoch 678/2000, Train Loss: 4.434151193731272, Val Loss: 4.523753535179865, Val MAE: 1.3897395133972168\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 679/2000, Train Loss: 4.433661480691414, Val Loss: 4.522744500920886, Val MAE: 1.3892412185668945\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 680/2000, Train Loss: 4.4334450535096686, Val Loss: 4.522968788232122, Val MAE: 1.3898893594741821\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 681/2000, Train Loss: 4.433652002114712, Val Loss: 4.522176027297974, Val MAE: 1.387895941734314\n",
      "Epoch 682/2000, Train Loss: 4.432625946985812, Val Loss: 4.520652420464016, Val MAE: 1.387327790260315\n",
      "Epoch 683/2000, Train Loss: 4.432801527248311, Val Loss: 4.521541296016602, Val MAE: 1.3909811973571777\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 684/2000, Train Loss: 4.431583456954751, Val Loss: 4.521016026536624, Val MAE: 1.3903493881225586\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 685/2000, Train Loss: 4.4313450326229225, Val Loss: 4.520720823889687, Val MAE: 1.390389084815979\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 686/2000, Train Loss: 4.43119430158477, Val Loss: 4.5208150779917124, Val MAE: 1.3895457983016968\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 687/2000, Train Loss: 4.430751500116916, Val Loss: 4.518991720818338, Val MAE: 1.387644648551941\n",
      "Epoch 688/2000, Train Loss: 4.430342132220639, Val Loss: 4.517933820684751, Val MAE: 1.3861597776412964\n",
      "Epoch 689/2000, Train Loss: 4.430022967085442, Val Loss: 4.518853210267567, Val MAE: 1.3891874551773071\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 690/2000, Train Loss: 4.429317529335738, Val Loss: 4.51877419366723, Val MAE: 1.3892625570297241\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 691/2000, Train Loss: 4.4289345511162885, Val Loss: 4.518382311576889, Val MAE: 1.3880722522735596\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 692/2000, Train Loss: 4.428813633905978, Val Loss: 4.517291612568355, Val MAE: 1.3871276378631592\n",
      "Epoch 693/2000, Train Loss: 4.428239578216389, Val Loss: 4.518038819233577, Val MAE: 1.3889360427856445\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 694/2000, Train Loss: 4.4276659022067895, Val Loss: 4.5178350657224655, Val MAE: 1.3887693881988525\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 695/2000, Train Loss: 4.427370587558593, Val Loss: 4.517583334020206, Val MAE: 1.3884824514389038\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 696/2000, Train Loss: 4.4273029127964705, Val Loss: 4.516978420671963, Val MAE: 1.3882421255111694\n",
      "Epoch 697/2000, Train Loss: 4.426887253973503, Val Loss: 4.514775549372037, Val MAE: 1.3853423595428467\n",
      "Epoch 698/2000, Train Loss: 4.4265850542697445, Val Loss: 4.5155277614082605, Val MAE: 1.387754201889038\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 699/2000, Train Loss: 4.4257466147476485, Val Loss: 4.516083244766508, Val MAE: 1.3884694576263428\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 700/2000, Train Loss: 4.425427039251251, Val Loss: 4.515633939277558, Val MAE: 1.38791024684906\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 701/2000, Train Loss: 4.42537840058273, Val Loss: 4.514345684931392, Val MAE: 1.385801911354065\n",
      "Epoch 702/2000, Train Loss: 4.42501936777028, Val Loss: 4.514630730663027, Val MAE: 1.3858590126037598\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 703/2000, Train Loss: 4.4252748099472825, Val Loss: 4.514932212375459, Val MAE: 1.3890271186828613\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 704/2000, Train Loss: 4.424032392514615, Val Loss: 4.513966048047656, Val MAE: 1.387115716934204\n",
      "Epoch 705/2000, Train Loss: 4.4236414336646845, Val Loss: 4.513458817487671, Val MAE: 1.387694239616394\n",
      "Epoch 706/2000, Train Loss: 4.423417941494857, Val Loss: 4.511510415446191, Val MAE: 1.3859578371047974\n",
      "Epoch 707/2000, Train Loss: 4.422836720464057, Val Loss: 4.511113925349145, Val MAE: 1.3841278553009033\n",
      "Epoch 708/2000, Train Loss: 4.423006512843892, Val Loss: 4.511972942522594, Val MAE: 1.3866544961929321\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 709/2000, Train Loss: 4.422211988362166, Val Loss: 4.5101700361285895, Val MAE: 1.383984088897705\n",
      "Epoch 710/2000, Train Loss: 4.422162716254472, Val Loss: 4.511882046148891, Val MAE: 1.3874940872192383\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 711/2000, Train Loss: 4.4213465321159875, Val Loss: 4.511337311494918, Val MAE: 1.387919306755066\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 712/2000, Train Loss: 4.420590836624677, Val Loss: 4.51033017890794, Val MAE: 1.3854831457138062\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 713/2000, Train Loss: 4.420427089721843, Val Loss: 4.509307079371952, Val MAE: 1.3844608068466187\n",
      "Epoch 714/2000, Train Loss: 4.419916514736718, Val Loss: 4.509370289388157, Val MAE: 1.3842517137527466\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 715/2000, Train Loss: 4.419631883861552, Val Loss: 4.508841083163307, Val MAE: 1.384120225906372\n",
      "Epoch 716/2000, Train Loss: 4.419183399338505, Val Loss: 4.5096674632458456, Val MAE: 1.3865718841552734\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 717/2000, Train Loss: 4.418637678386698, Val Loss: 4.509400284716061, Val MAE: 1.3867861032485962\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 718/2000, Train Loss: 4.418429615030979, Val Loss: 4.5090192918266565, Val MAE: 1.387022614479065\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 719/2000, Train Loss: 4.4181776091496365, Val Loss: 4.50798858560267, Val MAE: 1.3845558166503906\n",
      "Epoch 720/2000, Train Loss: 4.41748914002733, Val Loss: 4.507512679412251, Val MAE: 1.3842302560806274\n",
      "Epoch 721/2000, Train Loss: 4.418040595169681, Val Loss: 4.507909050300007, Val MAE: 1.3869116306304932\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 722/2000, Train Loss: 4.41666855952695, Val Loss: 4.507476658338592, Val MAE: 1.3859326839447021\n",
      "Epoch 723/2000, Train Loss: 4.416731955858082, Val Loss: 4.507758106504168, Val MAE: 1.386791467666626\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 724/2000, Train Loss: 4.416029262798402, Val Loss: 4.506164204506647, Val MAE: 1.3844029903411865\n",
      "Epoch 725/2000, Train Loss: 4.415807213923887, Val Loss: 4.506249834384237, Val MAE: 1.3852345943450928\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 726/2000, Train Loss: 4.4155890935227955, Val Loss: 4.5072984879925135, Val MAE: 1.3879808187484741\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 727/2000, Train Loss: 4.41548343254478, Val Loss: 4.504570288317544, Val MAE: 1.3842146396636963\n",
      "Epoch 728/2000, Train Loss: 4.4148507667930135, Val Loss: 4.505264771836145, Val MAE: 1.3844656944274902\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 729/2000, Train Loss: 4.413947739486081, Val Loss: 4.505914417051134, Val MAE: 1.3861347436904907\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 730/2000, Train Loss: 4.414035441728443, Val Loss: 4.505232822327387, Val MAE: 1.3869378566741943\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 731/2000, Train Loss: 4.41352851908584, Val Loss: 4.504021585697219, Val MAE: 1.3846359252929688\n",
      "Epoch 732/2000, Train Loss: 4.412918107439302, Val Loss: 4.50465742746989, Val MAE: 1.3868376016616821\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 733/2000, Train Loss: 4.41292308290906, Val Loss: 4.506486525138219, Val MAE: 1.38833749294281\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 734/2000, Train Loss: 4.412112849647174, Val Loss: 4.505428581010728, Val MAE: 1.3879287242889404\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 735/2000, Train Loss: 4.4115757092074475, Val Loss: 4.50521858958971, Val MAE: 1.3883452415466309\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 736/2000, Train Loss: 4.411449868301923, Val Loss: 4.504929582277934, Val MAE: 1.3884395360946655\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 737/2000, Train Loss: 4.410789721772754, Val Loss: 4.50417620511282, Val MAE: 1.3873498439788818\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 738/2000, Train Loss: 4.4108501119843755, Val Loss: 4.502259256584304, Val MAE: 1.385693073272705\n",
      "Epoch 739/2000, Train Loss: 4.410544413344151, Val Loss: 4.502616658806801, Val MAE: 1.3848824501037598\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 740/2000, Train Loss: 4.409671952193928, Val Loss: 4.502441498495283, Val MAE: 1.3857983350753784\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 741/2000, Train Loss: 4.409319637288357, Val Loss: 4.501514248904728, Val MAE: 1.3859643936157227\n",
      "Epoch 742/2000, Train Loss: 4.409216161707451, Val Loss: 4.50211623169127, Val MAE: 1.3864725828170776\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 743/2000, Train Loss: 4.408607539159044, Val Loss: 4.500668074403491, Val MAE: 1.3853800296783447\n",
      "Epoch 744/2000, Train Loss: 4.408704045950248, Val Loss: 4.500386133080437, Val MAE: 1.3864139318466187\n",
      "Epoch 745/2000, Train Loss: 4.4078363649966565, Val Loss: 4.499455940865335, Val MAE: 1.384189248085022\n",
      "Epoch 746/2000, Train Loss: 4.407446164547918, Val Loss: 4.499075451777095, Val MAE: 1.3834584951400757\n",
      "Epoch 747/2000, Train Loss: 4.407264126529642, Val Loss: 4.50036503019787, Val MAE: 1.3854306936264038\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 748/2000, Train Loss: 4.406934777789077, Val Loss: 4.498237265717416, Val MAE: 1.3834037780761719\n",
      "Epoch 749/2000, Train Loss: 4.40646155014754, Val Loss: 4.499222895928791, Val MAE: 1.3845322132110596\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 750/2000, Train Loss: 4.4060918524182195, Val Loss: 4.497086279449009, Val MAE: 1.3816312551498413\n",
      "Epoch 751/2000, Train Loss: 4.4055999501461, Val Loss: 4.497246852233296, Val MAE: 1.3818418979644775\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 752/2000, Train Loss: 4.405462327655455, Val Loss: 4.49637133592651, Val MAE: 1.3805458545684814\n",
      "Epoch 753/2000, Train Loss: 4.404974025951314, Val Loss: 4.497528791427612, Val MAE: 1.3830300569534302\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 754/2000, Train Loss: 4.404451342114815, Val Loss: 4.497323348408654, Val MAE: 1.3834350109100342\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 755/2000, Train Loss: 4.40428165392326, Val Loss: 4.496657611358733, Val MAE: 1.3814785480499268\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 756/2000, Train Loss: 4.403920309153703, Val Loss: 4.495389790762038, Val MAE: 1.379586935043335\n",
      "Epoch 757/2000, Train Loss: 4.403346482934006, Val Loss: 4.497219785338356, Val MAE: 1.3826451301574707\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 758/2000, Train Loss: 4.402892553774345, Val Loss: 4.496990033558437, Val MAE: 1.3826448917388916\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 759/2000, Train Loss: 4.402540752139871, Val Loss: 4.497626889319647, Val MAE: 1.3837071657180786\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 760/2000, Train Loss: 4.402154806152425, Val Loss: 4.497489828438986, Val MAE: 1.3836923837661743\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 761/2000, Train Loss: 4.401660133622607, Val Loss: 4.496145684094656, Val MAE: 1.3825469017028809\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 762/2000, Train Loss: 4.401295155686284, Val Loss: 4.496295877865383, Val MAE: 1.3823606967926025\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 763/2000, Train Loss: 4.401023152686316, Val Loss: 4.4963106498831795, Val MAE: 1.3818016052246094\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 764/2000, Train Loss: 4.400765166525547, Val Loss: 4.49652712118058, Val MAE: 1.3825109004974365\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 765/2000, Train Loss: 4.400350982318296, Val Loss: 4.496073255936305, Val MAE: 1.3816033601760864\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 766/2000, Train Loss: 4.400300230161754, Val Loss: 4.495178761936369, Val MAE: 1.3824172019958496\n",
      "Epoch 767/2000, Train Loss: 4.399786000596934, Val Loss: 4.492892616561481, Val MAE: 1.3795973062515259\n",
      "Epoch 768/2000, Train Loss: 4.399316130310856, Val Loss: 4.493229678698948, Val MAE: 1.3805445432662964\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 769/2000, Train Loss: 4.39867741428815, Val Loss: 4.492967018768901, Val MAE: 1.3798376321792603\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 770/2000, Train Loss: 4.398464456000852, Val Loss: 4.491742886248089, Val MAE: 1.3779523372650146\n",
      "Epoch 771/2000, Train Loss: 4.398239235456124, Val Loss: 4.49345273347128, Val MAE: 1.380048155784607\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 772/2000, Train Loss: 4.397517273317393, Val Loss: 4.492933185327621, Val MAE: 1.38040292263031\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 773/2000, Train Loss: 4.3970687050602075, Val Loss: 4.492570540734699, Val MAE: 1.3811469078063965\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 774/2000, Train Loss: 4.397105607526232, Val Loss: 4.493571528366634, Val MAE: 1.3823832273483276\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 775/2000, Train Loss: 4.396617444526734, Val Loss: 4.491810747555324, Val MAE: 1.3810205459594727\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 776/2000, Train Loss: 4.395933341724303, Val Loss: 4.492725843474979, Val MAE: 1.382604956626892\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 777/2000, Train Loss: 4.395649195356599, Val Loss: 4.492752405859175, Val MAE: 1.3821001052856445\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 778/2000, Train Loss: 4.395716231885609, Val Loss: 4.4929162136146, Val MAE: 1.383605718612671\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 779/2000, Train Loss: 4.394963798829761, Val Loss: 4.492264357351122, Val MAE: 1.3824820518493652\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 780/2000, Train Loss: 4.394668578462371, Val Loss: 4.491523568119321, Val MAE: 1.3810350894927979\n",
      "Epoch 781/2000, Train Loss: 4.394294246591768, Val Loss: 4.49183941029367, Val MAE: 1.3810594081878662\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 782/2000, Train Loss: 4.393988478279625, Val Loss: 4.491889902523586, Val MAE: 1.3810456991195679\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 783/2000, Train Loss: 4.393675182843656, Val Loss: 4.491173854186421, Val MAE: 1.3792510032653809\n",
      "Epoch 784/2000, Train Loss: 4.3934426269326705, Val Loss: 4.48961861928304, Val MAE: 1.3784281015396118\n",
      "Epoch 785/2000, Train Loss: 4.393199204759368, Val Loss: 4.489200844651177, Val MAE: 1.3778467178344727\n",
      "Epoch 786/2000, Train Loss: 4.392613350226476, Val Loss: 4.4899797808556325, Val MAE: 1.3799717426300049\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 787/2000, Train Loss: 4.392106584185889, Val Loss: 4.489907070284798, Val MAE: 1.3802778720855713\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 788/2000, Train Loss: 4.3920006131998015, Val Loss: 4.490899510326839, Val MAE: 1.3823373317718506\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 789/2000, Train Loss: 4.391707229869935, Val Loss: 4.491031130154927, Val MAE: 1.3825881481170654\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 790/2000, Train Loss: 4.391327611243118, Val Loss: 4.489613778534389, Val MAE: 1.379740595817566\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 791/2000, Train Loss: 4.390862220733479, Val Loss: 4.4896238048871355, Val MAE: 1.3802355527877808\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 792/2000, Train Loss: 4.391028215674229, Val Loss: 4.489190653676078, Val MAE: 1.381235957145691\n",
      "Epoch 793/2000, Train Loss: 4.389921826907202, Val Loss: 4.48823498402323, Val MAE: 1.3790560960769653\n",
      "Epoch 794/2000, Train Loss: 4.390359305824096, Val Loss: 4.486410539774668, Val MAE: 1.3759896755218506\n",
      "Epoch 795/2000, Train Loss: 4.3895026902411, Val Loss: 4.4875539016155965, Val MAE: 1.3775092363357544\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 796/2000, Train Loss: 4.3893033045546295, Val Loss: 4.487915747222447, Val MAE: 1.3797396421432495\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 797/2000, Train Loss: 4.388759874466597, Val Loss: 4.48620794074876, Val MAE: 1.3783174753189087\n",
      "Epoch 798/2000, Train Loss: 4.38835059733557, Val Loss: 4.487178094330288, Val MAE: 1.3800870180130005\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 799/2000, Train Loss: 4.388332768355873, Val Loss: 4.48707594190325, Val MAE: 1.380864143371582\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 800/2000, Train Loss: 4.387527389277082, Val Loss: 4.486598260345913, Val MAE: 1.379342794418335\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 801/2000, Train Loss: 4.387311674634509, Val Loss: 4.485249058121727, Val MAE: 1.3772680759429932\n",
      "Epoch 802/2000, Train Loss: 4.386948602129244, Val Loss: 4.486410487265814, Val MAE: 1.3783197402954102\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 803/2000, Train Loss: 4.386720820981759, Val Loss: 4.487076765015011, Val MAE: 1.3798273801803589\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 804/2000, Train Loss: 4.386175197826314, Val Loss: 4.485627401442755, Val MAE: 1.3792853355407715\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 805/2000, Train Loss: 4.385621658918366, Val Loss: 4.485925120966775, Val MAE: 1.3795653581619263\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 806/2000, Train Loss: 4.385369886342066, Val Loss: 4.485414390053068, Val MAE: 1.3794342279434204\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 807/2000, Train Loss: 4.385099241624888, Val Loss: 4.4849588090465184, Val MAE: 1.3786152601242065\n",
      "Epoch 808/2000, Train Loss: 4.384782929203146, Val Loss: 4.48390048245589, Val MAE: 1.3765356540679932\n",
      "Epoch 809/2000, Train Loss: 4.384379967927294, Val Loss: 4.484216678710211, Val MAE: 1.3777129650115967\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 810/2000, Train Loss: 4.383963427658695, Val Loss: 4.484131522121883, Val MAE: 1.3780666589736938\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 811/2000, Train Loss: 4.383655483377523, Val Loss: 4.483611287105651, Val MAE: 1.3781002759933472\n",
      "Epoch 812/2000, Train Loss: 4.383334678235706, Val Loss: 4.483407677639098, Val MAE: 1.3781827688217163\n",
      "Epoch 813/2000, Train Loss: 4.383391499838944, Val Loss: 4.4845702066307975, Val MAE: 1.3792898654937744\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 814/2000, Train Loss: 4.382892765244594, Val Loss: 4.482155890691848, Val MAE: 1.3752076625823975\n",
      "Epoch 815/2000, Train Loss: 4.382927153768872, Val Loss: 4.480989497332346, Val MAE: 1.373008131980896\n",
      "Epoch 816/2000, Train Loss: 4.381969417387934, Val Loss: 4.481780630492029, Val MAE: 1.3746670484542847\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 817/2000, Train Loss: 4.381991682359424, Val Loss: 4.481105822892416, Val MAE: 1.3751153945922852\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 818/2000, Train Loss: 4.381563934500032, Val Loss: 4.482038925801005, Val MAE: 1.3758957386016846\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 819/2000, Train Loss: 4.381119856565951, Val Loss: 4.481010493778047, Val MAE: 1.3750073909759521\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 820/2000, Train Loss: 4.380976088884369, Val Loss: 4.479350208526566, Val MAE: 1.3729134798049927\n",
      "Epoch 821/2000, Train Loss: 4.380347773472681, Val Loss: 4.480548320781617, Val MAE: 1.375030755996704\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 822/2000, Train Loss: 4.379930345366532, Val Loss: 4.480511160833495, Val MAE: 1.3751920461654663\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 823/2000, Train Loss: 4.380259483173769, Val Loss: 4.481477649438949, Val MAE: 1.3758087158203125\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 824/2000, Train Loss: 4.379702074598051, Val Loss: 4.481361047143028, Val MAE: 1.3769596815109253\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 825/2000, Train Loss: 4.380287403076008, Val Loss: 4.478650935349011, Val MAE: 1.3718106746673584\n",
      "Epoch 826/2000, Train Loss: 4.37906513393085, Val Loss: 4.479917297760646, Val MAE: 1.3755913972854614\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 827/2000, Train Loss: 4.378261741939882, Val Loss: 4.479568472930363, Val MAE: 1.3762602806091309\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 828/2000, Train Loss: 4.378208526018158, Val Loss: 4.479596095425742, Val MAE: 1.3760569095611572\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 829/2000, Train Loss: 4.3777188832894085, Val Loss: 4.480249514182408, Val MAE: 1.3778866529464722\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 830/2000, Train Loss: 4.377182555262588, Val Loss: 4.480247630959465, Val MAE: 1.3788317441940308\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 831/2000, Train Loss: 4.376988504271725, Val Loss: 4.479802841231937, Val MAE: 1.3790309429168701\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 832/2000, Train Loss: 4.37676998245812, Val Loss: 4.479582172064554, Val MAE: 1.377894401550293\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 833/2000, Train Loss: 4.376632774163826, Val Loss: 4.478098911898477, Val MAE: 1.375594139099121\n",
      "Epoch 834/2000, Train Loss: 4.376113294596327, Val Loss: 4.477994721560251, Val MAE: 1.3773138523101807\n",
      "Epoch 835/2000, Train Loss: 4.3758492572058305, Val Loss: 4.479144448325748, Val MAE: 1.3793851137161255\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 836/2000, Train Loss: 4.376073084951406, Val Loss: 4.478618413209915, Val MAE: 1.3771942853927612\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 837/2000, Train Loss: 4.374977099032568, Val Loss: 4.478802680969238, Val MAE: 1.3782744407653809\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 838/2000, Train Loss: 4.375458472535693, Val Loss: 4.479379984594527, Val MAE: 1.3778339624404907\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 839/2000, Train Loss: 4.374494331451907, Val Loss: 4.477563288949785, Val MAE: 1.3761171102523804\n",
      "Epoch 840/2000, Train Loss: 4.3743125363265545, Val Loss: 4.4775625964005785, Val MAE: 1.376861333847046\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 841/2000, Train Loss: 4.373881814307246, Val Loss: 4.476879741464343, Val MAE: 1.3757530450820923\n",
      "Epoch 842/2000, Train Loss: 4.373805067814067, Val Loss: 4.475750561271395, Val MAE: 1.3756234645843506\n",
      "Epoch 843/2000, Train Loss: 4.373407476389376, Val Loss: 4.47505276118006, Val MAE: 1.3741786479949951\n",
      "Epoch 844/2000, Train Loss: 4.372984562738331, Val Loss: 4.475653746298382, Val MAE: 1.3765536546707153\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 845/2000, Train Loss: 4.372925113097592, Val Loss: 4.476693266914005, Val MAE: 1.377022385597229\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 846/2000, Train Loss: 4.372382181898838, Val Loss: 4.476982512644359, Val MAE: 1.3781017065048218\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 847/2000, Train Loss: 4.372038902609981, Val Loss: 4.476163989021664, Val MAE: 1.3779020309448242\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 848/2000, Train Loss: 4.371573734539124, Val Loss: 4.475943307081859, Val MAE: 1.3765231370925903\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 849/2000, Train Loss: 4.371220988818212, Val Loss: 4.47596690200624, Val MAE: 1.3762675523757935\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 850/2000, Train Loss: 4.370953948504164, Val Loss: 4.474970027094796, Val MAE: 1.3751789331436157\n",
      "Epoch 851/2000, Train Loss: 4.371440887451172, Val Loss: 4.476590663194656, Val MAE: 1.3789007663726807\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 852/2000, Train Loss: 4.370408308729729, Val Loss: 4.475404905421393, Val MAE: 1.3769447803497314\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 853/2000, Train Loss: 4.3699200581609405, Val Loss: 4.474972563130515, Val MAE: 1.3764674663543701\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 854/2000, Train Loss: 4.369967773197164, Val Loss: 4.475496621358962, Val MAE: 1.3782472610473633\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 855/2000, Train Loss: 4.369432524765465, Val Loss: 4.4759212618782405, Val MAE: 1.3784286975860596\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 856/2000, Train Loss: 4.369218178153358, Val Loss: 4.475783579406285, Val MAE: 1.3782627582550049\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 857/2000, Train Loss: 4.368764175486628, Val Loss: 4.474282145500183, Val MAE: 1.3761777877807617\n",
      "Epoch 858/2000, Train Loss: 4.368414038947057, Val Loss: 4.47341893968128, Val MAE: 1.3756487369537354\n",
      "Epoch 859/2000, Train Loss: 4.3680755357000844, Val Loss: 4.473252523513067, Val MAE: 1.375815749168396\n",
      "Epoch 860/2000, Train Loss: 4.367900545411711, Val Loss: 4.473357833567119, Val MAE: 1.3753811120986938\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 861/2000, Train Loss: 4.367701400061395, Val Loss: 4.4715984265009565, Val MAE: 1.3733142614364624\n",
      "Epoch 862/2000, Train Loss: 4.367432172432662, Val Loss: 4.472842291707084, Val MAE: 1.3751658201217651\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 863/2000, Train Loss: 4.367075587725192, Val Loss: 4.47080003008956, Val MAE: 1.373067021369934\n",
      "Epoch 864/2000, Train Loss: 4.366528310980298, Val Loss: 4.471147453501111, Val MAE: 1.374024510383606\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 865/2000, Train Loss: 4.3663179017903015, Val Loss: 4.471071192906017, Val MAE: 1.3732271194458008\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 866/2000, Train Loss: 4.366170326122969, Val Loss: 4.471078956410999, Val MAE: 1.3737074136734009\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 867/2000, Train Loss: 4.365958752644925, Val Loss: 4.4688716268255595, Val MAE: 1.37067711353302\n",
      "Epoch 868/2000, Train Loss: 4.365564194185804, Val Loss: 4.468475432623, Val MAE: 1.370383620262146\n",
      "Epoch 869/2000, Train Loss: 4.3650541139352095, Val Loss: 4.46991393112001, Val MAE: 1.3717577457427979\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 870/2000, Train Loss: 4.3647887284889935, Val Loss: 4.4696998830352515, Val MAE: 1.3714454174041748\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 871/2000, Train Loss: 4.364635285998797, Val Loss: 4.469397414298284, Val MAE: 1.3707261085510254\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 872/2000, Train Loss: 4.364473661213075, Val Loss: 4.468469844687553, Val MAE: 1.3684557676315308\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 873/2000, Train Loss: 4.364770416919412, Val Loss: 4.470773593300865, Val MAE: 1.3731416463851929\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 874/2000, Train Loss: 4.363934422306337, Val Loss: 4.471803281988416, Val MAE: 1.3736919164657593\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 875/2000, Train Loss: 4.363175696406223, Val Loss: 4.470502735603423, Val MAE: 1.3723931312561035\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 876/2000, Train Loss: 4.36286025775981, Val Loss: 4.4695891581830525, Val MAE: 1.3709580898284912\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 877/2000, Train Loss: 4.362658341512604, Val Loss: 4.469657729069392, Val MAE: 1.3721719980239868\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 878/2000, Train Loss: 4.362459621544498, Val Loss: 4.47027007880665, Val MAE: 1.3728352785110474\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 879/2000, Train Loss: 4.362162426393729, Val Loss: 4.468708239850544, Val MAE: 1.3705412149429321\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 880/2000, Train Loss: 4.361658832662546, Val Loss: 4.468753972933406, Val MAE: 1.3703069686889648\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 881/2000, Train Loss: 4.361597155757628, Val Loss: 4.468070011053767, Val MAE: 1.3697457313537598\n",
      "Epoch 882/2000, Train Loss: 4.361970231616145, Val Loss: 4.470412313938141, Val MAE: 1.3720436096191406\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 883/2000, Train Loss: 4.3607753946698065, Val Loss: 4.468799325681868, Val MAE: 1.3710479736328125\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 884/2000, Train Loss: 4.360562149385345, Val Loss: 4.467807679658844, Val MAE: 1.3705530166625977\n",
      "Epoch 885/2000, Train Loss: 4.360352832574307, Val Loss: 4.467561193165325, Val MAE: 1.370790958404541\n",
      "Epoch 886/2000, Train Loss: 4.360367551246213, Val Loss: 4.468062451907566, Val MAE: 1.3696393966674805\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 887/2000, Train Loss: 4.359748996294855, Val Loss: 4.467613205313683, Val MAE: 1.3692691326141357\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 888/2000, Train Loss: 4.359579421240267, Val Loss: 4.4688045382499695, Val MAE: 1.37050461769104\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 889/2000, Train Loss: 4.359095691675795, Val Loss: 4.468083277344704, Val MAE: 1.3703851699829102\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 890/2000, Train Loss: 4.359497855240154, Val Loss: 4.469153043769655, Val MAE: 1.3725543022155762\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 891/2000, Train Loss: 4.359006757710638, Val Loss: 4.467898539134434, Val MAE: 1.369354486465454\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 892/2000, Train Loss: 4.358159562537881, Val Loss: 4.467212984959285, Val MAE: 1.3689701557159424\n",
      "Epoch 893/2000, Train Loss: 4.358185917698346, Val Loss: 4.468098319712139, Val MAE: 1.3724881410598755\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 894/2000, Train Loss: 4.357766089746204, Val Loss: 4.4663680756375905, Val MAE: 1.3702648878097534\n",
      "Epoch 895/2000, Train Loss: 4.357139444223358, Val Loss: 4.466909719364984, Val MAE: 1.370443344116211\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 896/2000, Train Loss: 4.357204273622733, Val Loss: 4.467257799137206, Val MAE: 1.3699977397918701\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 897/2000, Train Loss: 4.3568376945106975, Val Loss: 4.467707570110049, Val MAE: 1.3706514835357666\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 898/2000, Train Loss: 4.356544224889924, Val Loss: 4.466471767851284, Val MAE: 1.369631052017212\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 899/2000, Train Loss: 4.356073474117003, Val Loss: 4.466304298667681, Val MAE: 1.370208501815796\n",
      "Epoch 900/2000, Train Loss: 4.356126059795512, Val Loss: 4.466400132292793, Val MAE: 1.3713624477386475\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 901/2000, Train Loss: 4.3555643724692095, Val Loss: 4.465743315361795, Val MAE: 1.3698664903640747\n",
      "Epoch 902/2000, Train Loss: 4.355089535342464, Val Loss: 4.4654378067879446, Val MAE: 1.3698986768722534\n",
      "Epoch 903/2000, Train Loss: 4.354995059743324, Val Loss: 4.465664562724886, Val MAE: 1.3700274229049683\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 904/2000, Train Loss: 4.354748045790931, Val Loss: 4.464513680764607, Val MAE: 1.3686671257019043\n",
      "Epoch 905/2000, Train Loss: 4.354518771491166, Val Loss: 4.464999344377291, Val MAE: 1.3685194253921509\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 906/2000, Train Loss: 4.354505792060422, Val Loss: 4.466082640347027, Val MAE: 1.368661642074585\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 907/2000, Train Loss: 4.353686819127674, Val Loss: 4.465622982808521, Val MAE: 1.3686106204986572\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 908/2000, Train Loss: 4.353540451213438, Val Loss: 4.465655691566921, Val MAE: 1.3684041500091553\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 909/2000, Train Loss: 4.354212434298232, Val Loss: 4.466506177470798, Val MAE: 1.3726975917816162\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 910/2000, Train Loss: 4.352790549996711, Val Loss: 4.465433630205336, Val MAE: 1.3706564903259277\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 911/2000, Train Loss: 4.352555985744773, Val Loss: 4.464846212239492, Val MAE: 1.3708726167678833\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 912/2000, Train Loss: 4.352514986697854, Val Loss: 4.466179771082742, Val MAE: 1.3735400438308716\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 913/2000, Train Loss: 4.351894355651201, Val Loss: 4.4657639265060425, Val MAE: 1.3724831342697144\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 914/2000, Train Loss: 4.35182222156678, Val Loss: 4.464969339824858, Val MAE: 1.37200927734375\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 915/2000, Train Loss: 4.352046531902242, Val Loss: 4.463584727474621, Val MAE: 1.3687303066253662\n",
      "Epoch 916/2000, Train Loss: 4.351462878107066, Val Loss: 4.464557620741072, Val MAE: 1.3714838027954102\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 917/2000, Train Loss: 4.350660001943962, Val Loss: 4.465390890836716, Val MAE: 1.3718245029449463\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 918/2000, Train Loss: 4.350813343441838, Val Loss: 4.46639864501499, Val MAE: 1.3736454248428345\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 919/2000, Train Loss: 4.351191011894165, Val Loss: 4.4661247957320445, Val MAE: 1.3709349632263184\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 920/2000, Train Loss: 4.3499884413650145, Val Loss: 4.467471244789305, Val MAE: 1.3741575479507446\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 921/2000, Train Loss: 4.350080578320787, Val Loss: 4.467896793569837, Val MAE: 1.3747222423553467\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 922/2000, Train Loss: 4.34962901033601, Val Loss: 4.465748202233088, Val MAE: 1.3723127841949463\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 923/2000, Train Loss: 4.34921298781285, Val Loss: 4.4660055722509115, Val MAE: 1.373207449913025\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 924/2000, Train Loss: 4.348798906515495, Val Loss: 4.466109152351107, Val MAE: 1.3737504482269287\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 925/2000, Train Loss: 4.348739882256965, Val Loss: 4.465374157542274, Val MAE: 1.3728506565093994\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 926/2000, Train Loss: 4.348476348549687, Val Loss: 4.463809974136806, Val MAE: 1.3714642524719238\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 927/2000, Train Loss: 4.348048374416361, Val Loss: 4.465198346546718, Val MAE: 1.3738677501678467\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 928/2000, Train Loss: 4.347579647964191, Val Loss: 4.46512831676574, Val MAE: 1.3735617399215698\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 929/2000, Train Loss: 4.347366858423555, Val Loss: 4.4643490598315285, Val MAE: 1.3726643323898315\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 930/2000, Train Loss: 4.347350750787648, Val Loss: 4.464232021854038, Val MAE: 1.3719732761383057\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 931/2000, Train Loss: 4.346907775459596, Val Loss: 4.464180892422085, Val MAE: 1.3726829290390015\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 932/2000, Train Loss: 4.346811669122118, Val Loss: 4.463832564297176, Val MAE: 1.3731657266616821\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 933/2000, Train Loss: 4.346439277198935, Val Loss: 4.463481338251205, Val MAE: 1.3713728189468384\n",
      "Epoch 934/2000, Train Loss: 4.346419216800311, Val Loss: 4.462378152779171, Val MAE: 1.368682861328125\n",
      "Epoch 935/2000, Train Loss: 4.3464007556598245, Val Loss: 4.462253963663464, Val MAE: 1.3714940547943115\n",
      "Epoch 936/2000, Train Loss: 4.345678197794242, Val Loss: 4.461304261570885, Val MAE: 1.3690977096557617\n",
      "Epoch 937/2000, Train Loss: 4.345299059839735, Val Loss: 4.460916384345009, Val MAE: 1.3690346479415894\n",
      "Epoch 938/2000, Train Loss: 4.345452029967117, Val Loss: 4.461197980812618, Val MAE: 1.3679357767105103\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 939/2000, Train Loss: 4.344873289640084, Val Loss: 4.462232216483071, Val MAE: 1.3716832399368286\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 940/2000, Train Loss: 4.3445967298410535, Val Loss: 4.46225475981122, Val MAE: 1.3710711002349854\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 941/2000, Train Loss: 4.34466537969042, Val Loss: 4.462430613381522, Val MAE: 1.3730100393295288\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 942/2000, Train Loss: 4.343770619052345, Val Loss: 4.461893750088556, Val MAE: 1.371716856956482\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 943/2000, Train Loss: 4.343666963219323, Val Loss: 4.4618074255330225, Val MAE: 1.3716621398925781\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 944/2000, Train Loss: 4.343463076982677, Val Loss: 4.460991318736758, Val MAE: 1.3696646690368652\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 945/2000, Train Loss: 4.343512862361468, Val Loss: 4.459939675671714, Val MAE: 1.3675872087478638\n",
      "Epoch 946/2000, Train Loss: 4.3429719065852845, Val Loss: 4.4592121470542185, Val MAE: 1.3676331043243408\n",
      "Epoch 947/2000, Train Loss: 4.342813204824125, Val Loss: 4.4594447158631825, Val MAE: 1.367917776107788\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 948/2000, Train Loss: 4.342431510741205, Val Loss: 4.460389175585338, Val MAE: 1.3701122999191284\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 949/2000, Train Loss: 4.342289870929462, Val Loss: 4.4614986436707635, Val MAE: 1.3718090057373047\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 950/2000, Train Loss: 4.341853233828302, Val Loss: 4.460080957128888, Val MAE: 1.3686201572418213\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 951/2000, Train Loss: 4.3417258684500935, Val Loss: 4.460561003003802, Val MAE: 1.3681377172470093\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 952/2000, Train Loss: 4.341174240725929, Val Loss: 4.462225867169244, Val MAE: 1.3709310293197632\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 953/2000, Train Loss: 4.341212523207268, Val Loss: 4.461364289124806, Val MAE: 1.369023323059082\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 954/2000, Train Loss: 4.340925361771366, Val Loss: 4.462179131451107, Val MAE: 1.3718863725662231\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 955/2000, Train Loss: 4.340514217560797, Val Loss: 4.46078362493288, Val MAE: 1.3695605993270874\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 956/2000, Train Loss: 4.340231220460129, Val Loss: 4.460988724515552, Val MAE: 1.3704785108566284\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 957/2000, Train Loss: 4.3400586955349185, Val Loss: 4.460749709890003, Val MAE: 1.3716877698898315\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 958/2000, Train Loss: 4.339401479061423, Val Loss: 4.460157076517741, Val MAE: 1.3704692125320435\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 959/2000, Train Loss: 4.339571311071156, Val Loss: 4.459289779265721, Val MAE: 1.36893630027771\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 960/2000, Train Loss: 4.339375619274682, Val Loss: 4.4586551913193295, Val MAE: 1.368251085281372\n",
      "Epoch 961/2000, Train Loss: 4.339542514197628, Val Loss: 4.45950796348708, Val MAE: 1.3673855066299438\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 962/2000, Train Loss: 4.33877492718019, Val Loss: 4.461571589821861, Val MAE: 1.3710777759552002\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 963/2000, Train Loss: 4.338315770709163, Val Loss: 4.460313602572396, Val MAE: 1.370770812034607\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 964/2000, Train Loss: 4.338317660160422, Val Loss: 4.459699497336433, Val MAE: 1.3707735538482666\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 965/2000, Train Loss: 4.337855497569884, Val Loss: 4.460373106456938, Val MAE: 1.3705456256866455\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 966/2000, Train Loss: 4.338003010276815, Val Loss: 4.458839168151219, Val MAE: 1.3678703308105469\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 967/2000, Train Loss: 4.337081776866964, Val Loss: 4.459310696238563, Val MAE: 1.369443416595459\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 968/2000, Train Loss: 4.33717236825672, Val Loss: 4.460112834260578, Val MAE: 1.3713632822036743\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 969/2000, Train Loss: 4.337350887843176, Val Loss: 4.459305179970605, Val MAE: 1.3689290285110474\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 970/2000, Train Loss: 4.336620725831142, Val Loss: 4.4601565301418304, Val MAE: 1.3702025413513184\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 971/2000, Train Loss: 4.336798973441444, Val Loss: 4.459288060665131, Val MAE: 1.3710635900497437\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 972/2000, Train Loss: 4.335983681614853, Val Loss: 4.458426063969021, Val MAE: 1.3697458505630493\n",
      "Epoch 973/2000, Train Loss: 4.335739034110675, Val Loss: 4.45760713446708, Val MAE: 1.3682026863098145\n",
      "Epoch 974/2000, Train Loss: 4.335584608543335, Val Loss: 4.458014063891911, Val MAE: 1.3692245483398438\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 975/2000, Train Loss: 4.335247221325422, Val Loss: 4.457059032860256, Val MAE: 1.3672311305999756\n",
      "Epoch 976/2000, Train Loss: 4.3350742905133535, Val Loss: 4.456858034644808, Val MAE: 1.3675329685211182\n",
      "Epoch 977/2000, Train Loss: 4.3347990532023655, Val Loss: 4.458027765864418, Val MAE: 1.368406057357788\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 978/2000, Train Loss: 4.334466248670788, Val Loss: 4.457752850793657, Val MAE: 1.3691222667694092\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 979/2000, Train Loss: 4.334322805379095, Val Loss: 4.45707950421742, Val MAE: 1.3678088188171387\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 980/2000, Train Loss: 4.334044074245177, Val Loss: 4.457908975226538, Val MAE: 1.3689059019088745\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 981/2000, Train Loss: 4.333732482255623, Val Loss: 4.457312010583424, Val MAE: 1.3691458702087402\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 982/2000, Train Loss: 4.333358297079561, Val Loss: 4.457465420166652, Val MAE: 1.3696911334991455\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 983/2000, Train Loss: 4.3336279922771705, Val Loss: 4.456696209453401, Val MAE: 1.3672915697097778\n",
      "Epoch 984/2000, Train Loss: 4.332978280555786, Val Loss: 4.455929624182837, Val MAE: 1.3662755489349365\n",
      "Epoch 985/2000, Train Loss: 4.332636568565471, Val Loss: 4.456020328260603, Val MAE: 1.3670072555541992\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 986/2000, Train Loss: 4.332494096525872, Val Loss: 4.4566103759266085, Val MAE: 1.368598222732544\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 987/2000, Train Loss: 4.332125349594505, Val Loss: 4.455964873234431, Val MAE: 1.3667513132095337\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 988/2000, Train Loss: 4.331821517714227, Val Loss: 4.456209804330554, Val MAE: 1.367156982421875\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 989/2000, Train Loss: 4.331582442045851, Val Loss: 4.456147785697665, Val MAE: 1.367255687713623\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 990/2000, Train Loss: 4.331545932043653, Val Loss: 4.455762431735084, Val MAE: 1.3668183088302612\n",
      "Epoch 991/2000, Train Loss: 4.331197234964243, Val Loss: 4.455004019396646, Val MAE: 1.3650065660476685\n",
      "Epoch 992/2000, Train Loss: 4.3308646570261935, Val Loss: 4.455510279961994, Val MAE: 1.3660368919372559\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 993/2000, Train Loss: 4.330723782966348, Val Loss: 4.455105997267223, Val MAE: 1.3660049438476562\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 994/2000, Train Loss: 4.330838698164707, Val Loss: 4.457020719846089, Val MAE: 1.3702234029769897\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 995/2000, Train Loss: 4.330164593601994, Val Loss: 4.455628274452119, Val MAE: 1.3680471181869507\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 996/2000, Train Loss: 4.330026576729946, Val Loss: 4.456783269132886, Val MAE: 1.369382381439209\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 997/2000, Train Loss: 4.329761433537461, Val Loss: 4.455417212985811, Val MAE: 1.3667951822280884\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 998/2000, Train Loss: 4.32939689344759, Val Loss: 4.454564721811385, Val MAE: 1.3663216829299927\n",
      "Epoch 999/2000, Train Loss: 4.3290645047103435, Val Loss: 4.455179908445904, Val MAE: 1.367652177810669\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 1000/2000, Train Loss: 4.3294881061318735, Val Loss: 4.454956402381261, Val MAE: 1.3657505512237549\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 1001/2000, Train Loss: 4.328522334469548, Val Loss: 4.45551933277221, Val MAE: 1.3665777444839478\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 1002/2000, Train Loss: 4.328624819942198, Val Loss: 4.457057521456764, Val MAE: 1.369205117225647\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 1003/2000, Train Loss: 4.328057990956243, Val Loss: 4.457007230747314, Val MAE: 1.3686672449111938\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 1004/2000, Train Loss: 4.328000161347377, Val Loss: 4.456082836503074, Val MAE: 1.3670574426651\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 1005/2000, Train Loss: 4.327407443171851, Val Loss: 4.455413401126862, Val MAE: 1.3663935661315918\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 1006/2000, Train Loss: 4.327242077835124, Val Loss: 4.455536639406567, Val MAE: 1.3667312860488892\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 1007/2000, Train Loss: 4.327265734327383, Val Loss: 4.454580116839636, Val MAE: 1.3655688762664795\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 1008/2000, Train Loss: 4.326871912217332, Val Loss: 4.454254446994691, Val MAE: 1.3667635917663574\n",
      "Epoch 1009/2000, Train Loss: 4.327340157997193, Val Loss: 4.4525402670814875, Val MAE: 1.3629041910171509\n",
      "Epoch 1010/2000, Train Loss: 4.327161221977214, Val Loss: 4.455022136370341, Val MAE: 1.3668261766433716\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 1011/2000, Train Loss: 4.326054671494635, Val Loss: 4.453557707014538, Val MAE: 1.3661530017852783\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 1012/2000, Train Loss: 4.3259692991067515, Val Loss: 4.452987785850253, Val MAE: 1.3666422367095947\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 1013/2000, Train Loss: 4.325614255490955, Val Loss: 4.453257098084404, Val MAE: 1.3658422231674194\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 1014/2000, Train Loss: 4.3255916717225045, Val Loss: 4.452000172365279, Val MAE: 1.3634456396102905\n",
      "Epoch 1015/2000, Train Loss: 4.326060449150229, Val Loss: 4.451899280150731, Val MAE: 1.3623929023742676\n",
      "Epoch 1016/2000, Train Loss: 4.3248281466098, Val Loss: 4.452770145166488, Val MAE: 1.3652865886688232\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 1017/2000, Train Loss: 4.324917091441218, Val Loss: 4.4523265319211145, Val MAE: 1.3657991886138916\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 1018/2000, Train Loss: 4.324418264803234, Val Loss: 4.451302823566255, Val MAE: 1.364011287689209\n",
      "Epoch 1019/2000, Train Loss: 4.324012724388061, Val Loss: 4.45227501647813, Val MAE: 1.3663208484649658\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 1020/2000, Train Loss: 4.324508078935638, Val Loss: 4.454005753710156, Val MAE: 1.3695266246795654\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 1021/2000, Train Loss: 4.324053533594985, Val Loss: 4.4521869122982025, Val MAE: 1.3653806447982788\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 1022/2000, Train Loss: 4.323877098093723, Val Loss: 4.452354167188917, Val MAE: 1.3670010566711426\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 1023/2000, Train Loss: 4.323367926774012, Val Loss: 4.452110033659708, Val MAE: 1.3648573160171509\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 1024/2000, Train Loss: 4.322900559883015, Val Loss: 4.451225741988137, Val MAE: 1.3642733097076416\n",
      "Epoch 1025/2000, Train Loss: 4.322855146576828, Val Loss: 4.453400258507047, Val MAE: 1.3670129776000977\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 1026/2000, Train Loss: 4.322413489262476, Val Loss: 4.452622027624221, Val MAE: 1.3657121658325195\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 1027/2000, Train Loss: 4.322057429970749, Val Loss: 4.452380525214331, Val MAE: 1.3653920888900757\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 1028/2000, Train Loss: 4.321851841566071, Val Loss: 4.452360353299549, Val MAE: 1.3660163879394531\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 1029/2000, Train Loss: 4.321648722998898, Val Loss: 4.451414126725424, Val MAE: 1.3660911321640015\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 1030/2000, Train Loss: 4.3217088294093156, Val Loss: 4.4499669926507135, Val MAE: 1.3630784749984741\n",
      "Epoch 1031/2000, Train Loss: 4.321178560282526, Val Loss: 4.450082094896407, Val MAE: 1.363303780555725\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 1032/2000, Train Loss: 4.3208657110025035, Val Loss: 4.45105176170667, Val MAE: 1.364693522453308\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 1033/2000, Train Loss: 4.320636558788392, Val Loss: 4.451851885943186, Val MAE: 1.3655561208724976\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 1034/2000, Train Loss: 4.320788127807126, Val Loss: 4.451250774519784, Val MAE: 1.36367666721344\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 1035/2000, Train Loss: 4.320217665015213, Val Loss: 4.4521988062631515, Val MAE: 1.366857647895813\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 1036/2000, Train Loss: 4.3197730245922585, Val Loss: 4.451782164119539, Val MAE: 1.3663337230682373\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 1037/2000, Train Loss: 4.320224067800486, Val Loss: 4.4532788807437536, Val MAE: 1.3685529232025146\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 1038/2000, Train Loss: 4.319612955599624, Val Loss: 4.451215512695766, Val MAE: 1.366202712059021\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 1039/2000, Train Loss: 4.319625805913603, Val Loss: 4.45189860037395, Val MAE: 1.3662657737731934\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 1040/2000, Train Loss: 4.319303779755457, Val Loss: 4.450084250597727, Val MAE: 1.3629564046859741\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 1041/2000, Train Loss: 4.3186745797021775, Val Loss: 4.450490706023716, Val MAE: 1.3643461465835571\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 1042/2000, Train Loss: 4.318865276213945, Val Loss: 4.451022684574127, Val MAE: 1.3640412092208862\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 1043/2000, Train Loss: 4.318188386052927, Val Loss: 4.450615770760036, Val MAE: 1.3634653091430664\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 1044/2000, Train Loss: 4.318117794977756, Val Loss: 4.451018621524175, Val MAE: 1.365052342414856\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 1045/2000, Train Loss: 4.31854671863065, Val Loss: 4.449546534390676, Val MAE: 1.3619871139526367\n",
      "Epoch 1046/2000, Train Loss: 4.317890577597528, Val Loss: 4.450054238239924, Val MAE: 1.362982153892517\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 1047/2000, Train Loss: 4.318248292396279, Val Loss: 4.448666898977189, Val MAE: 1.361916422843933\n",
      "Epoch 1048/2000, Train Loss: 4.317491485350254, Val Loss: 4.449142260210855, Val MAE: 1.3647912740707397\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 1049/2000, Train Loss: 4.3170950431926, Val Loss: 4.4505153724125455, Val MAE: 1.3655288219451904\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 1050/2000, Train Loss: 4.316613212667265, Val Loss: 4.450072433267321, Val MAE: 1.3653453588485718\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 1051/2000, Train Loss: 4.31656407558886, Val Loss: 4.451606086322239, Val MAE: 1.3666951656341553\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 1052/2000, Train Loss: 4.316526695486687, Val Loss: 4.449367819797425, Val MAE: 1.36392080783844\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 1053/2000, Train Loss: 4.316448115791137, Val Loss: 4.449701067947206, Val MAE: 1.3631105422973633\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 1054/2000, Train Loss: 4.315832138061523, Val Loss: 4.451256067979903, Val MAE: 1.3656553030014038\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 1055/2000, Train Loss: 4.315467301386611, Val Loss: 4.451628132945015, Val MAE: 1.366347312927246\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 1056/2000, Train Loss: 4.315694373031085, Val Loss: 4.450538467793238, Val MAE: 1.3638908863067627\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 1057/2000, Train Loss: 4.315133164459515, Val Loss: 4.45061766959372, Val MAE: 1.3645811080932617\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 1058/2000, Train Loss: 4.314791146296279, Val Loss: 4.449685508296604, Val MAE: 1.3637025356292725\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 1059/2000, Train Loss: 4.314765289705496, Val Loss: 4.4488807916641235, Val MAE: 1.3640217781066895\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 1060/2000, Train Loss: 4.314317892447873, Val Loss: 4.449981942063286, Val MAE: 1.366124153137207\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 1061/2000, Train Loss: 4.314373399872562, Val Loss: 4.448948833204451, Val MAE: 1.36477530002594\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 1062/2000, Train Loss: 4.314105599239748, Val Loss: 4.448774960779009, Val MAE: 1.3643858432769775\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 1063/2000, Train Loss: 4.313591310230081, Val Loss: 4.449962059656779, Val MAE: 1.3651819229125977\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 1064/2000, Train Loss: 4.31358890559015, Val Loss: 4.450975721790677, Val MAE: 1.366904616355896\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 1065/2000, Train Loss: 4.313207918453473, Val Loss: 4.450838501964297, Val MAE: 1.3663928508758545\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Epoch 1066/2000, Train Loss: 4.312965595690239, Val Loss: 4.450273892709187, Val MAE: 1.366335153579712\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Epoch 1067/2000, Train Loss: 4.312841382806487, Val Loss: 4.450321299689157, Val MAE: 1.3651947975158691\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n",
      "Test Loss (MSE): 4.172488689422607\n",
      "Test Mean Absolute Error (MAE): 1.3510716992028642\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X input shape:\n",
      "(6, 8)\n",
      "d input shape:\n",
      "(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dean\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:4545: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with RNN_TANH can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(rnnModel(\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (rnn): RNN(8, 64, batch_first=True, bidirectional=True)\n",
       "   (attention): TemporalAttention(\n",
       "     (W): Linear(in_features=128, out_features=64, bias=False)\n",
       "     (v): Linear(in_features=64, out_features=1, bias=False)\n",
       "   )\n",
       "   (linear_relu_stack): Sequential(\n",
       "     (0): Linear(in_features=129, out_features=1, bias=True)\n",
       "   )\n",
       " ),\n",
       " {'train_mse': 4.312302112579346,\n",
       "  'train_mae': 1.3620350755615056,\n",
       "  'val_mse': 4.450321674346924,\n",
       "  'val_mae': 1.3651948767281803,\n",
       "  'test_mse': 4.172488689422607,\n",
       "  'test_mae': 1.3510716992028642,\n",
       "  'spear_corr': 0.5900342625154849})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 444\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "DATA_DIR = os.path.join(os.getcwd(), '..', 'data', 'clean_data')\n",
    "\n",
    "full_rnn_pipeline(DATA_DIR,\n",
    "                season = ['2024-25'], \n",
    "                position = 'GK', \n",
    "                window_size=6,\n",
    "                num_filters=64,\n",
    "                num_dense=64,\n",
    "                bidirectional=True,\n",
    "                temporal_attention=True,\n",
    "                batch_size = 32,\n",
    "                epochs = 2000,  \n",
    "                drop_low_playtime = True,\n",
    "                low_playtime_cutoff = 1e-6,\n",
    "                num_features = NUM_FEATURES_DICT[\"FWD\"][\"large\"],\n",
    "                cat_features = STANDARD_CAT_FEATURES, \n",
    "                stratify_by = 'stdev', \n",
    "                conv_activation = 'relu',\n",
    "                dense_activation = 'relu',\n",
    "                optimizer='adam',\n",
    "                learning_rate= 0.00001,  \n",
    "                loss = 'mse',\n",
    "                metrics = ['mae'],\n",
    "                verbose = True,\n",
    "                regularization = 0.01, \n",
    "                early_stopping = True, \n",
    "                tolerance = 1e-5, # only used if early stopping is turned on, threshold to define low val loss decrease\n",
    "                patience = 20,   # num of iterations before early stopping bc of low val loss decrease\n",
    "                plot = True, \n",
    "                draw_model = False,\n",
    "                standardize= True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from premier_league_models.rnn.experiment import gridsearch_rnn\n",
    "\n",
    "gridsearch_rnn(experiment_name = \"rnn_eval_big\", verbose = True)\n",
    "\n",
    "#PERFORMING VIA COMMAND LINE SCRIPT NOW FOR EFFICIENCY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
